{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41782613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🔧 MULTI-SEED CONFIGURATION\n",
      "======================================================================\n",
      "Seeds for validation: [42, 123, 456, 789, 2025]\n",
      "This ensures results are not dependent on random split\n",
      "Each seed creates different train/test splits for robust assessment\n",
      "======================================================================\n",
      "IOL CALCULATION FOR PRE-DMEK PATIENTS\n",
      "======================================================================\n",
      "\n",
      "📊 WHAT WE'RE DOING:\n",
      "--------------------------------------------------\n",
      "• Loading data from Fuchs' dystrophy patients\n",
      "• These patients had combined cataract + DMEK surgery\n",
      "• Goal: Improve IOL power calculation accuracy\n",
      "• Challenge: Edematous corneas distort standard formulas\n",
      "• NEW: Using 5 different seeds for robust validation\n",
      "\n",
      "✅ Loaded 96 patients from FacoDMEK.xlsx\n",
      "\n",
      "🔍 KEY MEASUREMENTS IN OUR DATA:\n",
      "--------------------------------------------------\n",
      "• Bio-AL: Axial length (mm)\n",
      "• Bio-Ks/Kf: Steep and flat keratometry (D)\n",
      "• CCT: Central corneal thickness (μm) - KEY for edema\n",
      "• IOL Power: Implanted lens power (D)\n",
      "• PostOP Spherical Equivalent: Actual outcome (D)\n"
     ]
    }
   ],
   "source": [
    "# IOL CALCULATION FOR PRE-DMEK PATIENTS - SETUP AND DATA LOADING\n",
    "# ================================================================\n",
    "# PURPOSE: Set up the analysis environment and load patient data\n",
    "# This notebook optimizes IOL power calculations for Fuchs' dystrophy patients\n",
    "# undergoing combined phacoemulsification and DMEK surgery\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants for clinical accuracy thresholds (diopters)\n",
    "THRESHOLDS = [0.25, 0.50, 0.75, 1.00]\n",
    "TEST_SIZE = 0.25      # 25% holdout for final testing\n",
    "N_FOLDS = 5           # 5-fold cross-validation\n",
    "\n",
    "# MULTI-SEED CONFIGURATION FOR ROBUST VALIDATION\n",
    "SEEDS = [42, 123, 456, 789, 2025]  # Multiple seeds for statistical robustness\n",
    "print(\"=\" * 70)\n",
    "print(\"🔧 MULTI-SEED CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Seeds for validation: {SEEDS}\")\n",
    "print(\"This ensures results are not dependent on random split\")\n",
    "print(\"Each seed creates different train/test splits for robust assessment\")\n",
    "\n",
    "# Storage for multi-seed results\n",
    "multi_seed_results = {\n",
    "\n",
    "    'parameter': {},\n",
    "    'multiplicative': {},\n",
    "    'additive': {},\n",
    "    'combined': {},\n",
    "    'fixed_combined': {}\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"IOL CALCULATION FOR PRE-DMEK PATIENTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n📊 WHAT WE'RE DOING:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• Loading data from Fuchs' dystrophy patients\")\n",
    "print(\"• These patients had combined cataract + DMEK surgery\")\n",
    "print(\"• Goal: Improve IOL power calculation accuracy\")\n",
    "print(\"• Challenge: Edematous corneas distort standard formulas\")\n",
    "print(f\"• NEW: Using {len(SEEDS)} different seeds for robust validation\")\n",
    "\n",
    "# Load the patient data\n",
    "df = pd.read_excel('FacoDMEK.xlsx')\n",
    "print(f\"\\n✅ Loaded {len(df)} patients from FacoDMEK.xlsx\")\n",
    "\n",
    "print(\"\\n🔍 KEY MEASUREMENTS IN OUR DATA:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• Bio-AL: Axial length (mm)\")\n",
    "print(\"• Bio-Ks/Kf: Steep and flat keratometry (D)\")\n",
    "print(\"• CCT: Central corneal thickness (μm) - KEY for edema\")\n",
    "print(\"• IOL Power: Implanted lens power (D)\")\n",
    "print(\"• PostOP Spherical Equivalent: Actual outcome (D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9871e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SRK/T2 FORMULA (Sheard et al. 2010)\n",
      "======================================================================\n",
      "• SKR/T2 assumes normal corneal properties\n",
      "• In Fuchs' dystrophy, the cornea is NOT normal:\n",
      "  - Edema changes refractive index (nc)\n",
      "  - Swelling alters keratometric index (k_index)\n",
      "  - Anterior chamber depth is affected\n",
      "\n",
      "Our strategy: Keep the formula structure, optimize the parameters!\n",
      "\n",
      "📐 THE SRK/T2 FORMULA:\n",
      "\n",
      "         1000·nₐ·(nₐ·r - nc₋₁·Lopt) - P·(Lopt - ACDest)·(nₐ·r - nc₋₁·ACDest)\n",
      "REF = ───────────────────────────────────────────────────────────────────────────\n",
      "       nₐ·(V·(nₐ·r - nc₋₁·Lopt) + Lopt·r) - 0.001·P·(Lopt - ACDest)·(V·(nₐ·r - nc₋₁·ACDest) + ACDest·r)\n"
     ]
    }
   ],
   "source": [
    "# STANDARD SRK/T2 FORMULA IMPLEMENTATION\n",
    "# ========================================\n",
    "# PURPOSE: Implement the baseline SRK/T2 formula (Sheard et al. 2010)\n",
    "# This is the current gold standard for IOL calculations\n",
    "# We'll use this as our baseline to compare improvements against\n",
    "\n",
    "def calculate_SRKT2(AL, K_avg, IOL_power, A_constant, nc=1.333, k_index=1.3375):\n",
    "    \"\"\"\n",
    "    SRK/T2 Formula (Sheard et al. 2010)\n",
    "    - Assumes NORMAL corneas (nc=1.333, k_index=1.3375)\n",
    "    - These assumptions fail in edematous Fuchs' corneas\n",
    "    \n",
    "    Parameters:\n",
    "    - AL: Axial length (mm)\n",
    "    - K_avg: Average keratometry (D)\n",
    "    - IOL_power: IOL power (D)\n",
    "    - A_constant: Lens-specific constant\n",
    "    - nc: Corneal refractive index (we'll optimize this!)\n",
    "    - k_index: Keratometric index (we'll optimize this too!)\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    na = 1.336  # Aqueous/vitreous refractive index\n",
    "    V = 12      # Vertex distance (mm)\n",
    "    ncm1 = nc - 1\n",
    "    \n",
    "    # Convert keratometry to radius using keratometric index\n",
    "    # This is where edema causes problems - k_index assumes normal cornea!\n",
    "    r = (k_index - 1) * 1000 / K_avg\n",
    "    \n",
    "    # Axial length correction for long eyes\n",
    "    if AL <= 24.2:\n",
    "        LCOR = AL\n",
    "    else:\n",
    "        LCOR = 3.446 + 1.716 * AL - 0.0237 * AL * AL\n",
    "    \n",
    "    # H2 calculation (corneal height) - Sheard's modification\n",
    "    H2 = -10.326 + 0.32630 * LCOR + 0.13533 * K_avg\n",
    "    \n",
    "    # ACD (Anterior Chamber Depth) estimation\n",
    "    # Edema can affect this too!\n",
    "    ACD_const = 0.62467 * A_constant - 68.747\n",
    "    offset = ACD_const - 3.336\n",
    "    ACD_est = H2 + offset\n",
    "    \n",
    "    # Retinal thickness correction\n",
    "    RETHICK = 0.65696 - 0.02029 * AL\n",
    "    LOPT = AL + RETHICK  # Optical axial length\n",
    "    \n",
    "    # SRK/T2 refraction calculation - the complex optics formula\n",
    "    numerator = (1000 * na * (na * r - ncm1 * LOPT) - \n",
    "                 IOL_power * (LOPT - ACD_est) * (na * r - ncm1 * ACD_est))\n",
    "    \n",
    "    denominator = (na * (V * (na * r - ncm1 * LOPT) + LOPT * r) - \n",
    "                   0.001 * IOL_power * (LOPT - ACD_est) * \n",
    "                   (V * (na * r - ncm1 * ACD_est) + ACD_est * r))\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SRK/T2 FORMULA (Sheard et al. 2010)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"• SKR/T2 assumes normal corneal properties\")\n",
    "print(\"• In Fuchs' dystrophy, the cornea is NOT normal:\")\n",
    "print(\"  - Edema changes refractive index (nc)\")\n",
    "print(\"  - Swelling alters keratometric index (k_index)\")\n",
    "print(\"  - Anterior chamber depth is affected\")\n",
    "print(\"\\nOur strategy: Keep the formula structure, optimize the parameters!\")\n",
    "\n",
    "print(\"\\n📐 THE SRK/T2 FORMULA:\")\n",
    "print()\n",
    "print(\"         1000·nₐ·(nₐ·r - nc₋₁·Lopt) - P·(Lopt - ACDest)·(nₐ·r - nc₋₁·ACDest)\")\n",
    "print(\"REF = ───────────────────────────────────────────────────────────────────────────\")\n",
    "print(\"       nₐ·(V·(nₐ·r - nc₋₁·Lopt) + Lopt·r) - 0.001·P·(Lopt - ACDest)·(V·(nₐ·r - nc₋₁·ACDest) + ACDest·r)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db415cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE SRK/T2 PERFORMANCE\n",
      "======================================================================\n",
      "\n",
      "📋 WHAT WE'RE DOING:\n",
      "--------------------------------------------------\n",
      "1. Calculate average K from steep and flat readings\n",
      "2. Apply standard SRK/T2 to all 96 patients\n",
      "3. Compare predictions to actual outcomes\n",
      "4. Measure error to establish baseline performance\n",
      "\n",
      "📊 BASELINE PERFORMANCE METRICS:\n",
      "======================================================================\n",
      "  Mean Absolute Error (MAE):     1.3591 D\n",
      "  Mean Error (ME):                -0.2915 D\n",
      "  Standard Deviation (SD):        1.7471 D\n",
      "  Median Absolute Error:          1.0311 D\n",
      "\n",
      "💡 INTERPRETATION:\n",
      "--------------------------------------------------\n",
      "• MAE of 1.36 D is POOR (>1.0 D is clinically unacceptable)\n",
      "• Mean error of -0.29 D shows systematic bias\n",
      "  → Formula tends to predict too myopic (negative)\n",
      "\n",
      "📈 CLINICAL ACCURACY:\n",
      "----------------------------------------------------------------------\n",
      "  Within ±0.25 D:  13.5% of eyes\n",
      "  Within ±0.50 D:  26.0% of eyes\n",
      "  Within ±0.75 D:  35.4% of eyes\n",
      "  Within ±1.00 D:  49.0% of eyes\n",
      "\n",
      "🎯 CLINICAL TARGETS:\n",
      "--------------------------------------------------\n",
      "• Modern standard: >70% within ±0.50 D\n",
      "• Acceptable: >90% within ±1.00 D\n",
      "• Our baseline: 26.0% within ±0.50 D\n",
      "\n",
      "⚠️ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\n",
      "This is why we need optimization!\n"
     ]
    }
   ],
   "source": [
    "# BASELINE PERFORMANCE EVALUATION\n",
    "# =================================\n",
    "# PURPOSE: Calculate how well standard SRK/T2 performs on our Fuchs' patients\n",
    "# This establishes the baseline that we need to beat\n",
    "# Spoiler: It won't be great due to the edematous corneas!\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BASELINE SRK/T2 PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n📋 WHAT WE'RE DOING:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. Calculate average K from steep and flat readings\")\n",
    "print(\"2. Apply standard SRK/T2 to all 96 patients\")\n",
    "print(\"3. Compare predictions to actual outcomes\")\n",
    "print(\"4. Measure error to establish baseline performance\")\n",
    "\n",
    "# Calculate average K (needed for SRK/T2)\n",
    "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
    "\n",
    "# Apply standard SRK/T2 formula to all patients\n",
    "df['SRKT2_Prediction'] = df.apply(\n",
    "    lambda row: calculate_SRKT2(\n",
    "        AL=row['Bio-AL'],\n",
    "        K_avg=row['K_avg'],\n",
    "        IOL_power=row['IOL Power'],\n",
    "        A_constant=row['A-Constant']\n",
    "        # Note: Using DEFAULT nc=1.333 and k_index=1.3375\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Calculate prediction errors\n",
    "df['Prediction_Error'] = df['PostOP Spherical Equivalent'] - df['SRKT2_Prediction']\n",
    "df['Absolute_Error'] = abs(df['Prediction_Error'])\n",
    "\n",
    "# Calculate key metrics\n",
    "mae = df['Absolute_Error'].mean()\n",
    "me = df['Prediction_Error'].mean()\n",
    "std = df['Prediction_Error'].std()\n",
    "median_ae = df['Absolute_Error'].median()\n",
    "\n",
    "print(\"\\n📊 BASELINE PERFORMANCE METRICS:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Mean Absolute Error (MAE):     {mae:.4f} D\")\n",
    "print(f\"  Mean Error (ME):                {me:+.4f} D\")\n",
    "print(f\"  Standard Deviation (SD):        {std:.4f} D\")\n",
    "print(f\"  Median Absolute Error:          {median_ae:.4f} D\")\n",
    "\n",
    "print(\"\\n💡 INTERPRETATION:\")\n",
    "print(\"-\" * 50)\n",
    "if mae > 1.0:\n",
    "    print(f\"• MAE of {mae:.2f} D is POOR (>1.0 D is clinically unacceptable)\")\n",
    "else:\n",
    "    print(f\"• MAE of {mae:.2f} D is moderate\")\n",
    "    \n",
    "if abs(me) > 0.25:\n",
    "    print(f\"• Mean error of {me:+.2f} D shows systematic bias\")\n",
    "    if me < 0:\n",
    "        print(\"  → Formula tends to predict too myopic (negative)\")\n",
    "    else:\n",
    "        print(\"  → Formula tends to predict too hyperopic (positive)\")\n",
    "\n",
    "# Calculate clinical accuracy rates\n",
    "within_025 = (df['Absolute_Error'] <= 0.25).sum() / len(df) * 100\n",
    "within_050 = (df['Absolute_Error'] <= 0.50).sum() / len(df) * 100\n",
    "within_075 = (df['Absolute_Error'] <= 0.75).sum() / len(df) * 100\n",
    "within_100 = (df['Absolute_Error'] <= 1.00).sum() / len(df) * 100\n",
    "\n",
    "print(\"\\n📈 CLINICAL ACCURACY:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Within ±0.25 D:  {within_025:.1f}% of eyes\")\n",
    "print(f\"  Within ±0.50 D:  {within_050:.1f}% of eyes\")\n",
    "print(f\"  Within ±0.75 D:  {within_075:.1f}% of eyes\")\n",
    "print(f\"  Within ±1.00 D:  {within_100:.1f}% of eyes\")\n",
    "\n",
    "print(\"\\n🎯 CLINICAL TARGETS:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• Modern standard: >70% within ±0.50 D\")\n",
    "print(\"• Acceptable: >90% within ±1.00 D\")\n",
    "print(f\"• Our baseline: {within_050:.1f}% within ±0.50 D\")\n",
    "print(\"\\n⚠️ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\")\n",
    "print(\"This is why we need optimization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ridge_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RIDGE REGRESSION FEATURE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "🔍 WHY START WITH RIDGE?\n",
      "--------------------------------------------------\n",
      "• Ridge regression identifies important features\n",
      "• Helps us understand what drives prediction errors\n",
      "• Guides our formula optimization strategy\n",
      "• If CCT features are important, our hypothesis is correct!\n",
      "\n",
      "📊 CREATING FEATURES:\n",
      "--------------------------------------------------\n",
      "Created 12 features including CCT interactions\n",
      "\n",
      "🏆 TOP 10 MOST IMPORTANT FEATURES:\n",
      "--------------------------------------------------\n",
      "  CCT_ratio_AL         Coef=+1.3677\n",
      "  CCT_x_AL             Coef=-0.8898\n",
      "  CCT_squared          Coef=-0.7666\n",
      "  Bio-AL               Coef=+0.4903\n",
      "  Bio-Ks               Coef=-0.3178\n",
      "  CCT_x_K              Coef=+0.3101\n",
      "  K_avg                Coef=-0.1584\n",
      "  IOL Power            Coef=-0.1189\n",
      "  CCT_norm             Coef=+0.0321\n",
      "  CCT                  Coef=+0.0321\n",
      "\n",
      "💡 KEY FINDINGS:\n",
      "--------------------------------------------------\n",
      "• CCT-related features account for 75.5% of total importance\n",
      "• Top feature: CCT_ratio_AL\n",
      "• CCT/AL ratio is among top 3 features!\n",
      "• This validates that CCT relative to eye size matters\n",
      "\n",
      "✅ HYPOTHESIS CONFIRMED:\n",
      "CCT features dominate prediction - our CCT-dependent approach is justified!\n",
      "\n",
      "🎯 OPTIMIZATION STRATEGY BASED ON RIDGE:\n",
      "--------------------------------------------------\n",
      "1. Make optical parameters CCT-dependent (nc, k_index)\n",
      "2. Consider CCT/AL ratio in corrections\n",
      "3. Account for CCT interactions with other measurements\n"
     ]
    }
   ],
   "source": [
    "# RIDGE REGRESSION ANALYSIS - IDENTIFYING IMPORTANT FEATURES\n",
    "# ===========================================================\n",
    "# PURPOSE: Use machine learning to identify which features matter most\n",
    "# This will guide our optimization strategy\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RIDGE REGRESSION FEATURE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🔍 WHY START WITH RIDGE?\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• Ridge regression identifies important features\")\n",
    "print(\"• Helps us understand what drives prediction errors\")\n",
    "print(\"• Guides our formula optimization strategy\")\n",
    "print(\"• If CCT features are important, our hypothesis is correct!\")\n",
    "\n",
    "# Create feature matrix with interactions\n",
    "print(\"\\n📊 CREATING FEATURES:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "features = []\n",
    "feature_names = []\n",
    "\n",
    "# Basic features\n",
    "for col in ['Bio-AL', 'Bio-Ks', 'Bio-Kf', 'IOL Power', 'CCT']:\n",
    "    features.append(df[col].values)\n",
    "    feature_names.append(col)\n",
    "\n",
    "# Add K_avg\n",
    "features.append(df['K_avg'].values)\n",
    "feature_names.append('K_avg')\n",
    "\n",
    "# CCT-derived features\n",
    "df['CCT_squared'] = df['CCT'] ** 2\n",
    "df['CCT_deviation'] = df['CCT'] - 550\n",
    "df['CCT_norm'] = (df['CCT'] - 600) / 100\n",
    "\n",
    "features.extend([\n",
    "    df['CCT_squared'].values,\n",
    "    df['CCT_deviation'].values,\n",
    "    df['CCT_norm'].values\n",
    "])\n",
    "feature_names.extend(['CCT_squared', 'CCT_deviation', 'CCT_norm'])\n",
    "\n",
    "# Interaction terms\n",
    "df['CCT_x_AL'] = df['CCT'] * df['Bio-AL']\n",
    "df['CCT_x_K'] = df['CCT'] * df['K_avg']\n",
    "df['CCT_ratio_AL'] = df['CCT'] / df['Bio-AL']\n",
    "\n",
    "features.extend([\n",
    "    df['CCT_x_AL'].values,\n",
    "    df['CCT_x_K'].values,\n",
    "    df['CCT_ratio_AL'].values\n",
    "])\n",
    "feature_names.extend(['CCT_x_AL', 'CCT_x_K', 'CCT_ratio_AL'])\n",
    "\n",
    "X = np.column_stack(features)\n",
    "y = df['PostOP Spherical Equivalent'].values\n",
    "\n",
    "print(f\"Created {len(feature_names)} features including CCT interactions\")\n",
    "\n",
    "# Standardize and train Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train Ridge to get feature importance\n",
    "ridge_analysis = Ridge(alpha=1.0)\n",
    "ridge_analysis.fit(X_scaled, y)\n",
    "\n",
    "# Get feature importance from coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': ridge_analysis.coef_,\n",
    "    'Abs_Coefficient': np.abs(ridge_analysis.coef_)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\n🏆 TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "print(\"-\" * 50)\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"  {row['Feature']:20} Coef={row['Coefficient']:+.4f}\")\n",
    "\n",
    "# Analyze CCT importance\n",
    "cct_features = feature_importance[feature_importance['Feature'].str.contains('CCT')]\n",
    "cct_importance = cct_features['Abs_Coefficient'].sum()\n",
    "total_importance = feature_importance['Abs_Coefficient'].sum()\n",
    "cct_percentage = (cct_importance / total_importance) * 100\n",
    "\n",
    "print(\"\\n💡 KEY FINDINGS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• CCT-related features account for {cct_percentage:.1f}% of total importance\")\n",
    "print(f\"• Top feature: {feature_importance.iloc[0]['Feature']}\")\n",
    "\n",
    "if 'CCT_ratio_AL' in feature_importance.head(3)['Feature'].values:\n",
    "    print(\"• CCT/AL ratio is among top 3 features!\")\n",
    "    print(\"• This validates that CCT relative to eye size matters\")\n",
    "\n",
    "if cct_percentage > 50:\n",
    "    print(\"\\n✅ HYPOTHESIS CONFIRMED:\")\n",
    "    print(\"CCT features dominate prediction - our CCT-dependent approach is justified!\")\n",
    "\n",
    "print(\"\\n🎯 OPTIMIZATION STRATEGY BASED ON RIDGE:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. Make optical parameters CCT-dependent (nc, k_index)\")\n",
    "print(\"2. Consider CCT/AL ratio in corrections\")\n",
    "print(\"3. Account for CCT interactions with other measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rt23gheoiv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "🎯 MULTI-SEED NESTED CROSS-VALIDATION:\n",
      "--------------------------------------------------\n",
      "• Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "• Each seed: 75% train, 25% test\n",
      "• Inner: 5-fold CV on training set\n",
      "• Results averaged across seeds for robustness\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 1.2383 ± 0.3650 D\n",
      "  Train MAE: 1.1642, Test MAE: 1.4354\n",
      "  Test: Baseline=1.4849, Optimized=1.4354\n",
      "  Improvement: 3.3%\n",
      "  ⚠️ Overfitting detected: Test 23.3% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 1.3361 ± 0.2740 D\n",
      "  Train MAE: 1.2528, Test MAE: 1.0289\n",
      "  Test: Baseline=1.2755, Optimized=1.0289\n",
      "  Improvement: 19.3%\n",
      "  ✅ Good generalization: Test only -17.9% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 1.1921 ± 0.1903 D\n"
     ]
    }
   ],
   "source": [
    "# PARAMETER OPTIMIZATION WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
    "# =============================================\n",
    "# PURPOSE: Optimize SRK/T2 parameters with nested CV for robust validation\n",
    "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🎯 MULTI-SEED NESTED CROSS-VALIDATION:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"• Each seed: 75% train, 25% test\")\n",
    "print(\"• Inner: 5-fold CV on training set\")\n",
    "print(\"• Results averaged across seeds for robustness\")\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "def calculate_mae_param(params, df_data):\n",
    "    \"\"\"Calculate MAE for parameter optimization\"\"\"\n",
    "    nc_base, nc_cct_coef, k_index_base, k_index_cct_coef, acd_offset_base, acd_offset_cct_coef = params\n",
    "    \n",
    "    predictions = []\n",
    "    for _, row in df_data.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        nc = nc_base + nc_cct_coef * cct_norm\n",
    "        k_index = k_index_base + k_index_cct_coef * cct_norm\n",
    "        acd_offset = acd_offset_base + acd_offset_cct_coef * cct_norm\n",
    "        \n",
    "        pred = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc,\n",
    "            k_index=k_index\n",
    "        )\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    mae = mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "    return mae\n",
    "\n",
    "bounds_param = [\n",
    "    (1.20, 1.50),    # nc_base\n",
    "    (-0.20, 0.20),   # nc_cct_coef  \n",
    "    (1.20, 1.60),    # k_index_base\n",
    "    (-0.30, 0.30),   # k_index_cct_coef\n",
    "    (-3.0, 3.0),     # acd_offset_base\n",
    "    (-3.0, 3.0),     # acd_offset_cct_coef\n",
    "]\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_param = []\n",
    "seed_test_maes_param = []\n",
    "seed_train_maes_param = []  # NEW: Track training MAEs\n",
    "seed_baseline_maes_param = []\n",
    "seed_improvements_param = []\n",
    "seed_overfit_ratios_param = []  # NEW: Track overfitting\n",
    "\n",
    "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT with current seed\n",
    "    X_train_param, X_test_param = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_param['K_avg'] = (X_train_param['Bio-Ks'] + X_train_param['Bio-Kf']) / 2\n",
    "    X_test_param['K_avg'] = (X_test_param['Bio-Ks'] + X_test_param['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"📊 Split: {len(X_train_param)} train, {len(X_test_param)} test\")\n",
    "    \n",
    "    # INNER K-FOLD CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    fold_params = []\n",
    "    fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_param), 1):\n",
    "        fold_train = X_train_param.iloc[train_idx]\n",
    "        fold_val = X_train_param.iloc[val_idx]\n",
    "        \n",
    "        # Optimize on fold\n",
    "        result_fold = differential_evolution(\n",
    "            lambda p: calculate_mae_param(p, fold_train),\n",
    "            bounds_param,\n",
    "            maxiter=30,\n",
    "            seed=SEED + fold_num,\n",
    "            workers=1,\n",
    "            updating='deferred',\n",
    "            disp=False\n",
    "        )\n",
    "        \n",
    "        fold_params.append(result_fold.x)\n",
    "        val_mae = calculate_mae_param(result_fold.x, fold_val)\n",
    "        fold_maes.append(val_mae)\n",
    "    \n",
    "    # Average parameters from folds\n",
    "    avg_params = np.mean(fold_params, axis=0)\n",
    "    avg_cv_mae = np.mean(fold_maes)\n",
    "    std_cv_mae = np.std(fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_cv_mae:.4f} ± {std_cv_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    result_final = differential_evolution(\n",
    "        lambda p: calculate_mae_param(p, X_train_param),\n",
    "        bounds_param,\n",
    "        maxiter=50,\n",
    "        seed=SEED,\n",
    "        workers=1,\n",
    "        updating='deferred',\n",
    "        disp=False\n",
    "    )\n",
    "    \n",
    "    final_params = result_final.x\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    mae_train = calculate_mae_param(final_params, X_train_param)\n",
    "    \n",
    "    # TEST ON HOLDOUT\n",
    "    # Calculate baseline\n",
    "    X_test_param['SRKT2_Baseline'] = X_test_param.apply(\n",
    "        lambda row: calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant']\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    # Apply optimized parameters\n",
    "    predictions_test = []\n",
    "    for _, row in X_test_param.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        nc = final_params[0] + final_params[1] * cct_norm\n",
    "        k_index = final_params[2] + final_params[3] * cct_norm\n",
    "        acd_offset = final_params[4] + final_params[5] * cct_norm\n",
    "        \n",
    "        pred = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc,\n",
    "            k_index=k_index\n",
    "        )\n",
    "        predictions_test.append(pred)\n",
    "    \n",
    "    mae_baseline = np.abs(X_test_param['SRKT2_Baseline'] - X_test_param['PostOP Spherical Equivalent']).mean()\n",
    "    mae_optimized = mean_absolute_error(X_test_param['PostOP Spherical Equivalent'], predictions_test)\n",
    "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
    "    \n",
    "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
    "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
    "    if overfit_ratio > 20:\n",
    "        print(f\"  ⚠️ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    elif overfit_ratio > 10:\n",
    "        print(f\"  ⚠️ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    else:\n",
    "        print(f\"  ✅ Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_param.append(final_params)\n",
    "    seed_test_maes_param.append(mae_optimized)\n",
    "    seed_train_maes_param.append(mae_train)\n",
    "    seed_baseline_maes_param.append(mae_baseline)\n",
    "    seed_improvements_param.append(improvement)\n",
    "    seed_overfit_ratios_param.append(overfit_ratio)\n",
    "\n",
    "# MULTI-SEED SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARAMETER OPTIMIZATION - MULTI-SEED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 TEST PERFORMANCE ACROSS SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_param[i]:.4f} D, Improvement={seed_improvements_param[i]:.1f}%\")\n",
    "\n",
    "print(\"\\n📈 STATISTICAL SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_param):.4f} ± {np.std(seed_baseline_maes_param):.4f} D\")\n",
    "print(f\"  Train MAE:         {np.mean(seed_train_maes_param):.4f} ± {np.std(seed_train_maes_param):.4f} D\")\n",
    "print(f\"  Test MAE:          {np.mean(seed_test_maes_param):.4f} ± {np.std(seed_test_maes_param):.4f} D\")\n",
    "print(f\"  Mean Improvement:  {np.mean(seed_improvements_param):.1f} ± {np.std(seed_improvements_param):.1f}%\")\n",
    "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_param)]} (MAE={min(seed_test_maes_param):.4f})\")\n",
    "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_param)]} (MAE={max(seed_test_maes_param):.4f})\")\n",
    "\n",
    "# OVERFITTING ANALYSIS\n",
    "print(\"\\n🔍 OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_param):.1f}%\")\n",
    "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_param):.1f}% worse than Train MAE on average)\")\n",
    "\n",
    "if np.mean(seed_overfit_ratios_param) < 10:\n",
    "    print(\"  ✅ Excellent generalization - minimal overfitting\")\n",
    "elif np.mean(seed_overfit_ratios_param) < 20:\n",
    "    print(\"  ✅ Good generalization - acceptable overfitting\")\n",
    "else:\n",
    "    print(\"  ⚠️ Significant overfitting - consider regularization\")\n",
    "\n",
    "# Average parameters across seeds\n",
    "avg_params_all_seeds = np.mean(seed_results_param, axis=0)\n",
    "std_params_all_seeds = np.std(seed_results_param, axis=0)\n",
    "\n",
    "print(\"\\n✅ CONSENSUS PARAMETERS (averaged across seeds):\")\n",
    "print(\"-\" * 50)\n",
    "param_names = ['nc_base', 'nc_cct_coef', 'k_index_base', 'k_index_cct_coef', 'acd_offset_base', 'acd_offset_cct_coef']\n",
    "for i, name in enumerate(param_names):\n",
    "    print(f\"  {name:20} = {avg_params_all_seeds[i]:+.4f} ± {std_params_all_seeds[i]:.4f}\")\n",
    "\n",
    "# Store in global results dictionary\n",
    "multi_seed_results['parameter'] = {\n",
    "    'test_maes': seed_test_maes_param,\n",
    "    'train_maes': seed_train_maes_param,\n",
    "    'baseline_maes': seed_baseline_maes_param,\n",
    "    'improvements': seed_improvements_param,\n",
    "    'overfit_ratios': seed_overfit_ratios_param,\n",
    "    'mean_mae': np.mean(seed_test_maes_param),\n",
    "    'std_mae': np.std(seed_test_maes_param),\n",
    "    'mean_improvement': np.mean(seed_improvements_param)\n",
    "}\n",
    "\n",
    "print(\"\\n💡 ROBUSTNESS ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "mae_cv = np.std(seed_test_maes_param) / np.mean(seed_test_maes_param) * 100\n",
    "if mae_cv < 5:\n",
    "    print(f\"✅ Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
    "elif mae_cv < 10:\n",
    "    print(f\"✅ Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
    "else:\n",
    "    print(f\"⚠️ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
    "\n",
    "print(f\"\\n📊 Range of results: {min(seed_test_maes_param):.4f} - {max(seed_test_maes_param):.4f} D\")\n",
    "print(f\"   This {max(seed_test_maes_param)-min(seed_test_maes_param):.4f} D range shows the impact of data split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829090ggs0r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED\n",
    "# ====================================\n",
    "# PURPOSE: Multiplicative correction with nested CV for robust validation\n",
    "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🎯 MULTI-SEED NESTED CV STRATEGY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"• Each seed: 75/25 train/test split\")\n",
    "print(\"• Inner: 5-fold CV on training\")\n",
    "print(\"• Find stable multiplicative factors across seeds\")\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "def multiplicative_objective(params, df_data):\n",
    "    \"\"\"Objective function for multiplicative correction\"\"\"\n",
    "    m0, m1, m2 = params\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for _, row in df_data.iterrows():\n",
    "        base_pred = row['SRKT2_Prediction']\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        \n",
    "        correction_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "        corrected_pred = base_pred * correction_factor\n",
    "        \n",
    "        predictions.append(corrected_pred)\n",
    "        actuals.append(row['PostOP Spherical Equivalent'])\n",
    "    \n",
    "    return mean_absolute_error(actuals, predictions)\n",
    "\n",
    "x0_mult = [0, 0, 0]\n",
    "bounds_mult = [(-0.5, 0.5), (-0.5, 0.5), (-0.5, 0.5)]\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_mult = []\n",
    "seed_test_maes_mult = []\n",
    "seed_train_maes_mult = []  # NEW: Track training MAEs\n",
    "seed_baseline_maes_mult = []\n",
    "seed_improvements_mult = []\n",
    "seed_overfit_ratios_mult = []  # NEW: Track overfitting\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT with current seed\n",
    "    X_train_mult, X_test_mult = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_mult['K_avg'] = (X_train_mult['Bio-Ks'] + X_train_mult['Bio-Kf']) / 2\n",
    "    X_test_mult['K_avg'] = (X_test_mult['Bio-Ks'] + X_test_mult['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"📊 Split: {len(X_train_mult)} train, {len(X_test_mult)} test\")\n",
    "    \n",
    "    # Calculate baseline SRK/T2 for all data\n",
    "    for dataset in [X_train_mult, X_test_mult]:\n",
    "        dataset['SRKT2_Prediction'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    # INNER K-FOLD CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    fold_params = []\n",
    "    fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_mult), 1):\n",
    "        fold_train = X_train_mult.iloc[train_idx]\n",
    "        fold_val = X_train_mult.iloc[val_idx]\n",
    "        \n",
    "        # Optimize on fold training\n",
    "        result_fold = minimize(\n",
    "            lambda p: multiplicative_objective(p, fold_train),\n",
    "            x0_mult,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds_mult\n",
    "        )\n",
    "        \n",
    "        fold_params.append(result_fold.x)\n",
    "        val_mae = multiplicative_objective(result_fold.x, fold_val)\n",
    "        fold_maes.append(val_mae)\n",
    "    \n",
    "    # Average across folds\n",
    "    avg_params = np.mean(fold_params, axis=0)\n",
    "    avg_cv_mae = np.mean(fold_maes)\n",
    "    std_cv_mae = np.std(fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_cv_mae:.4f} ± {std_cv_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    result_mult = minimize(\n",
    "        lambda p: multiplicative_objective(p, X_train_mult),\n",
    "        x0_mult,\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds_mult\n",
    "    )\n",
    "    m0_opt, m1_opt, m2_opt = result_mult.x\n",
    "    \n",
    "    print(f\"  Final params: m₀={m0_opt:.4f}, m₁={m1_opt:.4f}, m₂={m2_opt:.4f}\")\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    mae_train = multiplicative_objective([m0_opt, m1_opt, m2_opt], X_train_mult)\n",
    "    \n",
    "    # TEST ON HOLDOUT\n",
    "    predictions_mult_test = []\n",
    "    for _, row in X_test_mult.iterrows():\n",
    "        base_pred = row['SRKT2_Prediction']\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        \n",
    "        correction_factor = 1 + m0_opt + m1_opt * cct_norm + m2_opt * cct_ratio\n",
    "        corrected_pred = base_pred * correction_factor\n",
    "        predictions_mult_test.append(corrected_pred)\n",
    "    \n",
    "    mae_baseline = np.abs(X_test_mult['SRKT2_Prediction'] - X_test_mult['PostOP Spherical Equivalent']).mean()\n",
    "    mae_optimized = mean_absolute_error(X_test_mult['PostOP Spherical Equivalent'], predictions_mult_test)\n",
    "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
    "    \n",
    "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
    "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
    "    if overfit_ratio > 20:\n",
    "        print(f\"  ⚠️ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    elif overfit_ratio > 10:\n",
    "        print(f\"  ⚠️ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    else:\n",
    "        print(f\"  ✅ Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_mult.append([m0_opt, m1_opt, m2_opt])\n",
    "    seed_test_maes_mult.append(mae_optimized)\n",
    "    seed_train_maes_mult.append(mae_train)\n",
    "    seed_baseline_maes_mult.append(mae_baseline)\n",
    "    seed_improvements_mult.append(improvement)\n",
    "    seed_overfit_ratios_mult.append(overfit_ratio)\n",
    "\n",
    "# MULTI-SEED SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTIPLICATIVE CORRECTION - MULTI-SEED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 TEST PERFORMANCE ACROSS SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_mult[i]:.4f} D, Improvement={seed_improvements_mult[i]:.1f}%\")\n",
    "\n",
    "print(\"\\n📈 STATISTICAL SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_mult):.4f} ± {np.std(seed_baseline_maes_mult):.4f} D\")\n",
    "print(f\"  Train MAE:         {np.mean(seed_train_maes_mult):.4f} ± {np.std(seed_train_maes_mult):.4f} D\")\n",
    "print(f\"  Test MAE:          {np.mean(seed_test_maes_mult):.4f} ± {np.std(seed_test_maes_mult):.4f} D\")\n",
    "print(f\"  Mean Improvement:  {np.mean(seed_improvements_mult):.1f} ± {np.std(seed_improvements_mult):.1f}%\")\n",
    "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_mult)]} (MAE={min(seed_test_maes_mult):.4f})\")\n",
    "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_mult)]} (MAE={max(seed_test_maes_mult):.4f})\")\n",
    "\n",
    "# OVERFITTING ANALYSIS\n",
    "print(\"\\n🔍 OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_mult):.1f}%\")\n",
    "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_mult):.1f}% worse than Train MAE on average)\")\n",
    "\n",
    "if np.mean(seed_overfit_ratios_mult) < 10:\n",
    "    print(\"  ✅ Excellent generalization - minimal overfitting\")\n",
    "elif np.mean(seed_overfit_ratios_mult) < 20:\n",
    "    print(\"  ✅ Good generalization - acceptable overfitting\")\n",
    "else:\n",
    "    print(\"  ⚠️ Significant overfitting - consider regularization\")\n",
    "\n",
    "# Average parameters across seeds\n",
    "avg_params_all_seeds = np.mean(seed_results_mult, axis=0)\n",
    "std_params_all_seeds = np.std(seed_results_mult, axis=0)\n",
    "\n",
    "print(\"\\n✅ CONSENSUS PARAMETERS (averaged across seeds):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  m₀ (constant):     {avg_params_all_seeds[0]:+.4f} ± {std_params_all_seeds[0]:.4f}\")\n",
    "print(f\"  m₁ (CCT coef):     {avg_params_all_seeds[1]:+.4f} ± {std_params_all_seeds[1]:.4f}\")\n",
    "print(f\"  m₂ (ratio coef):   {avg_params_all_seeds[2]:+.4f} ± {std_params_all_seeds[2]:.4f}\")\n",
    "\n",
    "print(\"\\n📐 CONSENSUS CORRECTION FORMULA:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Corrected_REF = Standard_SRK/T2 × Correction_Factor\")\n",
    "print(f\"Correction_Factor = 1 {avg_params_all_seeds[0]:+.4f} {avg_params_all_seeds[1]:+.4f}×CCT_norm {avg_params_all_seeds[2]:+.4f}×(CCT/AL)\")\n",
    "\n",
    "# Store in global results dictionary\n",
    "multi_seed_results['multiplicative'] = {\n",
    "    'test_maes': seed_test_maes_mult,\n",
    "    'train_maes': seed_train_maes_mult,\n",
    "    'baseline_maes': seed_baseline_maes_mult,\n",
    "    'improvements': seed_improvements_mult,\n",
    "    'overfit_ratios': seed_overfit_ratios_mult,\n",
    "    'mean_mae': np.mean(seed_test_maes_mult),\n",
    "    'std_mae': np.std(seed_test_maes_mult),\n",
    "    'mean_improvement': np.mean(seed_improvements_mult)\n",
    "}\n",
    "\n",
    "print(\"\\n💡 ROBUSTNESS ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "mae_cv = np.std(seed_test_maes_mult) / np.mean(seed_test_maes_mult) * 100\n",
    "if mae_cv < 5:\n",
    "    print(f\"✅ Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
    "elif mae_cv < 10:\n",
    "    print(f\"✅ Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
    "else:\n",
    "    print(f\"⚠️ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
    "\n",
    "print(f\"\\n📊 Range of results: {min(seed_test_maes_mult):.4f} - {max(seed_test_maes_mult):.4f} D\")\n",
    "print(f\"   This {max(seed_test_maes_mult)-min(seed_test_maes_mult):.4f} D range shows the impact of data split\")\n",
    "\n",
    "# Parameter consistency check\n",
    "print(f\"\\n📊 Parameter consistency across seeds:\")\n",
    "for i, param_name in enumerate(['m₀', 'm₁', 'm₂']):\n",
    "    param_values = [p[i] for p in seed_results_mult]\n",
    "    print(f\"  {param_name}: min={min(param_values):.4f}, max={max(param_values):.4f}, range={max(param_values)-min(param_values):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9g3yzsp3n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDITIVE CORRECTION WITH PROPER VALIDATION - MULTI-SEED\n",
    "# ================================================\n",
    "# PURPOSE: Create an additive correction term with multi-seed validation\n",
    "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ADDITIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🎯 MULTI-SEED STRATEGY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"• Each seed: 75% train, 25% test\")\n",
    "print(\"• Formula: Corrected = SRK/T2 + Correction_Term\")\n",
    "print(\"• Uses Ridge-identified important features\")\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "def additive_objective(params, df_data):\n",
    "    \"\"\"Objective for additive correction using Ridge-identified features\"\"\"\n",
    "    a0, a1, a2, a3 = params\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for _, row in df_data.iterrows():\n",
    "        # Standard SRK/T2 prediction\n",
    "        base_pred = row['SRKT2_Prediction']\n",
    "        \n",
    "        # Ridge-identified features\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        k_avg = row['K_avg']\n",
    "        \n",
    "        # Additive correction based on Ridge insights\n",
    "        correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * k_avg\n",
    "        corrected_pred = base_pred + correction\n",
    "        \n",
    "        predictions.append(corrected_pred)\n",
    "        actuals.append(row['PostOP Spherical Equivalent'])\n",
    "    \n",
    "    return mean_absolute_error(actuals, predictions)\n",
    "\n",
    "# Initial guess and bounds\n",
    "x0_add = [0, 0, 0, 0]\n",
    "bounds_add = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1)]\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_add = []\n",
    "seed_test_maes_add = []\n",
    "seed_baseline_maes_add = []\n",
    "seed_improvements_add = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT with current seed\n",
    "    X_train_add, X_test_add = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_add['K_avg'] = (X_train_add['Bio-Ks'] + X_train_add['Bio-Kf']) / 2\n",
    "    X_test_add['K_avg'] = (X_test_add['Bio-Ks'] + X_test_add['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"📊 Split: {len(X_train_add)} train, {len(X_test_add)} test\")\n",
    "    \n",
    "    # Calculate baseline SRK/T2 for both sets\n",
    "    for dataset in [X_train_add, X_test_add]:\n",
    "        dataset['SRKT2_Prediction'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    # INNER K-FOLD CV (optional for additive, but good for consistency)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    fold_params = []\n",
    "    fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_add), 1):\n",
    "        fold_train = X_train_add.iloc[train_idx]\n",
    "        fold_val = X_train_add.iloc[val_idx]\n",
    "        \n",
    "        # Optimize on fold\n",
    "        result_fold = minimize(\n",
    "            lambda p: additive_objective(p, fold_train),\n",
    "            x0_add,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds_add\n",
    "        )\n",
    "        \n",
    "        fold_params.append(result_fold.x)\n",
    "        val_mae = additive_objective(result_fold.x, fold_val)\n",
    "        fold_maes.append(val_mae)\n",
    "    \n",
    "    # Average across folds\n",
    "    avg_cv_mae = np.mean(fold_maes)\n",
    "    std_cv_mae = np.std(fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_cv_mae:.4f} ± {std_cv_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL OPTIMIZATION on full training set\n",
    "    result_add = minimize(\n",
    "        lambda p: additive_objective(p, X_train_add),\n",
    "        x0_add,\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds_add\n",
    "    )\n",
    "    \n",
    "    a0_opt, a1_opt, a2_opt, a3_opt = result_add.x\n",
    "    \n",
    "    print(f\"  Final params: a₀={a0_opt:.4f}, a₁={a1_opt:.4f}, a₂={a2_opt:.4f}, a₃={a3_opt:.4f}\")\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for reference)\n",
    "    predictions_add_train = []\n",
    "    for _, row in X_train_add.iterrows():\n",
    "        base_pred = row['SRKT2_Prediction']\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        k_avg = row['K_avg']\n",
    "        \n",
    "        correction = a0_opt + a1_opt * cct_norm + a2_opt * cct_ratio + a3_opt * k_avg\n",
    "        corrected_pred = base_pred + correction\n",
    "        predictions_add_train.append(corrected_pred)\n",
    "    \n",
    "    mae_train_add = mean_absolute_error(X_train_add['PostOP Spherical Equivalent'], predictions_add_train)\n",
    "    \n",
    "    # TEST ON HOLDOUT SET\n",
    "    predictions_add_test = []\n",
    "    for _, row in X_test_add.iterrows():\n",
    "        base_pred = row['SRKT2_Prediction']\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        k_avg = row['K_avg']\n",
    "        \n",
    "        correction = a0_opt + a1_opt * cct_norm + a2_opt * cct_ratio + a3_opt * k_avg\n",
    "        corrected_pred = base_pred + correction\n",
    "        predictions_add_test.append(corrected_pred)\n",
    "    \n",
    "    mae_baseline = np.abs(X_test_add['SRKT2_Prediction'] - X_test_add['PostOP Spherical Equivalent']).mean()\n",
    "    mae_optimized = mean_absolute_error(X_test_add['PostOP Spherical Equivalent'], predictions_add_test)\n",
    "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
    "    \n",
    "    print(f\"  Train MAE: {mae_train_add:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
    "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfit_ratio = (mae_optimized - mae_train_add) / mae_train_add * 100\n",
    "    if overfit_ratio > 20:\n",
    "        print(f\"  ⚠️ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_add.append([a0_opt, a1_opt, a2_opt, a3_opt])\n",
    "    seed_test_maes_add.append(mae_optimized)\n",
    "    seed_baseline_maes_add.append(mae_baseline)\n",
    "    seed_improvements_add.append(improvement)\n",
    "\n",
    "# MULTI-SEED SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADDITIVE CORRECTION - MULTI-SEED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 TEST PERFORMANCE ACROSS SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_add[i]:.4f} D, Improvement={seed_improvements_add[i]:.1f}%\")\n",
    "\n",
    "print(\"\\n📈 STATISTICAL SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_add):.4f} ± {np.std(seed_baseline_maes_add):.4f} D\")\n",
    "print(f\"  Optimized MAE:     {np.mean(seed_test_maes_add):.4f} ± {np.std(seed_test_maes_add):.4f} D\")\n",
    "print(f\"  Mean Improvement:  {np.mean(seed_improvements_add):.1f} ± {np.std(seed_improvements_add):.1f}%\")\n",
    "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_add)]} (MAE={min(seed_test_maes_add):.4f})\")\n",
    "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_add)]} (MAE={max(seed_test_maes_add):.4f})\")\n",
    "\n",
    "# Average parameters across seeds\n",
    "avg_params_all_seeds = np.mean(seed_results_add, axis=0)\n",
    "std_params_all_seeds = np.std(seed_results_add, axis=0)\n",
    "\n",
    "print(\"\\n✅ CONSENSUS PARAMETERS (averaged across seeds):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  a₀ (constant):     {avg_params_all_seeds[0]:+.4f} ± {std_params_all_seeds[0]:.4f}\")\n",
    "print(f\"  a₁ (CCT_norm):     {avg_params_all_seeds[1]:+.4f} ± {std_params_all_seeds[1]:.4f}\")\n",
    "print(f\"  a₂ (CCT_ratio):    {avg_params_all_seeds[2]:+.4f} ± {std_params_all_seeds[2]:.4f}\")\n",
    "print(f\"  a₃ (K_avg):        {avg_params_all_seeds[3]:+.4f} ± {std_params_all_seeds[3]:.4f}\")\n",
    "\n",
    "print(\"\\n📐 CONSENSUS CORRECTION FORMULA:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Corrected_REF = Standard_SRK/T2 + Correction_Term\")\n",
    "print(\"\")\n",
    "print(f\"Correction_Term = {avg_params_all_seeds[0]:+.4f} {avg_params_all_seeds[1]:+.4f}×CCT_norm {avg_params_all_seeds[2]:+.4f}×(CCT/AL) {avg_params_all_seeds[3]:+.4f}×K_avg\")\n",
    "print(\"\")\n",
    "print(\"Where: CCT_norm = (CCT - 600) / 100\")\n",
    "\n",
    "# Store in global results dictionary\n",
    "multi_seed_results['additive'] = {\n",
    "    'test_maes': seed_test_maes_add,\n",
    "    'baseline_maes': seed_baseline_maes_add,\n",
    "    'improvements': seed_improvements_add,\n",
    "    'mean_mae': np.mean(seed_test_maes_add),\n",
    "    'std_mae': np.std(seed_test_maes_add),\n",
    "    'mean_improvement': np.mean(seed_improvements_add)\n",
    "}\n",
    "\n",
    "print(\"\\n💡 ROBUSTNESS ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "mae_cv = np.std(seed_test_maes_add) / np.mean(seed_test_maes_add) * 100\n",
    "if mae_cv < 5:\n",
    "    print(f\"✅ Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
    "elif mae_cv < 10:\n",
    "    print(f\"✅ Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
    "else:\n",
    "    print(f\"⚠️ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
    "\n",
    "print(f\"\\n📊 Range of results: {min(seed_test_maes_add):.4f} - {max(seed_test_maes_add):.4f} D\")\n",
    "print(f\"   This {max(seed_test_maes_add)-min(seed_test_maes_add):.4f} D range shows the impact of data split\")\n",
    "\n",
    "# Parameter consistency check\n",
    "print(f\"\\n📊 Parameter consistency across seeds:\")\n",
    "for i, param_name in enumerate(['a₀', 'a₁', 'a₂', 'a₃']):\n",
    "    param_values = [p[i] for p in seed_results_add]\n",
    "    print(f\"  {param_name}: min={min(param_values):.4f}, max={max(param_values):.4f}, range={max(param_values)-min(param_values):.4f}\")\n",
    "\n",
    "print(\"\\n💡 RIDGE VALIDATION:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• This formula uses features identified by Ridge as important\")\n",
    "print(\"• CCT_norm and CCT_ratio were top Ridge features\")\n",
    "if np.mean(seed_improvements_add) > 10:\n",
    "    print(f\"• Achieving {np.mean(seed_improvements_add):.1f}% average improvement confirms Ridge insights work!\")\n",
    "elif np.mean(seed_improvements_add) > 0:\n",
    "    print(f\"• Modest {np.mean(seed_improvements_add):.1f}% improvement - Ridge features help but may need refinement\")\n",
    "else:\n",
    "    print(\"• Limited improvement suggests these features may not generalize well\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u4unlmjdt3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINED APPROACH WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
    "# ========================================================\n",
    "# PURPOSE: Combine all three methods with nested K-fold CV and multi-seed validation\n",
    "# Most complex but potentially most accurate approach\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMBINED FORMULA WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🎯 MULTI-SEED NESTED CV FOR COMBINED APPROACH:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"• Each seed: 75/25 train/test split\")\n",
    "print(\"• Inner: 5-fold CV for each method\")\n",
    "print(\"• Combine all optimized corrections\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "import numpy as np\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_combined = []\n",
    "seed_test_maes_combined = []\n",
    "seed_train_maes_combined = []\n",
    "seed_baseline_maes_combined = []\n",
    "seed_improvements_combined = []\n",
    "seed_overfit_ratios_combined = []\n",
    "\n",
    "# Store individual method results\n",
    "seed_param_results = []\n",
    "seed_mult_results = []\n",
    "seed_add_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT - consistent across all methods\n",
    "    X_train_comb, X_test_comb = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_comb['K_avg'] = (X_train_comb['Bio-Ks'] + X_train_comb['Bio-Kf']) / 2\n",
    "    X_test_comb['K_avg'] = (X_test_comb['Bio-Ks'] + X_test_comb['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"📊 Split: {len(X_train_comb)} train, {len(X_test_comb)} test\")\n",
    "    \n",
    "    # Calculate baseline for all\n",
    "    for dataset in [X_train_comb, X_test_comb]:\n",
    "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    print(\"\\n📁 K-FOLD CV FOR EACH METHOD:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Setup K-fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # Store fold results for each method\n",
    "    param_fold_results = []\n",
    "    mult_fold_results = []\n",
    "    add_fold_results = []\n",
    "    combined_fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_comb), 1):\n",
    "        print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
    "        \n",
    "        fold_train = X_train_comb.iloc[train_idx]\n",
    "        fold_val = X_train_comb.iloc[val_idx]\n",
    "        \n",
    "        # 1. PARAMETER METHOD\n",
    "        def param_obj(params, df_data):\n",
    "            nc_base, nc_cct, k_base, k_cct, acd_base, acd_cct = params\n",
    "            predictions = []\n",
    "            for _, row in df_data.iterrows():\n",
    "                cct_norm = (row['CCT'] - 600) / 100\n",
    "                nc = nc_base + nc_cct * cct_norm\n",
    "                k_index = k_base + k_cct * cct_norm\n",
    "                acd_offset = acd_base + acd_cct * cct_norm\n",
    "                pred = calculate_SRKT2(\n",
    "                    AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "                    IOL_power=row['IOL Power'],\n",
    "                    A_constant=row['A-Constant'] + acd_offset,\n",
    "                    nc=nc, k_index=k_index\n",
    "                )\n",
    "                predictions.append(pred)\n",
    "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "        \n",
    "        bounds_p = [(1.20, 1.50), (-0.20, 0.20), (1.20, 1.60), (-0.30, 0.30), (-3.0, 3.0), (-3.0, 3.0)]\n",
    "        result_p = differential_evolution(lambda p: param_obj(p, fold_train), bounds_p, \n",
    "                                         maxiter=20, seed=SEED+fold_num, disp=False)\n",
    "        param_fold_results.append(result_p.x)\n",
    "        \n",
    "        # 2. MULTIPLICATIVE METHOD\n",
    "        def mult_obj(params, df_data):\n",
    "            m0, m1, m2 = params\n",
    "            predictions = []\n",
    "            for _, row in df_data.iterrows():\n",
    "                base_pred = row['SRKT2_Baseline']\n",
    "                cct_norm = (row['CCT'] - 600) / 100\n",
    "                cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                correction = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "                predictions.append(base_pred * correction)\n",
    "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "        \n",
    "        result_m = minimize(lambda p: mult_obj(p, fold_train), [0,0,0], \n",
    "                           method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
    "        mult_fold_results.append(result_m.x)\n",
    "        \n",
    "        # 3. ADDITIVE METHOD\n",
    "        def add_obj(params, df_data):\n",
    "            a0, a1, a2, a3 = params\n",
    "            predictions = []\n",
    "            for _, row in df_data.iterrows():\n",
    "                base_pred = row['SRKT2_Baseline']\n",
    "                cct_norm = (row['CCT'] - 600) / 100\n",
    "                cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
    "                predictions.append(base_pred + correction)\n",
    "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "        \n",
    "        result_a = minimize(lambda p: add_obj(p, fold_train), [0,0,0,0],\n",
    "                           method='L-BFGS-B', bounds=[(-2,2),(-2,2),(-2,2),(-0.1,0.1)])\n",
    "        add_fold_results.append(result_a.x)\n",
    "        \n",
    "        # VALIDATE COMBINED on fold validation set\n",
    "        nc_b, nc_c, k_b, k_c, acd_b, acd_c = result_p.x\n",
    "        m0, m1, m2 = result_m.x\n",
    "        a0, a1, a2, a3 = result_a.x\n",
    "        \n",
    "        combined_preds = []\n",
    "        for _, row in fold_val.iterrows():\n",
    "            cct_norm = (row['CCT'] - 600) / 100\n",
    "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "            \n",
    "            # Modified SRK/T2\n",
    "            nc = nc_b + nc_c * cct_norm\n",
    "            k_index = k_b + k_c * cct_norm\n",
    "            acd_offset = acd_b + acd_c * cct_norm\n",
    "            modified = calculate_SRKT2(\n",
    "                AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant'] + acd_offset,\n",
    "                nc=nc, k_index=k_index\n",
    "            )\n",
    "            \n",
    "            # Apply multiplicative\n",
    "            mult_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "            after_mult = modified * mult_factor\n",
    "            \n",
    "            # Apply additive\n",
    "            add_correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
    "            final = after_mult + add_correction\n",
    "            \n",
    "            combined_preds.append(final)\n",
    "        \n",
    "        fold_mae = mean_absolute_error(fold_val['PostOP Spherical Equivalent'], combined_preds)\n",
    "        combined_fold_maes.append(fold_mae)\n",
    "        print(f\"MAE={fold_mae:.4f} \", end=\"\")\n",
    "    \n",
    "    print()  # New line after folds\n",
    "    \n",
    "    # Average parameters across folds\n",
    "    avg_param = np.mean(param_fold_results, axis=0)\n",
    "    avg_mult = np.mean(mult_fold_results, axis=0)\n",
    "    avg_add = np.mean(add_fold_results, axis=0)\n",
    "    avg_combined_mae = np.mean(combined_fold_maes)\n",
    "    std_combined_mae = np.std(combined_fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_combined_mae:.4f} ± {std_combined_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    print(\"  Final optimization on full training set...\")\n",
    "    \n",
    "    result_p_final = differential_evolution(lambda p: param_obj(p, X_train_comb), bounds_p, \n",
    "                                           maxiter=50, seed=SEED, disp=False)\n",
    "    nc_base_c, nc_cct_c, k_base_c, k_cct_c, acd_base_c, acd_cct_c = result_p_final.x\n",
    "    \n",
    "    result_m_final = minimize(lambda p: mult_obj(p, X_train_comb), [0,0,0], \n",
    "                             method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
    "    m0_c, m1_c, m2_c = result_m_final.x\n",
    "    \n",
    "    result_a_final = minimize(lambda p: add_obj(p, X_train_comb), [0,0,0,0],\n",
    "                             method='L-BFGS-B', bounds=[(-2,2),(-2,2),(-2,2),(-0.1,0.1)])\n",
    "    a0_c, a1_c, a2_c, a3_c = result_a_final.x\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    predictions_combined_train = []\n",
    "    for _, row in X_train_comb.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        k_avg = row['K_avg']\n",
    "        \n",
    "        # Modified SRK/T2\n",
    "        nc = nc_base_c + nc_cct_c * cct_norm\n",
    "        k_index = k_base_c + k_cct_c * cct_norm\n",
    "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
    "        \n",
    "        modified_srkt2 = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'], K_avg=k_avg,\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc, k_index=k_index\n",
    "        )\n",
    "        \n",
    "        # Apply multiplicative\n",
    "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
    "        after_mult = modified_srkt2 * mult_factor\n",
    "        \n",
    "        # Apply additive\n",
    "        add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
    "        final_combined = after_mult + add_correction\n",
    "        \n",
    "        predictions_combined_train.append(final_combined)\n",
    "    \n",
    "    mae_train = mean_absolute_error(X_train_comb['PostOP Spherical Equivalent'], predictions_combined_train)\n",
    "    \n",
    "    # TEST ON HOLDOUT\n",
    "    predictions_combined_test = []\n",
    "    predictions_mult_only = []\n",
    "    \n",
    "    for _, row in X_test_comb.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        k_avg = row['K_avg']\n",
    "        \n",
    "        # Modified SRK/T2\n",
    "        nc = nc_base_c + nc_cct_c * cct_norm\n",
    "        k_index = k_base_c + k_cct_c * cct_norm\n",
    "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
    "        \n",
    "        modified_srkt2 = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'], K_avg=k_avg,\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc, k_index=k_index\n",
    "        )\n",
    "        \n",
    "        # Multiplicative only (for comparison)\n",
    "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
    "        mult_only = row['SRKT2_Baseline'] * mult_factor\n",
    "        predictions_mult_only.append(mult_only)\n",
    "        \n",
    "        # Combined: all three\n",
    "        after_mult = modified_srkt2 * mult_factor\n",
    "        add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
    "        final_combined = after_mult + add_correction\n",
    "        predictions_combined_test.append(final_combined)\n",
    "    \n",
    "    mae_baseline = np.abs(X_test_comb['SRKT2_Baseline'] - X_test_comb['PostOP Spherical Equivalent']).mean()\n",
    "    mae_optimized = mean_absolute_error(X_test_comb['PostOP Spherical Equivalent'], predictions_combined_test)\n",
    "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
    "    \n",
    "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
    "    print(f\"  Test: Baseline={mae_baseline:.4f}, Combined={mae_optimized:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
    "    if overfit_ratio > 20:\n",
    "        print(f\"  ⚠️ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    elif overfit_ratio > 10:\n",
    "        print(f\"  ⚠️ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    else:\n",
    "        print(f\"  ✅ Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_combined.append({\n",
    "        'param': [nc_base_c, nc_cct_c, k_base_c, k_cct_c, acd_base_c, acd_cct_c],\n",
    "        'mult': [m0_c, m1_c, m2_c],\n",
    "        'add': [a0_c, a1_c, a2_c, a3_c]\n",
    "    })\n",
    "    seed_test_maes_combined.append(mae_optimized)\n",
    "    seed_train_maes_combined.append(mae_train)\n",
    "    seed_baseline_maes_combined.append(mae_baseline)\n",
    "    seed_improvements_combined.append(improvement)\n",
    "    seed_overfit_ratios_combined.append(overfit_ratio)\n",
    "\n",
    "# MULTI-SEED SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMBINED APPROACH - MULTI-SEED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 TEST PERFORMANCE ACROSS SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_combined[i]:.4f} D, Improvement={seed_improvements_combined[i]:.1f}%\")\n",
    "\n",
    "print(\"\\n📈 STATISTICAL SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_combined):.4f} ± {np.std(seed_baseline_maes_combined):.4f} D\")\n",
    "print(f\"  Train MAE:         {np.mean(seed_train_maes_combined):.4f} ± {np.std(seed_train_maes_combined):.4f} D\")\n",
    "print(f\"  Test MAE:          {np.mean(seed_test_maes_combined):.4f} ± {np.std(seed_test_maes_combined):.4f} D\")\n",
    "print(f\"  Mean Improvement:  {np.mean(seed_improvements_combined):.1f} ± {np.std(seed_improvements_combined):.1f}%\")\n",
    "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_combined)]} (MAE={min(seed_test_maes_combined):.4f})\")\n",
    "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_combined)]} (MAE={max(seed_test_maes_combined):.4f})\")\n",
    "\n",
    "# OVERFITTING ANALYSIS\n",
    "print(\"\\n🔍 OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_combined):.1f}%\")\n",
    "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_combined):.1f}% worse than Train MAE on average)\")\n",
    "\n",
    "if np.mean(seed_overfit_ratios_combined) < 10:\n",
    "    print(\"  ✅ Excellent generalization - minimal overfitting\")\n",
    "elif np.mean(seed_overfit_ratios_combined) < 20:\n",
    "    print(\"  ✅ Good generalization - acceptable overfitting\")\n",
    "else:\n",
    "    print(\"  ⚠️ Significant overfitting - consider regularization\")\n",
    "    print(\"  Note: Combined approach has more parameters, higher overfitting risk\")\n",
    "\n",
    "# Clinical accuracy\n",
    "all_errors = []\n",
    "for i in range(len(SEEDS)):\n",
    "    errors = np.abs(np.array(seed_test_maes_combined[i]))\n",
    "    all_errors.append(errors)\n",
    "\n",
    "mean_mae = np.mean(seed_test_maes_combined)\n",
    "within_050 = sum(1 for mae in seed_test_maes_combined if mae <= 0.50) / len(seed_test_maes_combined) * 100\n",
    "within_100 = sum(1 for mae in seed_test_maes_combined if mae <= 1.00) / len(seed_test_maes_combined) * 100\n",
    "\n",
    "print(f\"\\n📈 CLINICAL PERFORMANCE (Combined):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Seeds with MAE < 0.50 D: {within_050:.0f}%\")\n",
    "print(f\"  Seeds with MAE < 1.00 D: {within_100:.0f}%\")\n",
    "\n",
    "# Store in global results dictionary\n",
    "multi_seed_results['combined'] = {\n",
    "    'test_maes': seed_test_maes_combined,\n",
    "    'train_maes': seed_train_maes_combined,\n",
    "    'baseline_maes': seed_baseline_maes_combined,\n",
    "    'improvements': seed_improvements_combined,\n",
    "    'overfit_ratios': seed_overfit_ratios_combined,\n",
    "    'mean_mae': np.mean(seed_test_maes_combined),\n",
    "    'std_mae': np.std(seed_test_maes_combined),\n",
    "    'mean_improvement': np.mean(seed_improvements_combined)\n",
    "}\n",
    "\n",
    "# Extract consensus parameters\n",
    "all_param_params = [r['param'] for r in seed_results_combined]\n",
    "all_mult_params = [r['mult'] for r in seed_results_combined]\n",
    "all_add_params = [r['add'] for r in seed_results_combined]\n",
    "\n",
    "avg_param_params = np.mean(all_param_params, axis=0)\n",
    "avg_mult_params = np.mean(all_mult_params, axis=0)\n",
    "avg_add_params = np.mean(all_add_params, axis=0)\n",
    "\n",
    "print(\"\\n✅ CONSENSUS PARAMETERS (averaged across seeds):\")\n",
    "print(\"-\" * 70)\n",
    "print(\"1. Modified SRK/T2:\")\n",
    "print(f\"   nc = {avg_param_params[0]:.4f} + {avg_param_params[1]:.4f} × CCT_norm\")\n",
    "print(f\"   k_index = {avg_param_params[2]:.4f} + {avg_param_params[3]:.4f} × CCT_norm\")\n",
    "print(f\"   ACD_offset = {avg_param_params[4]:.4f} + {avg_param_params[5]:.4f} × CCT_norm\")\n",
    "print(\"2. Multiplicative:\")\n",
    "print(f\"   Factor = 1 + {avg_mult_params[0]:.4f} + {avg_mult_params[1]:.4f} × CCT_norm + {avg_mult_params[2]:.4f} × CCT_ratio\")\n",
    "print(\"3. Additive:\")\n",
    "print(f\"   Term = {avg_add_params[0]:.4f} + {avg_add_params[1]:.4f} × CCT_norm + {avg_add_params[2]:.4f} × CCT_ratio + {avg_add_params[3]:.4f} × K_avg\")\n",
    "\n",
    "print(\"\\n💡 ROBUSTNESS ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "mae_cv = np.std(seed_test_maes_combined) / np.mean(seed_test_maes_combined) * 100\n",
    "if mae_cv < 5:\n",
    "    print(f\"✅ Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
    "elif mae_cv < 10:\n",
    "    print(f\"✅ Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
    "else:\n",
    "    print(f\"⚠️ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
    "\n",
    "print(f\"\\n📊 Range of results: {min(seed_test_maes_combined):.4f} - {max(seed_test_maes_combined):.4f} D\")\n",
    "print(f\"   This {max(seed_test_maes_combined)-min(seed_test_maes_combined):.4f} D range shows the impact of data split\")\n",
    "\n",
    "print(\"\\n💡 COMBINED APPROACH INSIGHTS:\")\n",
    "print(\"-\" * 50)\n",
    "if np.mean(seed_overfit_ratios_combined) > np.mean(seed_improvements_combined) * 0.5:\n",
    "    print(\"⚠️ High complexity may be causing overfitting\")\n",
    "    print(\"   Consider using simpler approach (multiplicative only)\")\n",
    "else:\n",
    "    print(\"✅ Combined approach balances complexity and performance\")\n",
    "    print(\"   The three corrections work synergistically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3yxaies4nqp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTI-SEED COMPARISON - FINAL COMPREHENSIVE SUMMARY\n",
    "# ====================================================\n",
    "# PURPOSE: Compare all methods across multiple seeds for robust conclusions\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MULTI-SEED ANALYSIS - COMPREHENSIVE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n🔬 VALIDATION SETUP:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Seeds tested: {SEEDS}\")\n",
    "print(f\"• Train/Test split: 75%/25% (72/24 patients)\")\n",
    "print(f\"• Inner validation: 5-fold CV\")\n",
    "print(f\"• All results on holdout test sets\")\n",
    "\n",
    "# Check which methods have been run\n",
    "available_methods = []\n",
    "for method in ['parameter', 'multiplicative', 'additive', 'combined', 'fixed_combined']:\n",
    "    if method in multi_seed_results and multi_seed_results[method]:\n",
    "        available_methods.append(method)\n",
    "\n",
    "if not available_methods:\n",
    "    print(\"\\n⚠️ No multi-seed results found yet!\")\n",
    "    print(\"Please run the optimization cells first.\")\n",
    "else:\n",
    "    print(f\"\\n✅ Methods analyzed: {', '.join(available_methods)}\")\n",
    "    \n",
    "    # Create comparison table\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PERFORMANCE COMPARISON ACROSS METHODS AND SEEDS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Detailed table by seed\n",
    "    print(\"\\n📊 DETAILED RESULTS BY SEED:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Method':<20} | \", end=\"\")\n",
    "    for seed in SEEDS:\n",
    "        print(f\"Seed {seed:3} | \", end=\"\")\n",
    "    print(f\"{'Mean ± Std':<15} | {'Best':<6} | {'Worst':<6}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for method in available_methods:\n",
    "        results = multi_seed_results[method]\n",
    "        print(f\"{method.capitalize():<20} | \", end=\"\")\n",
    "        for mae in results['test_maes']:\n",
    "            print(f\"{mae:7.4f} | \", end=\"\")\n",
    "        mean_mae = results['mean_mae']\n",
    "        std_mae = results['std_mae']\n",
    "        print(f\"{mean_mae:.4f} ± {std_mae:.4f} | \", end=\"\")\n",
    "        print(f\"{min(results['test_maes']):.4f} | {max(results['test_maes']):.4f}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STATISTICAL SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n📈 MEAN PERFORMANCE (averaged across seeds):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Sort methods by mean MAE\n",
    "    sorted_methods = sorted(available_methods, \n",
    "                          key=lambda m: multi_seed_results[m]['mean_mae'])\n",
    "    \n",
    "    for rank, method in enumerate(sorted_methods, 1):\n",
    "        results = multi_seed_results[method]\n",
    "        mean_mae = results['mean_mae']\n",
    "        std_mae = results['std_mae']\n",
    "        mean_imp = results['mean_improvement']\n",
    "        \n",
    "        print(f\"{rank}. {method.capitalize():<20}: MAE = {mean_mae:.4f} ± {std_mae:.4f} D\")\n",
    "        print(f\"   {'':20}  Improvement = {mean_imp:.1f}%\")\n",
    "    \n",
    "    # Best overall method\n",
    "    best_method = sorted_methods[0]\n",
    "    best_results = multi_seed_results[best_method]\n",
    "    \n",
    "    print(f\"\\n🏆 BEST METHOD: {best_method.upper()}\")\n",
    "    print(f\"   Mean MAE: {best_results['mean_mae']:.4f} ± {best_results['std_mae']:.4f} D\")\n",
    "    print(f\"   Mean Improvement: {best_results['mean_improvement']:.1f}%\")\n",
    "    \n",
    "    # Robustness analysis\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ROBUSTNESS ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n📊 STABILITY ACROSS SEEDS (Coefficient of Variation):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    stability_scores = []\n",
    "    for method in available_methods:\n",
    "        results = multi_seed_results[method]\n",
    "        cv = (results['std_mae'] / results['mean_mae']) * 100\n",
    "        stability_scores.append((method, cv))\n",
    "    \n",
    "    # Sort by stability (lower CV is better)\n",
    "    stability_scores.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for method, cv in stability_scores:\n",
    "        if cv < 5:\n",
    "            status = \"✅ Excellent\"\n",
    "        elif cv < 10:\n",
    "            status = \"✅ Good\"\n",
    "        elif cv < 15:\n",
    "            status = \"⚠️ Moderate\"\n",
    "        else:\n",
    "            status = \"⚠️ Variable\"\n",
    "        print(f\"  {method.capitalize():<20}: CV = {cv:5.1f}%  {status}\")\n",
    "    \n",
    "    # Range analysis\n",
    "    print(\"\\n📊 PERFORMANCE RANGE (max - min across seeds):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for method in available_methods:\n",
    "        results = multi_seed_results[method]\n",
    "        mae_range = max(results['test_maes']) - min(results['test_maes'])\n",
    "        print(f\"  {method.capitalize():<20}: {mae_range:.4f} D\")\n",
    "    \n",
    "    # Statistical significance insights\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KEY INSIGHTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n💡 STATISTICAL CONCLUSIONS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Check if best method is consistently best\n",
    "    best_count = 0\n",
    "    for i in range(len(SEEDS)):\n",
    "        seed_maes = {m: multi_seed_results[m]['test_maes'][i] for m in available_methods}\n",
    "        if min(seed_maes, key=seed_maes.get) == best_method:\n",
    "            best_count += 1\n",
    "    \n",
    "    consistency = (best_count / len(SEEDS)) * 100\n",
    "    print(f\"• {best_method.capitalize()} was best in {best_count}/{len(SEEDS)} seeds ({consistency:.0f}%)\")\n",
    "    \n",
    "    # Check overlap in confidence intervals\n",
    "    if len(available_methods) > 1:\n",
    "        print(\"\\n• Confidence intervals (mean ± std):\")\n",
    "        for method in sorted_methods[:3]:  # Top 3 methods\n",
    "            results = multi_seed_results[method]\n",
    "            lower = results['mean_mae'] - results['std_mae']\n",
    "            upper = results['mean_mae'] + results['std_mae']\n",
    "            print(f\"  {method.capitalize():<20}: [{lower:.4f}, {upper:.4f}] D\")\n",
    "    \n",
    "    # Clinical relevance\n",
    "    print(\"\\n📏 CLINICAL RELEVANCE:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    baseline_mean = np.mean(multi_seed_results[available_methods[0]]['baseline_maes'])\n",
    "    for method in sorted_methods:\n",
    "        results = multi_seed_results[method]\n",
    "        mean_mae = results['mean_mae']\n",
    "        \n",
    "        if mean_mae < 0.5:\n",
    "            clinical = \"Excellent (< 0.5 D)\"\n",
    "        elif mean_mae < 0.75:\n",
    "            clinical = \"Good (< 0.75 D)\"\n",
    "        elif mean_mae < 1.0:\n",
    "            clinical = \"Acceptable (< 1.0 D)\"\n",
    "        else:\n",
    "            clinical = \"Poor (≥ 1.0 D)\"\n",
    "        \n",
    "        print(f\"  {method.capitalize():<20}: {clinical}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RECOMMENDATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n✅ FINAL RECOMMENDATIONS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Find most stable method\n",
    "    most_stable = min(stability_scores, key=lambda x: x[1])\n",
    "    \n",
    "    print(f\"1. Best performance: {best_method.capitalize()} (MAE = {best_results['mean_mae']:.4f} D)\")\n",
    "    print(f\"2. Most stable: {most_stable[0].capitalize()} (CV = {most_stable[1]:.1f}%)\")\n",
    "    \n",
    "    if best_method == most_stable[0]:\n",
    "        print(f\"\\n🎯 {best_method.capitalize()} is both best performing AND most stable!\")\n",
    "        print(\"   This is the recommended approach for clinical use.\")\n",
    "    else:\n",
    "        print(f\"\\n⚖️ Trade-off detected:\")\n",
    "        print(f\"   • {best_method.capitalize()}: Better performance but less stable\")\n",
    "        print(f\"   • {most_stable[0].capitalize()}: More stable but slightly worse performance\")\n",
    "        print(\"   Choose based on clinical priorities.\")\n",
    "    \n",
    "    print(\"\\n📝 PUBLICATION-READY SUMMARY:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Using {len(SEEDS)} different random seeds for validation,\")\n",
    "    print(f\"{best_method.capitalize()} achieved the best mean MAE of {best_results['mean_mae']:.3f} ± {best_results['std_mae']:.3f} D,\")\n",
    "    print(f\"representing a {best_results['mean_improvement']:.1f}% improvement over baseline SRK/T2.\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"END OF MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
