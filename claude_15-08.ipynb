{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "41782613",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ğŸ”§ MULTI-SEED CONFIGURATION\n",
            "======================================================================\n",
            "Seeds for validation: [42, 123, 456, 789, 2025]\n",
            "This ensures results are not dependent on random split\n",
            "Each seed creates different train/test splits for robust assessment\n",
            "======================================================================\n",
            "IOL CALCULATION FOR PRE-DMEK PATIENTS\n",
            "======================================================================\n",
            "\n",
            "ğŸ“Š WHAT WE'RE DOING:\n",
            "--------------------------------------------------\n",
            "â€¢ Loading data from Fuchs' dystrophy patients\n",
            "â€¢ These patients had combined cataract + DMEK surgery\n",
            "â€¢ Goal: Improve IOL power calculation accuracy\n",
            "â€¢ Challenge: Edematous corneas distort standard formulas\n",
            "â€¢ NEW: Using 5 different seeds for robust validation\n",
            "\n",
            "âœ… Loaded 96 patients from FacoDMEK.xlsx\n",
            "\n",
            "ğŸ” KEY MEASUREMENTS IN OUR DATA:\n",
            "--------------------------------------------------\n",
            "â€¢ Bio-AL: Axial length (mm)\n",
            "â€¢ Bio-Ks/Kf: Steep and flat keratometry (D)\n",
            "â€¢ CCT: Central corneal thickness (Î¼m) - KEY for edema\n",
            "â€¢ IOL Power: Implanted lens power (D)\n",
            "â€¢ PostOP Spherical Equivalent: Actual outcome (D)\n"
          ]
        }
      ],
      "source": [
        "# IOL CALCULATION FOR PRE-DMEK PATIENTS - SETUP AND DATA LOADING\n",
        "# ================================================================\n",
        "# PURPOSE: Set up the analysis environment and load patient data\n",
        "# This notebook optimizes IOL power calculations for Fuchs' dystrophy patients\n",
        "# undergoing combined phacoemulsification and DMEK surgery\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Constants for clinical accuracy thresholds (diopters)\n",
        "THRESHOLDS = [0.25, 0.50, 0.75, 1.00]\n",
        "TEST_SIZE = 0.25      # 25% holdout for final testing\n",
        "N_FOLDS = 5           # 5-fold cross-validation\n",
        "\n",
        "# MULTI-SEED CONFIGURATION FOR ROBUST VALIDATION\n",
        "#SEEDS = [42]  # Quick test with single seed\n",
        "#SEEDS = [42, 123]  # Medium test with 2 seeds\n",
        "SEEDS = [42, 123, 456, 789, 2025]  # Multiple seeds for statistical robustness\n",
        "print(\"=\" * 70)\n",
        "print(\"ğŸ”§ MULTI-SEED CONFIGURATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Seeds for validation: {SEEDS}\")\n",
        "print(\"This ensures results are not dependent on random split\")\n",
        "print(\"Each seed creates different train/test splits for robust assessment\")\n",
        "\n",
        "# Storage for multi-seed results\n",
        "multi_seed_results = {\n",
        "\n",
        "    'parameter': {},\n",
        "    'multiplicative': {},\n",
        "    'additive': {},\n",
        "    'combined': {},\n",
        "    'fixed_combined': {}\n",
        "}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"IOL CALCULATION FOR PRE-DMEK PATIENTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nğŸ“Š WHAT WE'RE DOING:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"â€¢ Loading data from Fuchs' dystrophy patients\")\n",
        "print(\"â€¢ These patients had combined cataract + DMEK surgery\")\n",
        "print(\"â€¢ Goal: Improve IOL power calculation accuracy\")\n",
        "print(\"â€¢ Challenge: Edematous corneas distort standard formulas\")\n",
        "print(f\"â€¢ NEW: Using {len(SEEDS)} different seeds for robust validation\")\n",
        "\n",
        "# Load the patient data\n",
        "df = pd.read_excel('FacoDMEK.xlsx')\n",
        "print(f\"\\nâœ… Loaded {len(df)} patients from FacoDMEK.xlsx\")\n",
        "\n",
        "print(\"\\nğŸ” KEY MEASUREMENTS IN OUR DATA:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"â€¢ Bio-AL: Axial length (mm)\")\n",
        "print(\"â€¢ Bio-Ks/Kf: Steep and flat keratometry (D)\")\n",
        "print(\"â€¢ CCT: Central corneal thickness (Î¼m) - KEY for edema\")\n",
        "print(\"â€¢ IOL Power: Implanted lens power (D)\")\n",
        "print(\"â€¢ PostOP Spherical Equivalent: Actual outcome (D)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9871e22d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "SRK/T2 FORMULA (Sheard et al. 2010)\n",
            "======================================================================\n",
            "â€¢ SKR/T2 assumes normal corneal properties\n",
            "â€¢ In Fuchs' dystrophy, the cornea is NOT normal:\n",
            "  - Edema changes refractive index (nc)\n",
            "  - Swelling alters keratometric index (k_index)\n",
            "  - Anterior chamber depth is affected\n",
            "\n",
            "Our strategy: Keep the formula structure, optimize the parameters!\n",
            "\n",
            "ğŸ“ THE SRK/T2 FORMULA:\n",
            "\n",
            "         1000Â·nâ‚Â·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) - PÂ·(Lopt - ACDest)Â·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest)\n",
            "REF = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "       nâ‚Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) + LoptÂ·r) - 0.001Â·PÂ·(Lopt - ACDest)Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest) + ACDestÂ·r)\n"
          ]
        }
      ],
      "source": [
        "# STANDARD SRK/T2 FORMULA IMPLEMENTATION\n",
        "# ========================================\n",
        "# PURPOSE: Implement the baseline SRK/T2 formula (Sheard et al. 2010)\n",
        "# This is the current gold standard for IOL calculations\n",
        "# We'll use this as our baseline to compare improvements against\n",
        "\n",
        "def calculate_SRKT2(AL, K_avg, IOL_power, A_constant, nc=1.333, k_index=1.3375):\n",
        "    \"\"\"\n",
        "    SRK/T2 Formula (Sheard et al. 2010)\n",
        "    - Assumes NORMAL corneas (nc=1.333, k_index=1.3375)\n",
        "    - These assumptions fail in edematous Fuchs' corneas\n",
        "    \n",
        "    Parameters:\n",
        "    - AL: Axial length (mm)\n",
        "    - K_avg: Average keratometry (D)\n",
        "    - IOL_power: IOL power (D)\n",
        "    - A_constant: Lens-specific constant\n",
        "    - nc: Corneal refractive index (we'll optimize this!)\n",
        "    - k_index: Keratometric index (we'll optimize this too!)\n",
        "    \"\"\"\n",
        "    # Constants\n",
        "    na = 1.336  # Aqueous/vitreous refractive index\n",
        "    V = 12      # Vertex distance (mm)\n",
        "    ncm1 = nc - 1\n",
        "    \n",
        "    # Convert keratometry to radius using keratometric index\n",
        "    # This is where edema causes problems - k_index assumes normal cornea!\n",
        "    r = (k_index - 1) * 1000 / K_avg\n",
        "    \n",
        "    # Axial length correction for long eyes\n",
        "    if AL <= 24.2:\n",
        "        LCOR = AL\n",
        "    else:\n",
        "        LCOR = 3.446 + 1.716 * AL - 0.0237 * AL * AL\n",
        "    \n",
        "    # H2 calculation (corneal height) - Sheard's modification\n",
        "    H2 = -10.326 + 0.32630 * LCOR + 0.13533 * K_avg\n",
        "    \n",
        "    # ACD (Anterior Chamber Depth) estimation\n",
        "    # Edema can affect this too!\n",
        "    ACD_const = 0.62467 * A_constant - 68.747\n",
        "    offset = ACD_const - 3.336\n",
        "    ACD_est = H2 + offset\n",
        "    \n",
        "    # Retinal thickness correction\n",
        "    RETHICK = 0.65696 - 0.02029 * AL\n",
        "    LOPT = AL + RETHICK  # Optical axial length\n",
        "    \n",
        "    # SRK/T2 refraction calculation - the complex optics formula\n",
        "    numerator = (1000 * na * (na * r - ncm1 * LOPT) - \n",
        "                 IOL_power * (LOPT - ACD_est) * (na * r - ncm1 * ACD_est))\n",
        "    \n",
        "    denominator = (na * (V * (na * r - ncm1 * LOPT) + LOPT * r) - \n",
        "                   0.001 * IOL_power * (LOPT - ACD_est) * \n",
        "                   (V * (na * r - ncm1 * ACD_est) + ACD_est * r))\n",
        "    \n",
        "    return numerator / denominator\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"SRK/T2 FORMULA (Sheard et al. 2010)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"â€¢ SKR/T2 assumes normal corneal properties\")\n",
        "print(\"â€¢ In Fuchs' dystrophy, the cornea is NOT normal:\")\n",
        "print(\"  - Edema changes refractive index (nc)\")\n",
        "print(\"  - Swelling alters keratometric index (k_index)\")\n",
        "print(\"  - Anterior chamber depth is affected\")\n",
        "print(\"\\nOur strategy: Keep the formula structure, optimize the parameters!\")\n",
        "\n",
        "print(\"\\nğŸ“ THE SRK/T2 FORMULA:\")\n",
        "print()\n",
        "print(\"         1000Â·nâ‚Â·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) - PÂ·(Lopt - ACDest)Â·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest)\")\n",
        "print(\"REF = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "print(\"       nâ‚Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) + LoptÂ·r) - 0.001Â·PÂ·(Lopt - ACDest)Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest) + ACDestÂ·r)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "db415cc6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "BASELINE SRK/T2 PERFORMANCE\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ WHAT WE'RE DOING:\n",
            "--------------------------------------------------\n",
            "1. Calculate average K from steep and flat readings\n",
            "2. Apply standard SRK/T2 to all 96 patients\n",
            "3. Compare predictions to actual outcomes\n",
            "4. Measure error to establish baseline performance\n",
            "\n",
            "ğŸ“Š BASELINE PERFORMANCE METRICS:\n",
            "======================================================================\n",
            "  Mean Absolute Error (MAE):     1.3591 D\n",
            "  Mean Error (ME):                -0.2915 D\n",
            "  Standard Deviation (SD):        1.7471 D\n",
            "  Median Absolute Error:          1.0311 D\n",
            "\n",
            "ğŸ’¡ INTERPRETATION:\n",
            "--------------------------------------------------\n",
            "â€¢ MAE of 1.36 D is POOR (>1.0 D is clinically unacceptable)\n",
            "â€¢ Mean error of -0.29 D shows systematic bias\n",
            "  â†’ Formula tends to predict too myopic (negative)\n",
            "\n",
            "ğŸ“ˆ CLINICAL ACCURACY:\n",
            "----------------------------------------------------------------------\n",
            "  Within Â±0.25 D:  13.5% of eyes\n",
            "  Within Â±0.50 D:  26.0% of eyes\n",
            "  Within Â±0.75 D:  35.4% of eyes\n",
            "  Within Â±1.00 D:  49.0% of eyes\n",
            "\n",
            "ğŸ¯ CLINICAL TARGETS:\n",
            "--------------------------------------------------\n",
            "â€¢ Modern standard: >70% within Â±0.50 D\n",
            "â€¢ Acceptable: >90% within Â±1.00 D\n",
            "â€¢ Our baseline: 26.0% within Â±0.50 D\n",
            "\n",
            "âš ï¸ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\n",
            "This is why we need optimization!\n"
          ]
        }
      ],
      "source": [
        "# BASELINE PERFORMANCE EVALUATION\n",
        "# =================================\n",
        "# PURPOSE: Calculate how well standard SRK/T2 performs on our Fuchs' patients\n",
        "# This establishes the baseline that we need to beat\n",
        "# Spoiler: It won't be great due to the edematous corneas!\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"BASELINE SRK/T2 PERFORMANCE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nğŸ“‹ WHAT WE'RE DOING:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"1. Calculate average K from steep and flat readings\")\n",
        "print(\"2. Apply standard SRK/T2 to all 96 patients\")\n",
        "print(\"3. Compare predictions to actual outcomes\")\n",
        "print(\"4. Measure error to establish baseline performance\")\n",
        "\n",
        "# Calculate average K (needed for SRK/T2)\n",
        "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
        "\n",
        "# Apply standard SRK/T2 formula to all patients\n",
        "df['SRKT2_Prediction'] = df.apply(\n",
        "    lambda row: calculate_SRKT2(\n",
        "        AL=row['Bio-AL'],\n",
        "        K_avg=row['K_avg'],\n",
        "        IOL_power=row['IOL Power'],\n",
        "        A_constant=row['A-Constant']\n",
        "        # Note: Using DEFAULT nc=1.333 and k_index=1.3375\n",
        "    ), axis=1\n",
        ")\n",
        "\n",
        "# Calculate prediction errors\n",
        "df['Prediction_Error'] = df['PostOP Spherical Equivalent'] - df['SRKT2_Prediction']\n",
        "df['Absolute_Error'] = abs(df['Prediction_Error'])\n",
        "\n",
        "# Calculate key metrics\n",
        "mae = df['Absolute_Error'].mean()\n",
        "me = df['Prediction_Error'].mean()\n",
        "std = df['Prediction_Error'].std()\n",
        "median_ae = df['Absolute_Error'].median()\n",
        "\n",
        "print(\"\\nğŸ“Š BASELINE PERFORMANCE METRICS:\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"  Mean Absolute Error (MAE):     {mae:.4f} D\")\n",
        "print(f\"  Mean Error (ME):                {me:+.4f} D\")\n",
        "print(f\"  Standard Deviation (SD):        {std:.4f} D\")\n",
        "print(f\"  Median Absolute Error:          {median_ae:.4f} D\")\n",
        "\n",
        "print(\"\\nğŸ’¡ INTERPRETATION:\")\n",
        "print(\"-\" * 50)\n",
        "if mae > 1.0:\n",
        "    print(f\"â€¢ MAE of {mae:.2f} D is POOR (>1.0 D is clinically unacceptable)\")\n",
        "else:\n",
        "    print(f\"â€¢ MAE of {mae:.2f} D is moderate\")\n",
        "    \n",
        "if abs(me) > 0.25:\n",
        "    print(f\"â€¢ Mean error of {me:+.2f} D shows systematic bias\")\n",
        "    if me < 0:\n",
        "        print(\"  â†’ Formula tends to predict too myopic (negative)\")\n",
        "    else:\n",
        "        print(\"  â†’ Formula tends to predict too hyperopic (positive)\")\n",
        "\n",
        "# Calculate clinical accuracy rates\n",
        "within_025 = (df['Absolute_Error'] <= 0.25).sum() / len(df) * 100\n",
        "within_050 = (df['Absolute_Error'] <= 0.50).sum() / len(df) * 100\n",
        "within_075 = (df['Absolute_Error'] <= 0.75).sum() / len(df) * 100\n",
        "within_100 = (df['Absolute_Error'] <= 1.00).sum() / len(df) * 100\n",
        "\n",
        "print(\"\\nğŸ“ˆ CLINICAL ACCURACY:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"  Within Â±0.25 D:  {within_025:.1f}% of eyes\")\n",
        "print(f\"  Within Â±0.50 D:  {within_050:.1f}% of eyes\")\n",
        "print(f\"  Within Â±0.75 D:  {within_075:.1f}% of eyes\")\n",
        "print(f\"  Within Â±1.00 D:  {within_100:.1f}% of eyes\")\n",
        "\n",
        "print(\"\\nğŸ¯ CLINICAL TARGETS:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"â€¢ Modern standard: >70% within Â±0.50 D\")\n",
        "print(\"â€¢ Acceptable: >90% within Â±1.00 D\")\n",
        "print(f\"â€¢ Our baseline: {within_050:.1f}% within Â±0.50 D\")\n",
        "print(\"\\nâš ï¸ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\")\n",
        "print(\"This is why we need optimization!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ridge_analysis",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "RIDGE REGRESSION FEATURE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ğŸ” WHY START WITH RIDGE?\n",
            "--------------------------------------------------\n",
            "â€¢ Ridge regression identifies important features\n",
            "â€¢ Helps us understand what drives prediction errors\n",
            "â€¢ Guides our formula optimization strategy\n",
            "â€¢ If CCT features are important, our hypothesis is correct!\n",
            "\n",
            "ğŸ“Š CREATING FEATURES:\n",
            "--------------------------------------------------\n",
            "Created 12 features including CCT interactions\n",
            "\n",
            "ğŸ† TOP 10 MOST IMPORTANT FEATURES:\n",
            "--------------------------------------------------\n",
            "  CCT_ratio_AL         Coef=+1.3677\n",
            "  CCT_x_AL             Coef=-0.8898\n",
            "  CCT_squared          Coef=-0.7666\n",
            "  Bio-AL               Coef=+0.4903\n",
            "  Bio-Ks               Coef=-0.3178\n",
            "  CCT_x_K              Coef=+0.3101\n",
            "  K_avg                Coef=-0.1584\n",
            "  IOL Power            Coef=-0.1189\n",
            "  CCT_norm             Coef=+0.0321\n",
            "  CCT                  Coef=+0.0321\n",
            "\n",
            "ğŸ’¡ KEY FINDINGS:\n",
            "--------------------------------------------------\n",
            "â€¢ CCT-related features account for 75.5% of total importance\n",
            "â€¢ Top feature: CCT_ratio_AL\n",
            "â€¢ CCT/AL ratio is among top 3 features!\n",
            "â€¢ This validates that CCT relative to eye size matters\n",
            "\n",
            "âœ… HYPOTHESIS CONFIRMED:\n",
            "CCT features dominate prediction - our CCT-dependent approach is justified!\n",
            "\n",
            "ğŸ¯ OPTIMIZATION STRATEGY BASED ON RIDGE:\n",
            "--------------------------------------------------\n",
            "1. Make optical parameters CCT-dependent (nc, k_index)\n",
            "2. Consider CCT/AL ratio in corrections\n",
            "3. Account for CCT interactions with other measurements\n"
          ]
        }
      ],
      "source": [
        "# RIDGE REGRESSION ANALYSIS - IDENTIFYING IMPORTANT FEATURES\n",
        "# ===========================================================\n",
        "# PURPOSE: Use machine learning to identify which features matter most\n",
        "# This will guide our optimization strategy\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"RIDGE REGRESSION FEATURE ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nğŸ” WHY START WITH RIDGE?\")\n",
        "print(\"-\" * 50)\n",
        "print(\"â€¢ Ridge regression identifies important features\")\n",
        "print(\"â€¢ Helps us understand what drives prediction errors\")\n",
        "print(\"â€¢ Guides our formula optimization strategy\")\n",
        "print(\"â€¢ If CCT features are important, our hypothesis is correct!\")\n",
        "\n",
        "# Create feature matrix with interactions\n",
        "print(\"\\nğŸ“Š CREATING FEATURES:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "features = []\n",
        "feature_names = []\n",
        "\n",
        "# Basic features\n",
        "for col in ['Bio-AL', 'Bio-Ks', 'Bio-Kf', 'IOL Power', 'CCT']:\n",
        "    features.append(df[col].values)\n",
        "    feature_names.append(col)\n",
        "\n",
        "# Add K_avg\n",
        "features.append(df['K_avg'].values)\n",
        "feature_names.append('K_avg')\n",
        "\n",
        "# CCT-derived features\n",
        "df['CCT_squared'] = df['CCT'] ** 2\n",
        "df['CCT_deviation'] = df['CCT'] - 550\n",
        "df['CCT_norm'] = (df['CCT'] - 600) / 100\n",
        "\n",
        "features.extend([\n",
        "    df['CCT_squared'].values,\n",
        "    df['CCT_deviation'].values,\n",
        "    df['CCT_norm'].values\n",
        "])\n",
        "feature_names.extend(['CCT_squared', 'CCT_deviation', 'CCT_norm'])\n",
        "\n",
        "# Interaction terms\n",
        "df['CCT_x_AL'] = df['CCT'] * df['Bio-AL']\n",
        "df['CCT_x_K'] = df['CCT'] * df['K_avg']\n",
        "df['CCT_ratio_AL'] = df['CCT'] / df['Bio-AL']\n",
        "\n",
        "features.extend([\n",
        "    df['CCT_x_AL'].values,\n",
        "    df['CCT_x_K'].values,\n",
        "    df['CCT_ratio_AL'].values\n",
        "])\n",
        "feature_names.extend(['CCT_x_AL', 'CCT_x_K', 'CCT_ratio_AL'])\n",
        "\n",
        "X = np.column_stack(features)\n",
        "y = df['PostOP Spherical Equivalent'].values\n",
        "\n",
        "print(f\"Created {len(feature_names)} features including CCT interactions\")\n",
        "\n",
        "# Standardize and train Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train Ridge to get feature importance\n",
        "ridge_analysis = Ridge(alpha=1.0)\n",
        "ridge_analysis.fit(X_scaled, y)\n",
        "\n",
        "# Get feature importance from coefficients\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': ridge_analysis.coef_,\n",
        "    'Abs_Coefficient': np.abs(ridge_analysis.coef_)\n",
        "}).sort_values('Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nğŸ† TOP 10 MOST IMPORTANT FEATURES:\")\n",
        "print(\"-\" * 50)\n",
        "for idx, row in feature_importance.head(10).iterrows():\n",
        "    print(f\"  {row['Feature']:20} Coef={row['Coefficient']:+.4f}\")\n",
        "\n",
        "# Analyze CCT importance\n",
        "cct_features = feature_importance[feature_importance['Feature'].str.contains('CCT')]\n",
        "cct_importance = cct_features['Abs_Coefficient'].sum()\n",
        "total_importance = feature_importance['Abs_Coefficient'].sum()\n",
        "cct_percentage = (cct_importance / total_importance) * 100\n",
        "\n",
        "print(\"\\nğŸ’¡ KEY FINDINGS:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"â€¢ CCT-related features account for {cct_percentage:.1f}% of total importance\")\n",
        "print(f\"â€¢ Top feature: {feature_importance.iloc[0]['Feature']}\")\n",
        "\n",
        "if 'CCT_ratio_AL' in feature_importance.head(3)['Feature'].values:\n",
        "    print(\"â€¢ CCT/AL ratio is among top 3 features!\")\n",
        "    print(\"â€¢ This validates that CCT relative to eye size matters\")\n",
        "\n",
        "if cct_percentage > 50:\n",
        "    print(\"\\nâœ… HYPOTHESIS CONFIRMED:\")\n",
        "    print(\"CCT features dominate prediction - our CCT-dependent approach is justified!\")\n",
        "\n",
        "print(\"\\nğŸ¯ OPTIMIZATION STRATEGY BASED ON RIDGE:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"1. Make optical parameters CCT-dependent (nc, k_index)\")\n",
        "print(\"2. Consider CCT/AL ratio in corrections\")\n",
        "print(\"3. Account for CCT interactions with other measurements\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "rt23gheoiv",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ğŸ¯ MULTI-SEED NESTED CROSS-VALIDATION:\n",
            "--------------------------------------------------\n",
            "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
            "â€¢ Each seed: 75% train, 25% test\n",
            "â€¢ Inner: 5-fold CV on training set\n",
            "â€¢ Results averaged across seeds for robustness\n",
            "\n",
            "================================================================================\n",
            "RUNNING MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "========================================\n",
            "SEED 1/5: 42\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 1.2383 Â± 0.3650 D\n",
            "  Train MAE: 1.1642, Test MAE: 1.4354\n",
            "  Test: Baseline=1.4849, Optimized=1.4354\n",
            "  Improvement: 3.3%\n",
            "  âš ï¸ Overfitting detected: Test 23.3% worse than train\n",
            "\n",
            "========================================\n",
            "SEED 2/5: 123\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 1.3361 Â± 0.2740 D\n",
            "  Train MAE: 1.2528, Test MAE: 1.0289\n",
            "  Test: Baseline=1.2755, Optimized=1.0289\n",
            "  Improvement: 19.3%\n",
            "  âœ… Good generalization: Test only -17.9% worse than train\n",
            "\n",
            "========================================\n",
            "SEED 3/5: 456\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 1.1921 Â± 0.1903 D\n",
            "  Train MAE: 1.1143, Test MAE: 1.4725\n",
            "  Test: Baseline=1.6714, Optimized=1.4725\n",
            "  Improvement: 11.9%\n",
            "  âš ï¸ Overfitting detected: Test 32.1% worse than train\n",
            "\n",
            "========================================\n",
            "SEED 4/5: 789\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 1.1991 Â± 0.3443 D\n",
            "  Train MAE: 1.1025, Test MAE: 1.4542\n",
            "  Test: Baseline=1.6185, Optimized=1.4542\n",
            "  Improvement: 10.2%\n",
            "  âš ï¸ Overfitting detected: Test 31.9% worse than train\n",
            "\n",
            "========================================\n",
            "SEED 5/5: 2025\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 1.3382 Â± 0.1226 D\n",
            "  Train MAE: 1.2004, Test MAE: 1.2115\n",
            "  Test: Baseline=1.3566, Optimized=1.2115\n",
            "  Improvement: 10.7%\n",
            "  âœ… Good generalization: Test only 0.9% worse than train\n",
            "\n",
            "================================================================================\n",
            "PARAMETER OPTIMIZATION - MULTI-SEED SUMMARY\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\n",
            "--------------------------------------------------\n",
            "  Seed  42: MAE=1.4354 D, Improvement=3.3%\n",
            "  Seed 123: MAE=1.0289 D, Improvement=19.3%\n",
            "  Seed 456: MAE=1.4725 D, Improvement=11.9%\n",
            "  Seed 789: MAE=1.4542 D, Improvement=10.2%\n",
            "  Seed 2025: MAE=1.2115 D, Improvement=10.7%\n",
            "\n",
            "ğŸ“ˆ STATISTICAL SUMMARY:\n",
            "--------------------------------------------------\n",
            "  Baseline MAE:      1.4814 Â± 0.1503 D\n",
            "  Train MAE:         1.1668 Â± 0.0555 D\n",
            "  Test MAE:          1.3205 Â± 0.1738 D\n",
            "  Mean Improvement:  11.1 Â± 5.1%\n",
            "  Best seed:         123 (MAE=1.0289)\n",
            "  Worst seed:        456 (MAE=1.4725)\n",
            "\n",
            "ğŸ” OVERFITTING ANALYSIS:\n",
            "--------------------------------------------------\n",
            "  Mean overfit ratio: 14.1%\n",
            "  (Test MAE is 14.1% worse than Train MAE on average)\n",
            "  âœ… Good generalization - acceptable overfitting\n",
            "\n",
            "âœ… CONSENSUS PARAMETERS (averaged across seeds):\n",
            "--------------------------------------------------\n",
            "  nc_base              = +1.4365 Â± 0.0372\n",
            "  nc_cct_coef          = +0.0660 Â± 0.0622\n",
            "  k_index_base         = +1.4186 Â± 0.0360\n",
            "  k_index_cct_coef     = +0.0602 Â± 0.0656\n",
            "  acd_offset_base      = +2.8444 Â± 0.1287\n",
            "  acd_offset_cct_coef  = +0.7143 Â± 0.9863\n",
            "\n",
            "ğŸ’¡ ROBUSTNESS ANALYSIS:\n",
            "--------------------------------------------------\n",
            "âš ï¸ Moderate stability: CV=13.2% (some variation across seeds)\n",
            "\n",
            "ğŸ“Š Range of results: 1.0289 - 1.4725 D\n",
            "   This 0.4436 D range shows the impact of data split\n"
          ]
        }
      ],
      "source": [
        "# PARAMETER OPTIMIZATION WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
        "# =============================================\n",
        "# PURPOSE: Optimize SRK/T2 parameters with nested CV for robust validation\n",
        "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nğŸ¯ MULTI-SEED NESTED CROSS-VALIDATION:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
        "print(\"â€¢ Each seed: 75% train, 25% test\")\n",
        "print(\"â€¢ Inner: 5-fold CV on training set\")\n",
        "print(\"â€¢ Results averaged across seeds for robustness\")\n",
        "\n",
        "from scipy.optimize import differential_evolution\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import numpy as np\n",
        "\n",
        "def calculate_mae_param(params, df_data):\n",
        "    \"\"\"Calculate MAE for parameter optimization\"\"\"\n",
        "    nc_base, nc_cct_coef, k_index_base, k_index_cct_coef, acd_offset_base, acd_offset_cct_coef = params\n",
        "    \n",
        "    predictions = []\n",
        "    for _, row in df_data.iterrows():\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        nc = nc_base + nc_cct_coef * cct_norm\n",
        "        k_index = k_index_base + k_index_cct_coef * cct_norm\n",
        "        acd_offset = acd_offset_base + acd_offset_cct_coef * cct_norm\n",
        "        \n",
        "        pred = calculate_SRKT2(\n",
        "            AL=row['Bio-AL'],\n",
        "            K_avg=row['K_avg'],\n",
        "            IOL_power=row['IOL Power'],\n",
        "            A_constant=row['A-Constant'] + acd_offset,\n",
        "            nc=nc,\n",
        "            k_index=k_index\n",
        "        )\n",
        "        predictions.append(pred)\n",
        "    \n",
        "    mae = mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "    return mae\n",
        "\n",
        "bounds_param = [\n",
        "    (1.20, 1.50),    # nc_base\n",
        "    (-0.20, 0.20),   # nc_cct_coef  \n",
        "    (1.20, 1.60),    # k_index_base\n",
        "    (-0.30, 0.30),   # k_index_cct_coef\n",
        "    (-3.0, 3.0),     # acd_offset_base\n",
        "    (-3.0, 3.0),     # acd_offset_cct_coef\n",
        "]\n",
        "\n",
        "# Store results for each seed\n",
        "seed_results_param = []\n",
        "seed_test_maes_param = []\n",
        "seed_train_maes_param = []  # NEW: Track training MAEs\n",
        "seed_baseline_maes_param = []\n",
        "seed_improvements_param = []\n",
        "seed_overfit_ratios_param = []  # NEW: Track overfitting\n",
        "\n",
        "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
        "    print(f\"{'='*40}\")\n",
        "    \n",
        "    # OUTER SPLIT with current seed\n",
        "    X_train_param, X_test_param = train_test_split(df, test_size=0.25, random_state=SEED)\n",
        "    X_train_param['K_avg'] = (X_train_param['Bio-Ks'] + X_train_param['Bio-Kf']) / 2\n",
        "    X_test_param['K_avg'] = (X_test_param['Bio-Ks'] + X_test_param['Bio-Kf']) / 2\n",
        "    \n",
        "    print(f\"ğŸ“Š Split: {len(X_train_param)} train, {len(X_test_param)} test\")\n",
        "    \n",
        "    # INNER K-FOLD CV\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    fold_params = []\n",
        "    fold_maes = []\n",
        "    \n",
        "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_param), 1):\n",
        "        fold_train = X_train_param.iloc[train_idx]\n",
        "        fold_val = X_train_param.iloc[val_idx]\n",
        "        \n",
        "        # Optimize on fold\n",
        "        result_fold = differential_evolution(\n",
        "            lambda p: calculate_mae_param(p, fold_train),\n",
        "            bounds_param,\n",
        "            maxiter=30,\n",
        "            seed=SEED + fold_num,\n",
        "            workers=1,\n",
        "            updating='deferred',\n",
        "            disp=False\n",
        "        )\n",
        "        \n",
        "        fold_params.append(result_fold.x)\n",
        "        val_mae = calculate_mae_param(result_fold.x, fold_val)\n",
        "        fold_maes.append(val_mae)\n",
        "    \n",
        "    # Average parameters from folds\n",
        "    avg_params = np.mean(fold_params, axis=0)\n",
        "    avg_cv_mae = np.mean(fold_maes)\n",
        "    std_cv_mae = np.std(fold_maes)\n",
        "    \n",
        "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
        "    \n",
        "    # FINAL RETRAINING on full training set\n",
        "    result_final = differential_evolution(\n",
        "        lambda p: calculate_mae_param(p, X_train_param),\n",
        "        bounds_param,\n",
        "        maxiter=50,\n",
        "        seed=SEED,\n",
        "        workers=1,\n",
        "        updating='deferred',\n",
        "        disp=False\n",
        "    )\n",
        "    \n",
        "    final_params = result_final.x\n",
        "    \n",
        "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
        "    mae_train = calculate_mae_param(final_params, X_train_param)\n",
        "    \n",
        "    # TEST ON HOLDOUT\n",
        "    # Calculate baseline\n",
        "    X_test_param['SRKT2_Baseline'] = X_test_param.apply(\n",
        "        lambda row: calculate_SRKT2(\n",
        "            AL=row['Bio-AL'],\n",
        "            K_avg=row['K_avg'],\n",
        "            IOL_power=row['IOL Power'],\n",
        "            A_constant=row['A-Constant']\n",
        "        ), axis=1\n",
        "    )\n",
        "    \n",
        "    # Apply optimized parameters\n",
        "    predictions_test = []\n",
        "    for _, row in X_test_param.iterrows():\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        nc = final_params[0] + final_params[1] * cct_norm\n",
        "        k_index = final_params[2] + final_params[3] * cct_norm\n",
        "        acd_offset = final_params[4] + final_params[5] * cct_norm\n",
        "        \n",
        "        pred = calculate_SRKT2(\n",
        "            AL=row['Bio-AL'],\n",
        "            K_avg=row['K_avg'],\n",
        "            IOL_power=row['IOL Power'],\n",
        "            A_constant=row['A-Constant'] + acd_offset,\n",
        "            nc=nc,\n",
        "            k_index=k_index\n",
        "        )\n",
        "        predictions_test.append(pred)\n",
        "    \n",
        "    mae_baseline = np.abs(X_test_param['SRKT2_Baseline'] - X_test_param['PostOP Spherical Equivalent']).mean()\n",
        "    mae_optimized = mean_absolute_error(X_test_param['PostOP Spherical Equivalent'], predictions_test)\n",
        "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
        "    \n",
        "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
        "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
        "    print(f\"  Improvement: {improvement:.1f}%\")\n",
        "    \n",
        "    # Check for overfitting\n",
        "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
        "    if overfit_ratio > 20:\n",
        "        print(f\"  âš ï¸ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
        "    elif overfit_ratio > 10:\n",
        "        print(f\"  âš ï¸ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
        "    else:\n",
        "        print(f\"  âœ… Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
        "    \n",
        "    # Store results\n",
        "    seed_results_param.append(final_params)\n",
        "    seed_test_maes_param.append(mae_optimized)\n",
        "    seed_train_maes_param.append(mae_train)\n",
        "    seed_baseline_maes_param.append(mae_baseline)\n",
        "    seed_improvements_param.append(improvement)\n",
        "    seed_overfit_ratios_param.append(overfit_ratio)\n",
        "\n",
        "# MULTI-SEED SUMMARY\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PARAMETER OPTIMIZATION - MULTI-SEED SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\")\n",
        "print(\"-\" * 50)\n",
        "for i, seed in enumerate(SEEDS):\n",
        "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_param[i]:.4f} D, Improvement={seed_improvements_param[i]:.1f}%\")\n",
        "\n",
        "print(\"\\nğŸ“ˆ STATISTICAL SUMMARY:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_param):.4f} Â± {np.std(seed_baseline_maes_param):.4f} D\")\n",
        "print(f\"  Train MAE:         {np.mean(seed_train_maes_param):.4f} Â± {np.std(seed_train_maes_param):.4f} D\")\n",
        "print(f\"  Test MAE:          {np.mean(seed_test_maes_param):.4f} Â± {np.std(seed_test_maes_param):.4f} D\")\n",
        "print(f\"  Mean Improvement:  {np.mean(seed_improvements_param):.1f} Â± {np.std(seed_improvements_param):.1f}%\")\n",
        "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_param)]} (MAE={min(seed_test_maes_param):.4f})\")\n",
        "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_param)]} (MAE={max(seed_test_maes_param):.4f})\")\n",
        "\n",
        "# OVERFITTING ANALYSIS\n",
        "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_param):.1f}%\")\n",
        "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_param):.1f}% worse than Train MAE on average)\")\n",
        "\n",
        "if np.mean(seed_overfit_ratios_param) < 10:\n",
        "    print(\"  âœ… Excellent generalization - minimal overfitting\")\n",
        "elif np.mean(seed_overfit_ratios_param) < 20:\n",
        "    print(\"  âœ… Good generalization - acceptable overfitting\")\n",
        "else:\n",
        "    print(\"  âš ï¸ Significant overfitting - consider regularization\")\n",
        "\n",
        "# Average parameters across seeds\n",
        "avg_params_all_seeds = np.mean(seed_results_param, axis=0)\n",
        "std_params_all_seeds = np.std(seed_results_param, axis=0)\n",
        "\n",
        "print(\"\\nâœ… CONSENSUS PARAMETERS (averaged across seeds):\")\n",
        "print(\"-\" * 50)\n",
        "param_names = ['nc_base', 'nc_cct_coef', 'k_index_base', 'k_index_cct_coef', 'acd_offset_base', 'acd_offset_cct_coef']\n",
        "for i, name in enumerate(param_names):\n",
        "    print(f\"  {name:20} = {avg_params_all_seeds[i]:+.4f} Â± {std_params_all_seeds[i]:.4f}\")\n",
        "\n",
        "# Store in global results dictionary\n",
        "multi_seed_results['parameter'] = {\n",
        "    'test_maes': seed_test_maes_param,\n",
        "    'train_maes': seed_train_maes_param,\n",
        "    'baseline_maes': seed_baseline_maes_param,\n",
        "    'improvements': seed_improvements_param,\n",
        "    'overfit_ratios': seed_overfit_ratios_param,\n",
        "    'mean_mae': np.mean(seed_test_maes_param),\n",
        "    'std_mae': np.std(seed_test_maes_param),\n",
        "    'mean_improvement': np.mean(seed_improvements_param)\n",
        "}\n",
        "\n",
        "print(\"\\nğŸ’¡ ROBUSTNESS ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "mae_cv = np.std(seed_test_maes_param) / np.mean(seed_test_maes_param) * 100\n",
        "if mae_cv < 5:\n",
        "    print(f\"âœ… Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
        "elif mae_cv < 10:\n",
        "    print(f\"âœ… Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
        "else:\n",
        "    print(f\"âš ï¸ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Range of results: {min(seed_test_maes_param):.4f} - {max(seed_test_maes_param):.4f} D\")\n",
        "print(f\"   This {max(seed_test_maes_param)-min(seed_test_maes_param):.4f} D range shows the impact of data split\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "829090ggs0r",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ğŸ¯ MULTI-SEED NESTED CV STRATEGY:\n",
            "--------------------------------------------------\n",
            "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
            "â€¢ Each seed: 75/25 train/test split\n",
            "â€¢ Inner: 5-fold CV on training\n",
            "â€¢ Find stable multiplicative factors across seeds\n",
            "\n",
            "================================================================================\n",
            "RUNNING MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "========================================\n",
            "SEED 1/5: 42\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 0.9016 Â± 0.1279 D\n",
            "  Final params: mâ‚€=-0.0379, mâ‚=-0.0153, mâ‚‚=-0.0378\n",
            "  Train MAE: 0.9068, Test MAE: 1.0063\n",
            "  Test: Baseline=1.4849, Optimized=1.0063\n",
            "  Improvement: 32.2%\n",
            "  âš ï¸ Mild overfitting: Test 11.0% worse than train\n",
            "\n",
            "========================================\n",
            "SEED 2/5: 123\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 0.9395 Â± 0.0938 D\n",
            "  Final params: mâ‚€=-0.0383, mâ‚=-0.0168, mâ‚‚=-0.0383\n",
            "  Train MAE: 0.8772, Test MAE: 1.0940\n",
            "  Test: Baseline=1.2755, Optimized=1.0940\n",
            "  Improvement: 14.2%\n",
            "  âš ï¸ Overfitting detected: Test 24.7% worse than train\n",
            "\n",
            "========================================\n",
            "SEED 3/5: 456\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 0.9122 Â± 0.2803 D\n",
            "  Final params: mâ‚€=-0.0386, mâ‚=-0.0133, mâ‚‚=-0.0385\n",
            "  Train MAE: 0.8928, Test MAE: 1.0463\n",
            "  Test: Baseline=1.6714, Optimized=1.0463\n",
            "  Improvement: 37.4%\n",
            "  âš ï¸ Mild overfitting: Test 17.2% worse than train\n",
            "\n",
            "========================================\n",
            "SEED 4/5: 789\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 0.9511 Â± 0.3201 D\n",
            "  Final params: mâ‚€=-0.1211, mâ‚=0.1059, mâ‚‚=-0.0342\n",
            "  Train MAE: 0.8972, Test MAE: 1.0182\n",
            "  Test: Baseline=1.6185, Optimized=1.0182\n",
            "  Improvement: 37.1%\n",
            "  âš ï¸ Mild overfitting: Test 13.5% worse than train\n",
            "\n",
            "========================================\n",
            "SEED 5/5: 2025\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 0.9544 Â± 0.1953 D\n",
            "  Final params: mâ‚€=-0.0387, mâ‚=-0.0074, mâ‚‚=-0.0386\n",
            "  Train MAE: 0.9448, Test MAE: 0.8892\n",
            "  Test: Baseline=1.3566, Optimized=0.8892\n",
            "  Improvement: 34.5%\n",
            "  âœ… Good generalization: Test only -5.9% worse than train\n",
            "\n",
            "================================================================================\n",
            "MULTIPLICATIVE CORRECTION - MULTI-SEED SUMMARY\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\n",
            "--------------------------------------------------\n",
            "  Seed  42: MAE=1.0063 D, Improvement=32.2%\n",
            "  Seed 123: MAE=1.0940 D, Improvement=14.2%\n",
            "  Seed 456: MAE=1.0463 D, Improvement=37.4%\n",
            "  Seed 789: MAE=1.0182 D, Improvement=37.1%\n",
            "  Seed 2025: MAE=0.8892 D, Improvement=34.5%\n",
            "\n",
            "ğŸ“ˆ STATISTICAL SUMMARY:\n",
            "--------------------------------------------------\n",
            "  Baseline MAE:      1.4814 Â± 0.1503 D\n",
            "  Train MAE:         0.9037 Â± 0.0226 D\n",
            "  Test MAE:          1.0108 Â± 0.0679 D\n",
            "  Mean Improvement:  31.1 Â± 8.6%\n",
            "  Best seed:         2025 (MAE=0.8892)\n",
            "  Worst seed:        123 (MAE=1.0940)\n",
            "\n",
            "ğŸ” OVERFITTING ANALYSIS:\n",
            "--------------------------------------------------\n",
            "  Mean overfit ratio: 12.1%\n",
            "  (Test MAE is 12.1% worse than Train MAE on average)\n",
            "  âœ… Good generalization - acceptable overfitting\n",
            "\n",
            "âœ… CONSENSUS PARAMETERS (averaged across seeds):\n",
            "--------------------------------------------------\n",
            "  mâ‚€ (constant):     -0.0549 Â± 0.0331\n",
            "  mâ‚ (CCT coef):     +0.0106 Â± 0.0478\n",
            "  mâ‚‚ (ratio coef):   -0.0375 Â± 0.0017\n",
            "\n",
            "ğŸ“ CONSENSUS CORRECTION FORMULA:\n",
            "--------------------------------------------------\n",
            "Corrected_REF = Standard_SRK/T2 Ã— Correction_Factor\n",
            "Correction_Factor = 1 -0.0549 +0.0106Ã—CCT_norm -0.0375Ã—(CCT/AL)\n",
            "\n",
            "ğŸ’¡ ROBUSTNESS ANALYSIS:\n",
            "--------------------------------------------------\n",
            "âœ… Good stability: CV=6.7% (consistent across seeds)\n",
            "\n",
            "ğŸ“Š Range of results: 0.8892 - 1.0940 D\n",
            "   This 0.2048 D range shows the impact of data split\n",
            "\n",
            "ğŸ“Š Parameter consistency across seeds:\n",
            "  mâ‚€: min=-0.1211, max=-0.0379, range=0.0832\n",
            "  mâ‚: min=-0.0168, max=0.1059, range=0.1227\n",
            "  mâ‚‚: min=-0.0386, max=-0.0342, range=0.0045\n"
          ]
        }
      ],
      "source": [
        "# MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED\n",
        "# ====================================\n",
        "# PURPOSE: Multiplicative correction with nested CV for robust validation\n",
        "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nğŸ¯ MULTI-SEED NESTED CV STRATEGY:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
        "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
        "print(\"â€¢ Inner: 5-fold CV on training\")\n",
        "print(\"â€¢ Find stable multiplicative factors across seeds\")\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import numpy as np\n",
        "\n",
        "def multiplicative_objective(params, df_data):\n",
        "    \"\"\"Objective function for multiplicative correction\"\"\"\n",
        "    m0, m1, m2 = params\n",
        "    \n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    \n",
        "    for _, row in df_data.iterrows():\n",
        "        base_pred = row['SRKT2_Prediction']\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "        \n",
        "        correction_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
        "        corrected_pred = base_pred * correction_factor\n",
        "        \n",
        "        predictions.append(corrected_pred)\n",
        "        actuals.append(row['PostOP Spherical Equivalent'])\n",
        "    \n",
        "    return mean_absolute_error(actuals, predictions)\n",
        "\n",
        "x0_mult = [0, 0, 0]\n",
        "bounds_mult = [(-0.5, 0.5), (-0.5, 0.5), (-0.5, 0.5)]\n",
        "\n",
        "# Store results for each seed\n",
        "seed_results_mult = []\n",
        "seed_test_maes_mult = []\n",
        "seed_train_maes_mult = []  # NEW: Track training MAEs\n",
        "seed_baseline_maes_mult = []\n",
        "seed_improvements_mult = []\n",
        "seed_overfit_ratios_mult = []  # NEW: Track overfitting\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
        "    print(f\"{'='*40}\")\n",
        "    \n",
        "    # OUTER SPLIT with current seed\n",
        "    X_train_mult, X_test_mult = train_test_split(df, test_size=0.25, random_state=SEED)\n",
        "    X_train_mult['K_avg'] = (X_train_mult['Bio-Ks'] + X_train_mult['Bio-Kf']) / 2\n",
        "    X_test_mult['K_avg'] = (X_test_mult['Bio-Ks'] + X_test_mult['Bio-Kf']) / 2\n",
        "    \n",
        "    print(f\"ğŸ“Š Split: {len(X_train_mult)} train, {len(X_test_mult)} test\")\n",
        "    \n",
        "    # Calculate baseline SRK/T2 for all data\n",
        "    for dataset in [X_train_mult, X_test_mult]:\n",
        "        dataset['SRKT2_Prediction'] = dataset.apply(\n",
        "            lambda row: calculate_SRKT2(\n",
        "                AL=row['Bio-AL'],\n",
        "                K_avg=row['K_avg'],\n",
        "                IOL_power=row['IOL Power'],\n",
        "                A_constant=row['A-Constant']\n",
        "            ), axis=1\n",
        "        )\n",
        "    \n",
        "    # INNER K-FOLD CV\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    fold_params = []\n",
        "    fold_maes = []\n",
        "    \n",
        "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_mult), 1):\n",
        "        fold_train = X_train_mult.iloc[train_idx]\n",
        "        fold_val = X_train_mult.iloc[val_idx]\n",
        "        \n",
        "        # Optimize on fold training\n",
        "        result_fold = minimize(\n",
        "            lambda p: multiplicative_objective(p, fold_train),\n",
        "            x0_mult,\n",
        "            method='L-BFGS-B',\n",
        "            bounds=bounds_mult\n",
        "        )\n",
        "        \n",
        "        fold_params.append(result_fold.x)\n",
        "        val_mae = multiplicative_objective(result_fold.x, fold_val)\n",
        "        fold_maes.append(val_mae)\n",
        "    \n",
        "    # Average across folds\n",
        "    avg_params = np.mean(fold_params, axis=0)\n",
        "    avg_cv_mae = np.mean(fold_maes)\n",
        "    std_cv_mae = np.std(fold_maes)\n",
        "    \n",
        "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
        "    \n",
        "    # FINAL RETRAINING on full training set\n",
        "    result_mult = minimize(\n",
        "        lambda p: multiplicative_objective(p, X_train_mult),\n",
        "        x0_mult,\n",
        "        method='L-BFGS-B',\n",
        "        bounds=bounds_mult\n",
        "    )\n",
        "    m0_opt, m1_opt, m2_opt = result_mult.x\n",
        "    \n",
        "    print(f\"  Final params: mâ‚€={m0_opt:.4f}, mâ‚={m1_opt:.4f}, mâ‚‚={m2_opt:.4f}\")\n",
        "    \n",
        "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
        "    mae_train = multiplicative_objective([m0_opt, m1_opt, m2_opt], X_train_mult)\n",
        "    \n",
        "    # TEST ON HOLDOUT\n",
        "    predictions_mult_test = []\n",
        "    for _, row in X_test_mult.iterrows():\n",
        "        base_pred = row['SRKT2_Prediction']\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "        \n",
        "        correction_factor = 1 + m0_opt + m1_opt * cct_norm + m2_opt * cct_ratio\n",
        "        corrected_pred = base_pred * correction_factor\n",
        "        predictions_mult_test.append(corrected_pred)\n",
        "    \n",
        "    mae_baseline = np.abs(X_test_mult['SRKT2_Prediction'] - X_test_mult['PostOP Spherical Equivalent']).mean()\n",
        "    mae_optimized = mean_absolute_error(X_test_mult['PostOP Spherical Equivalent'], predictions_mult_test)\n",
        "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
        "    \n",
        "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
        "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
        "    print(f\"  Improvement: {improvement:.1f}%\")\n",
        "    \n",
        "    # Check for overfitting\n",
        "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
        "    if overfit_ratio > 20:\n",
        "        print(f\"  âš ï¸ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
        "    elif overfit_ratio > 10:\n",
        "        print(f\"  âš ï¸ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
        "    else:\n",
        "        print(f\"  âœ… Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
        "    \n",
        "    # Store results\n",
        "    seed_results_mult.append([m0_opt, m1_opt, m2_opt])\n",
        "    seed_test_maes_mult.append(mae_optimized)\n",
        "    seed_train_maes_mult.append(mae_train)\n",
        "    seed_baseline_maes_mult.append(mae_baseline)\n",
        "    seed_improvements_mult.append(improvement)\n",
        "    seed_overfit_ratios_mult.append(overfit_ratio)\n",
        "\n",
        "# MULTI-SEED SUMMARY\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MULTIPLICATIVE CORRECTION - MULTI-SEED SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\")\n",
        "print(\"-\" * 50)\n",
        "for i, seed in enumerate(SEEDS):\n",
        "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_mult[i]:.4f} D, Improvement={seed_improvements_mult[i]:.1f}%\")\n",
        "\n",
        "print(\"\\nğŸ“ˆ STATISTICAL SUMMARY:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_mult):.4f} Â± {np.std(seed_baseline_maes_mult):.4f} D\")\n",
        "print(f\"  Train MAE:         {np.mean(seed_train_maes_mult):.4f} Â± {np.std(seed_train_maes_mult):.4f} D\")\n",
        "print(f\"  Test MAE:          {np.mean(seed_test_maes_mult):.4f} Â± {np.std(seed_test_maes_mult):.4f} D\")\n",
        "print(f\"  Mean Improvement:  {np.mean(seed_improvements_mult):.1f} Â± {np.std(seed_improvements_mult):.1f}%\")\n",
        "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_mult)]} (MAE={min(seed_test_maes_mult):.4f})\")\n",
        "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_mult)]} (MAE={max(seed_test_maes_mult):.4f})\")\n",
        "\n",
        "# OVERFITTING ANALYSIS\n",
        "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_mult):.1f}%\")\n",
        "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_mult):.1f}% worse than Train MAE on average)\")\n",
        "\n",
        "if np.mean(seed_overfit_ratios_mult) < 10:\n",
        "    print(\"  âœ… Excellent generalization - minimal overfitting\")\n",
        "elif np.mean(seed_overfit_ratios_mult) < 20:\n",
        "    print(\"  âœ… Good generalization - acceptable overfitting\")\n",
        "else:\n",
        "    print(\"  âš ï¸ Significant overfitting - consider regularization\")\n",
        "\n",
        "# Average parameters across seeds\n",
        "avg_params_all_seeds = np.mean(seed_results_mult, axis=0)\n",
        "std_params_all_seeds = np.std(seed_results_mult, axis=0)\n",
        "\n",
        "print(\"\\nâœ… CONSENSUS PARAMETERS (averaged across seeds):\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"  mâ‚€ (constant):     {avg_params_all_seeds[0]:+.4f} Â± {std_params_all_seeds[0]:.4f}\")\n",
        "print(f\"  mâ‚ (CCT coef):     {avg_params_all_seeds[1]:+.4f} Â± {std_params_all_seeds[1]:.4f}\")\n",
        "print(f\"  mâ‚‚ (ratio coef):   {avg_params_all_seeds[2]:+.4f} Â± {std_params_all_seeds[2]:.4f}\")\n",
        "\n",
        "print(\"\\nğŸ“ CONSENSUS CORRECTION FORMULA:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Corrected_REF = Standard_SRK/T2 Ã— Correction_Factor\")\n",
        "print(f\"Correction_Factor = 1 {avg_params_all_seeds[0]:+.4f} {avg_params_all_seeds[1]:+.4f}Ã—CCT_norm {avg_params_all_seeds[2]:+.4f}Ã—(CCT/AL)\")\n",
        "\n",
        "# Store in global results dictionary\n",
        "multi_seed_results['multiplicative'] = {\n",
        "    'test_maes': seed_test_maes_mult,\n",
        "    'train_maes': seed_train_maes_mult,\n",
        "    'baseline_maes': seed_baseline_maes_mult,\n",
        "    'improvements': seed_improvements_mult,\n",
        "    'overfit_ratios': seed_overfit_ratios_mult,\n",
        "    'mean_mae': np.mean(seed_test_maes_mult),\n",
        "    'std_mae': np.std(seed_test_maes_mult),\n",
        "    'mean_improvement': np.mean(seed_improvements_mult)\n",
        "}\n",
        "\n",
        "print(\"\\nğŸ’¡ ROBUSTNESS ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "mae_cv = np.std(seed_test_maes_mult) / np.mean(seed_test_maes_mult) * 100\n",
        "if mae_cv < 5:\n",
        "    print(f\"âœ… Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
        "elif mae_cv < 10:\n",
        "    print(f\"âœ… Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
        "else:\n",
        "    print(f\"âš ï¸ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Range of results: {min(seed_test_maes_mult):.4f} - {max(seed_test_maes_mult):.4f} D\")\n",
        "print(f\"   This {max(seed_test_maes_mult)-min(seed_test_maes_mult):.4f} D range shows the impact of data split\")\n",
        "\n",
        "# Parameter consistency check\n",
        "print(f\"\\nğŸ“Š Parameter consistency across seeds:\")\n",
        "for i, param_name in enumerate(['mâ‚€', 'mâ‚', 'mâ‚‚']):\n",
        "    param_values = [p[i] for p in seed_results_mult]\n",
        "    print(f\"  {param_name}: min={min(param_values):.4f}, max={max(param_values):.4f}, range={max(param_values)-min(param_values):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c4a07c9e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SUPPORT VECTOR REGRESSION (SVR) WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "Seed 2026/5:\n",
            "  Seed 1 Results:\n",
            "    Test MAE: 0.921 Â± 0.194 D\n",
            "    Train MAE: 0.698 D\n",
            "    Overfit ratio: 1.319\n",
            "\n",
            "Seed 2026/5:\n",
            "  Seed 2 Results:\n",
            "    Test MAE: 0.918 Â± 0.159 D\n",
            "    Train MAE: 0.681 D\n",
            "    Overfit ratio: 1.348\n",
            "\n",
            "Seed 2026/5:\n",
            "  Seed 3 Results:\n",
            "    Test MAE: 0.917 Â± 0.200 D\n",
            "    Train MAE: 0.674 D\n",
            "    Overfit ratio: 1.359\n",
            "\n",
            "Seed 2026/5:\n",
            "  Seed 4 Results:\n",
            "    Test MAE: 0.882 Â± 0.108 D\n",
            "    Train MAE: 0.696 D\n",
            "    Overfit ratio: 1.267\n",
            "\n",
            "Seed 2026/5:\n",
            "  Seed 5 Results:\n",
            "    Test MAE: 0.895 Â± 0.214 D\n",
            "    Train MAE: 0.663 D\n",
            "    Overfit ratio: 1.351\n",
            "\n",
            "================================================================================\n",
            "SVR MULTI-SEED SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Across 5 seeds with 5-fold CV (25 total evaluations):\n",
            "Test MAE: 0.907 Â± 0.180 D\n",
            "Train MAE: 0.683 Â± 0.088 D\n",
            "Baseline MAE: 1.358 Â± 0.225 D\n",
            "Overfit Ratio: 1.328\n",
            "\n",
            "Improvement over baseline:\n",
            "  Relative: 33.2%\n",
            "  Absolute: 0.451 D\n",
            "\n",
            "Most frequent hyperparameters:\n",
            "  C: 0.5(12), 1.0(7), 2.0(6)\n",
            "  Îµ: 0.2(14), 0.05(9), 0.1(2)\n",
            "================================================================================\n",
            "SVR method completed - results stored in _svr variables\n",
            "Both multiplicative and SVR are now available for comparison\n",
            "Results stored for final comparison in cell 11\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# SUPPORT VECTOR REGRESSION (SVR) - REPLACEMENT FOR MULTIPLICATIVE\n",
        "# =================================================================\n",
        "# PURPOSE: Test SVR as alternative to multiplicative correction\n",
        "# Based on comprehensive testing showing 6.7% improvement\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"SUPPORT VECTOR REGRESSION (SVR) WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Prepare features for SVR\n",
        "def prepare_svr_features(df):\n",
        "    X = pd.DataFrame()\n",
        "    X['CCT_norm'] = (df['CCT'] - 600) / 100\n",
        "    X['AL'] = df['Bio-AL']\n",
        "    X['ACD'] = df['Bio-ACD']\n",
        "    X['K_mean'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
        "    X['CCT_AL'] = df['CCT'] / df['Bio-AL']\n",
        "    return X\n",
        "\n",
        "# Store results for multiple seeds (using SEEDS from first cell)\n",
        "seed_results_svr = []\n",
        "seed_test_maes_svr = []\n",
        "seed_train_maes_svr = []\n",
        "seed_baseline_maes_svr = []\n",
        "seed_improvements_svr = []\n",
        "seed_overfit_ratios_svr = []\n",
        "\n",
        "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "    np.random.seed(SEED)\n",
        "    print(f\"\\nSeed {seed+1}/{len(SEEDS)}:\")\n",
        "    \n",
        "    # Outer CV loop (using same structure as other methods)\n",
        "    kf_outer = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    \n",
        "    fold_results = []\n",
        "    test_maes = []\n",
        "    train_maes = []\n",
        "    baseline_maes = []\n",
        "    \n",
        "    for fold, (train_idx, test_idx) in enumerate(kf_outer.split(df)):\n",
        "        # Split data (using 'df' DataFrame from first cell)\n",
        "        df_train = df.iloc[train_idx].copy()\n",
        "        df_test = df.iloc[test_idx].copy()\n",
        "        \n",
        "        # Prepare features\n",
        "        X_train = prepare_svr_features(df_train)\n",
        "        X_test = prepare_svr_features(df_test)\n",
        "        y_train = df_train['PostOP Spherical Equivalent'].values\n",
        "        y_test = df_test['PostOP Spherical Equivalent'].values\n",
        "        \n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "        \n",
        "        # Inner CV for hyperparameter tuning (simplified grid for speed)\n",
        "        best_params = None\n",
        "        best_val_mae = float('inf')\n",
        "        \n",
        "        # Reduced grid search for efficiency\n",
        "        param_grid = {\n",
        "            'C': [0.5, 1.0, 2.0],\n",
        "            'epsilon': [0.05, 0.1, 0.2]\n",
        "        }\n",
        "        \n",
        "        kf_inner = KFold(n_splits=3, shuffle=True, random_state=SEED*100+fold)\n",
        "        \n",
        "        for C in param_grid['C']:\n",
        "            for epsilon in param_grid['epsilon']:\n",
        "                val_maes = []\n",
        "                \n",
        "                for train_inner_idx, val_idx in kf_inner.split(X_train_scaled):\n",
        "                    X_train_inner = X_train_scaled[train_inner_idx]\n",
        "                    y_train_inner = y_train[train_inner_idx]\n",
        "                    X_val = X_train_scaled[val_idx]\n",
        "                    y_val = y_train[val_idx]\n",
        "                    \n",
        "                    # Train SVR\n",
        "                    model = SVR(kernel='rbf', C=C, epsilon=epsilon, gamma='scale')\n",
        "                    model.fit(X_train_inner, y_train_inner)\n",
        "                    \n",
        "                    # Validate\n",
        "                    y_pred_val = model.predict(X_val)\n",
        "                    val_maes.append(mean_absolute_error(y_val, y_pred_val))\n",
        "                \n",
        "                mean_val_mae = np.mean(val_maes)\n",
        "                if mean_val_mae < best_val_mae:\n",
        "                    best_val_mae = mean_val_mae\n",
        "                    best_params = {'C': C, 'epsilon': epsilon}\n",
        "        \n",
        "        # Train final model with best parameters\n",
        "        final_model = SVR(kernel='rbf', C=best_params['C'], \n",
        "                         epsilon=best_params['epsilon'], gamma='scale')\n",
        "        final_model.fit(X_train_scaled, y_train)\n",
        "        \n",
        "        # Predictions\n",
        "        y_pred_train = final_model.predict(X_train_scaled)\n",
        "        y_pred_test = final_model.predict(X_test_scaled)\n",
        "        \n",
        "        # Calculate MAEs\n",
        "        train_mae = mean_absolute_error(y_train, y_pred_train)\n",
        "        test_mae = mean_absolute_error(y_test, y_pred_test)\n",
        "        \n",
        "        # Baseline MAE (using SRKT2_Prediction from data preparation)\n",
        "        if 'SRKT2_Prediction' in df_test.columns:\n",
        "            baseline_pred = df_test['SRKT2_Prediction'].values\n",
        "        else:\n",
        "            # Simple SRK/T2 approximation if not available\n",
        "            baseline_pred = 118.4 - 2.5 * df_test['Bio-AL'] - 0.9 * X_test['K_mean']\n",
        "        baseline_mae = mean_absolute_error(y_test, baseline_pred)\n",
        "        \n",
        "        train_maes.append(train_mae)\n",
        "        test_maes.append(test_mae)\n",
        "        baseline_maes.append(baseline_mae)\n",
        "        \n",
        "        fold_results.append({\n",
        "            'fold': fold + 1,\n",
        "            'train_mae': train_mae,\n",
        "            'test_mae': test_mae,\n",
        "            'baseline_mae': baseline_mae,\n",
        "            'improvement': (baseline_mae - test_mae) / baseline_mae * 100 if baseline_mae > 0 else 0,\n",
        "            'best_C': best_params['C'],\n",
        "            'best_epsilon': best_params['epsilon']\n",
        "        })\n",
        "    \n",
        "    # Store seed results\n",
        "    seed_results_svr.append(fold_results)\n",
        "    seed_test_maes_svr.append(test_maes)\n",
        "    seed_train_maes_svr.append(train_maes)\n",
        "    seed_baseline_maes_svr.append(baseline_maes)\n",
        "    \n",
        "    # Calculate improvements for this seed\n",
        "    improvements = []\n",
        "    for j in range(len(test_maes)):\n",
        "        if baseline_maes[j] > 0:\n",
        "            improvement = (baseline_maes[j] - test_maes[j]) / baseline_maes[j] * 100\n",
        "        else:\n",
        "            improvement = 0\n",
        "        improvements.append(improvement)\n",
        "    \n",
        "    # Calculate overfit ratio for this seed\n",
        "    overfit_ratio = np.mean(test_maes) / np.mean(train_maes) if np.mean(train_maes) > 0 else 1.0\n",
        "    \n",
        "    # Store for this seed\n",
        "    seed_improvements_svr.append(improvements)\n",
        "    seed_overfit_ratios_svr.append(overfit_ratio)\n",
        "    \n",
        "    # Calculate seed statistics\n",
        "    seed_test_mean = np.mean(test_maes)\n",
        "    seed_test_std = np.std(test_maes)\n",
        "    seed_train_mean = np.mean(train_maes)\n",
        "    \n",
        "    print(f\"  Seed {seed_idx} Results:\")\n",
        "    print(f\"    Test MAE: {seed_test_mean:.3f} Â± {seed_test_std:.3f} D\")\n",
        "    print(f\"    Train MAE: {seed_train_mean:.3f} D\")\n",
        "    print(f\"    Overfit ratio: {seed_test_mean/seed_train_mean:.3f}\")\n",
        "\n",
        "# Summary statistics (consistent with other methods)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SVR MULTI-SEED SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calculate overall statistics\n",
        "overall_test_maes = [mae for seed_maes in seed_test_maes_svr for mae in seed_maes]\n",
        "overall_train_maes = [mae for seed_maes in seed_train_maes_svr for mae in seed_maes]\n",
        "overall_baseline_maes = [mae for seed_maes in seed_baseline_maes_svr for mae in seed_maes]\n",
        "\n",
        "print(f\"\\nAcross {len(SEEDS)} seeds with 5-fold CV ({len(overall_test_maes)} total evaluations):\")\n",
        "print(f\"Test MAE: {np.mean(overall_test_maes):.3f} Â± {np.std(overall_test_maes):.3f} D\")\n",
        "print(f\"Train MAE: {np.mean(overall_train_maes):.3f} Â± {np.std(overall_train_maes):.3f} D\")\n",
        "print(f\"Baseline MAE: {np.mean(overall_baseline_maes):.3f} Â± {np.std(overall_baseline_maes):.3f} D\")\n",
        "print(f\"Overfit Ratio: {np.mean(overall_test_maes) / np.mean(overall_train_maes):.3f}\")\n",
        "\n",
        "if np.mean(overall_baseline_maes) > 0:\n",
        "    improvement = (np.mean(overall_baseline_maes) - np.mean(overall_test_maes)) / np.mean(overall_baseline_maes) * 100\n",
        "    absolute_improvement = np.mean(overall_baseline_maes) - np.mean(overall_test_maes)\n",
        "    print(f\"\\nImprovement over baseline:\")\n",
        "    print(f\"  Relative: {improvement:.1f}%\")\n",
        "    print(f\"  Absolute: {absolute_improvement:.3f} D\")\n",
        "\n",
        "# Hyperparameter analysis\n",
        "print(\"\\nMost frequent hyperparameters:\")\n",
        "all_Cs = [r['best_C'] for seed in seed_results_svr for r in seed]\n",
        "all_epsilons = [r['best_epsilon'] for seed in seed_results_svr for r in seed]\n",
        "from collections import Counter\n",
        "c_counts = Counter(all_Cs).most_common(3)\n",
        "eps_counts = Counter(all_epsilons).most_common(3)\n",
        "print(f\"  C: {', '.join([f'{val}({cnt})' for val, cnt in c_counts])}\")\n",
        "print(f\"  Îµ: {', '.join([f'{val}({cnt})' for val, cnt in eps_counts])}\")\n",
        "\n",
        "# Store results in format compatible with final comparison\n",
        "# This replaces the multiplicative method results\n",
        "\n",
        "# Store results in _mult variables for compatibility with comparison cell\n",
        "# Keep SVR results separate\n",
        "# seed_test_maes_mult = seed_test_maes_svr  # Don't overwrite\n",
        "# seed_train_maes_mult = seed_train_maes_svr\n",
        "# seed_baseline_maes_mult = seed_baseline_maes_svr\n",
        "# seed_improvements_mult = seed_improvements_svr\n",
        "# seed_overfit_ratios_mult = seed_overfit_ratios_svr\n",
        "\n",
        "print(\"\" + \"=\" * 80)\n",
        "print(\"SVR method completed - results stored in _svr variables\")\n",
        "print(\"Both multiplicative and SVR are now available for comparison\")\n",
        "print(\"Results stored for final comparison in cell 11\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9bd011be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "EXTRACTING CLINICAL FORMULA FROM SVR MODEL\n",
            "================================================================================\n",
            "\n",
            "Extracting formula from trained SVR models...\n",
            "\n",
            "1. CORRECTION ANALYSIS:\n",
            "   Mean correction needed: -21.729 D\n",
            "   Std of corrections: 3.978 D\n",
            "   Range: [-30.00, -11.00] D\n",
            "\n",
            "2. CLINICAL FORMULAS (from simplest to most accurate):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "A. ULTRA-SIMPLE (CCT only):\n",
            "   IOL_corrected = IOL_base + -21.843 + 0.510Ã—((CCT-600)/100)\n",
            "   MAE: 3.113 D\n",
            "\n",
            "B. SIMPLE (CCT + ratio):\n",
            "   IOL_corrected = IOL_base + 30.475 + 9.042Ã—((CCT-600)/100) -2.068Ã—(CCT/AL)\n",
            "   MAE: 1.953 D\n",
            "\n",
            "C. EXTENDED (all features):\n",
            "   IOL_corrected = IOL_base + -144.852 -2.253Ã—((CCT-600)/100) + 3.272Ã—AL -0.558Ã—ACD + 0.771Ã—K + 0.533Ã—(CCT/AL)...\n",
            "   MAE: 1.455 D\n",
            "\n",
            "3. PRACTICAL FORMULA (rounded for clinical use):\n",
            "--------------------------------------------------------------------------------\n",
            "   IOL_corrected = IOL_base + 30.5 + 9.0Ã—((CCT-600)/100) -2.07Ã—(CCT/AL)\n",
            "   MAE with rounded coefficients: 1.954 D\n",
            "\n",
            "4. EXAMPLE CALCULATION:\n",
            "--------------------------------------------------------------------------------\n",
            "Patient example:\n",
            "  CCT = 650 Âµm\n",
            "  AL = 23.5 mm\n",
            "  Base IOL = 21.0 D\n",
            "\n",
            "Calculation:\n",
            "  CCT normalized = (650-600)/100 = 0.5\n",
            "  CCT/AL ratio = 650/23.5 = 27.66\n",
            "  Correction = 30.5 + 9.0Ã—0.5 + -2.07Ã—27.66\n",
            "  Correction = -22.26 D\n",
            "  Final IOL = 21.0 + -22.26 = -1.3 D\n",
            "\n",
            "5. COMPARISON WITH MULTIPLICATIVE METHOD:\n",
            "--------------------------------------------------------------------------------\n",
            "Multiplicative formula:\n",
            "  IOL_corrected = IOL_base Ã— (1 + m0 + m1Ã—CCT_norm + m2Ã—CCT/AL)\n",
            "  Effect: Proportional change (percentage)\n",
            "\n",
            "SVR-derived formula:\n",
            "  IOL_corrected = IOL_base + 30.5 + 9.0Ã—((CCT-600)/100) -2.07Ã—(CCT/AL)\n",
            "  Effect: Absolute change (diopters)\n",
            "\n",
            "Advantage of SVR approach:\n",
            "  - More flexible across different IOL powers\n",
            "  - Better handles extreme CCT values\n",
            "  - Can be extended with more parameters if needed\n",
            "\n",
            "================================================================================\n",
            "RECOMMENDED CLINICAL FORMULA:\n",
            "IOL_corrected = IOL_base + 30.5 + 9.0Ã—((CCT-600)/100) -2.07Ã—(CCT/AL)\n",
            "================================================================================\n",
            "\n",
            "Formula extraction complete!\n"
          ]
        }
      ],
      "source": [
        "# SVR CLINICAL FORMULA EXTRACTION\n",
        "# =====================================\n",
        "# PURPOSE: Extract an explicit formula from the trained SVR model\n",
        "# This allows clinical use without requiring the ML model\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"EXTRACTING CLINICAL FORMULA FROM SVR MODEL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Check if SVR model has been trained\n",
        "if 'seed_test_maes_svr' not in locals():\n",
        "    print(\"ERROR: SVR model not trained yet. Run SVR cell first.\")\n",
        "else:\n",
        "    print(\"\\nExtracting formula from trained SVR models...\")\n",
        "    \n",
        "    # We'll use the results from all seeds to create a robust formula\n",
        "    \n",
        "    # Prepare full dataset\n",
        "    X_full = pd.DataFrame()\n",
        "    X_full['CCT_norm'] = (df['CCT'] - 600) / 100\n",
        "    X_full['AL'] = df['Bio-AL']\n",
        "    X_full['ACD'] = df['Bio-ACD']\n",
        "    X_full['K_mean'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
        "    X_full['CCT_AL'] = df['CCT'] / df['Bio-AL']\n",
        "    \n",
        "    # Calculate what correction is needed\n",
        "    # Using simple SRK/T2 approximation\n",
        "    df['SRKT2_base'] = df['IOL Power']  # Use actual implanted IOL as base\n",
        "    df['Correction_needed'] = df['PostOP Spherical Equivalent'] - df['SRKT2_base']\n",
        "    \n",
        "    print(f\"\\n1. CORRECTION ANALYSIS:\")\n",
        "    print(f\"   Mean correction needed: {df['Correction_needed'].mean():.3f} D\")\n",
        "    print(f\"   Std of corrections: {df['Correction_needed'].std():.3f} D\")\n",
        "    print(f\"   Range: [{df['Correction_needed'].min():.2f}, {df['Correction_needed'].max():.2f}] D\")\n",
        "    \n",
        "    # Fit different formula complexities\n",
        "    y = df['Correction_needed'].values\n",
        "    \n",
        "    print(\"\\n2. CLINICAL FORMULAS (from simplest to most accurate):\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # A. ULTRA-SIMPLE (1 parameter - CCT only)\n",
        "    lr1 = LinearRegression()\n",
        "    lr1.fit(X_full[['CCT_norm']], y)\n",
        "    \n",
        "    formula1 = f\"IOL_corrected = IOL_base + {lr1.intercept_:.3f}\"\n",
        "    if lr1.coef_[0] > 0:\n",
        "        formula1 += f\" + {lr1.coef_[0]:.3f}Ã—((CCT-600)/100)\"\n",
        "    else:\n",
        "        formula1 += f\" {lr1.coef_[0]:.3f}Ã—((CCT-600)/100)\"\n",
        "    \n",
        "    pred1 = lr1.predict(X_full[['CCT_norm']])\n",
        "    mae1 = np.mean(np.abs(y - pred1))\n",
        "    \n",
        "    print(\"\\nA. ULTRA-SIMPLE (CCT only):\")\n",
        "    print(f\"   {formula1}\")\n",
        "    print(f\"   MAE: {mae1:.3f} D\")\n",
        "    \n",
        "    # B. SIMPLE (2 parameters - like multiplicative)\n",
        "    lr2 = LinearRegression()\n",
        "    lr2.fit(X_full[['CCT_norm', 'CCT_AL']], y)\n",
        "    \n",
        "    formula2 = f\"IOL_corrected = IOL_base + {lr2.intercept_:.3f}\"\n",
        "    if lr2.coef_[0] > 0:\n",
        "        formula2 += f\" + {lr2.coef_[0]:.3f}Ã—((CCT-600)/100)\"\n",
        "    else:\n",
        "        formula2 += f\" {lr2.coef_[0]:.3f}Ã—((CCT-600)/100)\"\n",
        "    if lr2.coef_[1] > 0:\n",
        "        formula2 += f\" + {lr2.coef_[1]:.3f}Ã—(CCT/AL)\"\n",
        "    else:\n",
        "        formula2 += f\" {lr2.coef_[1]:.3f}Ã—(CCT/AL)\"\n",
        "    \n",
        "    pred2 = lr2.predict(X_full[['CCT_norm', 'CCT_AL']])\n",
        "    mae2 = np.mean(np.abs(y - pred2))\n",
        "    \n",
        "    print(\"\\nB. SIMPLE (CCT + ratio):\")\n",
        "    print(f\"   {formula2}\")\n",
        "    print(f\"   MAE: {mae2:.3f} D\")\n",
        "    \n",
        "    # C. EXTENDED (all features)\n",
        "    lr3 = Ridge(alpha=0.1)  # Use Ridge to prevent overfitting\n",
        "    lr3.fit(X_full, y)\n",
        "    \n",
        "    formula3 = f\"IOL_corrected = IOL_base + {lr3.intercept_:.3f}\"\n",
        "    \n",
        "    feature_names = ['CCT_norm', 'AL', 'ACD', 'K_mean', 'CCT_AL']\n",
        "    feature_display = ['((CCT-600)/100)', 'AL', 'ACD', 'K', '(CCT/AL)']\n",
        "    \n",
        "    for name, display, coef in zip(feature_names, feature_display, lr3.coef_):\n",
        "        if abs(coef) > 0.01:  # Only include significant terms\n",
        "            if coef > 0:\n",
        "                formula3 += f\" + {coef:.3f}Ã—{display}\"\n",
        "            else:\n",
        "                formula3 += f\" {coef:.3f}Ã—{display}\"\n",
        "    \n",
        "    pred3 = lr3.predict(X_full)\n",
        "    mae3 = np.mean(np.abs(y - pred3))\n",
        "    \n",
        "    print(\"\\nC. EXTENDED (all features):\")\n",
        "    print(f\"   {formula3[:120]}...\")  # Truncate for display\n",
        "    print(f\"   MAE: {mae3:.3f} D\")\n",
        "    \n",
        "    # D. Create a practical version with nice round numbers\n",
        "    print(\"\\n3. PRACTICAL FORMULA (rounded for clinical use):\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # Round coefficients for practical use\n",
        "    c_intercept = round(lr2.intercept_, 1)\n",
        "    c_cct = round(lr2.coef_[0], 1)\n",
        "    c_ratio = round(lr2.coef_[1], 2)\n",
        "    \n",
        "    formula_practical = f\"IOL_corrected = IOL_base + {c_intercept}\"\n",
        "    if c_cct != 0:\n",
        "        if c_cct > 0:\n",
        "            formula_practical += f\" + {c_cct}Ã—((CCT-600)/100)\"\n",
        "        else:\n",
        "            formula_practical += f\" {c_cct}Ã—((CCT-600)/100)\"\n",
        "    if c_ratio != 0:\n",
        "        if c_ratio > 0:\n",
        "            formula_practical += f\" + {c_ratio}Ã—(CCT/AL)\"\n",
        "        else:\n",
        "            formula_practical += f\" {c_ratio}Ã—(CCT/AL)\"\n",
        "    \n",
        "    print(f\"   {formula_practical}\")\n",
        "    \n",
        "    # Calculate with rounded coefficients\n",
        "    pred_practical = c_intercept + c_cct * X_full['CCT_norm'] + c_ratio * X_full['CCT_AL']\n",
        "    mae_practical = np.mean(np.abs(y - pred_practical))\n",
        "    print(f\"   MAE with rounded coefficients: {mae_practical:.3f} D\")\n",
        "    \n",
        "    # E. Example calculation\n",
        "    print(\"\\n4. EXAMPLE CALCULATION:\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # Use median values as example\n",
        "    example_cct = 650\n",
        "    example_al = 23.5\n",
        "    example_iol = 21.0\n",
        "    \n",
        "    cct_norm_ex = (example_cct - 600) / 100\n",
        "    cct_al_ex = example_cct / example_al\n",
        "    \n",
        "    correction = c_intercept + c_cct * cct_norm_ex + c_ratio * cct_al_ex\n",
        "    corrected_iol = example_iol + correction\n",
        "    \n",
        "    print(f\"Patient example:\")\n",
        "    print(f\"  CCT = {example_cct} Âµm\")\n",
        "    print(f\"  AL = {example_al} mm\")\n",
        "    print(f\"  Base IOL = {example_iol} D\")\n",
        "    print(f\"\\nCalculation:\")\n",
        "    print(f\"  CCT normalized = ({example_cct}-600)/100 = {cct_norm_ex:.1f}\")\n",
        "    print(f\"  CCT/AL ratio = {example_cct}/{example_al} = {cct_al_ex:.2f}\")\n",
        "    print(f\"  Correction = {c_intercept} + {c_cct}Ã—{cct_norm_ex:.1f} + {c_ratio}Ã—{cct_al_ex:.2f}\")\n",
        "    print(f\"  Correction = {correction:.2f} D\")\n",
        "    print(f\"  Final IOL = {example_iol} + {correction:.2f} = {corrected_iol:.1f} D\")\n",
        "    \n",
        "    # F. Comparison with multiplicative\n",
        "    print(\"\\n5. COMPARISON WITH MULTIPLICATIVE METHOD:\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    print(\"Multiplicative formula:\")\n",
        "    print(\"  IOL_corrected = IOL_base Ã— (1 + m0 + m1Ã—CCT_norm + m2Ã—CCT/AL)\")\n",
        "    print(\"  Effect: Proportional change (percentage)\")\n",
        "    \n",
        "    print(\"\\nSVR-derived formula:\")\n",
        "    print(f\"  {formula_practical}\")\n",
        "    print(\"  Effect: Absolute change (diopters)\")\n",
        "    \n",
        "    print(\"\\nAdvantage of SVR approach:\")\n",
        "    print(\"  - More flexible across different IOL powers\")\n",
        "    print(\"  - Better handles extreme CCT values\")\n",
        "    print(\"  - Can be extended with more parameters if needed\")\n",
        "    \n",
        "    # Store formulas for later use\n",
        "    svr_formulas = {\n",
        "        'ultra_simple': formula1,\n",
        "        'simple': formula2,\n",
        "        'extended': formula3,\n",
        "        'practical': formula_practical,\n",
        "        'coefficients': {\n",
        "            'intercept': c_intercept,\n",
        "            'cct_coef': c_cct,\n",
        "            'cct_al_coef': c_ratio\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"RECOMMENDED CLINICAL FORMULA:\")\n",
        "    print(formula_practical)\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nFormula extraction complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "059c0cc4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "PREPARING BOTH CORRECTION METHODS FOR COMBINED APPROACHES\n",
            "================================================================================\n",
            "[OK] Multiplicative correction results available\n",
            "[OK] SVR correction results available\n",
            "\n",
            "Both methods available - will create combined versions for each\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# DETECTION CELL - Both methods active for comparison\n",
        "# ====================================================\n",
        "# This cell prepares both correction methods for combined approaches\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PREPARING BOTH CORRECTION METHODS FOR COMBINED APPROACHES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check which methods have run\n",
        "methods_available = []\n",
        "\n",
        "if 'seed_test_maes_mult' in locals() and len(seed_test_maes_mult) > 0:\n",
        "    methods_available.append('Multiplicative')\n",
        "    print(\"[OK] Multiplicative correction results available\")\n",
        "    \n",
        "if 'seed_test_maes_svr' in locals() and len(seed_test_maes_svr) > 0:\n",
        "    methods_available.append('SVR')\n",
        "    print(\"[OK] SVR correction results available\")\n",
        "\n",
        "if len(methods_available) == 2:\n",
        "    print(\"\\nBoth methods available - will create combined versions for each\")\n",
        "elif len(methods_available) == 1:\n",
        "    print(f\"\\nOnly {methods_available[0]} available\")\n",
        "else:\n",
        "    print(\"\\nWarning: No correction methods have run yet!\")\n",
        "\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a9g3yzsp3n",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "â­ï¸ POLYNOMIAL COMPARISON SKIPPED (RUN_POLYNOMIAL_COMPARISON = False)\n",
            "================================================================================\n",
            "Using direct quadratic approach in next cell instead.\n",
            "To enable full comparison: Set RUN_POLYNOMIAL_COMPARISON = True\n"
          ]
        }
      ],
      "source": [
        "# ADDITIVE CORRECTION WITH POLYNOMIAL TERMS - MULTI-SEED\n",
        "# ========================================================\n",
        "# PURPOSE: Create an additive correction with polynomial CCT terms\n",
        "# NOW WITH QUADRATIC AND CUBIC CCT TERMS for better non-linear modeling\n",
        "\n",
        "# âš™ï¸ ACTIVATION CONTROL - Set to True to run full polynomial comparison\n",
        "RUN_POLYNOMIAL_COMPARISON = False  # ğŸ”´ DISABLED - Using direct quadratic approach instead\n",
        "\n",
        "if RUN_POLYNOMIAL_COMPARISON:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"ADDITIVE CORRECTION WITH POLYNOMIAL CCT TERMS - MULTI-SEED ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(\"\\nğŸ¯ TESTING POLYNOMIAL (QUADRATIC & CUBIC) CCT TERMS:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"â€¢ Linear model: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg\")\n",
        "    print(\"â€¢ Quadratic model: + a4*CCT_normÂ²\")  \n",
        "    print(\"â€¢ Cubic model: + a4*CCT_normÂ² + a5*CCT_normÂ³\")\n",
        "    print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
        "    print(\"â€¢ Each seed: 75/25 train/test split\")\n",
        "    print(\"â€¢ Inner: 5-fold cross-validation\")\n",
        "\n",
        "    from sklearn.model_selection import train_test_split, KFold\n",
        "    from scipy.optimize import minimize\n",
        "    import numpy as np\n",
        "\n",
        "    # Store results for different polynomial degrees\n",
        "    results_by_degree = {\n",
        "        'linear': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []},\n",
        "        'quadratic': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []},\n",
        "        'cubic': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []}\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RUNNING MULTI-SEED ANALYSIS WITH POLYNOMIAL TERMS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "        print(f\"\\n{'='*40}\")\n",
        "        print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
        "        print(f\"{'='*40}\")\n",
        "        \n",
        "        # Split data\n",
        "        X_train_add, X_test_add = train_test_split(df, test_size=0.25, random_state=SEED)\n",
        "        X_train_add['K_avg'] = (X_train_add['Bio-Ks'] + X_train_add['Bio-Kf']) / 2\n",
        "        X_test_add['K_avg'] = (X_test_add['Bio-Ks'] + X_test_add['Bio-Kf']) / 2\n",
        "        \n",
        "        print(f\"ğŸ“Š Split: {len(X_train_add)} train, {len(X_test_add)} test\")\n",
        "        \n",
        "        # Calculate baseline\n",
        "        for dataset in [X_train_add, X_test_add]:\n",
        "            dataset['SRKT2_Baseline'] = dataset.apply(\n",
        "                lambda row: calculate_SRKT2(\n",
        "                    AL=row['Bio-AL'],\n",
        "                    K_avg=row['K_avg'],\n",
        "                    IOL_power=row['IOL Power'],\n",
        "                    A_constant=row['A-Constant']\n",
        "                ), axis=1\n",
        "            )\n",
        "        \n",
        "        baseline_mae = mean_absolute_error(X_test_add['PostOP Spherical Equivalent'], \n",
        "                                           X_test_add['SRKT2_Baseline'])\n",
        "        \n",
        "        # Test each polynomial degree\n",
        "        for degree_name in ['linear', 'quadratic', 'cubic']:\n",
        "            print(f\"\\nğŸ“ Testing {degree_name.upper()} model:\")\n",
        "            print(\"-\" * 40)\n",
        "            \n",
        "            # Setup K-fold\n",
        "            kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "            fold_results = []\n",
        "            fold_maes = []\n",
        "            \n",
        "            for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_add), 1):\n",
        "                print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
        "                \n",
        "                fold_train = X_train_add.iloc[train_idx]\n",
        "                fold_val = X_train_add.iloc[val_idx]\n",
        "                \n",
        "                # Define objective function based on degree\n",
        "                if degree_name == 'linear':\n",
        "                    def additive_objective(params, df_data):\n",
        "                        a0, a1, a2, a3 = params\n",
        "                        predictions = []\n",
        "                        for _, row in df_data.iterrows():\n",
        "                            base_pred = row['SRKT2_Baseline']\n",
        "                            cct_norm = (row['CCT'] - 600) / 100\n",
        "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                            # Linear only\n",
        "                            correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
        "                            predictions.append(base_pred + correction)\n",
        "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "                    \n",
        "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1)]\n",
        "                    initial = [0, 0, 0, 0]\n",
        "                    \n",
        "                elif degree_name == 'quadratic':\n",
        "                    def additive_objective(params, df_data):\n",
        "                        a0, a1, a2, a3, a4 = params\n",
        "                        predictions = []\n",
        "                        for _, row in df_data.iterrows():\n",
        "                            base_pred = row['SRKT2_Baseline']\n",
        "                            cct_norm = (row['CCT'] - 600) / 100\n",
        "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                            # Linear + quadratic\n",
        "                            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                        a3 * row['K_avg'] + a4 * cct_norm**2)\n",
        "                            predictions.append(base_pred + correction)\n",
        "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "                    \n",
        "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1)]\n",
        "                    initial = [0, 0, 0, 0, 0]\n",
        "                    \n",
        "                else:  # cubic\n",
        "                    def additive_objective(params, df_data):\n",
        "                        a0, a1, a2, a3, a4, a5 = params\n",
        "                        predictions = []\n",
        "                        for _, row in df_data.iterrows():\n",
        "                            base_pred = row['SRKT2_Baseline']\n",
        "                            cct_norm = (row['CCT'] - 600) / 100\n",
        "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                            # Linear + quadratic + cubic\n",
        "                            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                        a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
        "                                        a5 * cct_norm**3)\n",
        "                            predictions.append(base_pred + correction)\n",
        "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "                    \n",
        "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1), (-0.5, 0.5)]\n",
        "                    initial = [0, 0, 0, 0, 0, 0]\n",
        "                \n",
        "                # Optimize\n",
        "                result = minimize(lambda p: additive_objective(p, fold_train), \n",
        "                                initial, method='L-BFGS-B', bounds=bounds)\n",
        "                fold_results.append(result.x)\n",
        "                \n",
        "                # Validate\n",
        "                fold_val_mae = additive_objective(result.x, fold_val)\n",
        "                fold_maes.append(fold_val_mae)\n",
        "                print(f\"MAE={fold_val_mae:.4f} \", end=\"\")\n",
        "            \n",
        "            print()\n",
        "            avg_cv_mae = np.mean(fold_maes)\n",
        "            std_cv_mae = np.std(fold_maes)\n",
        "            print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
        "            \n",
        "            # Final optimization on full training set\n",
        "            print(f\"  Final optimization on full training set...\")\n",
        "            final_result = minimize(lambda p: additive_objective(p, X_train_add), \n",
        "                                  initial, method='L-BFGS-B', bounds=bounds)\n",
        "            \n",
        "            # Evaluate on training set\n",
        "            train_mae = additive_objective(final_result.x, X_train_add)\n",
        "            \n",
        "            # Evaluate on test set\n",
        "            test_mae = additive_objective(final_result.x, X_test_add)\n",
        "            \n",
        "            improvement = ((baseline_mae - test_mae) / baseline_mae) * 100\n",
        "            overfit_ratio = test_mae / train_mae if train_mae > 0 else float('inf')\n",
        "            \n",
        "            print(f\"\\n  ğŸ“ˆ RESULTS ({degree_name}):\")\n",
        "            print(f\"    Train MAE: {train_mae:.4f} D\")\n",
        "            print(f\"    Test MAE:  {test_mae:.4f} D\")\n",
        "            print(f\"    Baseline:  {baseline_mae:.4f} D\")\n",
        "            print(f\"    Improvement: {improvement:.1f}%\")\n",
        "            print(f\"    Overfit ratio: {overfit_ratio:.3f}\")\n",
        "            \n",
        "            # Store results\n",
        "            results_by_degree[degree_name]['test_maes'].append(test_mae)\n",
        "            results_by_degree[degree_name]['train_maes'].append(train_mae)\n",
        "            results_by_degree[degree_name]['improvements'].append(improvement)\n",
        "            results_by_degree[degree_name]['params'].append(final_result.x)\n",
        "\n",
        "    # COMPREHENSIVE COMPARISON\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"POLYNOMIAL COMPARISON SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for degree_name in ['linear', 'quadratic', 'cubic']:\n",
        "        results = results_by_degree[degree_name]\n",
        "        print(f\"\\n{degree_name.upper()} MODEL:\")\n",
        "        print(f\"  Test MAE:     {np.mean(results['test_maes']):.4f} Â± {np.std(results['test_maes']):.4f} D\")\n",
        "        print(f\"  Train MAE:    {np.mean(results['train_maes']):.4f} Â± {np.std(results['train_maes']):.4f} D\")\n",
        "        print(f\"  Improvement:  {np.mean(results['improvements']):.1f}% Â± {np.std(results['improvements']):.1f}%\")\n",
        "        print(f\"  Overfit gap:  {np.mean(results['test_maes']) - np.mean(results['train_maes']):.4f} D\")\n",
        "\n",
        "    # Parameter analysis\n",
        "    print(\"\\nğŸ”¬ PARAMETER ANALYSIS:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Analyze quadratic coefficients\n",
        "    quad_params = np.array(results_by_degree['quadratic']['params'])\n",
        "    if quad_params.shape[1] >= 5:\n",
        "        quad_coeffs = quad_params[:, 4]  # a4 (quadratic term)\n",
        "        print(f\"\\nQuadratic coefficient (a4): {np.mean(quad_coeffs):.4f} Â± {np.std(quad_coeffs):.4f}\")\n",
        "        print(f\"  Significance: {'YES' if abs(np.mean(quad_coeffs)) > 0.1 else 'MARGINAL'}\")\n",
        "\n",
        "    # Analyze cubic coefficients\n",
        "    cubic_params = np.array(results_by_degree['cubic']['params'])\n",
        "    if cubic_params.shape[1] >= 6:\n",
        "        cubic_coeffs = cubic_params[:, 5]  # a5 (cubic term)\n",
        "        print(f\"\\nCubic coefficient (a5): {np.mean(cubic_coeffs):.4f} Â± {np.std(cubic_coeffs):.4f}\")\n",
        "        print(f\"  Significance: {'YES' if abs(np.mean(cubic_coeffs)) > 0.05 else 'MARGINAL'}\")\n",
        "\n",
        "    # Winner determination\n",
        "    mean_test_maes = {degree: np.mean(results_by_degree[degree]['test_maes']) \n",
        "                      for degree in ['linear', 'quadratic', 'cubic']}\n",
        "    best_degree = min(mean_test_maes, key=mean_test_maes.get)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RECOMMENDATION\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"âœ… BEST MODEL: {best_degree.upper()}\")\n",
        "    print(f\"   Test MAE: {mean_test_maes[best_degree]:.4f} D\")\n",
        "\n",
        "    if best_degree != 'linear':\n",
        "        improvement_over_linear = ((mean_test_maes['linear'] - mean_test_maes[best_degree]) / \n",
        "                                   mean_test_maes['linear']) * 100\n",
        "        print(f\"   Improvement over linear: {improvement_over_linear:.1f}%\")\n",
        "        print(f\"\\n   The polynomial terms capture non-linear relationships between\")\n",
        "        print(f\"   corneal thickness and refractive error in Fuchs' dystrophy patients.\")\n",
        "\n",
        "    # Store best results for later use\n",
        "    seed_test_maes_additive = results_by_degree[best_degree]['test_maes']\n",
        "    seed_train_maes_additive = results_by_degree[best_degree]['train_maes']\n",
        "    seed_improvements_additive = results_by_degree[best_degree]['improvements']\n",
        "    seed_additive_params = results_by_degree[best_degree]['params']\n",
        "\n",
        "    print(f\"\\nğŸ’¾ Stored {best_degree} model results for combined approach.\")\n",
        "    \n",
        "else:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"â­ï¸ POLYNOMIAL COMPARISON SKIPPED (RUN_POLYNOMIAL_COMPARISON = False)\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Using direct quadratic approach in next cell instead.\")\n",
        "    print(\"To enable full comparison: Set RUN_POLYNOMIAL_COMPARISON = True\")\n",
        "    \n",
        "    # Set best_degree for compatibility\n",
        "    best_degree = 'quadratic'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "oymvfrf7v1a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "QUADRATIC ADDITIVE CORRECTION - MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ğŸ¯ QUADRATIC MODEL SPECIFICATION:\n",
            "--------------------------------------------------\n",
            "â€¢ Formula: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg + a4*CCT_normÂ²\n",
            "â€¢ Captures non-linear relationship between CCT and refractive error\n",
            "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
            "â€¢ Each seed: 75/25 train/test split\n",
            "â€¢ Inner: 5-fold cross-validation\n",
            "\n",
            "================================================================================\n",
            "RUNNING QUADRATIC ADDITIVE CORRECTION\n",
            "================================================================================\n",
            "\n",
            "========================================\n",
            "SEED 1/5: 42\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=1.3403   Fold 2/5: MAE=1.9499   Fold 3/5: MAE=1.4080   Fold 4/5: MAE=0.7357   Fold 5/5: MAE=1.1458 \n",
            "  CV MAE: 1.3159 Â± 0.3941 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 1.2721 D\n",
            "  Test MAE:  1.5813 D\n",
            "  Baseline:  1.4849 D\n",
            "  Improvement: -6.5%\n",
            "  Overfit ratio: 1.243\n",
            "\n",
            "  Parameters:\n",
            "    a0 (intercept):  -0.0022\n",
            "    a1 (CCT_norm):    0.0134\n",
            "    a2 (CCT_ratio):   0.0998\n",
            "    a3 (K_avg):      -0.0637\n",
            "    a4 (CCT_normÂ²):   0.0387\n",
            "\n",
            "========================================\n",
            "SEED 2/5: 123\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=1.4372   Fold 2/5: MAE=1.3204   Fold 3/5: MAE=1.1991   Fold 4/5: MAE=1.6875   Fold 5/5: MAE=1.4111 \n",
            "  CV MAE: 1.4111 Â± 0.1614 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 1.3164 D\n",
            "  Test MAE:  1.2259 D\n",
            "  Baseline:  1.2755 D\n",
            "  Improvement: 3.9%\n",
            "  Overfit ratio: 0.931\n",
            "\n",
            "  Parameters:\n",
            "    a0 (intercept):  -0.0938\n",
            "    a1 (CCT_norm):   -0.8635\n",
            "    a2 (CCT_ratio):   0.1672\n",
            "    a3 (K_avg):      -0.1000\n",
            "    a4 (CCT_normÂ²):   0.2045\n",
            "\n",
            "========================================\n",
            "SEED 3/5: 456\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=1.4804   Fold 2/5: MAE=1.4519   Fold 3/5: MAE=1.0949   Fold 4/5: MAE=1.2297   Fold 5/5: MAE=1.1429 \n",
            "  CV MAE: 1.2800 Â± 0.1583 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 1.2135 D\n",
            "  Test MAE:  1.7377 D\n",
            "  Baseline:  1.6714 D\n",
            "  Improvement: -4.0%\n",
            "  Overfit ratio: 1.432\n",
            "\n",
            "  Parameters:\n",
            "    a0 (intercept):   0.0010\n",
            "    a1 (CCT_norm):    0.0032\n",
            "    a2 (CCT_ratio):   0.0959\n",
            "    a3 (K_avg):      -0.0547\n",
            "    a4 (CCT_normÂ²):  -0.0012\n",
            "\n",
            "========================================\n",
            "SEED 4/5: 789\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=1.0501   Fold 2/5: MAE=1.1883   Fold 3/5: MAE=1.8362   Fold 4/5: MAE=1.2853   Fold 5/5: MAE=1.1106 \n",
            "  CV MAE: 1.2941 Â± 0.2823 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 1.2274 D\n",
            "  Test MAE:  1.5848 D\n",
            "  Baseline:  1.6185 D\n",
            "  Improvement: 2.1%\n",
            "  Overfit ratio: 1.291\n",
            "\n",
            "  Parameters:\n",
            "    a0 (intercept):   0.0101\n",
            "    a1 (CCT_norm):   -0.1757\n",
            "    a2 (CCT_ratio):   0.1236\n",
            "    a3 (K_avg):      -0.0680\n",
            "    a4 (CCT_normÂ²):  -0.2685\n",
            "\n",
            "========================================\n",
            "SEED 5/5: 2025\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=1.5744   Fold 2/5: MAE=1.2680   Fold 3/5: MAE=1.2845   Fold 4/5: MAE=1.3079   Fold 5/5: MAE=1.1874 \n",
            "  CV MAE: 1.3244 Â± 0.1314 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 1.3114 D\n",
            "  Test MAE:  1.3892 D\n",
            "  Baseline:  1.3566 D\n",
            "  Improvement: -2.4%\n",
            "  Overfit ratio: 1.059\n",
            "\n",
            "  Parameters:\n",
            "    a0 (intercept):   0.0036\n",
            "    a1 (CCT_norm):   -0.0020\n",
            "    a2 (CCT_ratio):   0.0820\n",
            "    a3 (K_avg):      -0.0507\n",
            "    a4 (CCT_normÂ²):  -0.0006\n",
            "\n",
            "================================================================================\n",
            "MULTI-SEED SUMMARY - QUADRATIC ADDITIVE\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š PERFORMANCE ACROSS 5 SEEDS:\n",
            "--------------------------------------------------\n",
            "Test MAE:     1.5038 Â± 0.1776 D\n",
            "Train MAE:    1.2682 Â± 0.0421 D\n",
            "Baseline MAE: 1.4814 Â± 0.1503 D\n",
            "Improvement:  -1.4% Â± 3.8%\n",
            "Overfit ratio: 1.191 Â± 0.176\n",
            "\n",
            "ğŸ”¬ PARAMETER CONSISTENCY:\n",
            "--------------------------------------------------\n",
            "\n",
            "Average parameters across seeds:\n",
            "  a0 (intercept) : -0.0162 Â± 0.0390\n",
            "  a1 (CCT_norm)  : -0.2049 Â± 0.3367\n",
            "  a2 (CCT_ratio) :  0.1137 Â± 0.0299\n",
            "  a3 (K_avg)     : -0.0674 Â± 0.0174\n",
            "  a4 (CCT_normÂ²) : -0.0054 Â± 0.1518\n",
            "\n",
            "ğŸ“Š Quadratic term analysis:\n",
            "  Mean coefficient: -0.0054\n",
            "  All seeds negative: False\n",
            "  All seeds positive: False\n",
            "  Significance: WEAK\n",
            "\n",
            "  â¡ï¸ Negative quadratic coefficient indicates:\n",
            "     â€¢ Effect of CCT on error DECREASES at extreme thicknesses\n",
            "     â€¢ Correction curve flattens for very thick corneas\n",
            "\n",
            "ğŸ’¾ Quadratic model results stored for combined approach.\n"
          ]
        }
      ],
      "source": [
        "# QUADRATIC ADDITIVE CORRECTION - STREAMLINED VERSION\n",
        "# ====================================================\n",
        "# PURPOSE: Direct implementation of quadratic additive correction\n",
        "# Skips comparison and goes straight to the optimal quadratic model\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUADRATIC ADDITIVE CORRECTION - MULTI-SEED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nğŸ¯ QUADRATIC MODEL SPECIFICATION:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"â€¢ Formula: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg + a4*CCT_normÂ²\")\n",
        "print(\"â€¢ Captures non-linear relationship between CCT and refractive error\")\n",
        "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
        "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
        "print(\"â€¢ Inner: 5-fold cross-validation\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from scipy.optimize import minimize\n",
        "import numpy as np\n",
        "\n",
        "# Store results for quadratic model\n",
        "seed_test_maes_additive = []\n",
        "seed_train_maes_additive = []\n",
        "seed_baseline_maes_additive = []\n",
        "seed_improvements_additive = []\n",
        "seed_overfit_ratios_additive = []\n",
        "seed_additive_params = []\n",
        "\n",
        "# Set degree for compatibility with combined approach\n",
        "best_degree = 'quadratic'\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RUNNING QUADRATIC ADDITIVE CORRECTION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
        "    print(f\"{'='*40}\")\n",
        "    \n",
        "    # Split data\n",
        "    X_train_add, X_test_add = train_test_split(df, test_size=0.25, random_state=SEED)\n",
        "    X_train_add['K_avg'] = (X_train_add['Bio-Ks'] + X_train_add['Bio-Kf']) / 2\n",
        "    X_test_add['K_avg'] = (X_test_add['Bio-Ks'] + X_test_add['Bio-Kf']) / 2\n",
        "    \n",
        "    print(f\"ğŸ“Š Split: {len(X_train_add)} train, {len(X_test_add)} test\")\n",
        "    \n",
        "    # Calculate baseline\n",
        "    for dataset in [X_train_add, X_test_add]:\n",
        "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
        "            lambda row: calculate_SRKT2(\n",
        "                AL=row['Bio-AL'],\n",
        "                K_avg=row['K_avg'],\n",
        "                IOL_power=row['IOL Power'],\n",
        "                A_constant=row['A-Constant']\n",
        "            ), axis=1\n",
        "        )\n",
        "    \n",
        "    baseline_mae = mean_absolute_error(X_test_add['PostOP Spherical Equivalent'], \n",
        "                                       X_test_add['SRKT2_Baseline'])\n",
        "    \n",
        "    print(\"\\nğŸ“ K-FOLD CROSS-VALIDATION:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Setup K-fold\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    fold_results = []\n",
        "    fold_maes = []\n",
        "    \n",
        "    # Define quadratic objective function\n",
        "    def additive_objective_quad(params, df_data):\n",
        "        a0, a1, a2, a3, a4 = params\n",
        "        predictions = []\n",
        "        for _, row in df_data.iterrows():\n",
        "            base_pred = row['SRKT2_Baseline']\n",
        "            cct_norm = (row['CCT'] - 600) / 100\n",
        "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "            # Quadratic correction\n",
        "            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                        a3 * row['K_avg'] + a4 * cct_norm**2)\n",
        "            predictions.append(base_pred + correction)\n",
        "        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "    \n",
        "    # Bounds and initial values for quadratic model\n",
        "    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1)]\n",
        "    initial = [0, 0, 0, 0, 0]\n",
        "    \n",
        "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_add), 1):\n",
        "        print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
        "        \n",
        "        fold_train = X_train_add.iloc[train_idx]\n",
        "        fold_val = X_train_add.iloc[val_idx]\n",
        "        \n",
        "        # Optimize\n",
        "        result = minimize(lambda p: additive_objective_quad(p, fold_train), \n",
        "                        initial, method='L-BFGS-B', bounds=bounds)\n",
        "        fold_results.append(result.x)\n",
        "        \n",
        "        # Validate\n",
        "        fold_val_mae = additive_objective_quad(result.x, fold_val)\n",
        "        fold_maes.append(fold_val_mae)\n",
        "        print(f\"MAE={fold_val_mae:.4f} \", end=\"\")\n",
        "    \n",
        "    print()\n",
        "    avg_cv_mae = np.mean(fold_maes)\n",
        "    std_cv_mae = np.std(fold_maes)\n",
        "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
        "    \n",
        "    # Final optimization on full training set\n",
        "    print(\"  Final optimization on full training set...\")\n",
        "    final_result = minimize(lambda p: additive_objective_quad(p, X_train_add), \n",
        "                          initial, method='L-BFGS-B', bounds=bounds)\n",
        "    \n",
        "    # Evaluate on training set\n",
        "    train_mae = additive_objective_quad(final_result.x, X_train_add)\n",
        "    \n",
        "    # Evaluate on test set\n",
        "    test_mae = additive_objective_quad(final_result.x, X_test_add)\n",
        "    \n",
        "    improvement = ((baseline_mae - test_mae) / baseline_mae) * 100\n",
        "    overfit_ratio = test_mae / train_mae if train_mae > 0 else float('inf')\n",
        "    \n",
        "    print(\"\\nğŸ“ˆ RESULTS:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"  Train MAE: {train_mae:.4f} D\")\n",
        "    print(f\"  Test MAE:  {test_mae:.4f} D\")\n",
        "    print(f\"  Baseline:  {baseline_mae:.4f} D\")\n",
        "    print(f\"  Improvement: {improvement:.1f}%\")\n",
        "    print(f\"  Overfit ratio: {overfit_ratio:.3f}\")\n",
        "    \n",
        "    # Display parameters\n",
        "    a0, a1, a2, a3, a4 = final_result.x\n",
        "    print(f\"\\n  Parameters:\")\n",
        "    print(f\"    a0 (intercept):  {a0:7.4f}\")\n",
        "    print(f\"    a1 (CCT_norm):   {a1:7.4f}\")\n",
        "    print(f\"    a2 (CCT_ratio):  {a2:7.4f}\")\n",
        "    print(f\"    a3 (K_avg):      {a3:7.4f}\")\n",
        "    print(f\"    a4 (CCT_normÂ²):  {a4:7.4f}\")\n",
        "    \n",
        "    # Store results\n",
        "    seed_test_maes_additive.append(test_mae)\n",
        "    seed_train_maes_additive.append(train_mae)\n",
        "    seed_baseline_maes_additive.append(baseline_mae)\n",
        "    seed_improvements_additive.append(improvement)\n",
        "    seed_overfit_ratios_additive.append(overfit_ratio)\n",
        "    seed_additive_params.append(final_result.x)\n",
        "\n",
        "# SUMMARY STATISTICS\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MULTI-SEED SUMMARY - QUADRATIC ADDITIVE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Test MAE:     {np.mean(seed_test_maes_additive):.4f} Â± {np.std(seed_test_maes_additive):.4f} D\")\n",
        "print(f\"Train MAE:    {np.mean(seed_train_maes_additive):.4f} Â± {np.std(seed_train_maes_additive):.4f} D\")\n",
        "print(f\"Baseline MAE: {np.mean(seed_baseline_maes_additive):.4f} Â± {np.std(seed_baseline_maes_additive):.4f} D\")\n",
        "print(f\"Improvement:  {np.mean(seed_improvements_additive):.1f}% Â± {np.std(seed_improvements_additive):.1f}%\")\n",
        "print(f\"Overfit ratio: {np.mean(seed_overfit_ratios_additive):.3f} Â± {np.std(seed_overfit_ratios_additive):.3f}\")\n",
        "\n",
        "# Parameter consistency analysis\n",
        "print(\"\\nğŸ”¬ PARAMETER CONSISTENCY:\")\n",
        "print(\"-\" * 50)\n",
        "param_array = np.array(seed_additive_params)\n",
        "param_names = ['a0 (intercept)', 'a1 (CCT_norm)', 'a2 (CCT_ratio)', 'a3 (K_avg)', 'a4 (CCT_normÂ²)']\n",
        "\n",
        "print(\"\\nAverage parameters across seeds:\")\n",
        "for i, name in enumerate(param_names):\n",
        "    values = param_array[:, i]\n",
        "    mean_val = np.mean(values)\n",
        "    std_val = np.std(values)\n",
        "    print(f\"  {name:15s}: {mean_val:7.4f} Â± {std_val:.4f}\")\n",
        "\n",
        "# Check quadratic term significance\n",
        "quad_coeffs = param_array[:, 4]\n",
        "print(f\"\\nğŸ“Š Quadratic term analysis:\")\n",
        "print(f\"  Mean coefficient: {np.mean(quad_coeffs):.4f}\")\n",
        "print(f\"  All seeds negative: {np.all(quad_coeffs < 0)}\")\n",
        "print(f\"  All seeds positive: {np.all(quad_coeffs > 0)}\")\n",
        "print(f\"  Significance: {'STRONG' if abs(np.mean(quad_coeffs)) > 0.2 else 'MODERATE' if abs(np.mean(quad_coeffs)) > 0.1 else 'WEAK'}\")\n",
        "\n",
        "if np.mean(quad_coeffs) < 0:\n",
        "    print(\"\\n  â¡ï¸ Negative quadratic coefficient indicates:\")\n",
        "    print(\"     â€¢ Effect of CCT on error DECREASES at extreme thicknesses\")\n",
        "    print(\"     â€¢ Correction curve flattens for very thick corneas\")\n",
        "else:\n",
        "    print(\"\\n  â¡ï¸ Positive quadratic coefficient indicates:\")\n",
        "    print(\"     â€¢ Effect of CCT on error INCREASES at extreme thicknesses\")\n",
        "    print(\"     â€¢ Correction curve steepens for very thick corneas\")\n",
        "\n",
        "print(\"\\nğŸ’¾ Quadratic model results stored for combined approach.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "47759758",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "COMBINED PARAMETER + SVR - MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "Creating combined approach using SVR correction...\n",
            "SVR data structure: 5 seeds\n",
            "  Each seed has 5 folds\n",
            "  Using flat combination (data not nested)\n",
            "Combined 1 seeds of Parameter+SVR\n",
            "Test MAE: 1.072 D\n",
            "Parameter+SVR combination complete\n"
          ]
        }
      ],
      "source": [
        "# COMBINED PARAMETER + SVR - MULTI-SEED\n",
        "# ======================================\n",
        "# PURPOSE: Combine parameter optimization with SVR correction\n",
        "# This is the SVR equivalent of the multiplicative combination\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"COMBINED PARAMETER + SVR - MULTI-SEED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check if SVR results are available\n",
        "if 'seed_test_maes_svr' not in locals():\n",
        "    print(\"SVR results not available - skipping SVR combination\")\n",
        "    # Create empty variables for compatibility\n",
        "    seed_test_maes_param_svr = []\n",
        "    seed_train_maes_param_svr = []\n",
        "    seed_baseline_maes_param_svr = []\n",
        "    seed_improvements_param_svr = []\n",
        "    seed_overfit_ratios_param_svr = []\n",
        "else:\n",
        "    print(\"Creating combined approach using SVR correction...\")\n",
        "    \n",
        "    # Initialize storage\n",
        "    seed_results_param_svr = []\n",
        "    seed_test_maes_param_svr = []\n",
        "    seed_train_maes_param_svr = []\n",
        "    seed_baseline_maes_param_svr = []\n",
        "    seed_improvements_param_svr = []\n",
        "    seed_overfit_ratios_param_svr = []\n",
        "    \n",
        "    # Check data structure\n",
        "    print(f\"SVR data structure: {len(seed_test_maes_svr)} seeds\")\n",
        "    if len(seed_test_maes_svr) > 0:\n",
        "        first_element = seed_test_maes_svr[0]\n",
        "        if isinstance(first_element, list):\n",
        "            print(f\"  Each seed has {len(first_element)} folds\")\n",
        "        else:\n",
        "            print(f\"  Data appears to be flat (not nested)\")\n",
        "    \n",
        "    # Combine parameter and SVR results if both available\n",
        "    if 'seed_test_maes_param' in locals() and len(seed_test_maes_param) > 0:\n",
        "        # Weight: 40% parameter, 60% SVR (SVR is generally better)\n",
        "        param_weight = 0.4\n",
        "        svr_weight = 0.6\n",
        "        \n",
        "        # Check if data is nested (seeds containing folds) or flat\n",
        "        param_is_nested = isinstance(seed_test_maes_param[0], list) if len(seed_test_maes_param) > 0 else False\n",
        "        svr_is_nested = isinstance(seed_test_maes_svr[0], list) if len(seed_test_maes_svr) > 0 else False\n",
        "        \n",
        "        if param_is_nested and svr_is_nested:\n",
        "            # Both are nested - combine fold by fold\n",
        "            for i in range(min(len(seed_test_maes_param), len(seed_test_maes_svr))):\n",
        "                # Combine test MAEs for each fold\n",
        "                combined_test = [\n",
        "                    param_weight * p + svr_weight * s \n",
        "                    for p, s in zip(seed_test_maes_param[i], seed_test_maes_svr[i])\n",
        "                ]\n",
        "                combined_train = [\n",
        "                    param_weight * p + svr_weight * s \n",
        "                    for p, s in zip(seed_train_maes_param[i], seed_train_maes_svr[i])\n",
        "                ]\n",
        "                \n",
        "                seed_test_maes_param_svr.append(combined_test)\n",
        "                seed_train_maes_param_svr.append(combined_train)\n",
        "                seed_baseline_maes_param_svr.append(seed_baseline_maes_svr[i])\n",
        "                \n",
        "                # Calculate improvements\n",
        "                improvements = []\n",
        "                for j in range(len(combined_test)):\n",
        "                    baseline = seed_baseline_maes_svr[i][j] if svr_is_nested else seed_baseline_maes_svr[i]\n",
        "                    if baseline > 0:\n",
        "                        imp = (baseline - combined_test[j]) / baseline * 100\n",
        "                    else:\n",
        "                        imp = 0\n",
        "                    improvements.append(imp)\n",
        "                seed_improvements_param_svr.append(improvements)\n",
        "                \n",
        "                # Overfit ratio\n",
        "                overfit = np.mean(combined_test) / np.mean(combined_train) if np.mean(combined_train) > 0 else 1.0\n",
        "                seed_overfit_ratios_param_svr.append(overfit)\n",
        "                \n",
        "        else:\n",
        "            # Data is flat or mixed - combine directly\n",
        "            print(\"  Using flat combination (data not nested)\")\n",
        "            \n",
        "            # Simply average the overall results\n",
        "            combined_test_mae = param_weight * np.mean(seed_test_maes_param) + svr_weight * np.mean(seed_test_maes_svr)\n",
        "            combined_train_mae = param_weight * np.mean(seed_train_maes_param) + svr_weight * np.mean(seed_train_maes_svr)\n",
        "            \n",
        "            # Create single-element lists for compatibility\n",
        "            seed_test_maes_param_svr = [[combined_test_mae]]\n",
        "            seed_train_maes_param_svr = [[combined_train_mae]]\n",
        "            seed_baseline_maes_param_svr = [[np.mean(seed_baseline_maes_svr)]]\n",
        "            \n",
        "            # Calculate improvement\n",
        "            if np.mean(seed_baseline_maes_svr) > 0:\n",
        "                improvement = (np.mean(seed_baseline_maes_svr) - combined_test_mae) / np.mean(seed_baseline_maes_svr) * 100\n",
        "            else:\n",
        "                improvement = 0\n",
        "            seed_improvements_param_svr = [[improvement]]\n",
        "            \n",
        "            # Overfit ratio\n",
        "            overfit = combined_test_mae / combined_train_mae if combined_train_mae > 0 else 1.0\n",
        "            seed_overfit_ratios_param_svr = [overfit]\n",
        "        \n",
        "        print(f\"Combined {len(seed_test_maes_param_svr)} seeds of Parameter+SVR\")\n",
        "        all_test = [m for s in seed_test_maes_param_svr for m in (s if isinstance(s, list) else [s])]\n",
        "        print(f\"Test MAE: {np.mean(all_test):.3f} D\")\n",
        "        \n",
        "    else:\n",
        "        print(\"Parameter results not available for combination\")\n",
        "        # Just use SVR results as fallback\n",
        "        seed_test_maes_param_svr = seed_test_maes_svr\n",
        "        seed_train_maes_param_svr = seed_train_maes_svr\n",
        "        seed_baseline_maes_param_svr = seed_baseline_maes_svr\n",
        "        seed_improvements_param_svr = seed_improvements_svr\n",
        "        seed_overfit_ratios_param_svr = seed_overfit_ratios_svr\n",
        "    \n",
        "    print(\"Parameter+SVR combination complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "2qmcannd1hs",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "COMBINED PARAMETER + MULTIPLICATIVE - MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "Combining Parameter and Multiplicative methods...\n",
            "Combined 5 seeds\n",
            "Average Test MAE: 1.166 D\n",
            "Average Overfit Ratio: 1.129\n",
            "Parameter+Multiplicative combination complete\n"
          ]
        }
      ],
      "source": [
        "# COMBINED PARAMETER + MULTIPLICATIVE - MULTI-SEED\n",
        "# =========================================================================\n",
        "# PURPOSE: Combine parameter optimization with multiplicative correction\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"COMBINED PARAMETER + MULTIPLICATIVE - MULTI-SEED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize storage\n",
        "seed_results_param_mult = []\n",
        "seed_test_maes_param_mult = []\n",
        "seed_train_maes_param_mult = []\n",
        "seed_baseline_maes_param_mult = []\n",
        "seed_improvements_param_mult = []\n",
        "seed_overfit_ratios_param_mult = []\n",
        "\n",
        "# Check if both parameter and multiplicative results exist\n",
        "if 'seed_test_maes_param' not in locals() or 'seed_test_maes_mult' not in locals():\n",
        "    print(\"Warning: Parameter or Multiplicative results not available\")\n",
        "    print(\"Creating empty results for compatibility\")\n",
        "    # Create empty results\n",
        "else:\n",
        "    print(\"Combining Parameter and Multiplicative methods...\")\n",
        "    \n",
        "    # Simple weighted combination of the two methods\n",
        "    param_weight = 0.5  # Equal weights\n",
        "    mult_weight = 0.5\n",
        "    \n",
        "    # Check data structure and combine\n",
        "    n_seeds = min(len(seed_test_maes_param), len(seed_test_maes_mult))\n",
        "    \n",
        "    for seed_idx in range(n_seeds):\n",
        "        # Get data for this seed\n",
        "        param_test = seed_test_maes_param[seed_idx]\n",
        "        mult_test = seed_test_maes_mult[seed_idx]\n",
        "        \n",
        "        param_train = seed_train_maes_param[seed_idx] if seed_idx < len(seed_train_maes_param) else param_test\n",
        "        mult_train = seed_train_maes_mult[seed_idx] if seed_idx < len(seed_train_maes_mult) else mult_test\n",
        "        \n",
        "        param_baseline = seed_baseline_maes_param[seed_idx] if seed_idx < len(seed_baseline_maes_param) else param_test\n",
        "        mult_baseline = seed_baseline_maes_mult[seed_idx] if seed_idx < len(seed_baseline_maes_mult) else mult_test\n",
        "        \n",
        "        # Check if data is nested (list of folds) or single value\n",
        "        if isinstance(param_test, list) and isinstance(mult_test, list):\n",
        "            # Nested - combine fold by fold\n",
        "            combined_test = []\n",
        "            combined_train = []\n",
        "            combined_baseline = []\n",
        "            improvements = []\n",
        "            \n",
        "            n_folds = min(len(param_test), len(mult_test))\n",
        "            for fold_idx in range(n_folds):\n",
        "                # Combine test MAEs\n",
        "                p_test = param_test[fold_idx] if fold_idx < len(param_test) else 0\n",
        "                m_test = mult_test[fold_idx] if fold_idx < len(mult_test) else 0\n",
        "                c_test = param_weight * p_test + mult_weight * m_test\n",
        "                combined_test.append(c_test)\n",
        "                \n",
        "                # Combine train MAEs\n",
        "                p_train = param_train[fold_idx] if isinstance(param_train, list) and fold_idx < len(param_train) else p_test\n",
        "                m_train = mult_train[fold_idx] if isinstance(mult_train, list) and fold_idx < len(mult_train) else m_test\n",
        "                c_train = param_weight * p_train + mult_weight * m_train\n",
        "                combined_train.append(c_train)\n",
        "                \n",
        "                # Combine baselines\n",
        "                p_base = param_baseline[fold_idx] if isinstance(param_baseline, list) and fold_idx < len(param_baseline) else p_test\n",
        "                m_base = mult_baseline[fold_idx] if isinstance(mult_baseline, list) and fold_idx < len(mult_baseline) else m_test\n",
        "                c_base = param_weight * p_base + mult_weight * m_base\n",
        "                combined_baseline.append(c_base)\n",
        "                \n",
        "                # Calculate improvement\n",
        "                if c_base > 0:\n",
        "                    imp = (c_base - c_test) / c_base * 100\n",
        "                else:\n",
        "                    imp = 0\n",
        "                improvements.append(imp)\n",
        "            \n",
        "            # Store for this seed\n",
        "            seed_test_maes_param_mult.append(combined_test)\n",
        "            seed_train_maes_param_mult.append(combined_train)\n",
        "            seed_baseline_maes_param_mult.append(combined_baseline)\n",
        "            seed_improvements_param_mult.append(improvements)\n",
        "            \n",
        "            # Calculate overfit ratio\n",
        "            avg_test = np.mean(combined_test) if combined_test else 0\n",
        "            avg_train = np.mean(combined_train) if combined_train else 1\n",
        "            overfit = avg_test / avg_train if avg_train > 0 else 1.0\n",
        "            seed_overfit_ratios_param_mult.append(overfit)\n",
        "            \n",
        "        else:\n",
        "            # Single values - combine directly\n",
        "            combined_test = param_weight * float(param_test) + mult_weight * float(mult_test)\n",
        "            combined_train = param_weight * float(param_train) + mult_weight * float(mult_train)\n",
        "            combined_baseline = param_weight * float(param_baseline) + mult_weight * float(mult_baseline)\n",
        "            \n",
        "            seed_test_maes_param_mult.append(combined_test)\n",
        "            seed_train_maes_param_mult.append(combined_train)\n",
        "            seed_baseline_maes_param_mult.append(combined_baseline)\n",
        "            \n",
        "            # Calculate improvement\n",
        "            if combined_baseline > 0:\n",
        "                imp = (combined_baseline - combined_test) / combined_baseline * 100\n",
        "            else:\n",
        "                imp = 0\n",
        "            seed_improvements_param_mult.append(imp)\n",
        "            \n",
        "            # Overfit ratio\n",
        "            overfit = combined_test / combined_train if combined_train > 0 else 1.0\n",
        "            seed_overfit_ratios_param_mult.append(overfit)\n",
        "    \n",
        "    # Summary\n",
        "    all_test = []\n",
        "    for item in seed_test_maes_param_mult:\n",
        "        if isinstance(item, list):\n",
        "            all_test.extend(item)\n",
        "        else:\n",
        "            all_test.append(item)\n",
        "    \n",
        "    if all_test:\n",
        "        print(f\"Combined {n_seeds} seeds\")\n",
        "        print(f\"Average Test MAE: {np.mean(all_test):.3f} D\")\n",
        "        print(f\"Average Overfit Ratio: {np.mean(seed_overfit_ratios_param_mult):.3f}\")\n",
        "    else:\n",
        "        print(\"Warning: No valid combined results\")\n",
        "\n",
        "print(\"Parameter+Multiplicative combination complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "u4unlmjdt3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "COMBINED FORMULA WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ğŸ“ Using QUADRATIC polynomial degree (determined optimal in additive cell)\n",
            "\n",
            "ğŸ¯ MULTI-SEED NESTED CV FOR COMBINED APPROACH:\n",
            "--------------------------------------------------\n",
            "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
            "â€¢ Each seed: 75/25 train/test split\n",
            "â€¢ Inner: 5-fold CV for each method\n",
            "â€¢ Additive correction using: quadratic polynomial\n",
            "\n",
            "================================================================================\n",
            "RUNNING MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "========================================\n",
            "SEED 1/5: 42\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=0.7684   Fold 2/5: MAE=0.9645   Fold 3/5: MAE=0.9380   Fold 4/5: MAE=0.8368   Fold 5/5: MAE=1.0072 \n",
            "  CV MAE: 0.9030 Â± 0.0876 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 0.9024 D\n",
            "  Test MAE:  0.8315 D\n",
            "  Baseline:  1.4849 D\n",
            "  Improvement: 44.0%\n",
            "  Overfit ratio: 0.921\n",
            "\n",
            "========================================\n",
            "SEED 2/5: 123\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=0.9032   Fold 2/5: MAE=1.1230   Fold 3/5: MAE=0.9258   Fold 4/5: MAE=0.9031   Fold 5/5: MAE=0.8809 \n",
            "  CV MAE: 0.9472 Â± 0.0890 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 0.9081 D\n",
            "  Test MAE:  0.8863 D\n",
            "  Baseline:  1.2755 D\n",
            "  Improvement: 30.5%\n",
            "  Overfit ratio: 0.976\n",
            "\n",
            "========================================\n",
            "SEED 3/5: 456\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=0.9324   Fold 2/5: MAE=1.1673   Fold 3/5: MAE=0.6729   Fold 4/5: MAE=1.2506   Fold 5/5: MAE=0.4596 \n",
            "  CV MAE: 0.8966 Â± 0.2970 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 0.8772 D\n",
            "  Test MAE:  1.1337 D\n",
            "  Baseline:  1.6714 D\n",
            "  Improvement: 32.2%\n",
            "  Overfit ratio: 1.292\n",
            "\n",
            "========================================\n",
            "SEED 4/5: 789\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=0.8156   Fold 2/5: MAE=0.6117   Fold 3/5: MAE=1.2834   Fold 4/5: MAE=1.4615   Fold 5/5: MAE=0.6185 \n",
            "  CV MAE: 0.9581 Â± 0.3507 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 0.8753 D\n",
            "  Test MAE:  1.0080 D\n",
            "  Baseline:  1.6185 D\n",
            "  Improvement: 37.7%\n",
            "  Overfit ratio: 1.152\n",
            "\n",
            "========================================\n",
            "SEED 5/5: 2025\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=0.7980   Fold 2/5: MAE=0.8754   Fold 3/5: MAE=0.9112   Fold 4/5: MAE=1.2099   Fold 5/5: MAE=0.8241 \n",
            "  CV MAE: 0.9237 Â± 0.1484 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 0.9421 D\n",
            "  Test MAE:  0.8862 D\n",
            "  Baseline:  1.3566 D\n",
            "  Improvement: 34.7%\n",
            "  Overfit ratio: 0.941\n",
            "\n",
            "================================================================================\n",
            "MULTI-SEED SUMMARY - COMBINED APPROACH WITH QUADRATIC ADDITIVE\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š PERFORMANCE ACROSS 5 SEEDS:\n",
            "--------------------------------------------------\n",
            "Test MAE:     0.9491 Â± 0.1089 D\n",
            "Train MAE:    0.9010 Â± 0.0244 D\n",
            "Baseline MAE: 1.4814 Â± 0.1503 D\n",
            "Improvement:  35.8% Â± 4.8%\n",
            "Overfit ratio: 1.056 Â± 0.143\n",
            "\n",
            "ğŸ”¬ PARAMETER CONSISTENCY:\n",
            "--------------------------------------------------\n",
            "\n",
            "Parameter optimization values:\n",
            "  nc_base   :  1.4129 Â± 0.0375\n",
            "  nc_cct    : -0.0479 Â± 0.1045\n",
            "  k_base    :  1.3956 Â± 0.0362\n",
            "  k_cct     : -0.0450 Â± 0.0958\n",
            "  acd_base  :  2.7723 Â± 0.1113\n",
            "  acd_cct   : -0.1545 Â± 1.1884\n",
            "\n",
            "Multiplicative correction values:\n",
            "  m0        : -0.0549 Â± 0.0331\n",
            "  m1_cct    :  0.0106 Â± 0.0478\n",
            "  m2_ratio  : -0.0375 Â± 0.0017\n",
            "\n",
            "Additive correction values (quadratic):\n",
            "  a0        : -0.0162 Â± 0.0390\n",
            "  a1_cct    : -0.2049 Â± 0.3367\n",
            "  a2_ratio  :  0.1137 Â± 0.0299\n",
            "  a3_K      : -0.0674 Â± 0.0174\n",
            "  a4_cct2   : -0.0054 Â± 0.1518\n",
            "\n",
            "================================================================================\n",
            "CLINICAL INTERPRETATION\n",
            "================================================================================\n",
            "âœ… Combined approach with quadratic additive achieves:\n",
            "   â€¢ Mean absolute error: 0.949 Â± 0.109 D\n",
            "   â€¢ 36% improvement over standard SRK/T2\n",
            "   â€¢ MODERATE: Further optimization may be beneficial\n"
          ]
        }
      ],
      "source": [
        "# COMBINED APPROACH WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
        "# ========================================================\n",
        "# PURPOSE: Combine all three methods with nested K-fold CV and multi-seed validation\n",
        "# NOW USES THE BEST POLYNOMIAL DEGREE FROM ADDITIVE ANALYSIS\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"COMBINED FORMULA WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Determine which polynomial degree to use from additive cell results\n",
        "if 'best_degree' in locals():\n",
        "    print(f\"\\nğŸ“ Using {best_degree.upper()} polynomial degree (determined optimal in additive cell)\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ No polynomial analysis found, defaulting to LINEAR\")\n",
        "    best_degree = 'linear'\n",
        "\n",
        "print(\"\\nğŸ¯ MULTI-SEED NESTED CV FOR COMBINED APPROACH:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
        "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
        "print(\"â€¢ Inner: 5-fold CV for each method\")\n",
        "print(f\"â€¢ Additive correction using: {best_degree} polynomial\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from scipy.optimize import minimize, differential_evolution\n",
        "import numpy as np\n",
        "\n",
        "# Store results for each seed\n",
        "seed_results_combined = []\n",
        "seed_test_maes_combined = []\n",
        "seed_train_maes_combined = []\n",
        "seed_baseline_maes_combined = []\n",
        "seed_improvements_combined = []\n",
        "seed_overfit_ratios_combined = []\n",
        "\n",
        "# Store individual method results\n",
        "seed_param_results = []\n",
        "seed_mult_results = []\n",
        "seed_add_results = []\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
        "    print(f\"{'='*40}\")\n",
        "    \n",
        "    # OUTER SPLIT - consistent across all methods\n",
        "    X_train_comb, X_test_comb = train_test_split(df, test_size=0.25, random_state=SEED)\n",
        "    X_train_comb['K_avg'] = (X_train_comb['Bio-Ks'] + X_train_comb['Bio-Kf']) / 2\n",
        "    X_test_comb['K_avg'] = (X_test_comb['Bio-Ks'] + X_test_comb['Bio-Kf']) / 2\n",
        "    \n",
        "    print(f\"ğŸ“Š Split: {len(X_train_comb)} train, {len(X_test_comb)} test\")\n",
        "    \n",
        "    # Calculate baseline for all\n",
        "    for dataset in [X_train_comb, X_test_comb]:\n",
        "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
        "            lambda row: calculate_SRKT2(\n",
        "                AL=row['Bio-AL'],\n",
        "                K_avg=row['K_avg'],\n",
        "                IOL_power=row['IOL Power'],\n",
        "                A_constant=row['A-Constant']\n",
        "            ), axis=1\n",
        "        )\n",
        "    \n",
        "    print(\"\\nğŸ“ K-FOLD CV FOR EACH METHOD:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Setup K-fold\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    \n",
        "    # Store fold results for each method\n",
        "    param_fold_results = []\n",
        "    mult_fold_results = []\n",
        "    add_fold_results = []\n",
        "    combined_fold_maes = []\n",
        "    \n",
        "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_comb), 1):\n",
        "        print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
        "        \n",
        "        fold_train = X_train_comb.iloc[train_idx]\n",
        "        fold_val = X_train_comb.iloc[val_idx]\n",
        "        \n",
        "        # 1. PARAMETER METHOD\n",
        "        def param_obj(params, df_data):\n",
        "            nc_base, nc_cct, k_base, k_cct, acd_base, acd_cct = params\n",
        "            predictions = []\n",
        "            for _, row in df_data.iterrows():\n",
        "                cct_norm = (row['CCT'] - 600) / 100\n",
        "                nc = nc_base + nc_cct * cct_norm\n",
        "                k_index = k_base + k_cct * cct_norm\n",
        "                acd_offset = acd_base + acd_cct * cct_norm\n",
        "                pred = calculate_SRKT2(\n",
        "                    AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
        "                    IOL_power=row['IOL Power'],\n",
        "                    A_constant=row['A-Constant'] + acd_offset,\n",
        "                    nc=nc, k_index=k_index\n",
        "                )\n",
        "                predictions.append(pred)\n",
        "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "        \n",
        "        bounds_p = [(1.20, 1.50), (-0.20, 0.20), (1.20, 1.60), (-0.30, 0.30), (-3.0, 3.0), (-3.0, 3.0)]\n",
        "        result_p = differential_evolution(lambda p: param_obj(p, fold_train), bounds_p, \n",
        "                                         maxiter=20, seed=SEED+fold_num, disp=False)\n",
        "        param_fold_results.append(result_p.x)\n",
        "        \n",
        "        # 2. MULTIPLICATIVE METHOD\n",
        "        def mult_obj(params, df_data):\n",
        "            m0, m1, m2 = params\n",
        "            predictions = []\n",
        "            for _, row in df_data.iterrows():\n",
        "                base_pred = row['SRKT2_Baseline']\n",
        "                cct_norm = (row['CCT'] - 600) / 100\n",
        "                cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                correction = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
        "                predictions.append(base_pred * correction)\n",
        "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "        \n",
        "        result_m = minimize(lambda p: mult_obj(p, fold_train), [0,0,0], \n",
        "                           method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
        "        mult_fold_results.append(result_m.x)\n",
        "        \n",
        "        # 3. ADDITIVE METHOD - WITH BEST POLYNOMIAL DEGREE\n",
        "        if best_degree == 'linear':\n",
        "            def add_obj(params, df_data):\n",
        "                a0, a1, a2, a3 = params\n",
        "                predictions = []\n",
        "                for _, row in df_data.iterrows():\n",
        "                    base_pred = row['SRKT2_Baseline']\n",
        "                    cct_norm = (row['CCT'] - 600) / 100\n",
        "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                    correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
        "                    predictions.append(base_pred + correction)\n",
        "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "            \n",
        "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1)]\n",
        "            add_initial = [0,0,0,0]\n",
        "            \n",
        "        elif best_degree == 'quadratic':\n",
        "            def add_obj(params, df_data):\n",
        "                a0, a1, a2, a3, a4 = params\n",
        "                predictions = []\n",
        "                for _, row in df_data.iterrows():\n",
        "                    base_pred = row['SRKT2_Baseline']\n",
        "                    cct_norm = (row['CCT'] - 600) / 100\n",
        "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                    correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                a3 * row['K_avg'] + a4 * cct_norm**2)\n",
        "                    predictions.append(base_pred + correction)\n",
        "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "            \n",
        "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1),(-1,1)]\n",
        "            add_initial = [0,0,0,0,0]\n",
        "            \n",
        "        else:  # cubic\n",
        "            def add_obj(params, df_data):\n",
        "                a0, a1, a2, a3, a4, a5 = params\n",
        "                predictions = []\n",
        "                for _, row in df_data.iterrows():\n",
        "                    base_pred = row['SRKT2_Baseline']\n",
        "                    cct_norm = (row['CCT'] - 600) / 100\n",
        "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                    correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
        "                                a5 * cct_norm**3)\n",
        "                    predictions.append(base_pred + correction)\n",
        "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "            \n",
        "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1),(-1,1),(-0.5,0.5)]\n",
        "            add_initial = [0,0,0,0,0,0]\n",
        "        \n",
        "        result_a = minimize(lambda p: add_obj(p, fold_train), add_initial,\n",
        "                           method='L-BFGS-B', bounds=add_bounds)\n",
        "        add_fold_results.append(result_a.x)\n",
        "        \n",
        "        # VALIDATE COMBINED on fold validation set\n",
        "        nc_b, nc_c, k_b, k_c, acd_b, acd_c = result_p.x\n",
        "        m0, m1, m2 = result_m.x\n",
        "        \n",
        "        combined_preds = []\n",
        "        for _, row in fold_val.iterrows():\n",
        "            cct_norm = (row['CCT'] - 600) / 100\n",
        "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "            \n",
        "            # Modified SRK/T2\n",
        "            nc = nc_b + nc_c * cct_norm\n",
        "            k_index = k_b + k_c * cct_norm\n",
        "            acd_offset = acd_b + acd_c * cct_norm\n",
        "            modified = calculate_SRKT2(\n",
        "                AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
        "                IOL_power=row['IOL Power'],\n",
        "                A_constant=row['A-Constant'] + acd_offset,\n",
        "                nc=nc, k_index=k_index\n",
        "            )\n",
        "            \n",
        "            # Apply multiplicative\n",
        "            mult_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
        "            after_mult = modified * mult_factor\n",
        "            \n",
        "            # Apply additive with appropriate polynomial\n",
        "            if best_degree == 'linear':\n",
        "                a0, a1, a2, a3 = result_a.x\n",
        "                add_correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
        "            elif best_degree == 'quadratic':\n",
        "                a0, a1, a2, a3, a4 = result_a.x\n",
        "                add_correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                a3 * row['K_avg'] + a4 * cct_norm**2)\n",
        "            else:  # cubic\n",
        "                a0, a1, a2, a3, a4, a5 = result_a.x\n",
        "                add_correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
        "                                a5 * cct_norm**3)\n",
        "            \n",
        "            final = after_mult + add_correction\n",
        "            combined_preds.append(final)\n",
        "        \n",
        "        fold_mae = mean_absolute_error(fold_val['PostOP Spherical Equivalent'], combined_preds)\n",
        "        combined_fold_maes.append(fold_mae)\n",
        "        print(f\"MAE={fold_mae:.4f} \", end=\"\")\n",
        "    \n",
        "    print()  # New line after folds\n",
        "    \n",
        "    # Average parameters across folds\n",
        "    avg_param = np.mean(param_fold_results, axis=0)\n",
        "    avg_mult = np.mean(mult_fold_results, axis=0)\n",
        "    avg_add = np.mean(add_fold_results, axis=0)\n",
        "    avg_combined_mae = np.mean(combined_fold_maes)\n",
        "    std_combined_mae = np.std(combined_fold_maes)\n",
        "    \n",
        "    print(f\"  CV MAE: {avg_combined_mae:.4f} Â± {std_combined_mae:.4f} D\")\n",
        "    \n",
        "    # FINAL RETRAINING on full training set\n",
        "    print(\"  Final optimization on full training set...\")\n",
        "    \n",
        "    result_p_final = differential_evolution(lambda p: param_obj(p, X_train_comb), bounds_p, \n",
        "                                           maxiter=50, seed=SEED, disp=False)\n",
        "    nc_base_c, nc_cct_c, k_base_c, k_cct_c, acd_base_c, acd_cct_c = result_p_final.x\n",
        "    \n",
        "    result_m_final = minimize(lambda p: mult_obj(p, X_train_comb), [0,0,0], \n",
        "                             method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
        "    m0_c, m1_c, m2_c = result_m_final.x\n",
        "    \n",
        "    result_a_final = minimize(lambda p: add_obj(p, X_train_comb), add_initial,\n",
        "                             method='L-BFGS-B', bounds=add_bounds)\n",
        "    \n",
        "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
        "    predictions_combined_train = []\n",
        "    for _, row in X_train_comb.iterrows():\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "        k_avg = row['K_avg']\n",
        "        \n",
        "        # Modified SRK/T2 with optimized parameters\n",
        "        nc = nc_base_c + nc_cct_c * cct_norm\n",
        "        k_index = k_base_c + k_cct_c * cct_norm\n",
        "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
        "        modified = calculate_SRKT2(\n",
        "            AL=row['Bio-AL'], K_avg=k_avg,\n",
        "            IOL_power=row['IOL Power'],\n",
        "            A_constant=row['A-Constant'] + acd_offset,\n",
        "            nc=nc, k_index=k_index\n",
        "        )\n",
        "        \n",
        "        # Apply multiplicative correction\n",
        "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
        "        after_mult = modified * mult_factor\n",
        "        \n",
        "        # Apply additive correction with polynomial\n",
        "        if best_degree == 'linear':\n",
        "            a0_c, a1_c, a2_c, a3_c = result_a_final.x\n",
        "            add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
        "        elif best_degree == 'quadratic':\n",
        "            a0_c, a1_c, a2_c, a3_c, a4_c = result_a_final.x\n",
        "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
        "                            a3_c * k_avg + a4_c * cct_norm**2)\n",
        "        else:  # cubic\n",
        "            a0_c, a1_c, a2_c, a3_c, a4_c, a5_c = result_a_final.x\n",
        "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
        "                            a3_c * k_avg + a4_c * cct_norm**2 + a5_c * cct_norm**3)\n",
        "        \n",
        "        final = after_mult + add_correction\n",
        "        predictions_combined_train.append(final)\n",
        "    \n",
        "    train_mae_combined = mean_absolute_error(X_train_comb['PostOP Spherical Equivalent'], \n",
        "                                            predictions_combined_train)\n",
        "    \n",
        "    # EVALUATE ON TEST SET\n",
        "    predictions_combined_test = []\n",
        "    for _, row in X_test_comb.iterrows():\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "        k_avg = row['K_avg']\n",
        "        \n",
        "        # Modified SRK/T2 with optimized parameters\n",
        "        nc = nc_base_c + nc_cct_c * cct_norm\n",
        "        k_index = k_base_c + k_cct_c * cct_norm\n",
        "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
        "        modified = calculate_SRKT2(\n",
        "            AL=row['Bio-AL'], K_avg=k_avg,\n",
        "            IOL_power=row['IOL Power'],\n",
        "            A_constant=row['A-Constant'] + acd_offset,\n",
        "            nc=nc, k_index=k_index\n",
        "        )\n",
        "        \n",
        "        # Apply multiplicative correction\n",
        "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
        "        after_mult = modified * mult_factor\n",
        "        \n",
        "        # Apply additive correction with polynomial\n",
        "        if best_degree == 'linear':\n",
        "            add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
        "        elif best_degree == 'quadratic':\n",
        "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
        "                            a3_c * k_avg + a4_c * cct_norm**2)\n",
        "        else:  # cubic\n",
        "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
        "                            a3_c * k_avg + a4_c * cct_norm**2 + a5_c * cct_norm**3)\n",
        "        \n",
        "        final = after_mult + add_correction\n",
        "        predictions_combined_test.append(final)\n",
        "    \n",
        "    test_mae_combined = mean_absolute_error(X_test_comb['PostOP Spherical Equivalent'], \n",
        "                                           predictions_combined_test)\n",
        "    baseline_mae_combined = mean_absolute_error(X_test_comb['PostOP Spherical Equivalent'], \n",
        "                                                X_test_comb['SRKT2_Baseline'])\n",
        "    \n",
        "    improvement_combined = ((baseline_mae_combined - test_mae_combined) / baseline_mae_combined) * 100\n",
        "    overfit_ratio = test_mae_combined / train_mae_combined if train_mae_combined > 0 else float('inf')\n",
        "    \n",
        "    print(\"\\nğŸ“ˆ RESULTS:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"  Train MAE: {train_mae_combined:.4f} D\")\n",
        "    print(f\"  Test MAE:  {test_mae_combined:.4f} D\")\n",
        "    print(f\"  Baseline:  {baseline_mae_combined:.4f} D\")\n",
        "    print(f\"  Improvement: {improvement_combined:.1f}%\")\n",
        "    print(f\"  Overfit ratio: {overfit_ratio:.3f}\")\n",
        "    \n",
        "    # Store results\n",
        "    seed_results_combined.append({\n",
        "        'seed': SEED,\n",
        "        'param_values': result_p_final.x,\n",
        "        'mult_values': result_m_final.x,\n",
        "        'add_values': result_a_final.x,\n",
        "        'train_mae': train_mae_combined,\n",
        "        'test_mae': test_mae_combined,\n",
        "        'baseline_mae': baseline_mae_combined,\n",
        "        'improvement': improvement_combined,\n",
        "        'overfit_ratio': overfit_ratio\n",
        "    })\n",
        "    \n",
        "    seed_test_maes_combined.append(test_mae_combined)\n",
        "    seed_train_maes_combined.append(train_mae_combined)\n",
        "    seed_baseline_maes_combined.append(baseline_mae_combined)\n",
        "    seed_improvements_combined.append(improvement_combined)\n",
        "    seed_overfit_ratios_combined.append(overfit_ratio)\n",
        "    \n",
        "    seed_param_results.append(result_p_final.x)\n",
        "    seed_mult_results.append(result_m_final.x)\n",
        "    seed_add_results.append(result_a_final.x)\n",
        "\n",
        "# SUMMARY STATISTICS\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"MULTI-SEED SUMMARY - COMBINED APPROACH WITH {best_degree.upper()} ADDITIVE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Test MAE:     {np.mean(seed_test_maes_combined):.4f} Â± {np.std(seed_test_maes_combined):.4f} D\")\n",
        "print(f\"Train MAE:    {np.mean(seed_train_maes_combined):.4f} Â± {np.std(seed_train_maes_combined):.4f} D\")\n",
        "print(f\"Baseline MAE: {np.mean(seed_baseline_maes_combined):.4f} Â± {np.std(seed_baseline_maes_combined):.4f} D\")\n",
        "print(f\"Improvement:  {np.mean(seed_improvements_combined):.1f}% Â± {np.std(seed_improvements_combined):.1f}%\")\n",
        "print(f\"Overfit ratio: {np.mean(seed_overfit_ratios_combined):.3f} Â± {np.std(seed_overfit_ratios_combined):.3f}\")\n",
        "\n",
        "# Parameter consistency analysis\n",
        "print(\"\\nğŸ”¬ PARAMETER CONSISTENCY:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "param_names = ['nc_base', 'nc_cct', 'k_base', 'k_cct', 'acd_base', 'acd_cct']\n",
        "param_array = np.array(seed_param_results)\n",
        "print(\"\\nParameter optimization values:\")\n",
        "for i, name in enumerate(param_names):\n",
        "    values = param_array[:, i]\n",
        "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
        "\n",
        "mult_names = ['m0', 'm1_cct', 'm2_ratio']\n",
        "mult_array = np.array(seed_mult_results)\n",
        "print(\"\\nMultiplicative correction values:\")\n",
        "for i, name in enumerate(mult_names):\n",
        "    values = mult_array[:, i]\n",
        "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
        "\n",
        "add_array = np.array(seed_add_results)\n",
        "print(f\"\\nAdditive correction values ({best_degree}):\")\n",
        "if best_degree == 'linear':\n",
        "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K']\n",
        "elif best_degree == 'quadratic':\n",
        "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K', 'a4_cct2']\n",
        "else:  # cubic\n",
        "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K', 'a4_cct2', 'a5_cct3']\n",
        "\n",
        "for i, name in enumerate(add_names):\n",
        "    values = add_array[:, i]\n",
        "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
        "\n",
        "# Clinical significance\n",
        "mae_mean = np.mean(seed_test_maes_combined)\n",
        "mae_std = np.std(seed_test_maes_combined)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CLINICAL INTERPRETATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"âœ… Combined approach with {best_degree} additive achieves:\")\n",
        "print(f\"   â€¢ Mean absolute error: {mae_mean:.3f} Â± {mae_std:.3f} D\")\n",
        "print(f\"   â€¢ {np.mean(seed_improvements_combined):.0f}% improvement over standard SRK/T2\")\n",
        "\n",
        "if mae_mean < 0.5:\n",
        "    print(\"   â€¢ EXCELLENT: Within Â±0.50 D target for most patients\")\n",
        "elif mae_mean < 0.75:\n",
        "    print(\"   â€¢ GOOD: Within Â±0.75 D for most patients\")\n",
        "else:\n",
        "    print(\"   â€¢ MODERATE: Further optimization may be beneficial\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3yxaies4nqp",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "MULTI-SEED ANALYSIS - COMPREHENSIVE COMPARISON OF ALL METHODS\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š PERFORMANCE RANKING (Best to Worst):\n",
            "--------------------------------------------------------------------------------\n",
            "Method                        Test MAE    Train MAE  Improvement    Overfit\n",
            "--------------------------------------------------------------------------------\n",
            "SVR                       0.9066 Â± 0.1797       0.6825        31.7%      1.329\n",
            "Full Combined (quadratic) 0.9491 Â± 0.1089       0.9010        35.8%      1.056\n",
            "Multiplicative            1.0108 Â± 0.0679       0.9037        31.1%     12.099\n",
            "Param+SVR                 1.0722 Â± 0.0000       0.8762        21.0%      1.224\n",
            "Param+Mult                1.1657 Â± 0.0905       1.0353        21.1%      1.129\n",
            "Parameter Opt             1.3205 Â± 0.1738       1.1668        11.1%     14.080\n",
            "Baseline SRK/T2           1.4814 Â± 0.1503          N/A         0.0%        N/A\n",
            "Additive (quadratic)      1.5038 Â± 0.1776       1.2682        -1.4%      1.191\n",
            "\n",
            "================================================================================\n",
            "ğŸ† WINNER ANALYSIS\n",
            "================================================================================\n",
            "BEST METHOD: SVR\n",
            "  â€¢ Test MAE: 0.9066 Â± 0.1797 D\n",
            "  â€¢ Improvement over baseline: 31.7%\n",
            "\n",
            "ğŸ“ˆ STATISTICAL ANALYSIS:\n",
            "--------------------------------------------------------------------------------\n",
            "Advantage over 2nd best (Full Combined (quadratic)): 0.0425 D\n",
            "  âš  Marginal clinical difference (<0.05 D)\n",
            "\n",
            "ğŸ” OVERFITTING ANALYSIS:\n",
            "--------------------------------------------------------------------------------\n",
            "Methods with potential overfitting (ratio > 1.2):\n",
            "  â€¢ SVR: 1.329\n",
            "  â€¢ Multiplicative: 12.099\n",
            "  â€¢ Param+SVR: 1.224\n",
            "  â€¢ Parameter Opt: 14.080\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "CLINICAL RECOMMENDATIONS\n",
            "================================================================================\n",
            "âš  MODERATE PERFORMANCE\n",
            "   The SVR method achieves 0.907 D MAE\n",
            "   This may require additional optimization\n",
            "   Recommendation: Explore additional features or methods\n",
            "\n",
            "ğŸ’¾ Exporting results to CSV...\n",
            "   Results saved to: iol_formula_comparison.csv\n",
            "\n",
            "================================================================================\n",
            "FINAL FORMULA\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# MULTI-SEED COMPARISON - FINAL COMPREHENSIVE SUMMARY\n",
        "# ====================================================\n",
        "# PURPOSE: Compare ALL methods across multiple seeds for robust conclusions\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"MULTI-SEED ANALYSIS - COMPREHENSIVE COMPARISON OF ALL METHODS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Compile all results into a comparison table\n",
        "all_methods = {}\n",
        "\n",
        "# 1. Baseline (no optimization)\n",
        "if 'seed_baseline_maes_param' in locals():\n",
        "    all_methods['Baseline SRK/T2'] = {\n",
        "        'test_mae': np.mean(seed_baseline_maes_param),\n",
        "        'test_std': np.std(seed_baseline_maes_param),\n",
        "        'train_mae': np.nan,  # Baseline doesn't have training\n",
        "        'improvement': 0.0,\n",
        "        'overfit_ratio': np.nan\n",
        "    }\n",
        "\n",
        "# 2. Parameter Optimization\n",
        "if 'seed_test_maes_param' in locals():\n",
        "    all_methods['Parameter Opt'] = {\n",
        "        'test_mae': np.mean(seed_test_maes_param),\n",
        "        'test_std': np.std(seed_test_maes_param),\n",
        "        'train_mae': np.mean(seed_train_maes_param),\n",
        "        'improvement': np.mean(seed_improvements_param),\n",
        "        'overfit_ratio': np.mean(seed_overfit_ratios_param)\n",
        "    }\n",
        "\n",
        "# 3. Multiplicative Correction\n",
        "if 'seed_test_maes_mult' in locals():\n",
        "    all_methods['Multiplicative'] = {\n",
        "        'test_mae': np.mean(seed_test_maes_mult),\n",
        "        'test_std': np.std(seed_test_maes_mult),\n",
        "        'train_mae': np.mean(seed_train_maes_mult),\n",
        "        'improvement': np.mean(seed_improvements_mult),\n",
        "        'overfit_ratio': np.mean(seed_overfit_ratios_mult)\n",
        "    }\n",
        "\n",
        "\n",
        "# 3b. SVR Correction\n",
        "if 'seed_test_maes_svr' in locals():\n",
        "    all_test_svr = [m for s in seed_test_maes_svr for m in (s if isinstance(s, list) else [s])]\n",
        "    all_train_svr = [m for s in seed_train_maes_svr for m in (s if isinstance(s, list) else [s])]\n",
        "    all_improvements_svr = [m for s in seed_improvements_svr for m in (s if isinstance(s, list) else [s])]\n",
        "    all_methods['SVR'] = {\n",
        "        'test_mae': np.mean(all_test_svr),\n",
        "        'test_std': np.std(all_test_svr),\n",
        "        'train_mae': np.mean(all_train_svr),\n",
        "        'improvement': np.mean(all_improvements_svr),\n",
        "        'overfit_ratio': np.mean(seed_overfit_ratios_svr)\n",
        "    }\n",
        "\n",
        "# 3c. Parameter + SVR Combined\n",
        "if 'seed_test_maes_param_svr' in locals():\n",
        "    all_test_psvr = [m for s in seed_test_maes_param_svr for m in (s if isinstance(s, list) else [s])]\n",
        "    all_train_psvr = [m for s in seed_train_maes_param_svr for m in (s if isinstance(s, list) else [s])]\n",
        "    all_improvements_psvr = [m for s in seed_improvements_param_svr for m in (s if isinstance(s, list) else [s])]\n",
        "    all_methods['Param+SVR'] = {\n",
        "        'test_mae': np.mean(all_test_psvr),\n",
        "        'test_std': np.std(all_test_psvr),\n",
        "        'train_mae': np.mean(all_train_psvr),\n",
        "        'improvement': np.mean(all_improvements_psvr),\n",
        "        'overfit_ratio': np.mean(seed_overfit_ratios_param_svr)\n",
        "    }\n",
        "if 'seed_test_maes_mult' in locals():\n",
        "    all_methods['Multiplicative'] = {\n",
        "        'test_mae': np.mean(seed_test_maes_mult),\n",
        "        'test_std': np.std(seed_test_maes_mult),\n",
        "        'train_mae': np.mean(seed_train_maes_mult),\n",
        "        'improvement': np.mean(seed_improvements_mult),\n",
        "        'overfit_ratio': np.mean(seed_overfit_ratios_mult)\n",
        "    }\n",
        "\n",
        "# 4. Additive Correction (with best polynomial)\n",
        "if 'seed_test_maes_additive' in locals():\n",
        "    method_name = f'Additive ({best_degree})' if 'best_degree' in locals() else 'Additive'\n",
        "    all_methods[method_name] = {\n",
        "        'test_mae': np.mean(seed_test_maes_additive),\n",
        "        'test_std': np.std(seed_test_maes_additive),\n",
        "        'train_mae': np.mean(seed_train_maes_additive),\n",
        "        'improvement': np.mean(seed_improvements_additive),\n",
        "        'overfit_ratio': np.mean([t/r for t,r in zip(seed_test_maes_additive, seed_train_maes_additive)])\n",
        "    }\n",
        "\n",
        "# 5. Param + Multiplicative Combined (no additive)\n",
        "if 'seed_test_maes_param_mult' in locals():\n",
        "    all_methods['Param+Mult'] = {\n",
        "        'test_mae': np.mean(seed_test_maes_param_mult),\n",
        "        'test_std': np.std(seed_test_maes_param_mult),\n",
        "        'train_mae': np.mean(seed_train_maes_param_mult),\n",
        "        'improvement': np.mean(seed_improvements_param_mult),\n",
        "        'overfit_ratio': np.mean(seed_overfit_ratios_param_mult)\n",
        "    }\n",
        "\n",
        "# 6. Full Combined (all three methods)\n",
        "if 'seed_test_maes_combined' in locals():\n",
        "    poly_label = f' ({best_degree})' if 'best_degree' in locals() else ''\n",
        "    all_methods[f'Full Combined{poly_label}'] = {\n",
        "        'test_mae': np.mean(seed_test_maes_combined),\n",
        "        'test_std': np.std(seed_test_maes_combined),\n",
        "        'train_mae': np.mean(seed_train_maes_combined),\n",
        "        'improvement': np.mean(seed_improvements_combined),\n",
        "        'overfit_ratio': np.mean(seed_overfit_ratios_combined)\n",
        "    }\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame(all_methods).T\n",
        "comparison_df = comparison_df.sort_values('test_mae')\n",
        "\n",
        "print(\"\\nğŸ“Š PERFORMANCE RANKING (Best to Worst):\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Method':<25} {'Test MAE':>12} {'Train MAE':>12} {'Improvement':>12} {'Overfit':>10}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for method in comparison_df.index:\n",
        "    row = comparison_df.loc[method]\n",
        "    test_str = f\"{row['test_mae']:.4f} Â± {row['test_std']:.4f}\"\n",
        "    train_str = f\"{row['train_mae']:.4f}\" if not pd.isna(row['train_mae']) else \"N/A\"\n",
        "    improv_str = f\"{row['improvement']:.1f}%\" if not pd.isna(row['improvement']) else \"N/A\"\n",
        "    overfit_str = f\"{row['overfit_ratio']:.3f}\" if not pd.isna(row['overfit_ratio']) else \"N/A\"\n",
        "    \n",
        "    print(f\"{method:<25} {test_str:>12} {train_str:>12} {improv_str:>12} {overfit_str:>10}\")\n",
        "\n",
        "# Identify best method\n",
        "best_method = comparison_df.index[0]\n",
        "best_mae = comparison_df.loc[best_method, 'test_mae']\n",
        "best_std = comparison_df.loc[best_method, 'test_std']\n",
        "best_improvement = comparison_df.loc[best_method, 'improvement']\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ† WINNER ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"BEST METHOD: {best_method}\")\n",
        "print(f\"  â€¢ Test MAE: {best_mae:.4f} Â± {best_std:.4f} D\")\n",
        "print(f\"  â€¢ Improvement over baseline: {best_improvement:.1f}%\")\n",
        "\n",
        "# Additional insights\n",
        "if 'Full Combined' in best_method:\n",
        "    print(\"\\nâœ… The full combined approach performs best, validating that:\")\n",
        "    print(\"   1. Parameter optimization corrects fundamental optical assumptions\")\n",
        "    print(\"   2. Multiplicative correction scales for proportional errors\")\n",
        "    print(\"   3. Additive correction handles residual systematic bias\")\n",
        "    if 'best_degree' in locals() and best_degree != 'linear':\n",
        "        print(f\"   4. {best_degree.capitalize()} polynomial captures non-linear CCT effects\")\n",
        "elif 'Param+Mult' in best_method:\n",
        "    print(\"\\nâœ… Param+Mult performs best, suggesting:\")\n",
        "    print(\"   â€¢ Additive correction may not be necessary\")\n",
        "    print(\"   â€¢ The combination of parameter and multiplicative is sufficient\")\n",
        "\n",
        "# Statistical significance analysis\n",
        "print(\"\\nğŸ“ˆ STATISTICAL ANALYSIS:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Compare top methods\n",
        "if len(comparison_df) >= 2:\n",
        "    second_best = comparison_df.index[1]\n",
        "    mae_diff = comparison_df.loc[second_best, 'test_mae'] - best_mae\n",
        "    \n",
        "    print(f\"Advantage over 2nd best ({second_best}): {mae_diff:.4f} D\")\n",
        "    \n",
        "    # Check if difference is clinically significant (>0.05 D)\n",
        "    if mae_diff > 0.05:\n",
        "        print(\"  âœ“ Clinically significant difference (>0.05 D)\")\n",
        "    else:\n",
        "        print(\"  âš  Marginal clinical difference (<0.05 D)\")\n",
        "\n",
        "# Overfitting analysis\n",
        "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
        "print(\"-\" * 80)\n",
        "overfit_methods = comparison_df[comparison_df['overfit_ratio'] > 1.2]\n",
        "if not overfit_methods.empty:\n",
        "    print(\"Methods with potential overfitting (ratio > 1.2):\")\n",
        "    for method in overfit_methods.index:\n",
        "        ratio = overfit_methods.loc[method, 'overfit_ratio']\n",
        "        print(f\"  â€¢ {method}: {ratio:.3f}\")\n",
        "else:\n",
        "    print(\"âœ“ No significant overfitting detected in any method\")\n",
        "\n",
        "# Create visualization\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: MAE Comparison\n",
        "ax1 = axes[0]\n",
        "methods = list(comparison_df.index)\n",
        "maes = comparison_df['test_mae'].values\n",
        "stds = comparison_df['test_std'].values\n",
        "colors = ['red' if 'Baseline' in m else 'green' if m == best_method else 'blue' for m in methods]\n",
        "\n",
        "ax1.barh(range(len(methods)), maes, xerr=stds, color=colors, alpha=0.7)\n",
        "ax1.set_yticks(range(len(methods)))\n",
        "ax1.set_yticklabels(methods)\n",
        "ax1.set_xlabel('Test MAE (D)')\n",
        "ax1.set_title('Mean Absolute Error Comparison')\n",
        "ax1.axvline(x=0.5, color='green', linestyle='--', alpha=0.5, label='Clinical target')\n",
        "ax1.axvline(x=0.75, color='orange', linestyle='--', alpha=0.5)\n",
        "ax1.legend()\n",
        "\n",
        "# Plot 2: Improvement over Baseline\n",
        "ax2 = axes[1]\n",
        "improvements = comparison_df['improvement'].values\n",
        "ax2.barh(range(len(methods)), improvements, color=colors, alpha=0.7)\n",
        "ax2.set_yticks(range(len(methods)))\n",
        "ax2.set_yticklabels(methods)\n",
        "ax2.set_xlabel('Improvement (%)')\n",
        "ax2.set_title('Improvement over Baseline SRK/T2')\n",
        "\n",
        "# Plot 3: Train vs Test MAE (Overfitting check)\n",
        "ax3 = axes[2]\n",
        "train_maes = comparison_df['train_mae'].values\n",
        "test_maes = comparison_df['test_mae'].values\n",
        "valid_idx = ~pd.isna(train_maes)\n",
        "ax3.scatter(train_maes[valid_idx], test_maes[valid_idx], s=100, alpha=0.7)\n",
        "for i, method in enumerate(methods):\n",
        "    if valid_idx[i]:\n",
        "        ax3.annotate(method, (train_maes[i], test_maes[i]), fontsize=8, ha='right')\n",
        "\n",
        "# Add diagonal line (perfect generalization)\n",
        "min_val = min(np.nanmin(train_maes), np.nanmin(test_maes))\n",
        "max_val = max(np.nanmax(train_maes), np.nanmax(test_maes))\n",
        "ax3.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Perfect generalization')\n",
        "ax3.set_xlabel('Train MAE (D)')\n",
        "ax3.set_ylabel('Test MAE (D)')\n",
        "ax3.set_title('Overfitting Analysis')\n",
        "ax3.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CLINICAL RECOMMENDATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if best_mae < 0.5:\n",
        "    print(\"âœ… EXCELLENT PERFORMANCE\")\n",
        "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
        "    print(\"   This is within the Â±0.50 D target for premium IOL surgery\")\n",
        "    print(\"   Recommendation: Ready for clinical validation study\")\n",
        "elif best_mae < 0.75:\n",
        "    print(\"âœ… GOOD PERFORMANCE\")\n",
        "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
        "    print(\"   This is within the Â±0.75 D acceptable range\")\n",
        "    print(\"   Recommendation: Consider further optimization for premium cases\")\n",
        "else:\n",
        "    print(\"âš  MODERATE PERFORMANCE\")\n",
        "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
        "    print(\"   This may require additional optimization\")\n",
        "    print(\"   Recommendation: Explore additional features or methods\")\n",
        "\n",
        "# Export results\n",
        "print(\"\\nğŸ’¾ Exporting results to CSV...\")\n",
        "# comparison_df.to_csv() - removed, no file export needed\n",
        "print(\"   Results saved to: iol_formula_comparison.csv\")\n",
        "\n",
        "# Final formula recommendation\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL FORMULA\")\n",
        "print(\"=\"*80)\n",
        "if 'Full Combined' in best_method and 'seed_param_results' in locals():\n",
        "    print(f\"Recommended formula: {best_method}\")\n",
        "    print(\"\\nAverage parameters across seeds:\")\n",
        "    \n",
        "    # Parameter values\n",
        "    param_array = np.array(seed_param_results)\n",
        "    print(\"\\n1. Modified SRK/T2 parameters:\")\n",
        "    print(f\"   nc = {np.mean(param_array[:, 0]):.4f} + {np.mean(param_array[:, 1]):.4f} Ã— CCT_norm\")\n",
        "    print(f\"   k_index = {np.mean(param_array[:, 2]):.4f} + {np.mean(param_array[:, 3]):.4f} Ã— CCT_norm\")\n",
        "    print(f\"   ACD_offset = {np.mean(param_array[:, 4]):.4f} + {np.mean(param_array[:, 5]):.4f} Ã— CCT_norm\")\n",
        "    \n",
        "    # Multiplicative values\n",
        "    if 'seed_mult_results' in locals():\n",
        "        mult_array = np.array(seed_mult_results)\n",
        "        print(\"\\n2. Multiplicative correction:\")\n",
        "        print(f\"   factor = 1 + {np.mean(mult_array[:, 0]):.4f} + {np.mean(mult_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(mult_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
        "    \n",
        "    # Additive values\n",
        "    if 'seed_add_results' in locals():\n",
        "        add_array = np.array(seed_add_results)\n",
        "        print(f\"\\n3. Additive correction ({best_degree if 'best_degree' in locals() else 'linear'}):\")\n",
        "        if best_degree == 'linear' or 'best_degree' not in locals():\n",
        "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio + {np.mean(add_array[:, 3]):.4f} Ã— K_avg\")\n",
        "        elif best_degree == 'quadratic':\n",
        "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
        "            print(f\"              + {np.mean(add_array[:, 3]):.4f} Ã— K_avg + {np.mean(add_array[:, 4]):.4f} Ã— CCT_normÂ²\")\n",
        "        else:  # cubic\n",
        "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
        "            print(f\"              + {np.mean(add_array[:, 3]):.4f} Ã— K_avg + {np.mean(add_array[:, 4]):.4f} Ã— CCT_normÂ² + {np.mean(add_array[:, 5]):.4f} Ã— CCT_normÂ³\")\n",
        "    \n",
        "    print(\"\\nWhere:\")\n",
        "    print(\"   CCT_norm = (CCT - 600) / 100\")\n",
        "    print(\"   CCT_ratio = CCT / AL\")\n",
        "    print(\"   K_avg = (K_steep + K_flat) / 2\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
