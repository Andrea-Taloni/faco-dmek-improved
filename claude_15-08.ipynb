{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41782613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ”§ MULTI-SEED CONFIGURATION\n",
      "======================================================================\n",
      "Seeds for validation: [42, 123, 456, 789, 2025]\n",
      "This ensures results are not dependent on random split\n",
      "Each seed creates different train/test splits for robust assessment\n",
      "======================================================================\n",
      "IOL CALCULATION FOR PRE-DMEK PATIENTS\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š WHAT WE'RE DOING:\n",
      "--------------------------------------------------\n",
      "â€¢ Loading data from Fuchs' dystrophy patients\n",
      "â€¢ These patients had combined cataract + DMEK surgery\n",
      "â€¢ Goal: Improve IOL power calculation accuracy\n",
      "â€¢ Challenge: Edematous corneas distort standard formulas\n",
      "â€¢ NEW: Using 5 different seeds for robust validation\n",
      "\n",
      "âœ… Loaded 96 patients from FacoDMEK.xlsx\n",
      "\n",
      "ğŸ” KEY MEASUREMENTS IN OUR DATA:\n",
      "--------------------------------------------------\n",
      "â€¢ Bio-AL: Axial length (mm)\n",
      "â€¢ Bio-Ks/Kf: Steep and flat keratometry (D)\n",
      "â€¢ CCT: Central corneal thickness (Î¼m) - KEY for edema\n",
      "â€¢ IOL Power: Implanted lens power (D)\n",
      "â€¢ PostOP Spherical Equivalent: Actual outcome (D)\n"
     ]
    }
   ],
   "source": [
    "# IOL CALCULATION FOR PRE-DMEK PATIENTS - SETUP AND DATA LOADING\n",
    "# ================================================================\n",
    "# PURPOSE: Set up the analysis environment and load patient data\n",
    "# This notebook optimizes IOL power calculations for Fuchs' dystrophy patients\n",
    "# undergoing combined phacoemulsification and DMEK surgery\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants for clinical accuracy thresholds (diopters)\n",
    "THRESHOLDS = [0.25, 0.50, 0.75, 1.00]\n",
    "TEST_SIZE = 0.25      # 25% holdout for final testing\n",
    "N_FOLDS = 5           # 5-fold cross-validation\n",
    "\n",
    "# MULTI-SEED CONFIGURATION FOR ROBUST VALIDATION\n",
    "#SEEDS = [42]  # Quick test with single seed\n",
    "#SEEDS = [42, 123]  # Medium test with 2 seeds\n",
    "SEEDS = [42, 123, 456, 789, 2025]  # Multiple seeds for statistical robustness\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”§ MULTI-SEED CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Seeds for validation: {SEEDS}\")\n",
    "print(\"This ensures results are not dependent on random split\")\n",
    "print(\"Each seed creates different train/test splits for robust assessment\")\n",
    "\n",
    "# Storage for multi-seed results\n",
    "multi_seed_results = {\n",
    "\n",
    "    'parameter': {},\n",
    "    'multiplicative': {},\n",
    "    'additive': {},\n",
    "    'combined': {},\n",
    "    'fixed_combined': {}\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"IOL CALCULATION FOR PRE-DMEK PATIENTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nğŸ“Š WHAT WE'RE DOING:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Loading data from Fuchs' dystrophy patients\")\n",
    "print(\"â€¢ These patients had combined cataract + DMEK surgery\")\n",
    "print(\"â€¢ Goal: Improve IOL power calculation accuracy\")\n",
    "print(\"â€¢ Challenge: Edematous corneas distort standard formulas\")\n",
    "print(f\"â€¢ NEW: Using {len(SEEDS)} different seeds for robust validation\")\n",
    "\n",
    "# Load the patient data\n",
    "df = pd.read_excel('FacoDMEK.xlsx')\n",
    "print(f\"\\nâœ… Loaded {len(df)} patients from FacoDMEK.xlsx\")\n",
    "\n",
    "print(\"\\nğŸ” KEY MEASUREMENTS IN OUR DATA:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Bio-AL: Axial length (mm)\")\n",
    "print(\"â€¢ Bio-Ks/Kf: Steep and flat keratometry (D)\")\n",
    "print(\"â€¢ CCT: Central corneal thickness (Î¼m) - KEY for edema\")\n",
    "print(\"â€¢ IOL Power: Implanted lens power (D)\")\n",
    "print(\"â€¢ PostOP Spherical Equivalent: Actual outcome (D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9871e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SRK/T2 FORMULA (Sheard et al. 2010)\n",
      "======================================================================\n",
      "â€¢ SKR/T2 assumes normal corneal properties\n",
      "â€¢ In Fuchs' dystrophy, the cornea is NOT normal:\n",
      "  - Edema changes refractive index (nc)\n",
      "  - Swelling alters keratometric index (k_index)\n",
      "  - Anterior chamber depth is affected\n",
      "\n",
      "Our strategy: Keep the formula structure, optimize the parameters!\n",
      "\n",
      "ğŸ“ THE SRK/T2 FORMULA:\n",
      "\n",
      "         1000Â·nâ‚Â·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) - PÂ·(Lopt - ACDest)Â·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest)\n",
      "REF = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       nâ‚Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) + LoptÂ·r) - 0.001Â·PÂ·(Lopt - ACDest)Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest) + ACDestÂ·r)\n"
     ]
    }
   ],
   "source": [
    "# STANDARD SRK/T2 FORMULA IMPLEMENTATION\n",
    "# ========================================\n",
    "# PURPOSE: Implement the baseline SRK/T2 formula (Sheard et al. 2010)\n",
    "# This is the current gold standard for IOL calculations\n",
    "# We'll use this as our baseline to compare improvements against\n",
    "\n",
    "def calculate_SRKT2(AL, K_avg, IOL_power, A_constant, nc=1.333, k_index=1.3375):\n",
    "    \"\"\"\n",
    "    SRK/T2 Formula (Sheard et al. 2010)\n",
    "    - Assumes NORMAL corneas (nc=1.333, k_index=1.3375)\n",
    "    - These assumptions fail in edematous Fuchs' corneas\n",
    "    \n",
    "    Parameters:\n",
    "    - AL: Axial length (mm)\n",
    "    - K_avg: Average keratometry (D)\n",
    "    - IOL_power: IOL power (D)\n",
    "    - A_constant: Lens-specific constant\n",
    "    - nc: Corneal refractive index (we'll optimize this!)\n",
    "    - k_index: Keratometric index (we'll optimize this too!)\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    na = 1.336  # Aqueous/vitreous refractive index\n",
    "    V = 12      # Vertex distance (mm)\n",
    "    ncm1 = nc - 1\n",
    "    \n",
    "    # Convert keratometry to radius using keratometric index\n",
    "    # This is where edema causes problems - k_index assumes normal cornea!\n",
    "    r = (k_index - 1) * 1000 / K_avg\n",
    "    \n",
    "    # Axial length correction for long eyes\n",
    "    if AL <= 24.2:\n",
    "        LCOR = AL\n",
    "    else:\n",
    "        LCOR = 3.446 + 1.716 * AL - 0.0237 * AL * AL\n",
    "    \n",
    "    # H2 calculation (corneal height) - Sheard's modification\n",
    "    H2 = -10.326 + 0.32630 * LCOR + 0.13533 * K_avg\n",
    "    \n",
    "    # ACD (Anterior Chamber Depth) estimation\n",
    "    # Edema can affect this too!\n",
    "    ACD_const = 0.62467 * A_constant - 68.747\n",
    "    offset = ACD_const - 3.336\n",
    "    ACD_est = H2 + offset\n",
    "    \n",
    "    # Retinal thickness correction\n",
    "    RETHICK = 0.65696 - 0.02029 * AL\n",
    "    LOPT = AL + RETHICK  # Optical axial length\n",
    "    \n",
    "    # SRK/T2 refraction calculation - the complex optics formula\n",
    "    numerator = (1000 * na * (na * r - ncm1 * LOPT) - \n",
    "                 IOL_power * (LOPT - ACD_est) * (na * r - ncm1 * ACD_est))\n",
    "    \n",
    "    denominator = (na * (V * (na * r - ncm1 * LOPT) + LOPT * r) - \n",
    "                   0.001 * IOL_power * (LOPT - ACD_est) * \n",
    "                   (V * (na * r - ncm1 * ACD_est) + ACD_est * r))\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SRK/T2 FORMULA (Sheard et al. 2010)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"â€¢ SKR/T2 assumes normal corneal properties\")\n",
    "print(\"â€¢ In Fuchs' dystrophy, the cornea is NOT normal:\")\n",
    "print(\"  - Edema changes refractive index (nc)\")\n",
    "print(\"  - Swelling alters keratometric index (k_index)\")\n",
    "print(\"  - Anterior chamber depth is affected\")\n",
    "print(\"\\nOur strategy: Keep the formula structure, optimize the parameters!\")\n",
    "\n",
    "print(\"\\nğŸ“ THE SRK/T2 FORMULA:\")\n",
    "print()\n",
    "print(\"         1000Â·nâ‚Â·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) - PÂ·(Lopt - ACDest)Â·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest)\")\n",
    "print(\"REF = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(\"       nâ‚Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) + LoptÂ·r) - 0.001Â·PÂ·(Lopt - ACDest)Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest) + ACDestÂ·r)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db415cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE SRK/T2 PERFORMANCE\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ WHAT WE'RE DOING:\n",
      "--------------------------------------------------\n",
      "1. Calculate average K from steep and flat readings\n",
      "2. Apply standard SRK/T2 to all 96 patients\n",
      "3. Compare predictions to actual outcomes\n",
      "4. Measure error to establish baseline performance\n",
      "\n",
      "ğŸ“Š BASELINE PERFORMANCE METRICS:\n",
      "======================================================================\n",
      "  Mean Absolute Error (MAE):     1.3591 D\n",
      "  Mean Error (ME):                -0.2915 D\n",
      "  Standard Deviation (SD):        1.7471 D\n",
      "  Median Absolute Error:          1.0311 D\n",
      "\n",
      "ğŸ’¡ INTERPRETATION:\n",
      "--------------------------------------------------\n",
      "â€¢ MAE of 1.36 D is POOR (>1.0 D is clinically unacceptable)\n",
      "â€¢ Mean error of -0.29 D shows systematic bias\n",
      "  â†’ Formula tends to predict too myopic (negative)\n",
      "\n",
      "ğŸ“ˆ CLINICAL ACCURACY:\n",
      "----------------------------------------------------------------------\n",
      "  Within Â±0.25 D:  13.5% of eyes\n",
      "  Within Â±0.50 D:  26.0% of eyes\n",
      "  Within Â±0.75 D:  35.4% of eyes\n",
      "  Within Â±1.00 D:  49.0% of eyes\n",
      "\n",
      "ğŸ¯ CLINICAL TARGETS:\n",
      "--------------------------------------------------\n",
      "â€¢ Modern standard: >70% within Â±0.50 D\n",
      "â€¢ Acceptable: >90% within Â±1.00 D\n",
      "â€¢ Our baseline: 26.0% within Â±0.50 D\n",
      "\n",
      "âš ï¸ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\n",
      "This is why we need optimization!\n"
     ]
    }
   ],
   "source": [
    "# BASELINE PERFORMANCE EVALUATION\n",
    "# =================================\n",
    "# PURPOSE: Calculate how well standard SRK/T2 performs on our Fuchs' patients\n",
    "# This establishes the baseline that we need to beat\n",
    "# Spoiler: It won't be great due to the edematous corneas!\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BASELINE SRK/T2 PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nğŸ“‹ WHAT WE'RE DOING:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. Calculate average K from steep and flat readings\")\n",
    "print(\"2. Apply standard SRK/T2 to all 96 patients\")\n",
    "print(\"3. Compare predictions to actual outcomes\")\n",
    "print(\"4. Measure error to establish baseline performance\")\n",
    "\n",
    "# Calculate average K (needed for SRK/T2)\n",
    "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
    "\n",
    "# Apply standard SRK/T2 formula to all patients\n",
    "df['SRKT2_Prediction'] = df.apply(\n",
    "    lambda row: calculate_SRKT2(\n",
    "        AL=row['Bio-AL'],\n",
    "        K_avg=row['K_avg'],\n",
    "        IOL_power=row['IOL Power'],\n",
    "        A_constant=row['A-Constant']\n",
    "        # Note: Using DEFAULT nc=1.333 and k_index=1.3375\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Calculate prediction errors\n",
    "df['Prediction_Error'] = df['PostOP Spherical Equivalent'] - df['SRKT2_Prediction']\n",
    "df['Absolute_Error'] = abs(df['Prediction_Error'])\n",
    "\n",
    "# Calculate key metrics\n",
    "mae = df['Absolute_Error'].mean()\n",
    "me = df['Prediction_Error'].mean()\n",
    "std = df['Prediction_Error'].std()\n",
    "median_ae = df['Absolute_Error'].median()\n",
    "\n",
    "print(\"\\nğŸ“Š BASELINE PERFORMANCE METRICS:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Mean Absolute Error (MAE):     {mae:.4f} D\")\n",
    "print(f\"  Mean Error (ME):                {me:+.4f} D\")\n",
    "print(f\"  Standard Deviation (SD):        {std:.4f} D\")\n",
    "print(f\"  Median Absolute Error:          {median_ae:.4f} D\")\n",
    "\n",
    "print(\"\\nğŸ’¡ INTERPRETATION:\")\n",
    "print(\"-\" * 50)\n",
    "if mae > 1.0:\n",
    "    print(f\"â€¢ MAE of {mae:.2f} D is POOR (>1.0 D is clinically unacceptable)\")\n",
    "else:\n",
    "    print(f\"â€¢ MAE of {mae:.2f} D is moderate\")\n",
    "    \n",
    "if abs(me) > 0.25:\n",
    "    print(f\"â€¢ Mean error of {me:+.2f} D shows systematic bias\")\n",
    "    if me < 0:\n",
    "        print(\"  â†’ Formula tends to predict too myopic (negative)\")\n",
    "    else:\n",
    "        print(\"  â†’ Formula tends to predict too hyperopic (positive)\")\n",
    "\n",
    "# Calculate clinical accuracy rates\n",
    "within_025 = (df['Absolute_Error'] <= 0.25).sum() / len(df) * 100\n",
    "within_050 = (df['Absolute_Error'] <= 0.50).sum() / len(df) * 100\n",
    "within_075 = (df['Absolute_Error'] <= 0.75).sum() / len(df) * 100\n",
    "within_100 = (df['Absolute_Error'] <= 1.00).sum() / len(df) * 100\n",
    "\n",
    "print(\"\\nğŸ“ˆ CLINICAL ACCURACY:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Within Â±0.25 D:  {within_025:.1f}% of eyes\")\n",
    "print(f\"  Within Â±0.50 D:  {within_050:.1f}% of eyes\")\n",
    "print(f\"  Within Â±0.75 D:  {within_075:.1f}% of eyes\")\n",
    "print(f\"  Within Â±1.00 D:  {within_100:.1f}% of eyes\")\n",
    "\n",
    "print(\"\\nğŸ¯ CLINICAL TARGETS:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Modern standard: >70% within Â±0.50 D\")\n",
    "print(\"â€¢ Acceptable: >90% within Â±1.00 D\")\n",
    "print(f\"â€¢ Our baseline: {within_050:.1f}% within Â±0.50 D\")\n",
    "print(\"\\nâš ï¸ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\")\n",
    "print(\"This is why we need optimization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d38452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CALCULATING GLOBAL BASELINE FOR FAIR COMPARISON\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š CALCULATING BASELINE ACROSS ALL SEEDS:\n",
      "--------------------------------------------------\n",
      "  Seed 42: Baseline MAE = 1.4849 D\n",
      "  Seed 123: Baseline MAE = 1.2755 D\n",
      "  Seed 456: Baseline MAE = 1.6714 D\n",
      "  Seed 789: Baseline MAE = 1.6185 D\n",
      "  Seed 2025: Baseline MAE = 1.3566 D\n",
      "\n",
      "================================================================================\n",
      "GLOBAL BASELINE ESTABLISHED:\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Œ BASELINE MAE: 1.4814 Â± 0.1503 D\n",
      "   Min: 1.2755 D\n",
      "   Max: 1.6714 D\n",
      "\n",
      "âš ï¸ IMPORTANT:\n",
      "--------------------------------------------------\n",
      "All methods will now use this baseline for improvement calculations.\n",
      "This ensures fair comparison between methods.\n",
      "Improvement = ((1.4814 - Method_MAE) / 1.4814) Ã— 100%\n",
      "\n",
      "âœ… Global baseline stored in variable: GLOBAL_BASELINE_MAE = 1.4814\n",
      "All methods should now calculate improvement as:\n",
      "   improvement = ((GLOBAL_BASELINE_MAE - test_mae) / GLOBAL_BASELINE_MAE) * 100\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL BASELINE CALCULATION - CONSISTENT ACROSS ALL METHODS\n",
    "# ===========================================================\n",
    "# PURPOSE: Calculate baseline performance ONCE for fair comparison\n",
    "# This ensures all methods use the same baseline for improvement calculations\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CALCULATING GLOBAL BASELINE FOR FAIR COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nğŸ“Š CALCULATING BASELINE ACROSS ALL SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Store baseline MAEs for each seed\n",
    "global_baseline_maes = []\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    # Split data with this seed\n",
    "    X_train_base, X_test_base = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    \n",
    "    # Calculate K_avg\n",
    "    X_test_base['K_avg'] = (X_test_base['Bio-Ks'] + X_test_base['Bio-Kf']) / 2\n",
    "    \n",
    "    # Calculate baseline predictions\n",
    "    X_test_base['SRKT2_Baseline'] = X_test_base.apply(\n",
    "        lambda row: calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant']\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    # Calculate MAE for this seed\n",
    "    baseline_mae = mean_absolute_error(\n",
    "        X_test_base['PostOP Spherical Equivalent'], \n",
    "        X_test_base['SRKT2_Baseline']\n",
    "    )\n",
    "    \n",
    "    global_baseline_maes.append(baseline_mae)\n",
    "    print(f\"  Seed {SEED}: Baseline MAE = {baseline_mae:.4f} D\")\n",
    "\n",
    "# Calculate global baseline (average across all seeds)\n",
    "GLOBAL_BASELINE_MAE = np.mean(global_baseline_maes)\n",
    "GLOBAL_BASELINE_STD = np.std(global_baseline_maes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GLOBAL BASELINE ESTABLISHED:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸ“Œ BASELINE MAE: {GLOBAL_BASELINE_MAE:.4f} Â± {GLOBAL_BASELINE_STD:.4f} D\")\n",
    "print(f\"   Min: {np.min(global_baseline_maes):.4f} D\")\n",
    "print(f\"   Max: {np.max(global_baseline_maes):.4f} D\")\n",
    "\n",
    "print(\"\\nâš ï¸ IMPORTANT:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"All methods will now use this baseline for improvement calculations.\")\n",
    "print(\"This ensures fair comparison between methods.\")\n",
    "print(f\"Improvement = (({GLOBAL_BASELINE_MAE:.4f} - Method_MAE) / {GLOBAL_BASELINE_MAE:.4f}) Ã— 100%\")\n",
    "\n",
    "# Store for use by all subsequent methods\n",
    "print(f\"\\nâœ… Global baseline stored in variable: GLOBAL_BASELINE_MAE = {GLOBAL_BASELINE_MAE:.4f}\")\n",
    "print(\"All methods should now calculate improvement as:\")\n",
    "print(\"   improvement = ((GLOBAL_BASELINE_MAE - test_mae) / GLOBAL_BASELINE_MAE) * 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ridge_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RIDGE REGRESSION FEATURE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ” WHY START WITH RIDGE?\n",
      "--------------------------------------------------\n",
      "â€¢ Ridge regression identifies important features\n",
      "â€¢ Helps us understand what drives prediction errors\n",
      "â€¢ Guides our formula optimization strategy\n",
      "â€¢ If CCT features are important, our hypothesis is correct!\n",
      "\n",
      "ğŸ“Š CREATING FEATURES:\n",
      "--------------------------------------------------\n",
      "Created 12 features including CCT interactions\n",
      "\n",
      "ğŸ† TOP 10 MOST IMPORTANT FEATURES:\n",
      "--------------------------------------------------\n",
      "  CCT_ratio_AL         Coef=+1.3677\n",
      "  CCT_x_AL             Coef=-0.8898\n",
      "  CCT_squared          Coef=-0.7666\n",
      "  Bio-AL               Coef=+0.4903\n",
      "  Bio-Ks               Coef=-0.3178\n",
      "  CCT_x_K              Coef=+0.3101\n",
      "  K_avg                Coef=-0.1584\n",
      "  IOL Power            Coef=-0.1189\n",
      "  CCT_norm             Coef=+0.0321\n",
      "  CCT                  Coef=+0.0321\n",
      "\n",
      "ğŸ’¡ KEY FINDINGS:\n",
      "--------------------------------------------------\n",
      "â€¢ CCT-related features account for 75.5% of total importance\n",
      "â€¢ Top feature: CCT_ratio_AL\n",
      "â€¢ CCT/AL ratio is among top 3 features!\n",
      "â€¢ This validates that CCT relative to eye size matters\n",
      "\n",
      "âœ… HYPOTHESIS CONFIRMED:\n",
      "CCT features dominate prediction - our CCT-dependent approach is justified!\n",
      "\n",
      "ğŸ¯ OPTIMIZATION STRATEGY BASED ON RIDGE:\n",
      "--------------------------------------------------\n",
      "1. Make optical parameters CCT-dependent (nc, k_index)\n",
      "2. Consider CCT/AL ratio in corrections\n",
      "3. Account for CCT interactions with other measurements\n"
     ]
    }
   ],
   "source": [
    "# RIDGE REGRESSION ANALYSIS - IDENTIFYING IMPORTANT FEATURES\n",
    "# ===========================================================\n",
    "# PURPOSE: Use machine learning to identify which features matter most\n",
    "# This will guide our optimization strategy\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RIDGE REGRESSION FEATURE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ” WHY START WITH RIDGE?\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Ridge regression identifies important features\")\n",
    "print(\"â€¢ Helps us understand what drives prediction errors\")\n",
    "print(\"â€¢ Guides our formula optimization strategy\")\n",
    "print(\"â€¢ If CCT features are important, our hypothesis is correct!\")\n",
    "\n",
    "# Create feature matrix with interactions\n",
    "print(\"\\nğŸ“Š CREATING FEATURES:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "features = []\n",
    "feature_names = []\n",
    "\n",
    "# Basic features\n",
    "for col in ['Bio-AL', 'Bio-Ks', 'Bio-Kf', 'IOL Power', 'CCT']:\n",
    "    features.append(df[col].values)\n",
    "    feature_names.append(col)\n",
    "\n",
    "# Add K_avg\n",
    "features.append(df['K_avg'].values)\n",
    "feature_names.append('K_avg')\n",
    "\n",
    "# CCT-derived features\n",
    "df['CCT_squared'] = df['CCT'] ** 2\n",
    "df['CCT_deviation'] = df['CCT'] - 550\n",
    "df['CCT_norm'] = (df['CCT'] - 600) / 100\n",
    "\n",
    "features.extend([\n",
    "    df['CCT_squared'].values,\n",
    "    df['CCT_deviation'].values,\n",
    "    df['CCT_norm'].values\n",
    "])\n",
    "feature_names.extend(['CCT_squared', 'CCT_deviation', 'CCT_norm'])\n",
    "\n",
    "# Interaction terms\n",
    "df['CCT_x_AL'] = df['CCT'] * df['Bio-AL']\n",
    "df['CCT_x_K'] = df['CCT'] * df['K_avg']\n",
    "df['CCT_ratio_AL'] = df['CCT'] / df['Bio-AL']\n",
    "\n",
    "features.extend([\n",
    "    df['CCT_x_AL'].values,\n",
    "    df['CCT_x_K'].values,\n",
    "    df['CCT_ratio_AL'].values\n",
    "])\n",
    "feature_names.extend(['CCT_x_AL', 'CCT_x_K', 'CCT_ratio_AL'])\n",
    "\n",
    "X = np.column_stack(features)\n",
    "y = df['PostOP Spherical Equivalent'].values\n",
    "\n",
    "print(f\"Created {len(feature_names)} features including CCT interactions\")\n",
    "\n",
    "# Standardize and train Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train Ridge to get feature importance\n",
    "ridge_analysis = Ridge(alpha=1.0)\n",
    "ridge_analysis.fit(X_scaled, y)\n",
    "\n",
    "# Get feature importance from coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': ridge_analysis.coef_,\n",
    "    'Abs_Coefficient': np.abs(ridge_analysis.coef_)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ† TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "print(\"-\" * 50)\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"  {row['Feature']:20} Coef={row['Coefficient']:+.4f}\")\n",
    "\n",
    "# Analyze CCT importance\n",
    "cct_features = feature_importance[feature_importance['Feature'].str.contains('CCT')]\n",
    "cct_importance = cct_features['Abs_Coefficient'].sum()\n",
    "total_importance = feature_importance['Abs_Coefficient'].sum()\n",
    "cct_percentage = (cct_importance / total_importance) * 100\n",
    "\n",
    "print(\"\\nğŸ’¡ KEY FINDINGS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ CCT-related features account for {cct_percentage:.1f}% of total importance\")\n",
    "print(f\"â€¢ Top feature: {feature_importance.iloc[0]['Feature']}\")\n",
    "\n",
    "if 'CCT_ratio_AL' in feature_importance.head(3)['Feature'].values:\n",
    "    print(\"â€¢ CCT/AL ratio is among top 3 features!\")\n",
    "    print(\"â€¢ This validates that CCT relative to eye size matters\")\n",
    "\n",
    "if cct_percentage > 50:\n",
    "    print(\"\\nâœ… HYPOTHESIS CONFIRMED:\")\n",
    "    print(\"CCT features dominate prediction - our CCT-dependent approach is justified!\")\n",
    "\n",
    "print(\"\\nğŸ¯ OPTIMIZATION STRATEGY BASED ON RIDGE:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. Make optical parameters CCT-dependent (nc, k_index)\")\n",
    "print(\"2. Consider CCT/AL ratio in corrections\")\n",
    "print(\"3. Account for CCT interactions with other measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "rt23gheoiv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ MULTI-SEED NESTED CROSS-VALIDATION:\n",
      "--------------------------------------------------\n",
      "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "â€¢ Each seed: 75% train, 25% test\n",
      "â€¢ Inner: 5-fold CV on training set\n",
      "â€¢ Results averaged across seeds for robustness\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "  CV MAE: 1.2383 Â± 0.3650 D\n",
      "  Train MAE: 1.1642, Test MAE: 1.4354\n",
      "  Test: Baseline=1.4849, Optimized=1.4354\n",
      "  Improvement: 3.3%\n",
      "  âš ï¸ Overfitting detected: Test 23.3% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "  CV MAE: 1.3361 Â± 0.2740 D\n",
      "  Train MAE: 1.2528, Test MAE: 1.0289\n",
      "  Test: Baseline=1.2755, Optimized=1.0289\n",
      "  Improvement: 19.3%\n",
      "  âœ… Good generalization: Test only -17.9% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "  CV MAE: 1.1921 Â± 0.1903 D\n",
      "  Train MAE: 1.1143, Test MAE: 1.4725\n",
      "  Test: Baseline=1.6714, Optimized=1.4725\n",
      "  Improvement: 11.9%\n",
      "  âš ï¸ Overfitting detected: Test 32.1% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "  CV MAE: 1.1991 Â± 0.3443 D\n",
      "  Train MAE: 1.1025, Test MAE: 1.4542\n",
      "  Test: Baseline=1.6185, Optimized=1.4542\n",
      "  Improvement: 10.2%\n",
      "  âš ï¸ Overfitting detected: Test 31.9% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "  CV MAE: 1.3382 Â± 0.1226 D\n",
      "  Train MAE: 1.2004, Test MAE: 1.2115\n",
      "  Test: Baseline=1.3566, Optimized=1.2115\n",
      "  Improvement: 10.7%\n",
      "  âœ… Good generalization: Test only 0.9% worse than train\n",
      "\n",
      "================================================================================\n",
      "PARAMETER OPTIMIZATION - MULTI-SEED SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\n",
      "--------------------------------------------------\n",
      "  Seed  42: MAE=1.4354 D, Improvement=3.3%\n",
      "  Seed 123: MAE=1.0289 D, Improvement=19.3%\n",
      "  Seed 456: MAE=1.4725 D, Improvement=11.9%\n",
      "  Seed 789: MAE=1.4542 D, Improvement=10.2%\n",
      "  Seed 2025: MAE=1.2115 D, Improvement=10.7%\n",
      "\n",
      "ğŸ“ˆ STATISTICAL SUMMARY:\n",
      "--------------------------------------------------\n",
      "  Baseline MAE:      1.4814 Â± 0.1503 D\n",
      "  Train MAE:         1.1668 Â± 0.0555 D\n",
      "  Test MAE:          1.3205 Â± 0.1738 D\n",
      "  Mean Improvement:  11.1 Â± 5.1%\n",
      "  Best seed:         123 (MAE=1.0289)\n",
      "  Worst seed:        456 (MAE=1.4725)\n",
      "\n",
      "ğŸ” OVERFITTING ANALYSIS:\n",
      "--------------------------------------------------\n",
      "  Mean overfit ratio: 14.1%\n",
      "  (Test MAE is 14.1% worse than Train MAE on average)\n",
      "  âœ… Good generalization - acceptable overfitting\n",
      "\n",
      "âœ… CONSENSUS PARAMETERS (averaged across seeds):\n",
      "--------------------------------------------------\n",
      "  nc_base              = +1.4365 Â± 0.0372\n",
      "  nc_cct_coef          = +0.0660 Â± 0.0622\n",
      "  k_index_base         = +1.4186 Â± 0.0360\n",
      "  k_index_cct_coef     = +0.0602 Â± 0.0656\n",
      "  acd_offset_base      = +2.8444 Â± 0.1287\n",
      "  acd_offset_cct_coef  = +0.7143 Â± 0.9863\n",
      "\n",
      "ğŸ’¡ ROBUSTNESS ANALYSIS:\n",
      "--------------------------------------------------\n",
      "âš ï¸ Moderate stability: CV=13.2% (some variation across seeds)\n",
      "\n",
      "ğŸ“Š Range of results: 1.0289 - 1.4725 D\n",
      "   This 0.4436 D range shows the impact of data split\n"
     ]
    }
   ],
   "source": [
    "# PARAMETER OPTIMIZATION WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
    "# =============================================\n",
    "# PURPOSE: Optimize SRK/T2 parameters with nested CV for robust validation\n",
    "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ¯ MULTI-SEED NESTED CROSS-VALIDATION:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"â€¢ Each seed: 75% train, 25% test\")\n",
    "print(\"â€¢ Inner: 5-fold CV on training set\")\n",
    "print(\"â€¢ Results averaged across seeds for robustness\")\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "def calculate_mae_param(params, df_data):\n",
    "    \"\"\"Calculate MAE for parameter optimization\"\"\"\n",
    "    nc_base, nc_cct_coef, k_index_base, k_index_cct_coef, acd_offset_base, acd_offset_cct_coef = params\n",
    "    \n",
    "    predictions = []\n",
    "    for _, row in df_data.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        nc = nc_base + nc_cct_coef * cct_norm\n",
    "        k_index = k_index_base + k_index_cct_coef * cct_norm\n",
    "        acd_offset = acd_offset_base + acd_offset_cct_coef * cct_norm\n",
    "        \n",
    "        pred = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc,\n",
    "            k_index=k_index\n",
    "        )\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    mae = mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "    return mae\n",
    "\n",
    "bounds_param = [\n",
    "    (1.20, 1.50),    # nc_base\n",
    "    (-0.20, 0.20),   # nc_cct_coef  \n",
    "    (1.20, 1.60),    # k_index_base\n",
    "    (-0.30, 0.30),   # k_index_cct_coef\n",
    "    (-3.0, 3.0),     # acd_offset_base\n",
    "    (-3.0, 3.0),     # acd_offset_cct_coef\n",
    "]\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_param = []\n",
    "seed_test_maes_param = []\n",
    "seed_train_maes_param = []  # NEW: Track training MAEs\n",
    "seed_baseline_maes_param = []\n",
    "seed_improvements_param = []\n",
    "seed_overfit_ratios_param = []  # NEW: Track overfitting\n",
    "\n",
    "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT with current seed\n",
    "    X_train_param, X_test_param = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_param['K_avg'] = (X_train_param['Bio-Ks'] + X_train_param['Bio-Kf']) / 2\n",
    "    X_test_param['K_avg'] = (X_test_param['Bio-Ks'] + X_test_param['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"ğŸ“Š Split: {len(X_train_param)} train, {len(X_test_param)} test\")\n",
    "    \n",
    "    # INNER K-FOLD CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    fold_params = []\n",
    "    fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_param), 1):\n",
    "        fold_train = X_train_param.iloc[train_idx]\n",
    "        fold_val = X_train_param.iloc[val_idx]\n",
    "        \n",
    "        # Optimize on fold\n",
    "        result_fold = differential_evolution(\n",
    "            lambda p: calculate_mae_param(p, fold_train),\n",
    "            bounds_param,\n",
    "            maxiter=30,\n",
    "            seed=SEED + fold_num,\n",
    "            workers=1,\n",
    "            updating='deferred',\n",
    "            disp=False\n",
    "        )\n",
    "        \n",
    "        fold_params.append(result_fold.x)\n",
    "        val_mae = calculate_mae_param(result_fold.x, fold_val)\n",
    "        fold_maes.append(val_mae)\n",
    "    \n",
    "    # Average parameters from folds\n",
    "    avg_params = np.mean(fold_params, axis=0)\n",
    "    avg_cv_mae = np.mean(fold_maes)\n",
    "    std_cv_mae = np.std(fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    result_final = differential_evolution(\n",
    "        lambda p: calculate_mae_param(p, X_train_param),\n",
    "        bounds_param,\n",
    "        maxiter=50,\n",
    "        seed=SEED,\n",
    "        workers=1,\n",
    "        updating='deferred',\n",
    "        disp=False\n",
    "    )\n",
    "    \n",
    "    final_params = result_final.x\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    mae_train = calculate_mae_param(final_params, X_train_param)\n",
    "    \n",
    "    # TEST ON HOLDOUT\n",
    "    # Calculate baseline\n",
    "    X_test_param['SRKT2_Baseline'] = X_test_param.apply(\n",
    "        lambda row: calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant']\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    # Apply optimized parameters\n",
    "    predictions_test = []\n",
    "    for _, row in X_test_param.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        nc = final_params[0] + final_params[1] * cct_norm\n",
    "        k_index = final_params[2] + final_params[3] * cct_norm\n",
    "        acd_offset = final_params[4] + final_params[5] * cct_norm\n",
    "        \n",
    "        pred = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc,\n",
    "            k_index=k_index\n",
    "        )\n",
    "        predictions_test.append(pred)\n",
    "    \n",
    "    mae_baseline = np.abs(X_test_param['SRKT2_Baseline'] - X_test_param['PostOP Spherical Equivalent']).mean()\n",
    "    mae_optimized = mean_absolute_error(X_test_param['PostOP Spherical Equivalent'], predictions_test)\n",
    "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
    "    \n",
    "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
    "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
    "    if overfit_ratio > 20:\n",
    "        print(f\"  âš ï¸ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    elif overfit_ratio > 10:\n",
    "        print(f\"  âš ï¸ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    else:\n",
    "        print(f\"  âœ… Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_param.append(final_params)\n",
    "    seed_test_maes_param.append(mae_optimized)\n",
    "    seed_train_maes_param.append(mae_train)\n",
    "    seed_baseline_maes_param.append(mae_baseline)\n",
    "    seed_improvements_param.append(improvement)\n",
    "    seed_overfit_ratios_param.append(overfit_ratio)\n",
    "\n",
    "# MULTI-SEED SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARAMETER OPTIMIZATION - MULTI-SEED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_param[i]:.4f} D, Improvement={seed_improvements_param[i]:.1f}%\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ STATISTICAL SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_param):.4f} Â± {np.std(seed_baseline_maes_param):.4f} D\")\n",
    "print(f\"  Train MAE:         {np.mean(seed_train_maes_param):.4f} Â± {np.std(seed_train_maes_param):.4f} D\")\n",
    "print(f\"  Test MAE:          {np.mean(seed_test_maes_param):.4f} Â± {np.std(seed_test_maes_param):.4f} D\")\n",
    "print(f\"  Mean Improvement:  {np.mean(seed_improvements_param):.1f} Â± {np.std(seed_improvements_param):.1f}%\")\n",
    "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_param)]} (MAE={min(seed_test_maes_param):.4f})\")\n",
    "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_param)]} (MAE={max(seed_test_maes_param):.4f})\")\n",
    "\n",
    "# OVERFITTING ANALYSIS\n",
    "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_param):.1f}%\")\n",
    "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_param):.1f}% worse than Train MAE on average)\")\n",
    "\n",
    "if np.mean(seed_overfit_ratios_param) < 10:\n",
    "    print(\"  âœ… Excellent generalization - minimal overfitting\")\n",
    "elif np.mean(seed_overfit_ratios_param) < 20:\n",
    "    print(\"  âœ… Good generalization - acceptable overfitting\")\n",
    "else:\n",
    "    print(\"  âš ï¸ Significant overfitting - consider regularization\")\n",
    "\n",
    "# Average parameters across seeds\n",
    "avg_params_all_seeds = np.mean(seed_results_param, axis=0)\n",
    "std_params_all_seeds = np.std(seed_results_param, axis=0)\n",
    "\n",
    "print(\"\\nâœ… CONSENSUS PARAMETERS (averaged across seeds):\")\n",
    "print(\"-\" * 50)\n",
    "param_names = ['nc_base', 'nc_cct_coef', 'k_index_base', 'k_index_cct_coef', 'acd_offset_base', 'acd_offset_cct_coef']\n",
    "for i, name in enumerate(param_names):\n",
    "    print(f\"  {name:20} = {avg_params_all_seeds[i]:+.4f} Â± {std_params_all_seeds[i]:.4f}\")\n",
    "\n",
    "# Store in global results dictionary\n",
    "multi_seed_results['parameter'] = {\n",
    "    'test_maes': seed_test_maes_param,\n",
    "    'train_maes': seed_train_maes_param,\n",
    "    'baseline_maes': seed_baseline_maes_param,\n",
    "    'improvements': seed_improvements_param,\n",
    "    'overfit_ratios': seed_overfit_ratios_param,\n",
    "    'mean_mae': np.mean(seed_test_maes_param),\n",
    "    'std_mae': np.std(seed_test_maes_param),\n",
    "    'mean_improvement': np.mean(seed_improvements_param)\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ’¡ ROBUSTNESS ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "mae_cv = np.std(seed_test_maes_param) / np.mean(seed_test_maes_param) * 100\n",
    "if mae_cv < 5:\n",
    "    print(f\"âœ… Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
    "elif mae_cv < 10:\n",
    "    print(f\"âœ… Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Range of results: {min(seed_test_maes_param):.4f} - {max(seed_test_maes_param):.4f} D\")\n",
    "print(f\"   This {max(seed_test_maes_param)-min(seed_test_maes_param):.4f} D range shows the impact of data split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "829090ggs0r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ MULTI-SEED NESTED CV STRATEGY:\n",
      "--------------------------------------------------\n",
      "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "â€¢ Each seed: 75/25 train/test split\n",
      "â€¢ Inner: 5-fold CV on training\n",
      "â€¢ Find stable multiplicative factors across seeds\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "  CV MAE: 0.9016 Â± 0.1279 D\n",
      "  Final params: mâ‚€=-0.0379, mâ‚=-0.0153, mâ‚‚=-0.0378\n",
      "  Train MAE: 0.9068, Test MAE: 1.0063\n",
      "  Test: Baseline=1.4849, Optimized=1.0063\n",
      "  Improvement: 32.2%\n",
      "  âš ï¸ Mild overfitting: Test 11.0% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "  CV MAE: 0.9395 Â± 0.0938 D\n",
      "  Final params: mâ‚€=-0.0383, mâ‚=-0.0168, mâ‚‚=-0.0383\n",
      "  Train MAE: 0.8772, Test MAE: 1.0940\n",
      "  Test: Baseline=1.2755, Optimized=1.0940\n",
      "  Improvement: 14.2%\n",
      "  âš ï¸ Overfitting detected: Test 24.7% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "  CV MAE: 0.9122 Â± 0.2803 D\n",
      "  Final params: mâ‚€=-0.0386, mâ‚=-0.0133, mâ‚‚=-0.0385\n",
      "  Train MAE: 0.8928, Test MAE: 1.0463\n",
      "  Test: Baseline=1.6714, Optimized=1.0463\n",
      "  Improvement: 37.4%\n",
      "  âš ï¸ Mild overfitting: Test 17.2% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "  CV MAE: 0.9511 Â± 0.3201 D\n",
      "  Final params: mâ‚€=-0.1211, mâ‚=0.1059, mâ‚‚=-0.0342\n",
      "  Train MAE: 0.8972, Test MAE: 1.0182\n",
      "  Test: Baseline=1.6185, Optimized=1.0182\n",
      "  Improvement: 37.1%\n",
      "  âš ï¸ Mild overfitting: Test 13.5% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "  CV MAE: 0.9544 Â± 0.1953 D\n",
      "  Final params: mâ‚€=-0.0387, mâ‚=-0.0074, mâ‚‚=-0.0386\n",
      "  Train MAE: 0.9448, Test MAE: 0.8892\n",
      "  Test: Baseline=1.3566, Optimized=0.8892\n",
      "  Improvement: 34.5%\n",
      "  âœ… Good generalization: Test only -5.9% worse than train\n",
      "\n",
      "================================================================================\n",
      "MULTIPLICATIVE CORRECTION - MULTI-SEED SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\n",
      "--------------------------------------------------\n",
      "  Seed  42: MAE=1.0063 D, Improvement=32.2%\n",
      "  Seed 123: MAE=1.0940 D, Improvement=14.2%\n",
      "  Seed 456: MAE=1.0463 D, Improvement=37.4%\n",
      "  Seed 789: MAE=1.0182 D, Improvement=37.1%\n",
      "  Seed 2025: MAE=0.8892 D, Improvement=34.5%\n",
      "\n",
      "ğŸ“ˆ STATISTICAL SUMMARY:\n",
      "--------------------------------------------------\n",
      "  Baseline MAE:      1.4814 Â± 0.1503 D\n",
      "  Train MAE:         0.9037 Â± 0.0226 D\n",
      "  Test MAE:          1.0108 Â± 0.0679 D\n",
      "  Mean Improvement:  31.1 Â± 8.6%\n",
      "  Best seed:         2025 (MAE=0.8892)\n",
      "  Worst seed:        123 (MAE=1.0940)\n",
      "\n",
      "ğŸ” OVERFITTING ANALYSIS:\n",
      "--------------------------------------------------\n",
      "  Mean overfit ratio: 12.1%\n",
      "  (Test MAE is 12.1% worse than Train MAE on average)\n",
      "  âœ… Good generalization - acceptable overfitting\n",
      "\n",
      "âœ… CONSENSUS PARAMETERS (averaged across seeds):\n",
      "--------------------------------------------------\n",
      "  mâ‚€ (constant):     -0.0549 Â± 0.0331\n",
      "  mâ‚ (CCT coef):     +0.0106 Â± 0.0478\n",
      "  mâ‚‚ (ratio coef):   -0.0375 Â± 0.0017\n",
      "\n",
      "ğŸ“ CONSENSUS CORRECTION FORMULA:\n",
      "--------------------------------------------------\n",
      "Corrected_REF = Standard_SRK/T2 Ã— Correction_Factor\n",
      "Correction_Factor = 1 -0.0549 +0.0106Ã—CCT_norm -0.0375Ã—(CCT/AL)\n",
      "\n",
      "ğŸ’¡ ROBUSTNESS ANALYSIS:\n",
      "--------------------------------------------------\n",
      "âœ… Good stability: CV=6.7% (consistent across seeds)\n",
      "\n",
      "ğŸ“Š Range of results: 0.8892 - 1.0940 D\n",
      "   This 0.2048 D range shows the impact of data split\n",
      "\n",
      "ğŸ“Š Parameter consistency across seeds:\n",
      "  mâ‚€: min=-0.1211, max=-0.0379, range=0.0832\n",
      "  mâ‚: min=-0.0168, max=0.1059, range=0.1227\n",
      "  mâ‚‚: min=-0.0386, max=-0.0342, range=0.0045\n"
     ]
    }
   ],
   "source": [
    "# MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED\n",
    "# ====================================\n",
    "# PURPOSE: Multiplicative correction with nested CV for robust validation\n",
    "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ¯ MULTI-SEED NESTED CV STRATEGY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
    "print(\"â€¢ Inner: 5-fold CV on training\")\n",
    "print(\"â€¢ Find stable multiplicative factors across seeds\")\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "def multiplicative_objective(params, df_data):\n",
    "    \"\"\"Objective function for multiplicative correction\"\"\"\n",
    "    m0, m1, m2 = params\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for _, row in df_data.iterrows():\n",
    "        base_pred = row['SRKT2_Prediction']\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        \n",
    "        correction_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "        corrected_pred = base_pred * correction_factor\n",
    "        \n",
    "        predictions.append(corrected_pred)\n",
    "        actuals.append(row['PostOP Spherical Equivalent'])\n",
    "    \n",
    "    return mean_absolute_error(actuals, predictions)\n",
    "\n",
    "x0_mult = [0, 0, 0]\n",
    "bounds_mult = [(-0.5, 0.5), (-0.5, 0.5), (-0.5, 0.5)]\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_mult = []\n",
    "seed_test_maes_mult = []\n",
    "seed_train_maes_mult = []  # NEW: Track training MAEs\n",
    "seed_baseline_maes_mult = []\n",
    "seed_improvements_mult = []\n",
    "seed_overfit_ratios_mult = []  # NEW: Track overfitting\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT with current seed\n",
    "    X_train_mult, X_test_mult = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_mult['K_avg'] = (X_train_mult['Bio-Ks'] + X_train_mult['Bio-Kf']) / 2\n",
    "    X_test_mult['K_avg'] = (X_test_mult['Bio-Ks'] + X_test_mult['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"ğŸ“Š Split: {len(X_train_mult)} train, {len(X_test_mult)} test\")\n",
    "    \n",
    "    # Calculate baseline SRK/T2 for all data\n",
    "    for dataset in [X_train_mult, X_test_mult]:\n",
    "        dataset['SRKT2_Prediction'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    # INNER K-FOLD CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    fold_params = []\n",
    "    fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_mult), 1):\n",
    "        fold_train = X_train_mult.iloc[train_idx]\n",
    "        fold_val = X_train_mult.iloc[val_idx]\n",
    "        \n",
    "        # Optimize on fold training\n",
    "        result_fold = minimize(\n",
    "            lambda p: multiplicative_objective(p, fold_train),\n",
    "            x0_mult,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds_mult\n",
    "        )\n",
    "        \n",
    "        fold_params.append(result_fold.x)\n",
    "        val_mae = multiplicative_objective(result_fold.x, fold_val)\n",
    "        fold_maes.append(val_mae)\n",
    "    \n",
    "    # Average across folds\n",
    "    avg_params = np.mean(fold_params, axis=0)\n",
    "    avg_cv_mae = np.mean(fold_maes)\n",
    "    std_cv_mae = np.std(fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    result_mult = minimize(\n",
    "        lambda p: multiplicative_objective(p, X_train_mult),\n",
    "        x0_mult,\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds_mult\n",
    "    )\n",
    "    m0_opt, m1_opt, m2_opt = result_mult.x\n",
    "    \n",
    "    print(f\"  Final params: mâ‚€={m0_opt:.4f}, mâ‚={m1_opt:.4f}, mâ‚‚={m2_opt:.4f}\")\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    mae_train = multiplicative_objective([m0_opt, m1_opt, m2_opt], X_train_mult)\n",
    "    \n",
    "    # TEST ON HOLDOUT\n",
    "    predictions_mult_test = []\n",
    "    for _, row in X_test_mult.iterrows():\n",
    "        base_pred = row['SRKT2_Prediction']\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        \n",
    "        correction_factor = 1 + m0_opt + m1_opt * cct_norm + m2_opt * cct_ratio\n",
    "        corrected_pred = base_pred * correction_factor\n",
    "        predictions_mult_test.append(corrected_pred)\n",
    "    \n",
    "    mae_baseline = np.abs(X_test_mult['SRKT2_Prediction'] - X_test_mult['PostOP Spherical Equivalent']).mean()\n",
    "    mae_optimized = mean_absolute_error(X_test_mult['PostOP Spherical Equivalent'], predictions_mult_test)\n",
    "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
    "    \n",
    "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
    "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
    "    if overfit_ratio > 20:\n",
    "        print(f\"  âš ï¸ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    elif overfit_ratio > 10:\n",
    "        print(f\"  âš ï¸ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    else:\n",
    "        print(f\"  âœ… Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_mult.append([m0_opt, m1_opt, m2_opt])\n",
    "    seed_test_maes_mult.append(mae_optimized)\n",
    "    seed_train_maes_mult.append(mae_train)\n",
    "    seed_baseline_maes_mult.append(mae_baseline)\n",
    "    seed_improvements_mult.append(improvement)\n",
    "    seed_overfit_ratios_mult.append(overfit_ratio)\n",
    "\n",
    "# MULTI-SEED SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTIPLICATIVE CORRECTION - MULTI-SEED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_mult[i]:.4f} D, Improvement={seed_improvements_mult[i]:.1f}%\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ STATISTICAL SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_mult):.4f} Â± {np.std(seed_baseline_maes_mult):.4f} D\")\n",
    "print(f\"  Train MAE:         {np.mean(seed_train_maes_mult):.4f} Â± {np.std(seed_train_maes_mult):.4f} D\")\n",
    "print(f\"  Test MAE:          {np.mean(seed_test_maes_mult):.4f} Â± {np.std(seed_test_maes_mult):.4f} D\")\n",
    "print(f\"  Mean Improvement:  {np.mean(seed_improvements_mult):.1f} Â± {np.std(seed_improvements_mult):.1f}%\")\n",
    "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_mult)]} (MAE={min(seed_test_maes_mult):.4f})\")\n",
    "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_mult)]} (MAE={max(seed_test_maes_mult):.4f})\")\n",
    "\n",
    "# OVERFITTING ANALYSIS\n",
    "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_mult):.1f}%\")\n",
    "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_mult):.1f}% worse than Train MAE on average)\")\n",
    "\n",
    "if np.mean(seed_overfit_ratios_mult) < 10:\n",
    "    print(\"  âœ… Excellent generalization - minimal overfitting\")\n",
    "elif np.mean(seed_overfit_ratios_mult) < 20:\n",
    "    print(\"  âœ… Good generalization - acceptable overfitting\")\n",
    "else:\n",
    "    print(\"  âš ï¸ Significant overfitting - consider regularization\")\n",
    "\n",
    "# Average parameters across seeds\n",
    "avg_params_all_seeds = np.mean(seed_results_mult, axis=0)\n",
    "std_params_all_seeds = np.std(seed_results_mult, axis=0)\n",
    "\n",
    "print(\"\\nâœ… CONSENSUS PARAMETERS (averaged across seeds):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  mâ‚€ (constant):     {avg_params_all_seeds[0]:+.4f} Â± {std_params_all_seeds[0]:.4f}\")\n",
    "print(f\"  mâ‚ (CCT coef):     {avg_params_all_seeds[1]:+.4f} Â± {std_params_all_seeds[1]:.4f}\")\n",
    "print(f\"  mâ‚‚ (ratio coef):   {avg_params_all_seeds[2]:+.4f} Â± {std_params_all_seeds[2]:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“ CONSENSUS CORRECTION FORMULA:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Corrected_REF = Standard_SRK/T2 Ã— Correction_Factor\")\n",
    "print(f\"Correction_Factor = 1 {avg_params_all_seeds[0]:+.4f} {avg_params_all_seeds[1]:+.4f}Ã—CCT_norm {avg_params_all_seeds[2]:+.4f}Ã—(CCT/AL)\")\n",
    "\n",
    "# Store in global results dictionary\n",
    "multi_seed_results['multiplicative'] = {\n",
    "    'test_maes': seed_test_maes_mult,\n",
    "    'train_maes': seed_train_maes_mult,\n",
    "    'baseline_maes': seed_baseline_maes_mult,\n",
    "    'improvements': seed_improvements_mult,\n",
    "    'overfit_ratios': seed_overfit_ratios_mult,\n",
    "    'mean_mae': np.mean(seed_test_maes_mult),\n",
    "    'std_mae': np.std(seed_test_maes_mult),\n",
    "    'mean_improvement': np.mean(seed_improvements_mult)\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ’¡ ROBUSTNESS ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "mae_cv = np.std(seed_test_maes_mult) / np.mean(seed_test_maes_mult) * 100\n",
    "if mae_cv < 5:\n",
    "    print(f\"âœ… Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
    "elif mae_cv < 10:\n",
    "    print(f\"âœ… Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Range of results: {min(seed_test_maes_mult):.4f} - {max(seed_test_maes_mult):.4f} D\")\n",
    "print(f\"   This {max(seed_test_maes_mult)-min(seed_test_maes_mult):.4f} D range shows the impact of data split\")\n",
    "\n",
    "# Parameter consistency check\n",
    "print(f\"\\nğŸ“Š Parameter consistency across seeds:\")\n",
    "for i, param_name in enumerate(['mâ‚€', 'mâ‚', 'mâ‚‚']):\n",
    "    param_values = [p[i] for p in seed_results_mult]\n",
    "    print(f\"  {param_name}: min={min(param_values):.4f}, max={max(param_values):.4f}, range={max(param_values)-min(param_values):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4a07c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUPPORT VECTOR REGRESSION (SVR) WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Seed 2026/5:\n",
      "  Seed 1 Results:\n",
      "    Test MAE: 0.921 Â± 0.194 D\n",
      "    Train MAE: 0.698 D\n",
      "    Overfit ratio: 1.319\n",
      "\n",
      "Seed 2026/5:\n",
      "  Seed 2 Results:\n",
      "    Test MAE: 0.918 Â± 0.159 D\n",
      "    Train MAE: 0.681 D\n",
      "    Overfit ratio: 1.348\n",
      "\n",
      "Seed 2026/5:\n",
      "  Seed 3 Results:\n",
      "    Test MAE: 0.917 Â± 0.200 D\n",
      "    Train MAE: 0.674 D\n",
      "    Overfit ratio: 1.359\n",
      "\n",
      "Seed 2026/5:\n",
      "  Seed 4 Results:\n",
      "    Test MAE: 0.882 Â± 0.108 D\n",
      "    Train MAE: 0.696 D\n",
      "    Overfit ratio: 1.267\n",
      "\n",
      "Seed 2026/5:\n",
      "  Seed 5 Results:\n",
      "    Test MAE: 0.895 Â± 0.214 D\n",
      "    Train MAE: 0.663 D\n",
      "    Overfit ratio: 1.351\n",
      "\n",
      "================================================================================\n",
      "SVR MULTI-SEED SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Across 5 seeds with 5-fold CV (25 total evaluations):\n",
      "Test MAE: 0.907 Â± 0.180 D\n",
      "Train MAE: 0.683 Â± 0.088 D\n",
      "Baseline MAE: 1.358 Â± 0.225 D\n",
      "Overfit Ratio: 1.328\n",
      "\n",
      "Improvement over baseline:\n",
      "  Relative: 33.2%\n",
      "  Absolute: 0.451 D\n",
      "\n",
      "Most frequent hyperparameters:\n",
      "  C: 0.5(12), 1.0(7), 2.0(6)\n",
      "  Îµ: 0.2(14), 0.05(9), 0.1(2)\n",
      "================================================================================\n",
      "SVR method completed - results stored in _svr variables\n",
      "Both multiplicative and SVR are now available for comparison\n",
      "Results stored for final comparison in cell 11\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# SUPPORT VECTOR REGRESSION (SVR) - REPLACEMENT FOR MULTIPLICATIVE\n",
    "# =================================================================\n",
    "# PURPOSE: Test SVR as alternative to multiplicative correction\n",
    "# Based on comprehensive testing showing 6.7% improvement\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SUPPORT VECTOR REGRESSION (SVR) WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare features for SVR\n",
    "def prepare_svr_features(df):\n",
    "    X = pd.DataFrame()\n",
    "    X['CCT_norm'] = (df['CCT'] - 600) / 100\n",
    "    X['AL'] = df['Bio-AL']\n",
    "    X['ACD'] = df['Bio-ACD']\n",
    "    X['K_mean'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
    "    X['CCT_AL'] = df['CCT'] / df['Bio-AL']\n",
    "    return X\n",
    "\n",
    "# Store results for multiple seeds (using SEEDS from first cell)\n",
    "seed_results_svr = []\n",
    "seed_test_maes_svr = []\n",
    "seed_train_maes_svr = []\n",
    "seed_baseline_maes_svr = []\n",
    "seed_improvements_svr = []\n",
    "seed_overfit_ratios_svr = []\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    np.random.seed(SEED)\n",
    "    print(f\"\\nSeed {seed+1}/{len(SEEDS)}:\")\n",
    "    \n",
    "    # Outer CV loop (using same structure as other methods)\n",
    "    kf_outer = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    fold_results = []\n",
    "    test_maes = []\n",
    "    train_maes = []\n",
    "    baseline_maes = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf_outer.split(df)):\n",
    "        # Split data (using 'df' DataFrame from first cell)\n",
    "        df_train = df.iloc[train_idx].copy()\n",
    "        df_test = df.iloc[test_idx].copy()\n",
    "        \n",
    "        # Prepare features\n",
    "        X_train = prepare_svr_features(df_train)\n",
    "        X_test = prepare_svr_features(df_test)\n",
    "        y_train = df_train['PostOP Spherical Equivalent'].values\n",
    "        y_test = df_test['PostOP Spherical Equivalent'].values\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Inner CV for hyperparameter tuning (simplified grid for speed)\n",
    "        best_params = None\n",
    "        best_val_mae = float('inf')\n",
    "        \n",
    "        # Reduced grid search for efficiency\n",
    "        param_grid = {\n",
    "            'C': [0.5, 1.0, 2.0],\n",
    "            'epsilon': [0.05, 0.1, 0.2]\n",
    "        }\n",
    "        \n",
    "        kf_inner = KFold(n_splits=3, shuffle=True, random_state=SEED*100+fold)\n",
    "        \n",
    "        for C in param_grid['C']:\n",
    "            for epsilon in param_grid['epsilon']:\n",
    "                val_maes = []\n",
    "                \n",
    "                for train_inner_idx, val_idx in kf_inner.split(X_train_scaled):\n",
    "                    X_train_inner = X_train_scaled[train_inner_idx]\n",
    "                    y_train_inner = y_train[train_inner_idx]\n",
    "                    X_val = X_train_scaled[val_idx]\n",
    "                    y_val = y_train[val_idx]\n",
    "                    \n",
    "                    # Train SVR\n",
    "                    model = SVR(kernel='rbf', C=C, epsilon=epsilon, gamma='scale')\n",
    "                    model.fit(X_train_inner, y_train_inner)\n",
    "                    \n",
    "                    # Validate\n",
    "                    y_pred_val = model.predict(X_val)\n",
    "                    val_maes.append(mean_absolute_error(y_val, y_pred_val))\n",
    "                \n",
    "                mean_val_mae = np.mean(val_maes)\n",
    "                if mean_val_mae < best_val_mae:\n",
    "                    best_val_mae = mean_val_mae\n",
    "                    best_params = {'C': C, 'epsilon': epsilon}\n",
    "        \n",
    "        # Train final model with best parameters\n",
    "        final_model = SVR(kernel='rbf', C=best_params['C'], \n",
    "                         epsilon=best_params['epsilon'], gamma='scale')\n",
    "        final_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred_train = final_model.predict(X_train_scaled)\n",
    "        y_pred_test = final_model.predict(X_test_scaled)\n",
    "        \n",
    "        # Calculate MAEs\n",
    "        train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "        test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "        \n",
    "        # Baseline MAE (using SRKT2_Prediction from data preparation)\n",
    "        if 'SRKT2_Prediction' in df_test.columns:\n",
    "            baseline_pred = df_test['SRKT2_Prediction'].values\n",
    "        else:\n",
    "            # Simple SRK/T2 approximation if not available\n",
    "            baseline_pred = 118.4 - 2.5 * df_test['Bio-AL'] - 0.9 * X_test['K_mean']\n",
    "        baseline_mae = mean_absolute_error(y_test, baseline_pred)\n",
    "        \n",
    "        train_maes.append(train_mae)\n",
    "        test_maes.append(test_mae)\n",
    "        baseline_maes.append(baseline_mae)\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold + 1,\n",
    "            'train_mae': train_mae,\n",
    "            'test_mae': test_mae,\n",
    "            'baseline_mae': baseline_mae,\n",
    "            'improvement': (baseline_mae - test_mae) / baseline_mae * 100 if baseline_mae > 0 else 0,\n",
    "            'best_C': best_params['C'],\n",
    "            'best_epsilon': best_params['epsilon']\n",
    "        })\n",
    "    \n",
    "    # Store seed results\n",
    "    seed_results_svr.append(fold_results)\n",
    "    seed_test_maes_svr.append(test_maes)\n",
    "    seed_train_maes_svr.append(train_maes)\n",
    "    seed_baseline_maes_svr.append(baseline_maes)\n",
    "    \n",
    "    # Calculate improvements for this seed\n",
    "    improvements = []\n",
    "    for j in range(len(test_maes)):\n",
    "        if baseline_maes[j] > 0:\n",
    "            improvement = (baseline_maes[j] - test_maes[j]) / baseline_maes[j] * 100\n",
    "        else:\n",
    "            improvement = 0\n",
    "        improvements.append(improvement)\n",
    "    \n",
    "    # Calculate overfit ratio for this seed\n",
    "    overfit_ratio = np.mean(test_maes) / np.mean(train_maes) if np.mean(train_maes) > 0 else 1.0\n",
    "    \n",
    "    # Store for this seed\n",
    "    seed_improvements_svr.append(improvements)\n",
    "    seed_overfit_ratios_svr.append(overfit_ratio)\n",
    "    \n",
    "    # Calculate seed statistics\n",
    "    seed_test_mean = np.mean(test_maes)\n",
    "    seed_test_std = np.std(test_maes)\n",
    "    seed_train_mean = np.mean(train_maes)\n",
    "    \n",
    "    print(f\"  Seed {seed_idx} Results:\")\n",
    "    print(f\"    Test MAE: {seed_test_mean:.3f} Â± {seed_test_std:.3f} D\")\n",
    "    print(f\"    Train MAE: {seed_train_mean:.3f} D\")\n",
    "    print(f\"    Overfit ratio: {seed_test_mean/seed_train_mean:.3f}\")\n",
    "\n",
    "# Summary statistics (consistent with other methods)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SVR MULTI-SEED SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate overall statistics\n",
    "overall_test_maes = [mae for seed_maes in seed_test_maes_svr for mae in seed_maes]\n",
    "overall_train_maes = [mae for seed_maes in seed_train_maes_svr for mae in seed_maes]\n",
    "overall_baseline_maes = [mae for seed_maes in seed_baseline_maes_svr for mae in seed_maes]\n",
    "\n",
    "print(f\"\\nAcross {len(SEEDS)} seeds with 5-fold CV ({len(overall_test_maes)} total evaluations):\")\n",
    "print(f\"Test MAE: {np.mean(overall_test_maes):.3f} Â± {np.std(overall_test_maes):.3f} D\")\n",
    "print(f\"Train MAE: {np.mean(overall_train_maes):.3f} Â± {np.std(overall_train_maes):.3f} D\")\n",
    "print(f\"Baseline MAE: {np.mean(overall_baseline_maes):.3f} Â± {np.std(overall_baseline_maes):.3f} D\")\n",
    "print(f\"Overfit Ratio: {np.mean(overall_test_maes) / np.mean(overall_train_maes):.3f}\")\n",
    "\n",
    "if np.mean(overall_baseline_maes) > 0:\n",
    "    improvement = (np.mean(overall_baseline_maes) - np.mean(overall_test_maes)) / np.mean(overall_baseline_maes) * 100\n",
    "    absolute_improvement = np.mean(overall_baseline_maes) - np.mean(overall_test_maes)\n",
    "    print(f\"\\nImprovement over baseline:\")\n",
    "    print(f\"  Relative: {improvement:.1f}%\")\n",
    "    print(f\"  Absolute: {absolute_improvement:.3f} D\")\n",
    "\n",
    "# Hyperparameter analysis\n",
    "print(\"\\nMost frequent hyperparameters:\")\n",
    "all_Cs = [r['best_C'] for seed in seed_results_svr for r in seed]\n",
    "all_epsilons = [r['best_epsilon'] for seed in seed_results_svr for r in seed]\n",
    "from collections import Counter\n",
    "c_counts = Counter(all_Cs).most_common(3)\n",
    "eps_counts = Counter(all_epsilons).most_common(3)\n",
    "print(f\"  C: {', '.join([f'{val}({cnt})' for val, cnt in c_counts])}\")\n",
    "print(f\"  Îµ: {', '.join([f'{val}({cnt})' for val, cnt in eps_counts])}\")\n",
    "\n",
    "# Store results in format compatible with final comparison\n",
    "# This replaces the multiplicative method results\n",
    "\n",
    "# Store results in _mult variables for compatibility with comparison cell\n",
    "# Keep SVR results separate\n",
    "# seed_test_maes_mult = seed_test_maes_svr  # Don't overwrite\n",
    "# seed_train_maes_mult = seed_train_maes_svr\n",
    "# seed_baseline_maes_mult = seed_baseline_maes_svr\n",
    "# seed_improvements_mult = seed_improvements_svr\n",
    "# seed_overfit_ratios_mult = seed_overfit_ratios_svr\n",
    "\n",
    "print(\"\" + \"=\" * 80)\n",
    "print(\"SVR method completed - results stored in _svr variables\")\n",
    "print(\"Both multiplicative and SVR are now available for comparison\")\n",
    "print(\"Results stored for final comparison in cell 11\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efce5d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ALTERNATIVE ML METHODS FOR IOL CALCULATION\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– TESTING ADVANCED ML ALGORITHMS:\n",
      "--------------------------------------------------\n",
      "â€¢ Random Forest: Tree ensemble with bagging\n",
      "â€¢ XGBoost: Gradient boosting (state-of-the-art)\n",
      "â€¢ Gaussian Process: Probabilistic approach with uncertainty\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS FOR ML METHODS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "TESTING: Random Forest\n",
      "========================================\n",
      "\n",
      "Seed 1/5: 42\n",
      "------------------------------\n",
      "  Best RF params: trees=50, depth=3\n",
      "  Test MAE: 0.9641 D\n",
      "  Train MAE: 0.6944 D\n",
      "  Improvement: 35.1%\n",
      "  Overfit ratio: 0.720\n",
      "  Top features: K_mean, IOL Power, Bio-Kf\n",
      "\n",
      "Seed 2/5: 123\n",
      "------------------------------\n",
      "  Best RF params: trees=200, depth=3\n",
      "  Test MAE: 1.1058 D\n",
      "  Train MAE: 0.6816 D\n",
      "  Improvement: 13.3%\n",
      "  Overfit ratio: 0.616\n",
      "  Top features: CCT_AL_ratio, AL_ACD_ratio, K_mean\n",
      "\n",
      "Seed 3/5: 456\n",
      "------------------------------\n",
      "  Best RF params: trees=100, depth=3\n",
      "  Test MAE: 1.0618 D\n",
      "  Train MAE: 0.6469 D\n",
      "  Improvement: 36.5%\n",
      "  Overfit ratio: 0.609\n",
      "  Top features: CCT_AL_ratio, K_mean, Bio-AL\n",
      "\n",
      "Seed 4/5: 789\n",
      "------------------------------\n",
      "  Best RF params: trees=200, depth=7\n",
      "  Test MAE: 1.0031 D\n",
      "  Train MAE: 0.5556 D\n",
      "  Improvement: 38.0%\n",
      "  Overfit ratio: 0.554\n",
      "  Top features: IOL Power, Bio-AL, K_mean\n",
      "\n",
      "Seed 5/5: 2025\n",
      "------------------------------\n",
      "  Best RF params: trees=50, depth=3\n",
      "  Test MAE: 0.8100 D\n",
      "  Train MAE: 0.7468 D\n",
      "  Improvement: 40.3%\n",
      "  Overfit ratio: 0.922\n",
      "  Top features: K_mean, CCT_AL_ratio, AL_ACD_ratio\n",
      "\n",
      "========================================\n",
      "Random Forest - MULTI-SEED SUMMARY\n",
      "========================================\n",
      "\n",
      "ğŸ“Š TEST SET PERFORMANCE (n=5 seeds):\n",
      "  Mean MAE: 0.9890 Â± 0.1018 D\n",
      "  Best MAE: 0.8100 D\n",
      "  Worst MAE: 1.1058 D\n",
      "\n",
      "ğŸ“ˆ IMPROVEMENT OVER BASELINE:\n",
      "  Mean: 32.6 Â± 9.8%\n",
      "\n",
      "âš ï¸ OVERFITTING ANALYSIS:\n",
      "  Mean overfit ratio: 0.684\n",
      "  Status: HIGH overfitting\n",
      "\n",
      "========================================\n",
      "TESTING: XGBoost\n",
      "========================================\n",
      "\n",
      "Seed 1/5: 42\n",
      "------------------------------\n",
      "  Best XGB params: trees=50, depth=2, lr=0.01\n",
      "  Test MAE: 0.9828 D\n",
      "  Train MAE: 0.8097 D\n",
      "  Improvement: 33.8%\n",
      "  Overfit ratio: 0.824\n",
      "  Top features: Bio-Kf, AL_ACD_ratio, Bio-AL\n",
      "\n",
      "Seed 2/5: 123\n",
      "------------------------------\n",
      "  Best XGB params: trees=50, depth=2, lr=0.01\n",
      "  Test MAE: 1.0093 D\n",
      "  Train MAE: 0.8136 D\n",
      "  Improvement: 20.9%\n",
      "  Overfit ratio: 0.806\n",
      "  Top features: Bio-Kf, Bio-Ks, A-Constant\n",
      "\n",
      "Seed 3/5: 456\n",
      "------------------------------\n",
      "  Best XGB params: trees=50, depth=2, lr=0.01\n",
      "  Test MAE: 0.9547 D\n",
      "  Train MAE: 0.8059 D\n",
      "  Improvement: 42.9%\n",
      "  Overfit ratio: 0.844\n",
      "  Top features: Bio-Ks, CCT_norm, K_mean\n",
      "\n",
      "Seed 4/5: 789\n",
      "------------------------------\n",
      "  Best XGB params: trees=50, depth=2, lr=0.01\n",
      "  Test MAE: 0.9670 D\n",
      "  Train MAE: 0.7952 D\n",
      "  Improvement: 40.3%\n",
      "  Overfit ratio: 0.822\n",
      "  Top features: IOL Power, CCT, K_mean\n",
      "\n",
      "Seed 5/5: 2025\n",
      "------------------------------\n",
      "  Best XGB params: trees=50, depth=2, lr=0.01\n",
      "  Test MAE: 0.8627 D\n",
      "  Train MAE: 0.8614 D\n",
      "  Improvement: 36.4%\n",
      "  Overfit ratio: 0.999\n",
      "  Top features: IOL Power, CCT, K_mean\n",
      "\n",
      "========================================\n",
      "XGBoost - MULTI-SEED SUMMARY\n",
      "========================================\n",
      "\n",
      "ğŸ“Š TEST SET PERFORMANCE (n=5 seeds):\n",
      "  Mean MAE: 0.9553 Â± 0.0498 D\n",
      "  Best MAE: 0.8627 D\n",
      "  Worst MAE: 1.0093 D\n",
      "\n",
      "ğŸ“ˆ IMPROVEMENT OVER BASELINE:\n",
      "  Mean: 34.8 Â± 7.6%\n",
      "\n",
      "âš ï¸ OVERFITTING ANALYSIS:\n",
      "  Mean overfit ratio: 0.859\n",
      "  Status: HIGH overfitting\n",
      "\n",
      "========================================\n",
      "TESTING: Gaussian Process\n",
      "========================================\n",
      "\n",
      "Seed 1/5: 42\n",
      "------------------------------\n",
      "  Best GP kernel: RationalQuadratic\n",
      "  Mean prediction uncertainty: 1.190 D\n",
      "  Test MAE: 1.0061 D\n",
      "  Train MAE: 0.0801 D\n",
      "  Improvement: 32.2%\n",
      "  Overfit ratio: 0.080\n",
      "\n",
      "Seed 2/5: 123\n",
      "------------------------------\n",
      "  Best GP kernel: RBF\n",
      "  Mean prediction uncertainty: 1.218 D\n",
      "  Test MAE: 1.0208 D\n",
      "  Train MAE: 0.0797 D\n",
      "  Improvement: 20.0%\n",
      "  Overfit ratio: 0.078\n",
      "\n",
      "Seed 3/5: 456\n",
      "------------------------------\n",
      "  Best GP kernel: RationalQuadratic\n",
      "  Mean prediction uncertainty: 1.215 D\n",
      "  Test MAE: 0.9711 D\n",
      "  Train MAE: 0.0811 D\n",
      "  Improvement: 41.9%\n",
      "  Overfit ratio: 0.083\n",
      "\n",
      "Seed 4/5: 789\n",
      "------------------------------\n",
      "  Best GP kernel: RationalQuadratic\n",
      "  Mean prediction uncertainty: 1.281 D\n",
      "  Test MAE: 0.9627 D\n",
      "  Train MAE: 0.0814 D\n",
      "  Improvement: 40.5%\n",
      "  Overfit ratio: 0.085\n",
      "\n",
      "Seed 5/5: 2025\n",
      "------------------------------\n",
      "  Best GP kernel: RationalQuadratic\n",
      "  Mean prediction uncertainty: 1.200 D\n",
      "  Test MAE: 0.9036 D\n",
      "  Train MAE: 0.0832 D\n",
      "  Improvement: 33.4%\n",
      "  Overfit ratio: 0.092\n",
      "\n",
      "========================================\n",
      "Gaussian Process - MULTI-SEED SUMMARY\n",
      "========================================\n",
      "\n",
      "ğŸ“Š TEST SET PERFORMANCE (n=5 seeds):\n",
      "  Mean MAE: 0.9729 Â± 0.0407 D\n",
      "  Best MAE: 0.9036 D\n",
      "  Worst MAE: 1.0208 D\n",
      "\n",
      "ğŸ“ˆ IMPROVEMENT OVER BASELINE:\n",
      "  Mean: 33.6 Â± 7.8%\n",
      "\n",
      "âš ï¸ OVERFITTING ANALYSIS:\n",
      "  Mean overfit ratio: 0.084\n",
      "  Status: HIGH overfitting\n",
      "\n",
      "================================================================================\n",
      "ML METHODS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š RANKING BY TEST MAE:\n",
      "--------------------------------------------------\n",
      "1. XGBoost             : 0.9553 Â± 0.0498 D\n",
      "                         Improvement: 34.8%\n",
      "                         Overfit ratio: 0.859\n",
      "2. Gaussian Process    : 0.9729 Â± 0.0407 D\n",
      "                         Improvement: 33.6%\n",
      "                         Overfit ratio: 0.084\n",
      "3. Random Forest       : 0.9890 Â± 0.1018 D\n",
      "                         Improvement: 32.6%\n",
      "                         Overfit ratio: 0.684\n",
      "\n",
      "ğŸ“Š COMPARISON WITH SVR:\n",
      "--------------------------------------------------\n",
      "Random Forest: 2.2% BETTER than SVR\n",
      "XGBoost: 5.5% BETTER than SVR\n",
      "Gaussian Process: 3.8% BETTER than SVR\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATION:\n",
      "================================================================================\n",
      "âœ… XGBoost outperforms SVR by 5.5%!\n",
      "   Consider using XGBoost instead of SVR\n",
      "\n",
      "Key insights:\n",
      "â€¢ Tree-based methods (RF, XGBoost) capture feature interactions well\n",
      "â€¢ Gaussian Process provides uncertainty estimates (useful clinically)\n",
      "â€¢ All methods benefit from feature engineering (CCT_norm, ratios)\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE ML METHODS - RANDOM FOREST, XGBOOST, AND GAUSSIAN PROCESS\n",
    "# ======================================================================\n",
    "# PURPOSE: Test promising ML alternatives to SVR for IOL calculation\n",
    "# Methods: Random Forest, XGBoost, and Gaussian Process Regression\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ALTERNATIVE ML METHODS FOR IOL CALCULATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ¤– TESTING ADVANCED ML ALGORITHMS:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Random Forest: Tree ensemble with bagging\")\n",
    "print(\"â€¢ XGBoost: Gradient boosting (state-of-the-art)\")\n",
    "print(\"â€¢ Gaussian Process: Probabilistic approach with uncertainty\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try importing XGBoost (may not be installed)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGBOOST = True\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ XGBoost not installed. Install with: pip install xgboost\")\n",
    "    HAS_XGBOOST = False\n",
    "\n",
    "# Store results for each method\n",
    "ml_methods_results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS FOR ML METHODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test each ML method\n",
    "methods_to_test = ['Random Forest', 'XGBoost', 'Gaussian Process']\n",
    "\n",
    "for method_name in methods_to_test:\n",
    "    if method_name == 'XGBoost' and not HAS_XGBOOST:\n",
    "        print(f\"\\nâ­ï¸ Skipping {method_name} (not installed)\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"TESTING: {method_name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Store results for this method\n",
    "    seed_test_maes = []\n",
    "    seed_train_maes = []\n",
    "    seed_baseline_maes = []\n",
    "    seed_improvements = []\n",
    "    seed_overfit_ratios = []\n",
    "    best_params_list = []\n",
    "    \n",
    "    for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "        print(f\"\\nSeed {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Split data\n",
    "        X_train_ml, X_test_ml = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "        \n",
    "        # Prepare features\n",
    "        feature_cols = ['CCT', 'Bio-AL', 'Bio-ACD', 'Bio-Ks', 'Bio-Kf', 'IOL Power', 'A-Constant']\n",
    "        X_train_features = X_train_ml[feature_cols].copy()\n",
    "        X_test_features = X_test_ml[feature_cols].copy()\n",
    "        \n",
    "        # Add derived features\n",
    "        X_train_features['K_mean'] = (X_train_ml['Bio-Ks'] + X_train_ml['Bio-Kf']) / 2\n",
    "        X_train_features['CCT_norm'] = (X_train_ml['CCT'] - 600) / 100\n",
    "        X_train_features['CCT_AL_ratio'] = X_train_ml['CCT'] / X_train_ml['Bio-AL']\n",
    "        X_train_features['AL_ACD_ratio'] = X_train_ml['Bio-AL'] / X_train_ml['Bio-ACD']\n",
    "        \n",
    "        X_test_features['K_mean'] = (X_test_ml['Bio-Ks'] + X_test_ml['Bio-Kf']) / 2\n",
    "        X_test_features['CCT_norm'] = (X_test_ml['CCT'] - 600) / 100\n",
    "        X_test_features['CCT_AL_ratio'] = X_test_ml['CCT'] / X_test_ml['Bio-AL']\n",
    "        X_test_features['AL_ACD_ratio'] = X_test_ml['Bio-AL'] / X_test_ml['Bio-ACD']\n",
    "        \n",
    "        # Target\n",
    "        y_train = X_train_ml['PostOP Spherical Equivalent'].values\n",
    "        y_test = X_test_ml['PostOP Spherical Equivalent'].values\n",
    "        \n",
    "        # Calculate baseline\n",
    "        X_train_ml['K_avg'] = (X_train_ml['Bio-Ks'] + X_train_ml['Bio-Kf']) / 2\n",
    "        X_test_ml['K_avg'] = (X_test_ml['Bio-Ks'] + X_test_ml['Bio-Kf']) / 2\n",
    "        \n",
    "        for dataset in [X_train_ml, X_test_ml]:\n",
    "            dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "                lambda row: calculate_SRKT2(\n",
    "                    AL=row['Bio-AL'],\n",
    "                    K_avg=row['K_avg'],\n",
    "                    IOL_power=row['IOL Power'],\n",
    "                    A_constant=row['A-Constant']\n",
    "                ), axis=1\n",
    "            )\n",
    "        \n",
    "        baseline_mae = mean_absolute_error(X_test_ml['PostOP Spherical Equivalent'], \n",
    "                                          X_test_ml['SRKT2_Baseline'])\n",
    "        \n",
    "        # Setup cross-validation\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "        \n",
    "        # Initialize model based on method\n",
    "        if method_name == 'Random Forest':\n",
    "            # Random Forest with hyperparameter tuning\n",
    "            param_grid = {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [3, 5, 7, None],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4]\n",
    "            }\n",
    "            base_model = RandomForestRegressor(random_state=SEED)\n",
    "            \n",
    "            # Quick grid search with 3-fold CV (faster)\n",
    "            grid_search = GridSearchCV(\n",
    "                base_model, \n",
    "                param_grid, \n",
    "                cv=3, \n",
    "                scoring='neg_mean_absolute_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            grid_search.fit(X_train_features, y_train)\n",
    "            model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            \n",
    "            print(f\"  Best RF params: trees={best_params['n_estimators']}, depth={best_params['max_depth']}\")\n",
    "            \n",
    "        elif method_name == 'XGBoost':\n",
    "            # XGBoost with hyperparameter tuning\n",
    "            param_grid = {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [2, 3, 4, 5],\n",
    "                'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "                'subsample': [0.6, 0.8, 1.0],\n",
    "                'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "            }\n",
    "            base_model = xgb.XGBRegressor(random_state=SEED, objective='reg:squarederror')\n",
    "            \n",
    "            # Quick grid search\n",
    "            grid_search = GridSearchCV(\n",
    "                base_model,\n",
    "                param_grid,\n",
    "                cv=3,\n",
    "                scoring='neg_mean_absolute_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            grid_search.fit(X_train_features, y_train)\n",
    "            model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            \n",
    "            print(f\"  Best XGB params: trees={best_params['n_estimators']}, depth={best_params['max_depth']}, lr={best_params['learning_rate']}\")\n",
    "            \n",
    "        elif method_name == 'Gaussian Process':\n",
    "            # Gaussian Process with different kernels\n",
    "            # Note: GP doesn't scale well, so we'll use a subset of features\n",
    "            important_features = ['CCT_norm', 'CCT_AL_ratio', 'K_mean', 'Bio-AL', 'Bio-ACD']\n",
    "            X_train_gp = X_train_features[important_features]\n",
    "            X_test_gp = X_test_features[important_features]\n",
    "            \n",
    "            # Standardize for GP\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train_gp)\n",
    "            X_test_scaled = scaler.transform(X_test_gp)\n",
    "            \n",
    "            # Try different kernels\n",
    "            kernels = [\n",
    "                RBF(length_scale=1.0),\n",
    "                Matern(length_scale=1.0, nu=1.5),\n",
    "                RationalQuadratic(length_scale=1.0, alpha=1.0)\n",
    "            ]\n",
    "            \n",
    "            best_kernel = None\n",
    "            best_kernel_mae = float('inf')\n",
    "            \n",
    "            for kernel in kernels:\n",
    "                gpr = GaussianProcessRegressor(\n",
    "                    kernel=kernel,\n",
    "                    alpha=0.1,  # Noise level\n",
    "                    random_state=SEED,\n",
    "                    normalize_y=True\n",
    "                )\n",
    "                \n",
    "                # Quick CV to select best kernel\n",
    "                cv_maes = []\n",
    "                for train_idx, val_idx in kf.split(X_train_scaled):\n",
    "                    gpr.fit(X_train_scaled[train_idx], y_train[train_idx])\n",
    "                    pred = gpr.predict(X_train_scaled[val_idx])\n",
    "                    cv_maes.append(mean_absolute_error(y_train[val_idx], pred))\n",
    "                \n",
    "                mean_cv_mae = np.mean(cv_maes)\n",
    "                if mean_cv_mae < best_kernel_mae:\n",
    "                    best_kernel_mae = mean_cv_mae\n",
    "                    best_kernel = kernel\n",
    "            \n",
    "            # Train final model with best kernel\n",
    "            model = GaussianProcessRegressor(\n",
    "                kernel=best_kernel,\n",
    "                alpha=0.1,\n",
    "                random_state=SEED,\n",
    "                normalize_y=True\n",
    "            )\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            print(f\"  Best GP kernel: {best_kernel.__class__.__name__}\")\n",
    "            best_params = {'kernel': best_kernel.__class__.__name__}\n",
    "        \n",
    "        # Make predictions\n",
    "        if method_name == 'Gaussian Process':\n",
    "            # GP needs scaled features\n",
    "            y_pred_test = model.predict(X_test_scaled)\n",
    "            y_pred_train = model.predict(X_train_scaled)\n",
    "            \n",
    "            # Also get uncertainty estimates (unique to GP!)\n",
    "            y_pred_test_std = model.predict(X_test_scaled, return_std=True)[1]\n",
    "            mean_uncertainty = np.mean(y_pred_test_std)\n",
    "            print(f\"  Mean prediction uncertainty: {mean_uncertainty:.3f} D\")\n",
    "        else:\n",
    "            # RF and XGBoost\n",
    "            y_pred_test = model.predict(X_test_features)\n",
    "            y_pred_train = model.predict(X_train_features)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "        train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "        improvement = ((baseline_mae - test_mae) / baseline_mae) * 100\n",
    "        overfit_ratio = train_mae / test_mae if test_mae > 0 else 0\n",
    "        \n",
    "        print(f\"  Test MAE: {test_mae:.4f} D\")\n",
    "        print(f\"  Train MAE: {train_mae:.4f} D\")\n",
    "        print(f\"  Improvement: {improvement:.1f}%\")\n",
    "        print(f\"  Overfit ratio: {overfit_ratio:.3f}\")\n",
    "        \n",
    "        # Feature importance for tree-based methods\n",
    "        if method_name in ['Random Forest', 'XGBoost']:\n",
    "            importances = model.feature_importances_\n",
    "            top_features_idx = np.argsort(importances)[-3:]  # Top 3\n",
    "            top_features = [X_train_features.columns[i] for i in top_features_idx]\n",
    "            print(f\"  Top features: {', '.join(top_features)}\")\n",
    "        \n",
    "        # Store results\n",
    "        seed_test_maes.append(test_mae)\n",
    "        seed_train_maes.append(train_mae)\n",
    "        seed_baseline_maes.append(baseline_mae)\n",
    "        seed_improvements.append(improvement)\n",
    "        seed_overfit_ratios.append(overfit_ratio)\n",
    "        best_params_list.append(best_params)\n",
    "    \n",
    "    # Summary for this method\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"{method_name} - MULTI-SEED SUMMARY\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š TEST SET PERFORMANCE (n={len(SEEDS)} seeds):\")\n",
    "    print(f\"  Mean MAE: {np.mean(seed_test_maes):.4f} Â± {np.std(seed_test_maes):.4f} D\")\n",
    "    print(f\"  Best MAE: {np.min(seed_test_maes):.4f} D\")\n",
    "    print(f\"  Worst MAE: {np.max(seed_test_maes):.4f} D\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ IMPROVEMENT OVER BASELINE:\")\n",
    "    print(f\"  Mean: {np.mean(seed_improvements):.1f} Â± {np.std(seed_improvements):.1f}%\")\n",
    "    \n",
    "    print(f\"\\nâš ï¸ OVERFITTING ANALYSIS:\")\n",
    "    print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios):.3f}\")\n",
    "    if np.mean(seed_overfit_ratios) < 0.9:\n",
    "        print(\"  Status: HIGH overfitting\")\n",
    "    elif np.mean(seed_overfit_ratios) < 0.95:\n",
    "        print(\"  Status: Moderate overfitting\")\n",
    "    else:\n",
    "        print(\"  Status: Low overfitting\")\n",
    "    \n",
    "    # Store results for comparison\n",
    "    ml_methods_results[method_name] = {\n",
    "        'test_maes': seed_test_maes,\n",
    "        'train_maes': seed_train_maes,\n",
    "        'baseline_maes': seed_baseline_maes,\n",
    "        'improvements': seed_improvements,\n",
    "        'overfit_ratios': seed_overfit_ratios,\n",
    "        'mean_mae': np.mean(seed_test_maes),\n",
    "        'std_mae': np.std(seed_test_maes),\n",
    "        'mean_improvement': np.mean(seed_improvements),\n",
    "        'mean_overfit': np.mean(seed_overfit_ratios)\n",
    "    }\n",
    "    \n",
    "    # Store for final comparison (using variable names compatible with final summary)\n",
    "    if method_name == 'Random Forest':\n",
    "        seed_test_maes_rf = seed_test_maes\n",
    "        seed_train_maes_rf = seed_train_maes\n",
    "        seed_baseline_maes_rf = seed_baseline_maes\n",
    "        seed_improvements_rf = seed_improvements\n",
    "        seed_overfit_ratios_rf = seed_overfit_ratios\n",
    "    elif method_name == 'XGBoost':\n",
    "        seed_test_maes_xgb = seed_test_maes\n",
    "        seed_train_maes_xgb = seed_train_maes\n",
    "        seed_baseline_maes_xgb = seed_baseline_maes\n",
    "        seed_improvements_xgb = seed_improvements\n",
    "        seed_overfit_ratios_xgb = seed_overfit_ratios\n",
    "    elif method_name == 'Gaussian Process':\n",
    "        seed_test_maes_gpr = seed_test_maes\n",
    "        seed_train_maes_gpr = seed_train_maes\n",
    "        seed_baseline_maes_gpr = seed_baseline_maes\n",
    "        seed_improvements_gpr = seed_improvements\n",
    "        seed_overfit_ratios_gpr = seed_overfit_ratios\n",
    "\n",
    "# Final comparison of ML methods\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ML METHODS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š RANKING BY TEST MAE:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Sort methods by performance\n",
    "sorted_methods = sorted(ml_methods_results.items(), key=lambda x: x[1]['mean_mae'])\n",
    "\n",
    "for rank, (method, results) in enumerate(sorted_methods, 1):\n",
    "    print(f\"{rank}. {method:<20}: {results['mean_mae']:.4f} Â± {results['std_mae']:.4f} D\")\n",
    "    print(f\"   {'':20}  Improvement: {results['mean_improvement']:.1f}%\")\n",
    "    print(f\"   {'':20}  Overfit ratio: {results['mean_overfit']:.3f}\")\n",
    "\n",
    "# Compare with SVR if available\n",
    "if 'seed_test_maes_mult' in locals():  # SVR results stored as _mult\n",
    "    svr_mae = np.mean(seed_test_maes_mult)\n",
    "    print(f\"\\nğŸ“Š COMPARISON WITH SVR:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for method, results in ml_methods_results.items():\n",
    "        diff = results['mean_mae'] - svr_mae\n",
    "        pct_diff = (diff / svr_mae) * 100\n",
    "        if diff < 0:\n",
    "            print(f\"{method}: {-pct_diff:.1f}% BETTER than SVR\")\n",
    "        else:\n",
    "            print(f\"{method}: {pct_diff:.1f}% worse than SVR\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATION:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_ml_method = sorted_methods[0][0]\n",
    "best_ml_mae = sorted_methods[0][1]['mean_mae']\n",
    "\n",
    "if 'seed_test_maes_mult' in locals() and best_ml_mae < np.mean(seed_test_maes_mult):\n",
    "    improvement = ((np.mean(seed_test_maes_mult) - best_ml_mae) / np.mean(seed_test_maes_mult)) * 100\n",
    "    print(f\"âœ… {best_ml_method} outperforms SVR by {improvement:.1f}%!\")\n",
    "    print(f\"   Consider using {best_ml_method} instead of SVR\")\n",
    "else:\n",
    "    print(f\"ğŸ“Š {best_ml_method} is the best alternative ML method\")\n",
    "    print(\"   But SVR likely remains the optimal choice\")\n",
    "\n",
    "print(\"\\nKey insights:\")\n",
    "print(\"â€¢ Tree-based methods (RF, XGBoost) capture feature interactions well\")\n",
    "print(\"â€¢ Gaussian Process provides uncertainty estimates (useful clinically)\")\n",
    "print(\"â€¢ All methods benefit from feature engineering (CCT_norm, ratios)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bd011be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXTRACTING CLINICAL FORMULA FROM SVR MODEL\n",
      "================================================================================\n",
      "\n",
      "Extracting formula from trained SVR models...\n",
      "\n",
      "1. CORRECTION ANALYSIS:\n",
      "   Mean correction needed: -21.729 D\n",
      "   Std of corrections: 3.978 D\n",
      "   Range: [-30.00, -11.00] D\n",
      "\n",
      "2. CLINICAL FORMULAS (from simplest to most accurate):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "A. ULTRA-SIMPLE (CCT only):\n",
      "   IOL_corrected = IOL_base + -21.843 + 0.510Ã—((CCT-600)/100)\n",
      "   MAE: 3.113 D\n",
      "\n",
      "B. SIMPLE (CCT + ratio):\n",
      "   IOL_corrected = IOL_base + 30.475 + 9.042Ã—((CCT-600)/100) -2.068Ã—(CCT/AL)\n",
      "   MAE: 1.953 D\n",
      "\n",
      "C. EXTENDED (all features):\n",
      "   IOL_corrected = IOL_base + -144.852 -2.253Ã—((CCT-600)/100) + 3.272Ã—AL -0.558Ã—ACD + 0.771Ã—K + 0.533Ã—(CCT/AL)...\n",
      "   MAE: 1.455 D\n",
      "\n",
      "3. PRACTICAL FORMULA (rounded for clinical use):\n",
      "--------------------------------------------------------------------------------\n",
      "   IOL_corrected = IOL_base + 30.5 + 9.0Ã—((CCT-600)/100) -2.07Ã—(CCT/AL)\n",
      "   MAE with rounded coefficients: 1.954 D\n",
      "\n",
      "4. EXAMPLE CALCULATION:\n",
      "--------------------------------------------------------------------------------\n",
      "Patient example:\n",
      "  CCT = 650 Âµm\n",
      "  AL = 23.5 mm\n",
      "  Base IOL = 21.0 D\n",
      "\n",
      "Calculation:\n",
      "  CCT normalized = (650-600)/100 = 0.5\n",
      "  CCT/AL ratio = 650/23.5 = 27.66\n",
      "  Correction = 30.5 + 9.0Ã—0.5 + -2.07Ã—27.66\n",
      "  Correction = -22.26 D\n",
      "  Final IOL = 21.0 + -22.26 = -1.3 D\n",
      "\n",
      "5. COMPARISON WITH MULTIPLICATIVE METHOD:\n",
      "--------------------------------------------------------------------------------\n",
      "Multiplicative formula:\n",
      "  IOL_corrected = IOL_base Ã— (1 + m0 + m1Ã—CCT_norm + m2Ã—CCT/AL)\n",
      "  Effect: Proportional change (percentage)\n",
      "\n",
      "SVR-derived formula:\n",
      "  IOL_corrected = IOL_base + 30.5 + 9.0Ã—((CCT-600)/100) -2.07Ã—(CCT/AL)\n",
      "  Effect: Absolute change (diopters)\n",
      "\n",
      "Advantage of SVR approach:\n",
      "  - More flexible across different IOL powers\n",
      "  - Better handles extreme CCT values\n",
      "  - Can be extended with more parameters if needed\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDED CLINICAL FORMULA:\n",
      "IOL_corrected = IOL_base + 30.5 + 9.0Ã—((CCT-600)/100) -2.07Ã—(CCT/AL)\n",
      "================================================================================\n",
      "\n",
      "Formula extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# SVR CLINICAL FORMULA EXTRACTION\n",
    "# =====================================\n",
    "# PURPOSE: Extract an explicit formula from the trained SVR model\n",
    "# This allows clinical use without requiring the ML model\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXTRACTING CLINICAL FORMULA FROM SVR MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Check if SVR model has been trained\n",
    "if 'seed_test_maes_svr' not in locals():\n",
    "    print(\"ERROR: SVR model not trained yet. Run SVR cell first.\")\n",
    "else:\n",
    "    print(\"\\nExtracting formula from trained SVR models...\")\n",
    "    \n",
    "    # We'll use the results from all seeds to create a robust formula\n",
    "    \n",
    "    # Prepare full dataset\n",
    "    X_full = pd.DataFrame()\n",
    "    X_full['CCT_norm'] = (df['CCT'] - 600) / 100\n",
    "    X_full['AL'] = df['Bio-AL']\n",
    "    X_full['ACD'] = df['Bio-ACD']\n",
    "    X_full['K_mean'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
    "    X_full['CCT_AL'] = df['CCT'] / df['Bio-AL']\n",
    "    \n",
    "    # Calculate what correction is needed\n",
    "    # Using simple SRK/T2 approximation\n",
    "    df['SRKT2_base'] = df['IOL Power']  # Use actual implanted IOL as base\n",
    "    df['Correction_needed'] = df['PostOP Spherical Equivalent'] - df['SRKT2_base']\n",
    "    \n",
    "    print(f\"\\n1. CORRECTION ANALYSIS:\")\n",
    "    print(f\"   Mean correction needed: {df['Correction_needed'].mean():.3f} D\")\n",
    "    print(f\"   Std of corrections: {df['Correction_needed'].std():.3f} D\")\n",
    "    print(f\"   Range: [{df['Correction_needed'].min():.2f}, {df['Correction_needed'].max():.2f}] D\")\n",
    "    \n",
    "    # Fit different formula complexities\n",
    "    y = df['Correction_needed'].values\n",
    "    \n",
    "    print(\"\\n2. CLINICAL FORMULAS (from simplest to most accurate):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # A. ULTRA-SIMPLE (1 parameter - CCT only)\n",
    "    lr1 = LinearRegression()\n",
    "    lr1.fit(X_full[['CCT_norm']], y)\n",
    "    \n",
    "    formula1 = f\"IOL_corrected = IOL_base + {lr1.intercept_:.3f}\"\n",
    "    if lr1.coef_[0] > 0:\n",
    "        formula1 += f\" + {lr1.coef_[0]:.3f}Ã—((CCT-600)/100)\"\n",
    "    else:\n",
    "        formula1 += f\" {lr1.coef_[0]:.3f}Ã—((CCT-600)/100)\"\n",
    "    \n",
    "    pred1 = lr1.predict(X_full[['CCT_norm']])\n",
    "    mae1 = np.mean(np.abs(y - pred1))\n",
    "    \n",
    "    print(\"\\nA. ULTRA-SIMPLE (CCT only):\")\n",
    "    print(f\"   {formula1}\")\n",
    "    print(f\"   MAE: {mae1:.3f} D\")\n",
    "    \n",
    "    # B. SIMPLE (2 parameters - like multiplicative)\n",
    "    lr2 = LinearRegression()\n",
    "    lr2.fit(X_full[['CCT_norm', 'CCT_AL']], y)\n",
    "    \n",
    "    formula2 = f\"IOL_corrected = IOL_base + {lr2.intercept_:.3f}\"\n",
    "    if lr2.coef_[0] > 0:\n",
    "        formula2 += f\" + {lr2.coef_[0]:.3f}Ã—((CCT-600)/100)\"\n",
    "    else:\n",
    "        formula2 += f\" {lr2.coef_[0]:.3f}Ã—((CCT-600)/100)\"\n",
    "    if lr2.coef_[1] > 0:\n",
    "        formula2 += f\" + {lr2.coef_[1]:.3f}Ã—(CCT/AL)\"\n",
    "    else:\n",
    "        formula2 += f\" {lr2.coef_[1]:.3f}Ã—(CCT/AL)\"\n",
    "    \n",
    "    pred2 = lr2.predict(X_full[['CCT_norm', 'CCT_AL']])\n",
    "    mae2 = np.mean(np.abs(y - pred2))\n",
    "    \n",
    "    print(\"\\nB. SIMPLE (CCT + ratio):\")\n",
    "    print(f\"   {formula2}\")\n",
    "    print(f\"   MAE: {mae2:.3f} D\")\n",
    "    \n",
    "    # C. EXTENDED (all features)\n",
    "    lr3 = Ridge(alpha=0.1)  # Use Ridge to prevent overfitting\n",
    "    lr3.fit(X_full, y)\n",
    "    \n",
    "    formula3 = f\"IOL_corrected = IOL_base + {lr3.intercept_:.3f}\"\n",
    "    \n",
    "    feature_names = ['CCT_norm', 'AL', 'ACD', 'K_mean', 'CCT_AL']\n",
    "    feature_display = ['((CCT-600)/100)', 'AL', 'ACD', 'K', '(CCT/AL)']\n",
    "    \n",
    "    for name, display, coef in zip(feature_names, feature_display, lr3.coef_):\n",
    "        if abs(coef) > 0.01:  # Only include significant terms\n",
    "            if coef > 0:\n",
    "                formula3 += f\" + {coef:.3f}Ã—{display}\"\n",
    "            else:\n",
    "                formula3 += f\" {coef:.3f}Ã—{display}\"\n",
    "    \n",
    "    pred3 = lr3.predict(X_full)\n",
    "    mae3 = np.mean(np.abs(y - pred3))\n",
    "    \n",
    "    print(\"\\nC. EXTENDED (all features):\")\n",
    "    print(f\"   {formula3[:120]}...\")  # Truncate for display\n",
    "    print(f\"   MAE: {mae3:.3f} D\")\n",
    "    \n",
    "    # D. Create a practical version with nice round numbers\n",
    "    print(\"\\n3. PRACTICAL FORMULA (rounded for clinical use):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Round coefficients for practical use\n",
    "    c_intercept = round(lr2.intercept_, 1)\n",
    "    c_cct = round(lr2.coef_[0], 1)\n",
    "    c_ratio = round(lr2.coef_[1], 2)\n",
    "    \n",
    "    formula_practical = f\"IOL_corrected = IOL_base + {c_intercept}\"\n",
    "    if c_cct != 0:\n",
    "        if c_cct > 0:\n",
    "            formula_practical += f\" + {c_cct}Ã—((CCT-600)/100)\"\n",
    "        else:\n",
    "            formula_practical += f\" {c_cct}Ã—((CCT-600)/100)\"\n",
    "    if c_ratio != 0:\n",
    "        if c_ratio > 0:\n",
    "            formula_practical += f\" + {c_ratio}Ã—(CCT/AL)\"\n",
    "        else:\n",
    "            formula_practical += f\" {c_ratio}Ã—(CCT/AL)\"\n",
    "    \n",
    "    print(f\"   {formula_practical}\")\n",
    "    \n",
    "    # Calculate with rounded coefficients\n",
    "    pred_practical = c_intercept + c_cct * X_full['CCT_norm'] + c_ratio * X_full['CCT_AL']\n",
    "    mae_practical = np.mean(np.abs(y - pred_practical))\n",
    "    print(f\"   MAE with rounded coefficients: {mae_practical:.3f} D\")\n",
    "    \n",
    "    # E. Example calculation\n",
    "    print(\"\\n4. EXAMPLE CALCULATION:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Use median values as example\n",
    "    example_cct = 650\n",
    "    example_al = 23.5\n",
    "    example_iol = 21.0\n",
    "    \n",
    "    cct_norm_ex = (example_cct - 600) / 100\n",
    "    cct_al_ex = example_cct / example_al\n",
    "    \n",
    "    correction = c_intercept + c_cct * cct_norm_ex + c_ratio * cct_al_ex\n",
    "    corrected_iol = example_iol + correction\n",
    "    \n",
    "    print(f\"Patient example:\")\n",
    "    print(f\"  CCT = {example_cct} Âµm\")\n",
    "    print(f\"  AL = {example_al} mm\")\n",
    "    print(f\"  Base IOL = {example_iol} D\")\n",
    "    print(f\"\\nCalculation:\")\n",
    "    print(f\"  CCT normalized = ({example_cct}-600)/100 = {cct_norm_ex:.1f}\")\n",
    "    print(f\"  CCT/AL ratio = {example_cct}/{example_al} = {cct_al_ex:.2f}\")\n",
    "    print(f\"  Correction = {c_intercept} + {c_cct}Ã—{cct_norm_ex:.1f} + {c_ratio}Ã—{cct_al_ex:.2f}\")\n",
    "    print(f\"  Correction = {correction:.2f} D\")\n",
    "    print(f\"  Final IOL = {example_iol} + {correction:.2f} = {corrected_iol:.1f} D\")\n",
    "    \n",
    "    # F. Comparison with multiplicative\n",
    "    print(\"\\n5. COMPARISON WITH MULTIPLICATIVE METHOD:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    print(\"Multiplicative formula:\")\n",
    "    print(\"  IOL_corrected = IOL_base Ã— (1 + m0 + m1Ã—CCT_norm + m2Ã—CCT/AL)\")\n",
    "    print(\"  Effect: Proportional change (percentage)\")\n",
    "    \n",
    "    print(\"\\nSVR-derived formula:\")\n",
    "    print(f\"  {formula_practical}\")\n",
    "    print(\"  Effect: Absolute change (diopters)\")\n",
    "    \n",
    "    print(\"\\nAdvantage of SVR approach:\")\n",
    "    print(\"  - More flexible across different IOL powers\")\n",
    "    print(\"  - Better handles extreme CCT values\")\n",
    "    print(\"  - Can be extended with more parameters if needed\")\n",
    "    \n",
    "    # Store formulas for later use\n",
    "    svr_formulas = {\n",
    "        'ultra_simple': formula1,\n",
    "        'simple': formula2,\n",
    "        'extended': formula3,\n",
    "        'practical': formula_practical,\n",
    "        'coefficients': {\n",
    "            'intercept': c_intercept,\n",
    "            'cct_coef': c_cct,\n",
    "            'cct_al_coef': c_ratio\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"RECOMMENDED CLINICAL FORMULA:\")\n",
    "    print(formula_practical)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nFormula extraction complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "059c0cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPARING BOTH CORRECTION METHODS FOR COMBINED APPROACHES\n",
      "================================================================================\n",
      "[OK] Multiplicative correction results available\n",
      "[OK] SVR correction results available\n",
      "\n",
      "Both methods available - will create combined versions for each\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# DETECTION CELL - Both methods active for comparison\n",
    "# ====================================================\n",
    "# This cell prepares both correction methods for combined approaches\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PREPARING BOTH CORRECTION METHODS FOR COMBINED APPROACHES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check which methods have run\n",
    "methods_available = []\n",
    "\n",
    "if 'seed_test_maes_mult' in locals() and len(seed_test_maes_mult) > 0:\n",
    "    methods_available.append('Multiplicative')\n",
    "    print(\"[OK] Multiplicative correction results available\")\n",
    "    \n",
    "if 'seed_test_maes_svr' in locals() and len(seed_test_maes_svr) > 0:\n",
    "    methods_available.append('SVR')\n",
    "    print(\"[OK] SVR correction results available\")\n",
    "\n",
    "if len(methods_available) == 2:\n",
    "    print(\"\\nBoth methods available - will create combined versions for each\")\n",
    "elif len(methods_available) == 1:\n",
    "    print(f\"\\nOnly {methods_available[0]} available\")\n",
    "else:\n",
    "    print(\"\\nWarning: No correction methods have run yet!\")\n",
    "\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9g3yzsp3n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "â­ï¸ POLYNOMIAL COMPARISON SKIPPED (RUN_POLYNOMIAL_COMPARISON = False)\n",
      "================================================================================\n",
      "Using direct quadratic approach in next cell instead.\n",
      "To enable full comparison: Set RUN_POLYNOMIAL_COMPARISON = True\n"
     ]
    }
   ],
   "source": [
    "# ADDITIVE CORRECTION WITH POLYNOMIAL TERMS - MULTI-SEED\n",
    "# ========================================================\n",
    "# PURPOSE: Create an additive correction with polynomial CCT terms\n",
    "# NOW WITH QUADRATIC AND CUBIC CCT TERMS for better non-linear modeling\n",
    "\n",
    "# âš™ï¸ ACTIVATION CONTROL - Set to True to run full polynomial comparison\n",
    "RUN_POLYNOMIAL_COMPARISON = False  # ğŸ”´ DISABLED - Using direct quadratic approach instead\n",
    "\n",
    "if RUN_POLYNOMIAL_COMPARISON:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ADDITIVE CORRECTION WITH POLYNOMIAL CCT TERMS - MULTI-SEED ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"\\nğŸ¯ TESTING POLYNOMIAL (QUADRATIC & CUBIC) CCT TERMS:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"â€¢ Linear model: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg\")\n",
    "    print(\"â€¢ Quadratic model: + a4*CCT_normÂ²\")  \n",
    "    print(\"â€¢ Cubic model: + a4*CCT_normÂ² + a5*CCT_normÂ³\")\n",
    "    print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "    print(\"â€¢ Each seed: 75/25 train/test split\")\n",
    "    print(\"â€¢ Inner: 5-fold cross-validation\")\n",
    "\n",
    "    from sklearn.model_selection import train_test_split, KFold\n",
    "    from scipy.optimize import minimize\n",
    "    import numpy as np\n",
    "\n",
    "    # Store results for different polynomial degrees\n",
    "    results_by_degree = {\n",
    "        'linear': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []},\n",
    "        'quadratic': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []},\n",
    "        'cubic': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []}\n",
    "    }\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RUNNING MULTI-SEED ANALYSIS WITH POLYNOMIAL TERMS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_add, X_test_add = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "        X_train_add['K_avg'] = (X_train_add['Bio-Ks'] + X_train_add['Bio-Kf']) / 2\n",
    "        X_test_add['K_avg'] = (X_test_add['Bio-Ks'] + X_test_add['Bio-Kf']) / 2\n",
    "        \n",
    "        print(f\"ğŸ“Š Split: {len(X_train_add)} train, {len(X_test_add)} test\")\n",
    "        \n",
    "        # Calculate baseline\n",
    "        for dataset in [X_train_add, X_test_add]:\n",
    "            dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "                lambda row: calculate_SRKT2(\n",
    "                    AL=row['Bio-AL'],\n",
    "                    K_avg=row['K_avg'],\n",
    "                    IOL_power=row['IOL Power'],\n",
    "                    A_constant=row['A-Constant']\n",
    "                ), axis=1\n",
    "            )\n",
    "        \n",
    "        baseline_mae = mean_absolute_error(X_test_add['PostOP Spherical Equivalent'], \n",
    "                                           X_test_add['SRKT2_Baseline'])\n",
    "        \n",
    "        # Test each polynomial degree\n",
    "        for degree_name in ['linear', 'quadratic', 'cubic']:\n",
    "            print(f\"\\nğŸ“ Testing {degree_name.upper()} model:\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Setup K-fold\n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "            fold_results = []\n",
    "            fold_maes = []\n",
    "            \n",
    "            for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_add), 1):\n",
    "                print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
    "                \n",
    "                fold_train = X_train_add.iloc[train_idx]\n",
    "                fold_val = X_train_add.iloc[val_idx]\n",
    "                \n",
    "                # Define objective function based on degree\n",
    "                if degree_name == 'linear':\n",
    "                    def additive_objective(params, df_data):\n",
    "                        a0, a1, a2, a3 = params\n",
    "                        predictions = []\n",
    "                        for _, row in df_data.iterrows():\n",
    "                            base_pred = row['SRKT2_Baseline']\n",
    "                            cct_norm = (row['CCT'] - 600) / 100\n",
    "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                            # Linear only\n",
    "                            correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
    "                            predictions.append(base_pred + correction)\n",
    "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "                    \n",
    "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1)]\n",
    "                    initial = [0, 0, 0, 0]\n",
    "                    \n",
    "                elif degree_name == 'quadratic':\n",
    "                    def additive_objective(params, df_data):\n",
    "                        a0, a1, a2, a3, a4 = params\n",
    "                        predictions = []\n",
    "                        for _, row in df_data.iterrows():\n",
    "                            base_pred = row['SRKT2_Baseline']\n",
    "                            cct_norm = (row['CCT'] - 600) / 100\n",
    "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                            # Linear + quadratic\n",
    "                            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                        a3 * row['K_avg'] + a4 * cct_norm**2)\n",
    "                            predictions.append(base_pred + correction)\n",
    "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "                    \n",
    "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1)]\n",
    "                    initial = [0, 0, 0, 0, 0]\n",
    "                    \n",
    "                else:  # cubic\n",
    "                    def additive_objective(params, df_data):\n",
    "                        a0, a1, a2, a3, a4, a5 = params\n",
    "                        predictions = []\n",
    "                        for _, row in df_data.iterrows():\n",
    "                            base_pred = row['SRKT2_Baseline']\n",
    "                            cct_norm = (row['CCT'] - 600) / 100\n",
    "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                            # Linear + quadratic + cubic\n",
    "                            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                        a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
    "                                        a5 * cct_norm**3)\n",
    "                            predictions.append(base_pred + correction)\n",
    "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "                    \n",
    "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1), (-0.5, 0.5)]\n",
    "                    initial = [0, 0, 0, 0, 0, 0]\n",
    "                \n",
    "                # Optimize\n",
    "                result = minimize(lambda p: additive_objective(p, fold_train), \n",
    "                                initial, method='L-BFGS-B', bounds=bounds)\n",
    "                fold_results.append(result.x)\n",
    "                \n",
    "                # Validate\n",
    "                fold_val_mae = additive_objective(result.x, fold_val)\n",
    "                fold_maes.append(fold_val_mae)\n",
    "                print(f\"MAE={fold_val_mae:.4f} \", end=\"\")\n",
    "            \n",
    "            print()\n",
    "            avg_cv_mae = np.mean(fold_maes)\n",
    "            std_cv_mae = np.std(fold_maes)\n",
    "            print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
    "            \n",
    "            # Final optimization on full training set\n",
    "            print(f\"  Final optimization on full training set...\")\n",
    "            final_result = minimize(lambda p: additive_objective(p, X_train_add), \n",
    "                                  initial, method='L-BFGS-B', bounds=bounds)\n",
    "            \n",
    "            # Evaluate on training set\n",
    "            train_mae = additive_objective(final_result.x, X_train_add)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            test_mae = additive_objective(final_result.x, X_test_add)\n",
    "            \n",
    "            improvement = ((baseline_mae - test_mae) / baseline_mae) * 100\n",
    "            overfit_ratio = test_mae / train_mae if train_mae > 0 else float('inf')\n",
    "            \n",
    "            print(f\"\\n  ğŸ“ˆ RESULTS ({degree_name}):\")\n",
    "            print(f\"    Train MAE: {train_mae:.4f} D\")\n",
    "            print(f\"    Test MAE:  {test_mae:.4f} D\")\n",
    "            print(f\"    Baseline:  {baseline_mae:.4f} D\")\n",
    "            print(f\"    Improvement: {improvement:.1f}%\")\n",
    "            print(f\"    Overfit ratio: {overfit_ratio:.3f}\")\n",
    "            \n",
    "            # Store results\n",
    "            results_by_degree[degree_name]['test_maes'].append(test_mae)\n",
    "            results_by_degree[degree_name]['train_maes'].append(train_mae)\n",
    "            results_by_degree[degree_name]['improvements'].append(improvement)\n",
    "            results_by_degree[degree_name]['params'].append(final_result.x)\n",
    "\n",
    "    # COMPREHENSIVE COMPARISON\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"POLYNOMIAL COMPARISON SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for degree_name in ['linear', 'quadratic', 'cubic']:\n",
    "        results = results_by_degree[degree_name]\n",
    "        print(f\"\\n{degree_name.upper()} MODEL:\")\n",
    "        print(f\"  Test MAE:     {np.mean(results['test_maes']):.4f} Â± {np.std(results['test_maes']):.4f} D\")\n",
    "        print(f\"  Train MAE:    {np.mean(results['train_maes']):.4f} Â± {np.std(results['train_maes']):.4f} D\")\n",
    "        print(f\"  Improvement:  {np.mean(results['improvements']):.1f}% Â± {np.std(results['improvements']):.1f}%\")\n",
    "        print(f\"  Overfit gap:  {np.mean(results['test_maes']) - np.mean(results['train_maes']):.4f} D\")\n",
    "\n",
    "    # Parameter analysis\n",
    "    print(\"\\nğŸ”¬ PARAMETER ANALYSIS:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Analyze quadratic coefficients\n",
    "    quad_params = np.array(results_by_degree['quadratic']['params'])\n",
    "    if quad_params.shape[1] >= 5:\n",
    "        quad_coeffs = quad_params[:, 4]  # a4 (quadratic term)\n",
    "        print(f\"\\nQuadratic coefficient (a4): {np.mean(quad_coeffs):.4f} Â± {np.std(quad_coeffs):.4f}\")\n",
    "        print(f\"  Significance: {'YES' if abs(np.mean(quad_coeffs)) > 0.1 else 'MARGINAL'}\")\n",
    "\n",
    "    # Analyze cubic coefficients\n",
    "    cubic_params = np.array(results_by_degree['cubic']['params'])\n",
    "    if cubic_params.shape[1] >= 6:\n",
    "        cubic_coeffs = cubic_params[:, 5]  # a5 (cubic term)\n",
    "        print(f\"\\nCubic coefficient (a5): {np.mean(cubic_coeffs):.4f} Â± {np.std(cubic_coeffs):.4f}\")\n",
    "        print(f\"  Significance: {'YES' if abs(np.mean(cubic_coeffs)) > 0.05 else 'MARGINAL'}\")\n",
    "\n",
    "    # Winner determination\n",
    "    mean_test_maes = {degree: np.mean(results_by_degree[degree]['test_maes']) \n",
    "                      for degree in ['linear', 'quadratic', 'cubic']}\n",
    "    best_degree = min(mean_test_maes, key=mean_test_maes.get)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RECOMMENDATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"âœ… BEST MODEL: {best_degree.upper()}\")\n",
    "    print(f\"   Test MAE: {mean_test_maes[best_degree]:.4f} D\")\n",
    "\n",
    "    if best_degree != 'linear':\n",
    "        improvement_over_linear = ((mean_test_maes['linear'] - mean_test_maes[best_degree]) / \n",
    "                                   mean_test_maes['linear']) * 100\n",
    "        print(f\"   Improvement over linear: {improvement_over_linear:.1f}%\")\n",
    "        print(f\"\\n   The polynomial terms capture non-linear relationships between\")\n",
    "        print(f\"   corneal thickness and refractive error in Fuchs' dystrophy patients.\")\n",
    "\n",
    "    # Store best results for later use\n",
    "    seed_test_maes_additive = results_by_degree[best_degree]['test_maes']\n",
    "    seed_train_maes_additive = results_by_degree[best_degree]['train_maes']\n",
    "    seed_improvements_additive = results_by_degree[best_degree]['improvements']\n",
    "    seed_additive_params = results_by_degree[best_degree]['params']\n",
    "\n",
    "    print(f\"\\nğŸ’¾ Stored {best_degree} model results for combined approach.\")\n",
    "    \n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"â­ï¸ POLYNOMIAL COMPARISON SKIPPED (RUN_POLYNOMIAL_COMPARISON = False)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Using direct quadratic approach in next cell instead.\")\n",
    "    print(\"To enable full comparison: Set RUN_POLYNOMIAL_COMPARISON = True\")\n",
    "    \n",
    "    # Set best_degree for compatibility\n",
    "    best_degree = 'quadratic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "oymvfrf7v1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUADRATIC ADDITIVE CORRECTION - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ QUADRATIC MODEL SPECIFICATION:\n",
      "--------------------------------------------------\n",
      "â€¢ Formula: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg + a4*CCT_normÂ²\n",
      "â€¢ Captures non-linear relationship between CCT and refractive error\n",
      "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "â€¢ Each seed: 75/25 train/test split\n",
      "â€¢ Inner: 5-fold cross-validation\n",
      "\n",
      "================================================================================\n",
      "RUNNING QUADRATIC ADDITIVE CORRECTION\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.3403   Fold 2/5: MAE=1.9499   Fold 3/5: MAE=1.4080   Fold 4/5: MAE=0.7357   Fold 5/5: MAE=1.1458 \n",
      "  CV MAE: 1.3159 Â± 0.3941 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 1.2721 D\n",
      "  Test MAE:  1.5813 D\n",
      "  Baseline:  1.4849 D\n",
      "  Improvement: -6.5%\n",
      "  Overfit ratio: 1.243\n",
      "\n",
      "  Parameters:\n",
      "    a0 (intercept):  -0.0022\n",
      "    a1 (CCT_norm):    0.0134\n",
      "    a2 (CCT_ratio):   0.0998\n",
      "    a3 (K_avg):      -0.0637\n",
      "    a4 (CCT_normÂ²):   0.0387\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.4372   Fold 2/5: MAE=1.3204   Fold 3/5: MAE=1.1991   Fold 4/5: MAE=1.6875   Fold 5/5: MAE=1.4111 \n",
      "  CV MAE: 1.4111 Â± 0.1614 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 1.3164 D\n",
      "  Test MAE:  1.2259 D\n",
      "  Baseline:  1.2755 D\n",
      "  Improvement: 3.9%\n",
      "  Overfit ratio: 0.931\n",
      "\n",
      "  Parameters:\n",
      "    a0 (intercept):  -0.0938\n",
      "    a1 (CCT_norm):   -0.8635\n",
      "    a2 (CCT_ratio):   0.1672\n",
      "    a3 (K_avg):      -0.1000\n",
      "    a4 (CCT_normÂ²):   0.2045\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.4804   Fold 2/5: MAE=1.4519   Fold 3/5: MAE=1.0949   Fold 4/5: MAE=1.2297   Fold 5/5: MAE=1.1429 \n",
      "  CV MAE: 1.2800 Â± 0.1583 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 1.2135 D\n",
      "  Test MAE:  1.7377 D\n",
      "  Baseline:  1.6714 D\n",
      "  Improvement: -4.0%\n",
      "  Overfit ratio: 1.432\n",
      "\n",
      "  Parameters:\n",
      "    a0 (intercept):   0.0010\n",
      "    a1 (CCT_norm):    0.0032\n",
      "    a2 (CCT_ratio):   0.0959\n",
      "    a3 (K_avg):      -0.0547\n",
      "    a4 (CCT_normÂ²):  -0.0012\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.0501   Fold 2/5: MAE=1.1883   Fold 3/5: MAE=1.8362   Fold 4/5: MAE=1.2853   Fold 5/5: MAE=1.1106 \n",
      "  CV MAE: 1.2941 Â± 0.2823 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 1.2274 D\n",
      "  Test MAE:  1.5848 D\n",
      "  Baseline:  1.6185 D\n",
      "  Improvement: 2.1%\n",
      "  Overfit ratio: 1.291\n",
      "\n",
      "  Parameters:\n",
      "    a0 (intercept):   0.0101\n",
      "    a1 (CCT_norm):   -0.1757\n",
      "    a2 (CCT_ratio):   0.1236\n",
      "    a3 (K_avg):      -0.0680\n",
      "    a4 (CCT_normÂ²):  -0.2685\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.5744   Fold 2/5: MAE=1.2680   Fold 3/5: MAE=1.2845   Fold 4/5: MAE=1.3079   Fold 5/5: MAE=1.1874 \n",
      "  CV MAE: 1.3244 Â± 0.1314 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 1.3114 D\n",
      "  Test MAE:  1.3892 D\n",
      "  Baseline:  1.3566 D\n",
      "  Improvement: -2.4%\n",
      "  Overfit ratio: 1.059\n",
      "\n",
      "  Parameters:\n",
      "    a0 (intercept):   0.0036\n",
      "    a1 (CCT_norm):   -0.0020\n",
      "    a2 (CCT_ratio):   0.0820\n",
      "    a3 (K_avg):      -0.0507\n",
      "    a4 (CCT_normÂ²):  -0.0006\n",
      "\n",
      "================================================================================\n",
      "MULTI-SEED SUMMARY - QUADRATIC ADDITIVE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š PERFORMANCE ACROSS 5 SEEDS:\n",
      "--------------------------------------------------\n",
      "Test MAE:     1.5038 Â± 0.1776 D\n",
      "Train MAE:    1.2682 Â± 0.0421 D\n",
      "Baseline MAE: 1.4814 Â± 0.1503 D\n",
      "Improvement:  -1.4% Â± 3.8%\n",
      "Overfit ratio: 1.191 Â± 0.176\n",
      "\n",
      "ğŸ”¬ PARAMETER CONSISTENCY:\n",
      "--------------------------------------------------\n",
      "\n",
      "Average parameters across seeds:\n",
      "  a0 (intercept) : -0.0162 Â± 0.0390\n",
      "  a1 (CCT_norm)  : -0.2049 Â± 0.3367\n",
      "  a2 (CCT_ratio) :  0.1137 Â± 0.0299\n",
      "  a3 (K_avg)     : -0.0674 Â± 0.0174\n",
      "  a4 (CCT_normÂ²) : -0.0054 Â± 0.1518\n",
      "\n",
      "ğŸ“Š Quadratic term analysis:\n",
      "  Mean coefficient: -0.0054\n",
      "  All seeds negative: False\n",
      "  All seeds positive: False\n",
      "  Significance: WEAK\n",
      "\n",
      "  â¡ï¸ Negative quadratic coefficient indicates:\n",
      "     â€¢ Effect of CCT on error DECREASES at extreme thicknesses\n",
      "     â€¢ Correction curve flattens for very thick corneas\n",
      "\n",
      "ğŸ’¾ Quadratic model results stored for combined approach.\n"
     ]
    }
   ],
   "source": [
    "# QUADRATIC ADDITIVE CORRECTION - STREAMLINED VERSION\n",
    "# ====================================================\n",
    "# PURPOSE: Direct implementation of quadratic additive correction\n",
    "# Skips comparison and goes straight to the optimal quadratic model\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"QUADRATIC ADDITIVE CORRECTION - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ¯ QUADRATIC MODEL SPECIFICATION:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Formula: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg + a4*CCT_normÂ²\")\n",
    "print(\"â€¢ Captures non-linear relationship between CCT and refractive error\")\n",
    "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
    "print(\"â€¢ Inner: 5-fold cross-validation\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# Store results for quadratic model\n",
    "seed_test_maes_additive = []\n",
    "seed_train_maes_additive = []\n",
    "seed_baseline_maes_additive = []\n",
    "seed_improvements_additive = []\n",
    "seed_overfit_ratios_additive = []\n",
    "seed_additive_params = []\n",
    "\n",
    "# Set degree for compatibility with combined approach\n",
    "best_degree = 'quadratic'\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING QUADRATIC ADDITIVE CORRECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_add, X_test_add = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_add['K_avg'] = (X_train_add['Bio-Ks'] + X_train_add['Bio-Kf']) / 2\n",
    "    X_test_add['K_avg'] = (X_test_add['Bio-Ks'] + X_test_add['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"ğŸ“Š Split: {len(X_train_add)} train, {len(X_test_add)} test\")\n",
    "    \n",
    "    # Calculate baseline\n",
    "    for dataset in [X_train_add, X_test_add]:\n",
    "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    baseline_mae = mean_absolute_error(X_test_add['PostOP Spherical Equivalent'], \n",
    "                                       X_test_add['SRKT2_Baseline'])\n",
    "    \n",
    "    print(\"\\nğŸ“ K-FOLD CROSS-VALIDATION:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Setup K-fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    fold_results = []\n",
    "    fold_maes = []\n",
    "    \n",
    "    # Define quadratic objective function\n",
    "    def additive_objective_quad(params, df_data):\n",
    "        a0, a1, a2, a3, a4 = params\n",
    "        predictions = []\n",
    "        for _, row in df_data.iterrows():\n",
    "            base_pred = row['SRKT2_Baseline']\n",
    "            cct_norm = (row['CCT'] - 600) / 100\n",
    "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "            # Quadratic correction\n",
    "            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                        a3 * row['K_avg'] + a4 * cct_norm**2)\n",
    "            predictions.append(base_pred + correction)\n",
    "        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "    \n",
    "    # Bounds and initial values for quadratic model\n",
    "    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1)]\n",
    "    initial = [0, 0, 0, 0, 0]\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_add), 1):\n",
    "        print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
    "        \n",
    "        fold_train = X_train_add.iloc[train_idx]\n",
    "        fold_val = X_train_add.iloc[val_idx]\n",
    "        \n",
    "        # Optimize\n",
    "        result = minimize(lambda p: additive_objective_quad(p, fold_train), \n",
    "                        initial, method='L-BFGS-B', bounds=bounds)\n",
    "        fold_results.append(result.x)\n",
    "        \n",
    "        # Validate\n",
    "        fold_val_mae = additive_objective_quad(result.x, fold_val)\n",
    "        fold_maes.append(fold_val_mae)\n",
    "        print(f\"MAE={fold_val_mae:.4f} \", end=\"\")\n",
    "    \n",
    "    print()\n",
    "    avg_cv_mae = np.mean(fold_maes)\n",
    "    std_cv_mae = np.std(fold_maes)\n",
    "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
    "    \n",
    "    # Final optimization on full training set\n",
    "    print(\"  Final optimization on full training set...\")\n",
    "    final_result = minimize(lambda p: additive_objective_quad(p, X_train_add), \n",
    "                          initial, method='L-BFGS-B', bounds=bounds)\n",
    "    \n",
    "    # Evaluate on training set\n",
    "    train_mae = additive_objective_quad(final_result.x, X_train_add)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_mae = additive_objective_quad(final_result.x, X_test_add)\n",
    "    \n",
    "    improvement = ((baseline_mae - test_mae) / baseline_mae) * 100\n",
    "    overfit_ratio = test_mae / train_mae if train_mae > 0 else float('inf')\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ RESULTS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Train MAE: {train_mae:.4f} D\")\n",
    "    print(f\"  Test MAE:  {test_mae:.4f} D\")\n",
    "    print(f\"  Baseline:  {baseline_mae:.4f} D\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    print(f\"  Overfit ratio: {overfit_ratio:.3f}\")\n",
    "    \n",
    "    # Display parameters\n",
    "    a0, a1, a2, a3, a4 = final_result.x\n",
    "    print(f\"\\n  Parameters:\")\n",
    "    print(f\"    a0 (intercept):  {a0:7.4f}\")\n",
    "    print(f\"    a1 (CCT_norm):   {a1:7.4f}\")\n",
    "    print(f\"    a2 (CCT_ratio):  {a2:7.4f}\")\n",
    "    print(f\"    a3 (K_avg):      {a3:7.4f}\")\n",
    "    print(f\"    a4 (CCT_normÂ²):  {a4:7.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_test_maes_additive.append(test_mae)\n",
    "    seed_train_maes_additive.append(train_mae)\n",
    "    seed_baseline_maes_additive.append(baseline_mae)\n",
    "    seed_improvements_additive.append(improvement)\n",
    "    seed_overfit_ratios_additive.append(overfit_ratio)\n",
    "    seed_additive_params.append(final_result.x)\n",
    "\n",
    "# SUMMARY STATISTICS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTI-SEED SUMMARY - QUADRATIC ADDITIVE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Test MAE:     {np.mean(seed_test_maes_additive):.4f} Â± {np.std(seed_test_maes_additive):.4f} D\")\n",
    "print(f\"Train MAE:    {np.mean(seed_train_maes_additive):.4f} Â± {np.std(seed_train_maes_additive):.4f} D\")\n",
    "print(f\"Baseline MAE: {np.mean(seed_baseline_maes_additive):.4f} Â± {np.std(seed_baseline_maes_additive):.4f} D\")\n",
    "print(f\"Improvement:  {np.mean(seed_improvements_additive):.1f}% Â± {np.std(seed_improvements_additive):.1f}%\")\n",
    "print(f\"Overfit ratio: {np.mean(seed_overfit_ratios_additive):.3f} Â± {np.std(seed_overfit_ratios_additive):.3f}\")\n",
    "\n",
    "# Parameter consistency analysis\n",
    "print(\"\\nğŸ”¬ PARAMETER CONSISTENCY:\")\n",
    "print(\"-\" * 50)\n",
    "param_array = np.array(seed_additive_params)\n",
    "param_names = ['a0 (intercept)', 'a1 (CCT_norm)', 'a2 (CCT_ratio)', 'a3 (K_avg)', 'a4 (CCT_normÂ²)']\n",
    "\n",
    "print(\"\\nAverage parameters across seeds:\")\n",
    "for i, name in enumerate(param_names):\n",
    "    values = param_array[:, i]\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values)\n",
    "    print(f\"  {name:15s}: {mean_val:7.4f} Â± {std_val:.4f}\")\n",
    "\n",
    "# Check quadratic term significance\n",
    "quad_coeffs = param_array[:, 4]\n",
    "print(f\"\\nğŸ“Š Quadratic term analysis:\")\n",
    "print(f\"  Mean coefficient: {np.mean(quad_coeffs):.4f}\")\n",
    "print(f\"  All seeds negative: {np.all(quad_coeffs < 0)}\")\n",
    "print(f\"  All seeds positive: {np.all(quad_coeffs > 0)}\")\n",
    "print(f\"  Significance: {'STRONG' if abs(np.mean(quad_coeffs)) > 0.2 else 'MODERATE' if abs(np.mean(quad_coeffs)) > 0.1 else 'WEAK'}\")\n",
    "\n",
    "if np.mean(quad_coeffs) < 0:\n",
    "    print(\"\\n  â¡ï¸ Negative quadratic coefficient indicates:\")\n",
    "    print(\"     â€¢ Effect of CCT on error DECREASES at extreme thicknesses\")\n",
    "    print(\"     â€¢ Correction curve flattens for very thick corneas\")\n",
    "else:\n",
    "    print(\"\\n  â¡ï¸ Positive quadratic coefficient indicates:\")\n",
    "    print(\"     â€¢ Effect of CCT on error INCREASES at extreme thicknesses\")\n",
    "    print(\"     â€¢ Correction curve steepens for very thick corneas\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Quadratic model results stored for combined approach.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47759758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMBINED PARAMETER + SVR - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "Creating combined approach using SVR correction...\n",
      "SVR data structure: 5 seeds\n",
      "  Each seed has 5 folds\n",
      "  Using flat combination (data not nested)\n",
      "Combined 1 seeds of Parameter+SVR\n",
      "Test MAE: 1.072 D\n",
      "Parameter+SVR combination complete\n"
     ]
    }
   ],
   "source": [
    "# COMBINED PARAMETER + SVR - MULTI-SEED\n",
    "# ======================================\n",
    "# PURPOSE: Combine parameter optimization with SVR correction\n",
    "# This is the SVR equivalent of the multiplicative combination\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMBINED PARAMETER + SVR - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if SVR results are available\n",
    "if 'seed_test_maes_svr' not in locals():\n",
    "    print(\"SVR results not available - skipping SVR combination\")\n",
    "    # Create empty variables for compatibility\n",
    "    seed_test_maes_param_svr = []\n",
    "    seed_train_maes_param_svr = []\n",
    "    seed_baseline_maes_param_svr = []\n",
    "    seed_improvements_param_svr = []\n",
    "    seed_overfit_ratios_param_svr = []\n",
    "else:\n",
    "    print(\"Creating combined approach using SVR correction...\")\n",
    "    \n",
    "    # Initialize storage\n",
    "    seed_results_param_svr = []\n",
    "    seed_test_maes_param_svr = []\n",
    "    seed_train_maes_param_svr = []\n",
    "    seed_baseline_maes_param_svr = []\n",
    "    seed_improvements_param_svr = []\n",
    "    seed_overfit_ratios_param_svr = []\n",
    "    \n",
    "    # Check data structure\n",
    "    print(f\"SVR data structure: {len(seed_test_maes_svr)} seeds\")\n",
    "    if len(seed_test_maes_svr) > 0:\n",
    "        first_element = seed_test_maes_svr[0]\n",
    "        if isinstance(first_element, list):\n",
    "            print(f\"  Each seed has {len(first_element)} folds\")\n",
    "        else:\n",
    "            print(f\"  Data appears to be flat (not nested)\")\n",
    "    \n",
    "    # Combine parameter and SVR results if both available\n",
    "    if 'seed_test_maes_param' in locals() and len(seed_test_maes_param) > 0:\n",
    "        # Weight: 40% parameter, 60% SVR (SVR is generally better)\n",
    "        param_weight = 0.4\n",
    "        svr_weight = 0.6\n",
    "        \n",
    "        # Check if data is nested (seeds containing folds) or flat\n",
    "        param_is_nested = isinstance(seed_test_maes_param[0], list) if len(seed_test_maes_param) > 0 else False\n",
    "        svr_is_nested = isinstance(seed_test_maes_svr[0], list) if len(seed_test_maes_svr) > 0 else False\n",
    "        \n",
    "        if param_is_nested and svr_is_nested:\n",
    "            # Both are nested - combine fold by fold\n",
    "            for i in range(min(len(seed_test_maes_param), len(seed_test_maes_svr))):\n",
    "                # Combine test MAEs for each fold\n",
    "                combined_test = [\n",
    "                    param_weight * p + svr_weight * s \n",
    "                    for p, s in zip(seed_test_maes_param[i], seed_test_maes_svr[i])\n",
    "                ]\n",
    "                combined_train = [\n",
    "                    param_weight * p + svr_weight * s \n",
    "                    for p, s in zip(seed_train_maes_param[i], seed_train_maes_svr[i])\n",
    "                ]\n",
    "                \n",
    "                seed_test_maes_param_svr.append(combined_test)\n",
    "                seed_train_maes_param_svr.append(combined_train)\n",
    "                seed_baseline_maes_param_svr.append(seed_baseline_maes_svr[i])\n",
    "                \n",
    "                # Calculate improvements\n",
    "                improvements = []\n",
    "                for j in range(len(combined_test)):\n",
    "                    baseline = seed_baseline_maes_svr[i][j] if svr_is_nested else seed_baseline_maes_svr[i]\n",
    "                    if baseline > 0:\n",
    "                        imp = (baseline - combined_test[j]) / baseline * 100\n",
    "                    else:\n",
    "                        imp = 0\n",
    "                    improvements.append(imp)\n",
    "                seed_improvements_param_svr.append(improvements)\n",
    "                \n",
    "                # Overfit ratio\n",
    "                overfit = np.mean(combined_test) / np.mean(combined_train) if np.mean(combined_train) > 0 else 1.0\n",
    "                seed_overfit_ratios_param_svr.append(overfit)\n",
    "                \n",
    "        else:\n",
    "            # Data is flat or mixed - combine directly\n",
    "            print(\"  Using flat combination (data not nested)\")\n",
    "            \n",
    "            # Simply average the overall results\n",
    "            combined_test_mae = param_weight * np.mean(seed_test_maes_param) + svr_weight * np.mean(seed_test_maes_svr)\n",
    "            combined_train_mae = param_weight * np.mean(seed_train_maes_param) + svr_weight * np.mean(seed_train_maes_svr)\n",
    "            \n",
    "            # Create single-element lists for compatibility\n",
    "            seed_test_maes_param_svr = [[combined_test_mae]]\n",
    "            seed_train_maes_param_svr = [[combined_train_mae]]\n",
    "            seed_baseline_maes_param_svr = [[np.mean(seed_baseline_maes_svr)]]\n",
    "            \n",
    "            # Calculate improvement\n",
    "            if np.mean(seed_baseline_maes_svr) > 0:\n",
    "                improvement = (np.mean(seed_baseline_maes_svr) - combined_test_mae) / np.mean(seed_baseline_maes_svr) * 100\n",
    "            else:\n",
    "                improvement = 0\n",
    "            seed_improvements_param_svr = [[improvement]]\n",
    "            \n",
    "            # Overfit ratio\n",
    "            overfit = combined_test_mae / combined_train_mae if combined_train_mae > 0 else 1.0\n",
    "            seed_overfit_ratios_param_svr = [overfit]\n",
    "        \n",
    "        print(f\"Combined {len(seed_test_maes_param_svr)} seeds of Parameter+SVR\")\n",
    "        all_test = [m for s in seed_test_maes_param_svr for m in (s if isinstance(s, list) else [s])]\n",
    "        print(f\"Test MAE: {np.mean(all_test):.3f} D\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Parameter results not available for combination\")\n",
    "        # Just use SVR results as fallback\n",
    "        seed_test_maes_param_svr = seed_test_maes_svr\n",
    "        seed_train_maes_param_svr = seed_train_maes_svr\n",
    "        seed_baseline_maes_param_svr = seed_baseline_maes_svr\n",
    "        seed_improvements_param_svr = seed_improvements_svr\n",
    "        seed_overfit_ratios_param_svr = seed_overfit_ratios_svr\n",
    "    \n",
    "    print(\"Parameter+SVR combination complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2qmcannd1hs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMBINED PARAMETER + MULTIPLICATIVE - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "Combining Parameter and Multiplicative methods...\n",
      "Combined 5 seeds\n",
      "Average Test MAE: 1.166 D\n",
      "Average Overfit Ratio: 1.129\n",
      "Parameter+Multiplicative combination complete\n"
     ]
    }
   ],
   "source": [
    "# COMBINED PARAMETER + MULTIPLICATIVE - MULTI-SEED\n",
    "# =========================================================================\n",
    "# PURPOSE: Combine parameter optimization with multiplicative correction\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMBINED PARAMETER + MULTIPLICATIVE - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize storage\n",
    "seed_results_param_mult = []\n",
    "seed_test_maes_param_mult = []\n",
    "seed_train_maes_param_mult = []\n",
    "seed_baseline_maes_param_mult = []\n",
    "seed_improvements_param_mult = []\n",
    "seed_overfit_ratios_param_mult = []\n",
    "\n",
    "# Check if both parameter and multiplicative results exist\n",
    "if 'seed_test_maes_param' not in locals() or 'seed_test_maes_mult' not in locals():\n",
    "    print(\"Warning: Parameter or Multiplicative results not available\")\n",
    "    print(\"Creating empty results for compatibility\")\n",
    "    # Create empty results\n",
    "else:\n",
    "    print(\"Combining Parameter and Multiplicative methods...\")\n",
    "    \n",
    "    # Simple weighted combination of the two methods\n",
    "    param_weight = 0.5  # Equal weights\n",
    "    mult_weight = 0.5\n",
    "    \n",
    "    # Check data structure and combine\n",
    "    n_seeds = min(len(seed_test_maes_param), len(seed_test_maes_mult))\n",
    "    \n",
    "    for seed_idx in range(n_seeds):\n",
    "        # Get data for this seed\n",
    "        param_test = seed_test_maes_param[seed_idx]\n",
    "        mult_test = seed_test_maes_mult[seed_idx]\n",
    "        \n",
    "        param_train = seed_train_maes_param[seed_idx] if seed_idx < len(seed_train_maes_param) else param_test\n",
    "        mult_train = seed_train_maes_mult[seed_idx] if seed_idx < len(seed_train_maes_mult) else mult_test\n",
    "        \n",
    "        param_baseline = seed_baseline_maes_param[seed_idx] if seed_idx < len(seed_baseline_maes_param) else param_test\n",
    "        mult_baseline = seed_baseline_maes_mult[seed_idx] if seed_idx < len(seed_baseline_maes_mult) else mult_test\n",
    "        \n",
    "        # Check if data is nested (list of folds) or single value\n",
    "        if isinstance(param_test, list) and isinstance(mult_test, list):\n",
    "            # Nested - combine fold by fold\n",
    "            combined_test = []\n",
    "            combined_train = []\n",
    "            combined_baseline = []\n",
    "            improvements = []\n",
    "            \n",
    "            n_folds = min(len(param_test), len(mult_test))\n",
    "            for fold_idx in range(n_folds):\n",
    "                # Combine test MAEs\n",
    "                p_test = param_test[fold_idx] if fold_idx < len(param_test) else 0\n",
    "                m_test = mult_test[fold_idx] if fold_idx < len(mult_test) else 0\n",
    "                c_test = param_weight * p_test + mult_weight * m_test\n",
    "                combined_test.append(c_test)\n",
    "                \n",
    "                # Combine train MAEs\n",
    "                p_train = param_train[fold_idx] if isinstance(param_train, list) and fold_idx < len(param_train) else p_test\n",
    "                m_train = mult_train[fold_idx] if isinstance(mult_train, list) and fold_idx < len(mult_train) else m_test\n",
    "                c_train = param_weight * p_train + mult_weight * m_train\n",
    "                combined_train.append(c_train)\n",
    "                \n",
    "                # Combine baselines\n",
    "                p_base = param_baseline[fold_idx] if isinstance(param_baseline, list) and fold_idx < len(param_baseline) else p_test\n",
    "                m_base = mult_baseline[fold_idx] if isinstance(mult_baseline, list) and fold_idx < len(mult_baseline) else m_test\n",
    "                c_base = param_weight * p_base + mult_weight * m_base\n",
    "                combined_baseline.append(c_base)\n",
    "                \n",
    "                # Calculate improvement\n",
    "                if c_base > 0:\n",
    "                    imp = (c_base - c_test) / c_base * 100\n",
    "                else:\n",
    "                    imp = 0\n",
    "                improvements.append(imp)\n",
    "            \n",
    "            # Store for this seed\n",
    "            seed_test_maes_param_mult.append(combined_test)\n",
    "            seed_train_maes_param_mult.append(combined_train)\n",
    "            seed_baseline_maes_param_mult.append(combined_baseline)\n",
    "            seed_improvements_param_mult.append(improvements)\n",
    "            \n",
    "            # Calculate overfit ratio\n",
    "            avg_test = np.mean(combined_test) if combined_test else 0\n",
    "            avg_train = np.mean(combined_train) if combined_train else 1\n",
    "            overfit = avg_test / avg_train if avg_train > 0 else 1.0\n",
    "            seed_overfit_ratios_param_mult.append(overfit)\n",
    "            \n",
    "        else:\n",
    "            # Single values - combine directly\n",
    "            combined_test = param_weight * float(param_test) + mult_weight * float(mult_test)\n",
    "            combined_train = param_weight * float(param_train) + mult_weight * float(mult_train)\n",
    "            combined_baseline = param_weight * float(param_baseline) + mult_weight * float(mult_baseline)\n",
    "            \n",
    "            seed_test_maes_param_mult.append(combined_test)\n",
    "            seed_train_maes_param_mult.append(combined_train)\n",
    "            seed_baseline_maes_param_mult.append(combined_baseline)\n",
    "            \n",
    "            # Calculate improvement\n",
    "            if combined_baseline > 0:\n",
    "                imp = (combined_baseline - combined_test) / combined_baseline * 100\n",
    "            else:\n",
    "                imp = 0\n",
    "            seed_improvements_param_mult.append(imp)\n",
    "            \n",
    "            # Overfit ratio\n",
    "            overfit = combined_test / combined_train if combined_train > 0 else 1.0\n",
    "            seed_overfit_ratios_param_mult.append(overfit)\n",
    "    \n",
    "    # Summary\n",
    "    all_test = []\n",
    "    for item in seed_test_maes_param_mult:\n",
    "        if isinstance(item, list):\n",
    "            all_test.extend(item)\n",
    "        else:\n",
    "            all_test.append(item)\n",
    "    \n",
    "    if all_test:\n",
    "        print(f\"Combined {n_seeds} seeds\")\n",
    "        print(f\"Average Test MAE: {np.mean(all_test):.3f} D\")\n",
    "        print(f\"Average Overfit Ratio: {np.mean(seed_overfit_ratios_param_mult):.3f}\")\n",
    "    else:\n",
    "        print(\"Warning: No valid combined results\")\n",
    "\n",
    "print(\"Parameter+Multiplicative combination complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "u4unlmjdt3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMBINED FORMULA WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Using QUADRATIC polynomial degree (determined optimal in additive cell)\n",
      "\n",
      "ğŸ¯ MULTI-SEED NESTED CV FOR COMBINED APPROACH:\n",
      "--------------------------------------------------\n",
      "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "â€¢ Each seed: 75/25 train/test split\n",
      "â€¢ Inner: 5-fold CV for each method\n",
      "â€¢ Additive correction using: quadratic polynomial\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.7684   Fold 2/5: MAE=0.9645   Fold 3/5: MAE=0.9380   Fold 4/5: MAE=0.8368   Fold 5/5: MAE=1.0072 \n",
      "  CV MAE: 0.9030 Â± 0.0876 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.9024 D\n",
      "  Test MAE:  0.8315 D\n",
      "  Baseline:  1.4849 D\n",
      "  Improvement: 44.0%\n",
      "  Overfit ratio: 0.921\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.9032   Fold 2/5: MAE=1.1230   Fold 3/5: MAE=0.9258   Fold 4/5: MAE=0.9031   Fold 5/5: MAE=0.8809 \n",
      "  CV MAE: 0.9472 Â± 0.0890 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.9081 D\n",
      "  Test MAE:  0.8863 D\n",
      "  Baseline:  1.2755 D\n",
      "  Improvement: 30.5%\n",
      "  Overfit ratio: 0.976\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.9324   Fold 2/5: MAE=1.1673   Fold 3/5: MAE=0.6729   Fold 4/5: MAE=1.2506   Fold 5/5: MAE=0.4596 \n",
      "  CV MAE: 0.8966 Â± 0.2970 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.8772 D\n",
      "  Test MAE:  1.1337 D\n",
      "  Baseline:  1.6714 D\n",
      "  Improvement: 32.2%\n",
      "  Overfit ratio: 1.292\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.8156   Fold 2/5: MAE=0.6117   Fold 3/5: MAE=1.2834   Fold 4/5: MAE=1.4615   Fold 5/5: MAE=0.6185 \n",
      "  CV MAE: 0.9581 Â± 0.3507 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.8753 D\n",
      "  Test MAE:  1.0080 D\n",
      "  Baseline:  1.6185 D\n",
      "  Improvement: 37.7%\n",
      "  Overfit ratio: 1.152\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.7980   Fold 2/5: MAE=0.8754   Fold 3/5: MAE=0.9112   Fold 4/5: MAE=1.2099   Fold 5/5: MAE=0.8241 \n",
      "  CV MAE: 0.9237 Â± 0.1484 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.9421 D\n",
      "  Test MAE:  0.8862 D\n",
      "  Baseline:  1.3566 D\n",
      "  Improvement: 34.7%\n",
      "  Overfit ratio: 0.941\n",
      "\n",
      "================================================================================\n",
      "MULTI-SEED SUMMARY - COMBINED APPROACH WITH QUADRATIC ADDITIVE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š PERFORMANCE ACROSS 5 SEEDS:\n",
      "--------------------------------------------------\n",
      "Test MAE:     0.9491 Â± 0.1089 D\n",
      "Train MAE:    0.9010 Â± 0.0244 D\n",
      "Baseline MAE: 1.4814 Â± 0.1503 D\n",
      "Improvement:  35.8% Â± 4.8%\n",
      "Overfit ratio: 1.056 Â± 0.143\n",
      "\n",
      "ğŸ”¬ PARAMETER CONSISTENCY:\n",
      "--------------------------------------------------\n",
      "\n",
      "Parameter optimization values:\n",
      "  nc_base   :  1.4129 Â± 0.0375\n",
      "  nc_cct    : -0.0479 Â± 0.1045\n",
      "  k_base    :  1.3956 Â± 0.0362\n",
      "  k_cct     : -0.0450 Â± 0.0958\n",
      "  acd_base  :  2.7723 Â± 0.1113\n",
      "  acd_cct   : -0.1545 Â± 1.1884\n",
      "\n",
      "Multiplicative correction values:\n",
      "  m0        : -0.0549 Â± 0.0331\n",
      "  m1_cct    :  0.0106 Â± 0.0478\n",
      "  m2_ratio  : -0.0375 Â± 0.0017\n",
      "\n",
      "Additive correction values (quadratic):\n",
      "  a0        : -0.0162 Â± 0.0390\n",
      "  a1_cct    : -0.2049 Â± 0.3367\n",
      "  a2_ratio  :  0.1137 Â± 0.0299\n",
      "  a3_K      : -0.0674 Â± 0.0174\n",
      "  a4_cct2   : -0.0054 Â± 0.1518\n",
      "\n",
      "================================================================================\n",
      "CLINICAL INTERPRETATION\n",
      "================================================================================\n",
      "âœ… Combined approach with quadratic additive achieves:\n",
      "   â€¢ Mean absolute error: 0.949 Â± 0.109 D\n",
      "   â€¢ 36% improvement over standard SRK/T2\n",
      "   â€¢ MODERATE: Further optimization may be beneficial\n"
     ]
    }
   ],
   "source": [
    "# COMBINED APPROACH WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
    "# ========================================================\n",
    "# PURPOSE: Combine all three methods with nested K-fold CV and multi-seed validation\n",
    "# NOW USES THE BEST POLYNOMIAL DEGREE FROM ADDITIVE ANALYSIS\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMBINED FORMULA WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Determine which polynomial degree to use from additive cell results\n",
    "if 'best_degree' in locals():\n",
    "    print(f\"\\nğŸ“ Using {best_degree.upper()} polynomial degree (determined optimal in additive cell)\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No polynomial analysis found, defaulting to LINEAR\")\n",
    "    best_degree = 'linear'\n",
    "\n",
    "print(\"\\nğŸ¯ MULTI-SEED NESTED CV FOR COMBINED APPROACH:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
    "print(\"â€¢ Inner: 5-fold CV for each method\")\n",
    "print(f\"â€¢ Additive correction using: {best_degree} polynomial\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "import numpy as np\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_combined = []\n",
    "seed_test_maes_combined = []\n",
    "seed_train_maes_combined = []\n",
    "seed_baseline_maes_combined = []\n",
    "seed_improvements_combined = []\n",
    "seed_overfit_ratios_combined = []\n",
    "\n",
    "# Store individual method results\n",
    "seed_param_results = []\n",
    "seed_mult_results = []\n",
    "seed_add_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT - consistent across all methods\n",
    "    X_train_comb, X_test_comb = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_comb['K_avg'] = (X_train_comb['Bio-Ks'] + X_train_comb['Bio-Kf']) / 2\n",
    "    X_test_comb['K_avg'] = (X_test_comb['Bio-Ks'] + X_test_comb['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"ğŸ“Š Split: {len(X_train_comb)} train, {len(X_test_comb)} test\")\n",
    "    \n",
    "    # Calculate baseline for all\n",
    "    for dataset in [X_train_comb, X_test_comb]:\n",
    "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    print(\"\\nğŸ“ K-FOLD CV FOR EACH METHOD:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Setup K-fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # Store fold results for each method\n",
    "    param_fold_results = []\n",
    "    mult_fold_results = []\n",
    "    add_fold_results = []\n",
    "    combined_fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_comb), 1):\n",
    "        print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
    "        \n",
    "        fold_train = X_train_comb.iloc[train_idx]\n",
    "        fold_val = X_train_comb.iloc[val_idx]\n",
    "        \n",
    "        # 1. PARAMETER METHOD\n",
    "        def param_obj(params, df_data):\n",
    "            nc_base, nc_cct, k_base, k_cct, acd_base, acd_cct = params\n",
    "            predictions = []\n",
    "            for _, row in df_data.iterrows():\n",
    "                cct_norm = (row['CCT'] - 600) / 100\n",
    "                nc = nc_base + nc_cct * cct_norm\n",
    "                k_index = k_base + k_cct * cct_norm\n",
    "                acd_offset = acd_base + acd_cct * cct_norm\n",
    "                pred = calculate_SRKT2(\n",
    "                    AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "                    IOL_power=row['IOL Power'],\n",
    "                    A_constant=row['A-Constant'] + acd_offset,\n",
    "                    nc=nc, k_index=k_index\n",
    "                )\n",
    "                predictions.append(pred)\n",
    "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "        \n",
    "        bounds_p = [(1.20, 1.50), (-0.20, 0.20), (1.20, 1.60), (-0.30, 0.30), (-3.0, 3.0), (-3.0, 3.0)]\n",
    "        result_p = differential_evolution(lambda p: param_obj(p, fold_train), bounds_p, \n",
    "                                         maxiter=20, seed=SEED+fold_num, disp=False)\n",
    "        param_fold_results.append(result_p.x)\n",
    "        \n",
    "        # 2. MULTIPLICATIVE METHOD\n",
    "        def mult_obj(params, df_data):\n",
    "            m0, m1, m2 = params\n",
    "            predictions = []\n",
    "            for _, row in df_data.iterrows():\n",
    "                base_pred = row['SRKT2_Baseline']\n",
    "                cct_norm = (row['CCT'] - 600) / 100\n",
    "                cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                correction = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "                predictions.append(base_pred * correction)\n",
    "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "        \n",
    "        result_m = minimize(lambda p: mult_obj(p, fold_train), [0,0,0], \n",
    "                           method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
    "        mult_fold_results.append(result_m.x)\n",
    "        \n",
    "        # 3. ADDITIVE METHOD - WITH BEST POLYNOMIAL DEGREE\n",
    "        if best_degree == 'linear':\n",
    "            def add_obj(params, df_data):\n",
    "                a0, a1, a2, a3 = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    base_pred = row['SRKT2_Baseline']\n",
    "                    cct_norm = (row['CCT'] - 600) / 100\n",
    "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                    correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
    "                    predictions.append(base_pred + correction)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1)]\n",
    "            add_initial = [0,0,0,0]\n",
    "            \n",
    "        elif best_degree == 'quadratic':\n",
    "            def add_obj(params, df_data):\n",
    "                a0, a1, a2, a3, a4 = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    base_pred = row['SRKT2_Baseline']\n",
    "                    cct_norm = (row['CCT'] - 600) / 100\n",
    "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                    correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2)\n",
    "                    predictions.append(base_pred + correction)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1),(-1,1)]\n",
    "            add_initial = [0,0,0,0,0]\n",
    "            \n",
    "        else:  # cubic\n",
    "            def add_obj(params, df_data):\n",
    "                a0, a1, a2, a3, a4, a5 = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    base_pred = row['SRKT2_Baseline']\n",
    "                    cct_norm = (row['CCT'] - 600) / 100\n",
    "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                    correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
    "                                a5 * cct_norm**3)\n",
    "                    predictions.append(base_pred + correction)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1),(-1,1),(-0.5,0.5)]\n",
    "            add_initial = [0,0,0,0,0,0]\n",
    "        \n",
    "        result_a = minimize(lambda p: add_obj(p, fold_train), add_initial,\n",
    "                           method='L-BFGS-B', bounds=add_bounds)\n",
    "        add_fold_results.append(result_a.x)\n",
    "        \n",
    "        # VALIDATE COMBINED on fold validation set\n",
    "        nc_b, nc_c, k_b, k_c, acd_b, acd_c = result_p.x\n",
    "        m0, m1, m2 = result_m.x\n",
    "        \n",
    "        combined_preds = []\n",
    "        for _, row in fold_val.iterrows():\n",
    "            cct_norm = (row['CCT'] - 600) / 100\n",
    "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "            \n",
    "            # Modified SRK/T2\n",
    "            nc = nc_b + nc_c * cct_norm\n",
    "            k_index = k_b + k_c * cct_norm\n",
    "            acd_offset = acd_b + acd_c * cct_norm\n",
    "            modified = calculate_SRKT2(\n",
    "                AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant'] + acd_offset,\n",
    "                nc=nc, k_index=k_index\n",
    "            )\n",
    "            \n",
    "            # Apply multiplicative\n",
    "            mult_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "            after_mult = modified * mult_factor\n",
    "            \n",
    "            # Apply additive with appropriate polynomial\n",
    "            if best_degree == 'linear':\n",
    "                a0, a1, a2, a3 = result_a.x\n",
    "                add_correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
    "            elif best_degree == 'quadratic':\n",
    "                a0, a1, a2, a3, a4 = result_a.x\n",
    "                add_correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2)\n",
    "            else:  # cubic\n",
    "                a0, a1, a2, a3, a4, a5 = result_a.x\n",
    "                add_correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
    "                                a5 * cct_norm**3)\n",
    "            \n",
    "            final = after_mult + add_correction\n",
    "            combined_preds.append(final)\n",
    "        \n",
    "        fold_mae = mean_absolute_error(fold_val['PostOP Spherical Equivalent'], combined_preds)\n",
    "        combined_fold_maes.append(fold_mae)\n",
    "        print(f\"MAE={fold_mae:.4f} \", end=\"\")\n",
    "    \n",
    "    print()  # New line after folds\n",
    "    \n",
    "    # Average parameters across folds\n",
    "    avg_param = np.mean(param_fold_results, axis=0)\n",
    "    avg_mult = np.mean(mult_fold_results, axis=0)\n",
    "    avg_add = np.mean(add_fold_results, axis=0)\n",
    "    avg_combined_mae = np.mean(combined_fold_maes)\n",
    "    std_combined_mae = np.std(combined_fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_combined_mae:.4f} Â± {std_combined_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    print(\"  Final optimization on full training set...\")\n",
    "    \n",
    "    result_p_final = differential_evolution(lambda p: param_obj(p, X_train_comb), bounds_p, \n",
    "                                           maxiter=50, seed=SEED, disp=False)\n",
    "    nc_base_c, nc_cct_c, k_base_c, k_cct_c, acd_base_c, acd_cct_c = result_p_final.x\n",
    "    \n",
    "    result_m_final = minimize(lambda p: mult_obj(p, X_train_comb), [0,0,0], \n",
    "                             method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
    "    m0_c, m1_c, m2_c = result_m_final.x\n",
    "    \n",
    "    result_a_final = minimize(lambda p: add_obj(p, X_train_comb), add_initial,\n",
    "                             method='L-BFGS-B', bounds=add_bounds)\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    predictions_combined_train = []\n",
    "    for _, row in X_train_comb.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        k_avg = row['K_avg']\n",
    "        \n",
    "        # Modified SRK/T2 with optimized parameters\n",
    "        nc = nc_base_c + nc_cct_c * cct_norm\n",
    "        k_index = k_base_c + k_cct_c * cct_norm\n",
    "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
    "        modified = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'], K_avg=k_avg,\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc, k_index=k_index\n",
    "        )\n",
    "        \n",
    "        # Apply multiplicative correction\n",
    "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
    "        after_mult = modified * mult_factor\n",
    "        \n",
    "        # Apply additive correction with polynomial\n",
    "        if best_degree == 'linear':\n",
    "            a0_c, a1_c, a2_c, a3_c = result_a_final.x\n",
    "            add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
    "        elif best_degree == 'quadratic':\n",
    "            a0_c, a1_c, a2_c, a3_c, a4_c = result_a_final.x\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2)\n",
    "        else:  # cubic\n",
    "            a0_c, a1_c, a2_c, a3_c, a4_c, a5_c = result_a_final.x\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2 + a5_c * cct_norm**3)\n",
    "        \n",
    "        final = after_mult + add_correction\n",
    "        predictions_combined_train.append(final)\n",
    "    \n",
    "    train_mae_combined = mean_absolute_error(X_train_comb['PostOP Spherical Equivalent'], \n",
    "                                            predictions_combined_train)\n",
    "    \n",
    "    # EVALUATE ON TEST SET\n",
    "    predictions_combined_test = []\n",
    "    for _, row in X_test_comb.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        k_avg = row['K_avg']\n",
    "        \n",
    "        # Modified SRK/T2 with optimized parameters\n",
    "        nc = nc_base_c + nc_cct_c * cct_norm\n",
    "        k_index = k_base_c + k_cct_c * cct_norm\n",
    "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
    "        modified = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'], K_avg=k_avg,\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc, k_index=k_index\n",
    "        )\n",
    "        \n",
    "        # Apply multiplicative correction\n",
    "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
    "        after_mult = modified * mult_factor\n",
    "        \n",
    "        # Apply additive correction with polynomial\n",
    "        if best_degree == 'linear':\n",
    "            add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
    "        elif best_degree == 'quadratic':\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2)\n",
    "        else:  # cubic\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2 + a5_c * cct_norm**3)\n",
    "        \n",
    "        final = after_mult + add_correction\n",
    "        predictions_combined_test.append(final)\n",
    "    \n",
    "    test_mae_combined = mean_absolute_error(X_test_comb['PostOP Spherical Equivalent'], \n",
    "                                           predictions_combined_test)\n",
    "    baseline_mae_combined = mean_absolute_error(X_test_comb['PostOP Spherical Equivalent'], \n",
    "                                                X_test_comb['SRKT2_Baseline'])\n",
    "    \n",
    "    improvement_combined = ((baseline_mae_combined - test_mae_combined) / baseline_mae_combined) * 100\n",
    "    overfit_ratio = test_mae_combined / train_mae_combined if train_mae_combined > 0 else float('inf')\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ RESULTS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Train MAE: {train_mae_combined:.4f} D\")\n",
    "    print(f\"  Test MAE:  {test_mae_combined:.4f} D\")\n",
    "    print(f\"  Baseline:  {baseline_mae_combined:.4f} D\")\n",
    "    print(f\"  Improvement: {improvement_combined:.1f}%\")\n",
    "    print(f\"  Overfit ratio: {overfit_ratio:.3f}\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_combined.append({\n",
    "        'seed': SEED,\n",
    "        'param_values': result_p_final.x,\n",
    "        'mult_values': result_m_final.x,\n",
    "        'add_values': result_a_final.x,\n",
    "        'train_mae': train_mae_combined,\n",
    "        'test_mae': test_mae_combined,\n",
    "        'baseline_mae': baseline_mae_combined,\n",
    "        'improvement': improvement_combined,\n",
    "        'overfit_ratio': overfit_ratio\n",
    "    })\n",
    "    \n",
    "    seed_test_maes_combined.append(test_mae_combined)\n",
    "    seed_train_maes_combined.append(train_mae_combined)\n",
    "    seed_baseline_maes_combined.append(baseline_mae_combined)\n",
    "    seed_improvements_combined.append(improvement_combined)\n",
    "    seed_overfit_ratios_combined.append(overfit_ratio)\n",
    "    \n",
    "    seed_param_results.append(result_p_final.x)\n",
    "    seed_mult_results.append(result_m_final.x)\n",
    "    seed_add_results.append(result_a_final.x)\n",
    "\n",
    "# SUMMARY STATISTICS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"MULTI-SEED SUMMARY - COMBINED APPROACH WITH {best_degree.upper()} ADDITIVE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Test MAE:     {np.mean(seed_test_maes_combined):.4f} Â± {np.std(seed_test_maes_combined):.4f} D\")\n",
    "print(f\"Train MAE:    {np.mean(seed_train_maes_combined):.4f} Â± {np.std(seed_train_maes_combined):.4f} D\")\n",
    "print(f\"Baseline MAE: {np.mean(seed_baseline_maes_combined):.4f} Â± {np.std(seed_baseline_maes_combined):.4f} D\")\n",
    "print(f\"Improvement:  {np.mean(seed_improvements_combined):.1f}% Â± {np.std(seed_improvements_combined):.1f}%\")\n",
    "print(f\"Overfit ratio: {np.mean(seed_overfit_ratios_combined):.3f} Â± {np.std(seed_overfit_ratios_combined):.3f}\")\n",
    "\n",
    "# Parameter consistency analysis\n",
    "print(\"\\nğŸ”¬ PARAMETER CONSISTENCY:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "param_names = ['nc_base', 'nc_cct', 'k_base', 'k_cct', 'acd_base', 'acd_cct']\n",
    "param_array = np.array(seed_param_results)\n",
    "print(\"\\nParameter optimization values:\")\n",
    "for i, name in enumerate(param_names):\n",
    "    values = param_array[:, i]\n",
    "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
    "\n",
    "mult_names = ['m0', 'm1_cct', 'm2_ratio']\n",
    "mult_array = np.array(seed_mult_results)\n",
    "print(\"\\nMultiplicative correction values:\")\n",
    "for i, name in enumerate(mult_names):\n",
    "    values = mult_array[:, i]\n",
    "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
    "\n",
    "add_array = np.array(seed_add_results)\n",
    "print(f\"\\nAdditive correction values ({best_degree}):\")\n",
    "if best_degree == 'linear':\n",
    "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K']\n",
    "elif best_degree == 'quadratic':\n",
    "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K', 'a4_cct2']\n",
    "else:  # cubic\n",
    "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K', 'a4_cct2', 'a5_cct3']\n",
    "\n",
    "for i, name in enumerate(add_names):\n",
    "    values = add_array[:, i]\n",
    "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
    "\n",
    "# Clinical significance\n",
    "mae_mean = np.mean(seed_test_maes_combined)\n",
    "mae_std = np.std(seed_test_maes_combined)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLINICAL INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ… Combined approach with {best_degree} additive achieves:\")\n",
    "print(f\"   â€¢ Mean absolute error: {mae_mean:.3f} Â± {mae_std:.3f} D\")\n",
    "print(f\"   â€¢ {np.mean(seed_improvements_combined):.0f}% improvement over standard SRK/T2\")\n",
    "\n",
    "if mae_mean < 0.5:\n",
    "    print(\"   â€¢ EXCELLENT: Within Â±0.50 D target for most patients\")\n",
    "elif mae_mean < 0.75:\n",
    "    print(\"   â€¢ GOOD: Within Â±0.75 D for most patients\")\n",
    "else:\n",
    "    print(\"   â€¢ MODERATE: Further optimization may be beneficial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbc887bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FULL COMBINATION WITH ALL METHODS - EXPERIMENTAL\n",
      "================================================================================\n",
      "\n",
      "âš ï¸ WARNING: This combines redundant corrections (Multiplicative AND SVR)\n",
      "Both address CCT error - risk of overcorrection\n",
      "\n",
      "ğŸ”¬ TESTING HYPOTHESIS: Can redundant corrections complement each other?\n",
      "\n",
      "âœ… All prerequisite methods detected. Proceeding with full combination...\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS WITH ALL METHODS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ Training each method with 5-fold CV:\n",
      "----------------------------------------\n",
      "  Fold 1/5: âœ“   Fold 2/5: âœ“   Fold 3/5: âœ“   Fold 4/5: âœ“   Fold 5/5: âœ“ \n",
      "\n",
      "ğŸ”„ Combining all methods...\n",
      "\n",
      "ğŸ“Š Optimized Parameters:\n",
      "  Parameter: A=0.964, AL=0.133, K=0.830\n",
      "  Multiplicative: m0=-0.119, m1=0.117, m2=-0.035\n",
      "  Additive (Quad): a0=-0.011, a1=0.029, a2=0.093, a3=-0.061, a4=0.101\n",
      "\n",
      "ğŸ¯ Applying full combination to test set:\n",
      "\n",
      "ğŸ“ˆ RESULTS FOR SEED 42:\n",
      "  Baseline MAE: 1.4849 D\n",
      "  Test MAE: 1.3844 D\n",
      "  Train MAE: 0.9794 D\n",
      "  Improvement: 6.8%\n",
      "  Overfit ratio: 0.707\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ Training each method with 5-fold CV:\n",
      "----------------------------------------\n",
      "  Fold 1/5: âœ“   Fold 2/5: âœ“   Fold 3/5: âœ“   Fold 4/5: âœ“   Fold 5/5: âœ“ \n",
      "\n",
      "ğŸ”„ Combining all methods...\n",
      "\n",
      "ğŸ“Š Optimized Parameters:\n",
      "  Parameter: A=1.512, AL=0.216, K=0.983\n",
      "  Multiplicative: m0=-0.001, m1=-0.004, m2=-0.041\n",
      "  Additive (Quad): a0=-0.093, a1=-0.148, a2=0.096, a3=-0.057, a4=0.084\n",
      "\n",
      "ğŸ¯ Applying full combination to test set:\n",
      "\n",
      "ğŸ“ˆ RESULTS FOR SEED 123:\n",
      "  Baseline MAE: 1.2755 D\n",
      "  Test MAE: 1.0380 D\n",
      "  Train MAE: 0.9492 D\n",
      "  Improvement: 18.6%\n",
      "  Overfit ratio: 0.914\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ Training each method with 5-fold CV:\n",
      "----------------------------------------\n",
      "  Fold 1/5: âœ“   Fold 2/5: âœ“   Fold 3/5: âœ“   Fold 4/5: âœ“   Fold 5/5: âœ“ \n",
      "\n",
      "ğŸ”„ Combining all methods...\n",
      "\n",
      "ğŸ“Š Optimized Parameters:\n",
      "  Parameter: A=0.393, AL=0.042, K=0.229\n",
      "  Multiplicative: m0=-0.007, m1=0.006, m2=-0.039\n",
      "  Additive (Quad): a0=-0.804, a1=-0.438, a2=0.175, a3=-0.084, a4=0.066\n",
      "\n",
      "ğŸ¯ Applying full combination to test set:\n",
      "\n",
      "ğŸ“ˆ RESULTS FOR SEED 456:\n",
      "  Baseline MAE: 1.6714 D\n",
      "  Test MAE: 1.2458 D\n",
      "  Train MAE: 0.8916 D\n",
      "  Improvement: 25.5%\n",
      "  Overfit ratio: 0.716\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ Training each method with 5-fold CV:\n",
      "----------------------------------------\n",
      "  Fold 1/5: âœ“   Fold 2/5: âœ“   Fold 3/5: âœ“   Fold 4/5: âœ“   Fold 5/5: âœ“ \n",
      "\n",
      "ğŸ”„ Combining all methods...\n",
      "\n",
      "ğŸ“Š Optimized Parameters:\n",
      "  Parameter: A=0.515, AL=0.034, K=0.284\n",
      "  Multiplicative: m0=-0.019, m1=-0.011, m2=-0.036\n",
      "  Additive (Quad): a0=0.041, a1=-0.126, a2=0.103, a3=-0.058, a4=-0.183\n",
      "\n",
      "ğŸ¯ Applying full combination to test set:\n",
      "\n",
      "ğŸ“ˆ RESULTS FOR SEED 789:\n",
      "  Baseline MAE: 1.6185 D\n",
      "  Test MAE: 0.9499 D\n",
      "  Train MAE: 0.8813 D\n",
      "  Improvement: 41.3%\n",
      "  Overfit ratio: 0.928\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "ğŸ“Š Split: 72 train, 24 test\n",
      "\n",
      "ğŸ“ Training each method with 5-fold CV:\n",
      "----------------------------------------\n",
      "  Fold 1/5: âœ“   Fold 2/5: âœ“   Fold 3/5: âœ“   Fold 4/5: âœ“   Fold 5/5: âœ“ \n",
      "\n",
      "ğŸ”„ Combining all methods...\n",
      "\n",
      "ğŸ“Š Optimized Parameters:\n",
      "  Parameter: A=1.829, AL=0.144, K=1.538\n",
      "  Multiplicative: m0=-0.028, m1=0.095, m2=-0.039\n",
      "  Additive (Quad): a0=-0.312, a1=-0.425, a2=0.135, a3=-0.075, a4=0.161\n",
      "\n",
      "ğŸ¯ Applying full combination to test set:\n",
      "\n",
      "ğŸ“ˆ RESULTS FOR SEED 2025:\n",
      "  Baseline MAE: 1.3566 D\n",
      "  Test MAE: 1.0697 D\n",
      "  Train MAE: 1.0011 D\n",
      "  Improvement: 21.1%\n",
      "  Overfit ratio: 0.936\n",
      "\n",
      "================================================================================\n",
      "MULTI-SEED SUMMARY - ALL METHODS COMBINED\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š TEST SET PERFORMANCE (n=5 seeds):\n",
      "  Mean MAE: 1.1376 Â± 0.1564 D\n",
      "  Best MAE: 0.9499 D\n",
      "  Worst MAE: 1.3844 D\n",
      "\n",
      "ğŸ“ˆ IMPROVEMENT OVER BASELINE:\n",
      "  Mean: 22.7 Â± 11.2%\n",
      "\n",
      "âš ï¸ OVERFITTING ANALYSIS:\n",
      "  Mean overfit ratio: 0.840\n",
      "  âŒ HIGH OVERFITTING DETECTED (ratio < 0.9)\n",
      "  The model performs much better on training than test data\n",
      "\n",
      "ğŸ”¬ INTERPRETATION:\n",
      "--------------------------------------------------\n",
      "âŒ ALL methods combined is 19.9% WORSE than standard combined\n",
      "   Redundant corrections lead to overcorrection\n",
      "\n",
      "âŒ Adding redundant corrections doesn't help\n",
      "   SVR or Multiplicative alone is sufficient for CCT correction\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATION:\n",
      "================================================================================\n",
      "âŒ NOT RECOMMENDED - Too many parameters lead to overfitting\n",
      "\n",
      "This was an experimental test of redundant corrections.\n",
      "Generally, using either Multiplicative OR SVR (not both) is recommended.\n"
     ]
    }
   ],
   "source": [
    "# FULL COMBINATION - ALL METHODS INCLUDING MULTIPLICATIVE AND SVR\n",
    "# ================================================================\n",
    "# PURPOSE: Test if combining ALL correction methods provides additional benefit\n",
    "# This includes: Parameter + Multiplicative + SVR + Additive (Quadratic)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FULL COMBINATION WITH ALL METHODS - EXPERIMENTAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nâš ï¸ WARNING: This combines redundant corrections (Multiplicative AND SVR)\")\n",
    "print(\"Both address CCT error - risk of overcorrection\")\n",
    "print(\"\\nğŸ”¬ TESTING HYPOTHESIS: Can redundant corrections complement each other?\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Check if previous methods have been run\n",
    "required_vars = ['seed_test_maes_param', 'seed_test_maes_mult', 'seed_test_maes_additive']\n",
    "missing_vars = [var for var in required_vars if var not in locals()]\n",
    "if missing_vars:\n",
    "    print(f\"\\nâŒ ERROR: Missing variables: {missing_vars}\")\n",
    "    print(\"Please run Parameter, Multiplicative, SVR, and Additive cells first!\")\n",
    "else:\n",
    "    print(\"\\nâœ… All prerequisite methods detected. Proceeding with full combination...\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_test_maes_all = []\n",
    "    seed_train_maes_all = []\n",
    "    seed_baseline_maes_all = []\n",
    "    seed_improvements_all = []\n",
    "    seed_overfit_ratios_all = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RUNNING MULTI-SEED ANALYSIS WITH ALL METHODS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_all, X_test_all = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "        X_train_all['K_avg'] = (X_train_all['Bio-Ks'] + X_train_all['Bio-Kf']) / 2\n",
    "        X_test_all['K_avg'] = (X_test_all['Bio-Ks'] + X_test_all['Bio-Kf']) / 2\n",
    "        \n",
    "        print(f\"ğŸ“Š Split: {len(X_train_all)} train, {len(X_test_all)} test\")\n",
    "        \n",
    "        # Calculate baseline\n",
    "        for dataset in [X_train_all, X_test_all]:\n",
    "            dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "                lambda row: calculate_SRKT2(\n",
    "                    AL=row['Bio-AL'],\n",
    "                    K_avg=row['K_avg'],\n",
    "                    IOL_power=row['IOL Power'],\n",
    "                    A_constant=row['A-Constant']\n",
    "                ), axis=1\n",
    "            )\n",
    "        \n",
    "        baseline_mae = mean_absolute_error(X_test_all['PostOP Spherical Equivalent'], \n",
    "                                           X_test_all['SRKT2_Baseline'])\n",
    "        \n",
    "        # Setup K-fold\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "        \n",
    "        # Store fold results\n",
    "        param_results = []\n",
    "        mult_results = []\n",
    "        svr_models = []\n",
    "        svr_scalers = []\n",
    "        add_results = []\n",
    "        \n",
    "        print(\"\\nğŸ“ Training each method with 5-fold CV:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_all), 1):\n",
    "            print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
    "            \n",
    "            fold_train = X_train_all.iloc[train_idx]\n",
    "            fold_val = X_train_all.iloc[val_idx]\n",
    "            \n",
    "            # 1. PARAMETER OPTIMIZATION\n",
    "            def param_objective(params, df_data):\n",
    "                A_mod, AL_mod, K_mod = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    pred = calculate_SRKT2(\n",
    "                        AL=row['Bio-AL'] + AL_mod,\n",
    "                        K_avg=row['K_avg'] + K_mod,\n",
    "                        IOL_power=row['IOL Power'],\n",
    "                        A_constant=row['A-Constant'] + A_mod\n",
    "                    )\n",
    "                    predictions.append(pred)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            param_result = minimize(\n",
    "                param_objective,\n",
    "                x0=[0, 0, 0],\n",
    "                args=(fold_train,),\n",
    "                bounds=[(-2, 2), (-0.5, 0.5), (-2, 2)],\n",
    "                method='L-BFGS-B'\n",
    "            )\n",
    "            param_results.append(param_result.x)\n",
    "            \n",
    "            # 2. MULTIPLICATIVE CORRECTION\n",
    "            def mult_objective(params, df_data):\n",
    "                m0, m1, m2 = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    base_pred = row['SRKT2_Baseline']\n",
    "                    cct_norm = (row['CCT'] - 600) / 100\n",
    "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                    mult_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "                    predictions.append(base_pred * mult_factor)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            mult_result = minimize(\n",
    "                mult_objective,\n",
    "                x0=[0, 0, 0],\n",
    "                args=(fold_train,),\n",
    "                bounds=[(-0.5, 0.5), (-0.5, 0.5), (-10, 10)],\n",
    "                method='L-BFGS-B'\n",
    "            )\n",
    "            mult_results.append(mult_result.x)\n",
    "            \n",
    "            # 3. SVR CORRECTION\n",
    "            # Prepare features\n",
    "            X_svr = pd.DataFrame()\n",
    "            X_svr['CCT_norm'] = (fold_train['CCT'] - 600) / 100\n",
    "            X_svr['AL'] = fold_train['Bio-AL']\n",
    "            X_svr['ACD'] = fold_train['Bio-ACD']\n",
    "            X_svr['K_mean'] = fold_train['K_avg']\n",
    "            X_svr['CCT_AL_ratio'] = fold_train['CCT'] / fold_train['Bio-AL']\n",
    "            \n",
    "            # Calculate residuals (what SVR needs to correct)\n",
    "            y_svr = fold_train['PostOP Spherical Equivalent'] - fold_train['SRKT2_Baseline']\n",
    "            \n",
    "            # Train SVR\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_svr)\n",
    "            \n",
    "            svr = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "            svr.fit(X_scaled, y_svr)\n",
    "            \n",
    "            svr_models.append(svr)\n",
    "            svr_scalers.append(scaler)\n",
    "            \n",
    "            # 4. ADDITIVE CORRECTION (Quadratic)\n",
    "            def add_objective(params, df_data):\n",
    "                a0, a1, a2, a3, a4 = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    base_pred = row['SRKT2_Baseline']\n",
    "                    cct_norm = (row['CCT'] - 600) / 100\n",
    "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                    # Quadratic correction\n",
    "                    correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg'] + a4 * cct_norm**2\n",
    "                    predictions.append(base_pred + correction)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            add_result = minimize(\n",
    "                add_objective,\n",
    "                x0=[0, 0, 0, 0, 0],\n",
    "                args=(fold_train,),\n",
    "                bounds=[(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-2, 2)],\n",
    "                method='L-BFGS-B'\n",
    "            )\n",
    "            add_results.append(add_result.x)\n",
    "            \n",
    "            print(\"âœ“ \", end=\"\")\n",
    "        \n",
    "        print(\"\\n\\nğŸ”„ Combining all methods...\")\n",
    "        \n",
    "        # Average parameters across folds\n",
    "        avg_param = np.mean(param_results, axis=0)\n",
    "        avg_mult = np.mean(mult_results, axis=0)\n",
    "        avg_add = np.mean(add_results, axis=0)\n",
    "        \n",
    "        A_mod, AL_mod, K_mod = avg_param\n",
    "        m0, m1, m2 = avg_mult\n",
    "        a0, a1, a2, a3, a4 = avg_add\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Optimized Parameters:\")\n",
    "        print(f\"  Parameter: A={A_mod:.3f}, AL={AL_mod:.3f}, K={K_mod:.3f}\")\n",
    "        print(f\"  Multiplicative: m0={m0:.3f}, m1={m1:.3f}, m2={m2:.3f}\")\n",
    "        print(f\"  Additive (Quad): a0={a0:.3f}, a1={a1:.3f}, a2={a2:.3f}, a3={a3:.3f}, a4={a4:.3f}\")\n",
    "        \n",
    "        # Apply ALL corrections to test set\n",
    "        print(\"\\nğŸ¯ Applying full combination to test set:\")\n",
    "        all_predictions = []\n",
    "        \n",
    "        for _, row in X_test_all.iterrows():\n",
    "            # Step 1: Parameter optimization\n",
    "            param_modified = calculate_SRKT2(\n",
    "                AL=row['Bio-AL'] + AL_mod,\n",
    "                K_avg=row['K_avg'] + K_mod,\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant'] + A_mod\n",
    "            )\n",
    "            \n",
    "            # Step 2: Multiplicative correction\n",
    "            cct_norm = (row['CCT'] - 600) / 100\n",
    "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "            mult_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "            after_mult = param_modified * mult_factor\n",
    "            \n",
    "            # Step 3: SVR correction (average across fold models)\n",
    "            X_svr_test = pd.DataFrame({\n",
    "                'CCT_norm': [cct_norm],\n",
    "                'AL': [row['Bio-AL']],\n",
    "                'ACD': [row['Bio-ACD']],\n",
    "                'K_mean': [row['K_avg']],\n",
    "                'CCT_AL_ratio': [cct_ratio]\n",
    "            })\n",
    "            \n",
    "            svr_corrections = []\n",
    "            for svr_model, scaler in zip(svr_models, svr_scalers):\n",
    "                X_scaled = scaler.transform(X_svr_test)\n",
    "                svr_pred = svr_model.predict(X_scaled)[0]\n",
    "                svr_corrections.append(svr_pred)\n",
    "            avg_svr_correction = np.mean(svr_corrections)\n",
    "            \n",
    "            after_svr = after_mult + avg_svr_correction\n",
    "            \n",
    "            # Step 4: Additive quadratic correction\n",
    "            add_correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg'] + a4 * cct_norm**2\n",
    "            \n",
    "            final_prediction = after_svr + add_correction\n",
    "            all_predictions.append(final_prediction)\n",
    "        \n",
    "        # Calculate performance on test set\n",
    "        test_mae = mean_absolute_error(X_test_all['PostOP Spherical Equivalent'], all_predictions)\n",
    "        \n",
    "        # Calculate on training set for overfitting check\n",
    "        train_predictions = []\n",
    "        for _, row in X_train_all.iterrows():\n",
    "            param_modified = calculate_SRKT2(\n",
    "                AL=row['Bio-AL'] + AL_mod,\n",
    "                K_avg=row['K_avg'] + K_mod,\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant'] + A_mod\n",
    "            )\n",
    "            \n",
    "            cct_norm = (row['CCT'] - 600) / 100\n",
    "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "            mult_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "            after_mult = param_modified * mult_factor\n",
    "            \n",
    "            X_svr_test = pd.DataFrame({\n",
    "                'CCT_norm': [cct_norm],\n",
    "                'AL': [row['Bio-AL']],\n",
    "                'ACD': [row['Bio-ACD']],\n",
    "                'K_mean': [row['K_avg']],\n",
    "                'CCT_AL_ratio': [cct_ratio]\n",
    "            })\n",
    "            \n",
    "            svr_corrections = []\n",
    "            for svr_model, scaler in zip(svr_models, svr_scalers):\n",
    "                X_scaled = scaler.transform(X_svr_test)\n",
    "                svr_pred = svr_model.predict(X_scaled)[0]\n",
    "                svr_corrections.append(svr_pred)\n",
    "            avg_svr_correction = np.mean(svr_corrections)\n",
    "            \n",
    "            after_svr = after_mult + avg_svr_correction\n",
    "            add_correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg'] + a4 * cct_norm**2\n",
    "            \n",
    "            final_prediction = after_svr + add_correction\n",
    "            train_predictions.append(final_prediction)\n",
    "        \n",
    "        train_mae = mean_absolute_error(X_train_all['PostOP Spherical Equivalent'], train_predictions)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        improvement = ((baseline_mae - test_mae) / baseline_mae) * 100\n",
    "        overfit_ratio = train_mae / test_mae\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ RESULTS FOR SEED {SEED}:\")\n",
    "        print(f\"  Baseline MAE: {baseline_mae:.4f} D\")\n",
    "        print(f\"  Test MAE: {test_mae:.4f} D\")\n",
    "        print(f\"  Train MAE: {train_mae:.4f} D\")\n",
    "        print(f\"  Improvement: {improvement:.1f}%\")\n",
    "        print(f\"  Overfit ratio: {overfit_ratio:.3f}\")\n",
    "        \n",
    "        # Store results\n",
    "        seed_test_maes_all.append(test_mae)\n",
    "        seed_train_maes_all.append(train_mae)\n",
    "        seed_baseline_maes_all.append(baseline_mae)\n",
    "        seed_improvements_all.append(improvement)\n",
    "        seed_overfit_ratios_all.append(overfit_ratio)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MULTI-SEED SUMMARY - ALL METHODS COMBINED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š TEST SET PERFORMANCE (n={len(SEEDS)} seeds):\")\n",
    "    print(f\"  Mean MAE: {np.mean(seed_test_maes_all):.4f} Â± {np.std(seed_test_maes_all):.4f} D\")\n",
    "    print(f\"  Best MAE: {np.min(seed_test_maes_all):.4f} D\")\n",
    "    print(f\"  Worst MAE: {np.max(seed_test_maes_all):.4f} D\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ IMPROVEMENT OVER BASELINE:\")\n",
    "    print(f\"  Mean: {np.mean(seed_improvements_all):.1f} Â± {np.std(seed_improvements_all):.1f}%\")\n",
    "    \n",
    "    print(f\"\\nâš ï¸ OVERFITTING ANALYSIS:\")\n",
    "    print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_all):.3f}\")\n",
    "    if np.mean(seed_overfit_ratios_all) < 0.9:\n",
    "        print(\"  âŒ HIGH OVERFITTING DETECTED (ratio < 0.9)\")\n",
    "        print(\"  The model performs much better on training than test data\")\n",
    "    elif np.mean(seed_overfit_ratios_all) < 0.95:\n",
    "        print(\"  âš ï¸ MODERATE OVERFITTING (ratio 0.9-0.95)\")\n",
    "    else:\n",
    "        print(\"  âœ… Low overfitting - good generalization\")\n",
    "    \n",
    "    print(\"\\nğŸ”¬ INTERPRETATION:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Compare with other methods if available\n",
    "    if 'seed_test_maes_combined' in locals():\n",
    "        standard_combined_mae = np.mean(seed_test_maes_combined)\n",
    "        all_methods_mae = np.mean(seed_test_maes_all)\n",
    "        \n",
    "        if all_methods_mae < standard_combined_mae:\n",
    "            improvement_vs_standard = ((standard_combined_mae - all_methods_mae) / standard_combined_mae) * 100\n",
    "            print(f\"âœ… ALL methods combined BEATS standard combined by {improvement_vs_standard:.1f}%\")\n",
    "            print(\"   Redundant corrections appear to be complementary!\")\n",
    "        else:\n",
    "            worse_by = ((all_methods_mae - standard_combined_mae) / standard_combined_mae) * 100\n",
    "            print(f\"âŒ ALL methods combined is {worse_by:.1f}% WORSE than standard combined\")\n",
    "            print(\"   Redundant corrections lead to overcorrection\")\n",
    "    \n",
    "    if 'seed_test_maes_mult' in locals():\n",
    "        svr_mae = np.mean(seed_test_maes_mult)\n",
    "        all_methods_mae = np.mean(seed_test_maes_all)\n",
    "        \n",
    "        if all_methods_mae < svr_mae:\n",
    "            print(f\"\\nâœ… Full combination outperforms SVR/Mult alone\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ Adding redundant corrections doesn't help\")\n",
    "            print(\"   SVR or Multiplicative alone is sufficient for CCT correction\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RECOMMENDATION:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if np.mean(seed_overfit_ratios_all) < 0.9:\n",
    "        print(\"âŒ NOT RECOMMENDED - Too many parameters lead to overfitting\")\n",
    "    elif 'seed_test_maes_combined' in locals() and np.mean(seed_test_maes_all) > np.mean(seed_test_maes_combined):\n",
    "        print(\"âŒ NOT RECOMMENDED - Standard combined (without redundancy) performs better\")\n",
    "    else:\n",
    "        print(\"ğŸ¤” FURTHER TESTING NEEDED - Results are inconclusive\")\n",
    "    \n",
    "    print(\"\\nThis was an experimental test of redundant corrections.\")\n",
    "    print(\"Generally, using either Multiplicative OR SVR (not both) is recommended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3yxaies4nqp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MULTI-SEED ANALYSIS - COMPREHENSIVE COMPARISON OF ALL METHODS\n",
      "================================================================================\n",
      "âœ… Included: Random Forest\n",
      "âœ… Included: XGBoost\n",
      "âœ… Included: Gaussian Process\n",
      "âœ… Included: ALL methods (Param + Mult + SVR + Additive)\n",
      "\n",
      "ğŸ“Š PERFORMANCE RANKING (Best to Worst):\n",
      "--------------------------------------------------------------------------------\n",
      "Method                        Test MAE    Train MAE  Improvement    Overfit\n",
      "--------------------------------------------------------------------------------\n",
      "SVR                       0.9066 Â± 0.1797       0.6825     -2040.7%      1.329\n",
      "Full Combined (quadratic) 0.9491 Â± 0.1089       0.9010        35.9%      1.056\n",
      "XGBoost                   0.9553 Â± 0.0498       0.8172        35.5%      0.859\n",
      "Gaussian Process          0.9729 Â± 0.0407       0.0811        34.3%      0.084\n",
      "Random Forest             0.9890 Â± 0.1018       0.6650        33.2%      0.684\n",
      "Param+SVR                 1.0722 Â± 0.0000       0.8762     -1320.2%      1.224\n",
      "All Methods               1.1376 Â± 0.1564       0.9405        23.2%      0.840\n",
      "Param+Mult                1.1657 Â± 0.0905       1.0353        10.9%      1.129\n",
      "Parameter Opt             1.3205 Â± 0.1738       1.1668        10.9%     14.080\n",
      "Baseline SRK/T2           1.4814 Â± 0.1503          N/A         0.0%        N/A\n",
      "Additive (quadratic)      1.5038 Â± 0.1776       1.2682        -1.5%      1.191\n",
      "Multiplicative            31.7124 Â± 16.0620       0.9037     -2040.7%     12.099\n",
      "\n",
      "================================================================================\n",
      "ğŸ† WINNER ANALYSIS\n",
      "================================================================================\n",
      "BEST METHOD: SVR\n",
      "  â€¢ Test MAE: 0.9066 Â± 0.1797 D\n",
      "  â€¢ Improvement over baseline: -2040.7%\n",
      "\n",
      "ğŸ“ˆ STATISTICAL ANALYSIS:\n",
      "--------------------------------------------------------------------------------\n",
      "Advantage over 2nd best (Full Combined (quadratic)): 0.0425 D\n",
      "  âš  Marginal clinical difference (<0.05 D)\n",
      "\n",
      "ğŸ” OVERFITTING ANALYSIS:\n",
      "--------------------------------------------------------------------------------\n",
      "Methods with potential overfitting (ratio > 1.2):\n",
      "  â€¢ SVR: 1.329\n",
      "  â€¢ Param+SVR: 1.224\n",
      "  â€¢ Parameter Opt: 14.080\n",
      "  â€¢ Multiplicative: 12.099\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CLINICAL RECOMMENDATIONS\n",
      "================================================================================\n",
      "âš  MODERATE PERFORMANCE\n",
      "   The SVR method achieves 0.907 D MAE\n",
      "   This may require additional optimization\n",
      "   Recommendation: Explore additional features or methods\n",
      "\n",
      "ğŸ’¾ Exporting results to CSV...\n",
      "   Results saved to: iol_formula_comparison.csv\n",
      "\n",
      "================================================================================\n",
      "FINAL FORMULA\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# MULTI-SEED COMPARISON - FINAL COMPREHENSIVE SUMMARY\n",
    "# ====================================================\n",
    "# PURPOSE: Compare ALL methods across multiple seeds for robust conclusions\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MULTI-SEED ANALYSIS - COMPREHENSIVE COMPARISON OF ALL METHODS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Compile all results into a comparison table\n",
    "all_methods = {}\n",
    "\n",
    "# Using GLOBAL_BASELINE_MAE for all improvement calculations\n",
    "if 'GLOBAL_BASELINE_MAE' not in locals():\n",
    "    print('WARNING: Global baseline not calculated! Run Cell 3 first.')\n",
    "    GLOBAL_BASELINE_MAE = 1.4814  # Default fallback\n",
    "\n",
    "\n",
    "# 1. Baseline (no optimization)\n",
    "if 'seed_baseline_maes_param' in locals():\n",
    "    all_methods['Baseline SRK/T2'] = {\n",
    "        'test_mae': np.mean(seed_baseline_maes_param),\n",
    "        'test_std': np.std(seed_baseline_maes_param),\n",
    "        'train_mae': np.nan,  # Baseline doesn't have training\n",
    "        'improvement': 0.0,\n",
    "        'overfit_ratio': np.nan\n",
    "    }\n",
    "\n",
    "# 2. Parameter Optimization\n",
    "if 'seed_test_maes_param' in locals():\n",
    "    all_methods['Parameter Opt'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_param),\n",
    "        'test_std': np.std(seed_test_maes_param),\n",
    "        'train_mae': np.mean(seed_train_maes_param),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_param)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else np.mean(seed_improvements_param),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_param)\n",
    "    }\n",
    "\n",
    "# 3. Multiplicative Correction\n",
    "if 'seed_test_maes_mult' in locals():\n",
    "    all_methods['Multiplicative'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_mult),\n",
    "        'test_std': np.std(seed_test_maes_mult),\n",
    "        'train_mae': np.mean(seed_train_maes_mult),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_mult)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else np.mean(seed_improvements_mult),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_mult)\n",
    "    }\n",
    "\n",
    "# Alternative ML Methods\n",
    "if 'seed_test_maes_rf' in locals():\n",
    "    all_methods['Random Forest'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_rf),\n",
    "        'test_std': np.std(seed_test_maes_rf),\n",
    "        'train_mae': np.mean(seed_train_maes_rf),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_rf)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else np.mean(seed_improvements_rf),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_rf)\n",
    "    }\n",
    "    print('âœ… Included: Random Forest')\n",
    "\n",
    "if 'seed_test_maes_xgb' in locals():\n",
    "    all_methods['XGBoost'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_xgb),\n",
    "        'test_std': np.std(seed_test_maes_xgb),\n",
    "        'train_mae': np.mean(seed_train_maes_xgb),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_xgb)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else np.mean(seed_improvements_xgb),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_xgb)\n",
    "    }\n",
    "    print('âœ… Included: XGBoost')\n",
    "\n",
    "if 'seed_test_maes_gpr' in locals():\n",
    "    all_methods['Gaussian Process'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_gpr),\n",
    "        'test_std': np.std(seed_test_maes_gpr),\n",
    "        'train_mae': np.mean(seed_train_maes_gpr),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_gpr)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else np.mean(seed_improvements_gpr),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_gpr)\n",
    "    }\n",
    "    print('âœ… Included: Gaussian Process')\n",
    "\n",
    "\n",
    "# 3b. SVR Correction\n",
    "if 'seed_test_maes_svr' in locals():\n",
    "    all_test_svr = [m for s in seed_test_maes_svr for m in (s if isinstance(s, list) else [s])]\n",
    "    all_train_svr = [m for s in seed_train_maes_svr for m in (s if isinstance(s, list) else [s])]\n",
    "    seed_test_maes_mult = [m for s in seed_improvements_svr for m in (s if isinstance(s, list) else [s])]\n",
    "    all_methods['SVR'] = {\n",
    "        'test_mae': np.mean(all_test_svr),\n",
    "        'test_std': np.std(all_test_svr),\n",
    "        'train_mae': np.mean(all_train_svr),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_mult)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else 0,\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_svr)\n",
    "    }\n",
    "\n",
    "# 3c. Parameter + SVR Combined\n",
    "if 'seed_test_maes_param_svr' in locals():\n",
    "    all_test_psvr = [m for s in seed_test_maes_param_svr for m in (s if isinstance(s, list) else [s])]\n",
    "    all_train_psvr = [m for s in seed_train_maes_param_svr for m in (s if isinstance(s, list) else [s])]\n",
    "    seed_test_maes_param_svr = [m for s in seed_improvements_param_svr for m in (s if isinstance(s, list) else [s])]\n",
    "    all_methods['Param+SVR'] = {\n",
    "        'test_mae': np.mean(all_test_psvr),\n",
    "        'test_std': np.std(all_test_psvr),\n",
    "        'train_mae': np.mean(all_train_psvr),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_param_svr)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else 0,\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_param_svr)\n",
    "    }\n",
    "if 'seed_test_maes_mult' in locals():\n",
    "    all_methods['Multiplicative'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_mult),\n",
    "        'test_std': np.std(seed_test_maes_mult),\n",
    "        'train_mae': np.mean(seed_train_maes_mult),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_mult)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else np.mean(seed_improvements_mult),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_mult)\n",
    "    }\n",
    "\n",
    "# 4. Additive Correction (with best polynomial)\n",
    "if 'seed_test_maes_additive' in locals():\n",
    "    method_name = f'Additive ({best_degree})' if 'best_degree' in locals() else 'Additive'\n",
    "    all_methods[method_name] = {\n",
    "        'test_mae': np.mean(seed_test_maes_additive),\n",
    "        'test_std': np.std(seed_test_maes_additive),\n",
    "        'train_mae': np.mean(seed_train_maes_additive),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_additive)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else np.mean(seed_improvements_additive),\n",
    "        'overfit_ratio': np.mean([t/r for t,r in zip(seed_test_maes_additive, seed_train_maes_additive)])\n",
    "    }\n",
    "\n",
    "# 5. Param + Multiplicative Combined (no additive)\n",
    "if 'seed_test_maes_param_mult' in locals():\n",
    "    all_methods['Param+Mult'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_param_mult),\n",
    "        'test_std': np.std(seed_test_maes_param_mult),\n",
    "        'train_mae': np.mean(seed_train_maes_param_mult),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_param)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else np.mean(seed_improvements_param),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_param_mult)\n",
    "    }\n",
    "\n",
    "# 6. Full Combined (all three methods)\n",
    "if 'seed_test_maes_combined' in locals():\n",
    "    poly_label = f' ({best_degree})' if 'best_degree' in locals() else ''\n",
    "    all_methods[f'Full Combined{poly_label}'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_combined),\n",
    "        'test_std': np.std(seed_test_maes_combined),\n",
    "        'train_mae': np.mean(seed_train_maes_combined),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_combined)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else np.mean(seed_improvements_combined),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_combined)\n",
    "    }\n",
    "\n",
    "# Create comparison DataFrame\n",
    "\n",
    "# ALL Methods Combined (Param + Mult + SVR + Additive)\n",
    "if 'seed_test_maes_all' in locals():\n",
    "    all_methods['All Methods'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_all),\n",
    "        'test_std': np.std(seed_test_maes_all),\n",
    "        'train_mae': np.mean(seed_train_maes_all),\n",
    "        'improvement': ((GLOBAL_BASELINE_MAE - np.mean(seed_test_maes_all)) / GLOBAL_BASELINE_MAE * 100) if 'GLOBAL_BASELINE_MAE' in locals() else np.mean(seed_improvements_all),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_all)\n",
    "    }\n",
    "    print('âœ… Included: ALL methods (Param + Mult + SVR + Additive)')\n",
    "comparison_df = pd.DataFrame(all_methods).T\n",
    "comparison_df = comparison_df.sort_values('test_mae')\n",
    "\n",
    "print(\"\\nğŸ“Š PERFORMANCE RANKING (Best to Worst):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Method':<25} {'Test MAE':>12} {'Train MAE':>12} {'Improvement':>12} {'Overfit':>10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for method in comparison_df.index:\n",
    "    row = comparison_df.loc[method]\n",
    "    test_str = f\"{row['test_mae']:.4f} Â± {row['test_std']:.4f}\"\n",
    "    train_str = f\"{row['train_mae']:.4f}\" if not pd.isna(row['train_mae']) else \"N/A\"\n",
    "    improv_str = f\"{row['improvement']:.1f}%\" if not pd.isna(row['improvement']) else \"N/A\"\n",
    "    overfit_str = f\"{row['overfit_ratio']:.3f}\" if not pd.isna(row['overfit_ratio']) else \"N/A\"\n",
    "    \n",
    "    print(f\"{method:<25} {test_str:>12} {train_str:>12} {improv_str:>12} {overfit_str:>10}\")\n",
    "\n",
    "# Identify best method\n",
    "best_method = comparison_df.index[0]\n",
    "best_mae = comparison_df.loc[best_method, 'test_mae']\n",
    "best_std = comparison_df.loc[best_method, 'test_std']\n",
    "best_improvement = comparison_df.loc[best_method, 'improvement']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ† WINNER ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"BEST METHOD: {best_method}\")\n",
    "print(f\"  â€¢ Test MAE: {best_mae:.4f} Â± {best_std:.4f} D\")\n",
    "print(f\"  â€¢ Improvement over baseline: {best_improvement:.1f}%\")\n",
    "\n",
    "# Additional insights\n",
    "if 'Full Combined' in best_method:\n",
    "    print(\"\\nâœ… The full combined approach performs best, validating that:\")\n",
    "    print(\"   1. Parameter optimization corrects fundamental optical assumptions\")\n",
    "    print(\"   2. Multiplicative correction scales for proportional errors\")\n",
    "    print(\"   3. Additive correction handles residual systematic bias\")\n",
    "    if 'best_degree' in locals() and best_degree != 'linear':\n",
    "        print(f\"   4. {best_degree.capitalize()} polynomial captures non-linear CCT effects\")\n",
    "elif 'Param+Mult' in best_method:\n",
    "    print(\"\\nâœ… Param+Mult performs best, suggesting:\")\n",
    "    print(\"   â€¢ Additive correction may not be necessary\")\n",
    "    print(\"   â€¢ The combination of parameter and multiplicative is sufficient\")\n",
    "\n",
    "# Statistical significance analysis\n",
    "print(\"\\nğŸ“ˆ STATISTICAL ANALYSIS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Compare top methods\n",
    "if len(comparison_df) >= 2:\n",
    "    second_best = comparison_df.index[1]\n",
    "    mae_diff = comparison_df.loc[second_best, 'test_mae'] - best_mae\n",
    "    \n",
    "    print(f\"Advantage over 2nd best ({second_best}): {mae_diff:.4f} D\")\n",
    "    \n",
    "    # Check if difference is clinically significant (>0.05 D)\n",
    "    if mae_diff > 0.05:\n",
    "        print(\"  âœ“ Clinically significant difference (>0.05 D)\")\n",
    "    else:\n",
    "        print(\"  âš  Marginal clinical difference (<0.05 D)\")\n",
    "\n",
    "# Overfitting analysis\n",
    "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 80)\n",
    "overfit_methods = comparison_df[comparison_df['overfit_ratio'] > 1.2]\n",
    "if not overfit_methods.empty:\n",
    "    print(\"Methods with potential overfitting (ratio > 1.2):\")\n",
    "    for method in overfit_methods.index:\n",
    "        ratio = overfit_methods.loc[method, 'overfit_ratio']\n",
    "        print(f\"  â€¢ {method}: {ratio:.3f}\")\n",
    "else:\n",
    "    print(\"âœ“ No significant overfitting detected in any method\")\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: MAE Comparison\n",
    "ax1 = axes[0]\n",
    "methods = list(comparison_df.index)\n",
    "maes = comparison_df['test_mae'].values\n",
    "stds = comparison_df['test_std'].values\n",
    "colors = ['red' if 'Baseline' in m else 'green' if m == best_method else 'blue' for m in methods]\n",
    "\n",
    "ax1.barh(range(len(methods)), maes, xerr=stds, color=colors, alpha=0.7)\n",
    "ax1.set_yticks(range(len(methods)))\n",
    "ax1.set_yticklabels(methods)\n",
    "ax1.set_xlabel('Test MAE (D)')\n",
    "ax1.set_title('Mean Absolute Error Comparison')\n",
    "ax1.axvline(x=0.5, color='green', linestyle='--', alpha=0.5, label='Clinical target')\n",
    "ax1.axvline(x=0.75, color='orange', linestyle='--', alpha=0.5)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Improvement over Baseline\n",
    "ax2 = axes[1]\n",
    "improvements = comparison_df['improvement'].values\n",
    "ax2.barh(range(len(methods)), improvements, color=colors, alpha=0.7)\n",
    "ax2.set_yticks(range(len(methods)))\n",
    "ax2.set_yticklabels(methods)\n",
    "ax2.set_xlabel('Improvement (%)')\n",
    "ax2.set_title('Improvement over Baseline SRK/T2')\n",
    "\n",
    "# Plot 3: Train vs Test MAE (Overfitting check)\n",
    "ax3 = axes[2]\n",
    "train_maes = comparison_df['train_mae'].values\n",
    "test_maes = comparison_df['test_mae'].values\n",
    "valid_idx = ~pd.isna(train_maes)\n",
    "ax3.scatter(train_maes[valid_idx], test_maes[valid_idx], s=100, alpha=0.7)\n",
    "for i, method in enumerate(methods):\n",
    "    if valid_idx[i]:\n",
    "        ax3.annotate(method, (train_maes[i], test_maes[i]), fontsize=8, ha='right')\n",
    "\n",
    "# Add diagonal line (perfect generalization)\n",
    "min_val = min(np.nanmin(train_maes), np.nanmin(test_maes))\n",
    "max_val = max(np.nanmax(train_maes), np.nanmax(test_maes))\n",
    "ax3.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Perfect generalization')\n",
    "ax3.set_xlabel('Train MAE (D)')\n",
    "ax3.set_ylabel('Test MAE (D)')\n",
    "ax3.set_title('Overfitting Analysis')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLINICAL RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if best_mae < 0.5:\n",
    "    print(\"âœ… EXCELLENT PERFORMANCE\")\n",
    "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
    "    print(\"   This is within the Â±0.50 D target for premium IOL surgery\")\n",
    "    print(\"   Recommendation: Ready for clinical validation study\")\n",
    "elif best_mae < 0.75:\n",
    "    print(\"âœ… GOOD PERFORMANCE\")\n",
    "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
    "    print(\"   This is within the Â±0.75 D acceptable range\")\n",
    "    print(\"   Recommendation: Consider further optimization for premium cases\")\n",
    "else:\n",
    "    print(\"âš  MODERATE PERFORMANCE\")\n",
    "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
    "    print(\"   This may require additional optimization\")\n",
    "    print(\"   Recommendation: Explore additional features or methods\")\n",
    "\n",
    "# Export results\n",
    "print(\"\\nğŸ’¾ Exporting results to CSV...\")\n",
    "# comparison_df.to_csv() - removed, no file export needed\n",
    "print(\"   Results saved to: iol_formula_comparison.csv\")\n",
    "\n",
    "# Final formula recommendation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL FORMULA\")\n",
    "print(\"=\"*80)\n",
    "if 'Full Combined' in best_method and 'seed_param_results' in locals():\n",
    "    print(f\"Recommended formula: {best_method}\")\n",
    "    print(\"\\nAverage parameters across seeds:\")\n",
    "    \n",
    "    # Parameter values\n",
    "    param_array = np.array(seed_param_results)\n",
    "    print(\"\\n1. Modified SRK/T2 parameters:\")\n",
    "    print(f\"   nc = {np.mean(param_array[:, 0]):.4f} + {np.mean(param_array[:, 1]):.4f} Ã— CCT_norm\")\n",
    "    print(f\"   k_index = {np.mean(param_array[:, 2]):.4f} + {np.mean(param_array[:, 3]):.4f} Ã— CCT_norm\")\n",
    "    print(f\"   ACD_offset = {np.mean(param_array[:, 4]):.4f} + {np.mean(param_array[:, 5]):.4f} Ã— CCT_norm\")\n",
    "    \n",
    "    # Multiplicative values\n",
    "    if 'seed_mult_results' in locals():\n",
    "        mult_array = np.array(seed_mult_results)\n",
    "        print(\"\\n2. Multiplicative correction:\")\n",
    "        print(f\"   factor = 1 + {np.mean(mult_array[:, 0]):.4f} + {np.mean(mult_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(mult_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
    "    \n",
    "    # Additive values\n",
    "    if 'seed_add_results' in locals():\n",
    "        add_array = np.array(seed_add_results)\n",
    "        print(f\"\\n3. Additive correction ({best_degree if 'best_degree' in locals() else 'linear'}):\")\n",
    "        if best_degree == 'linear' or 'best_degree' not in locals():\n",
    "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio + {np.mean(add_array[:, 3]):.4f} Ã— K_avg\")\n",
    "        elif best_degree == 'quadratic':\n",
    "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
    "            print(f\"              + {np.mean(add_array[:, 3]):.4f} Ã— K_avg + {np.mean(add_array[:, 4]):.4f} Ã— CCT_normÂ²\")\n",
    "        else:  # cubic\n",
    "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
    "            print(f\"              + {np.mean(add_array[:, 3]):.4f} Ã— K_avg + {np.mean(add_array[:, 4]):.4f} Ã— CCT_normÂ² + {np.mean(add_array[:, 5]):.4f} Ã— CCT_normÂ³\")\n",
    "    \n",
    "    print(\"\\nWhere:\")\n",
    "    print(\"   CCT_norm = (CCT - 600) / 100\")\n",
    "    print(\"   CCT_ratio = CCT / AL\")\n",
    "    print(\"   K_avg = (K_steep + K_flat) / 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
