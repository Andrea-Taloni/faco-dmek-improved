{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41782613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ”§ MULTI-SEED CONFIGURATION\n",
      "======================================================================\n",
      "Seeds for validation: [42, 123, 456, 789, 2025]\n",
      "This ensures results are not dependent on random split\n",
      "Each seed creates different train/test splits for robust assessment\n",
      "======================================================================\n",
      "IOL CALCULATION FOR PRE-DMEK PATIENTS\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š WHAT WE'RE DOING:\n",
      "--------------------------------------------------\n",
      "â€¢ Loading data from Fuchs' dystrophy patients\n",
      "â€¢ These patients had combined cataract + DMEK surgery\n",
      "â€¢ Goal: Improve IOL power calculation accuracy\n",
      "â€¢ Challenge: Edematous corneas distort standard formulas\n",
      "â€¢ NEW: Using 5 different seeds for robust validation\n",
      "\n",
      "âœ… Loaded 88 patients from FacoDMEK.xlsx\n",
      "\n",
      "ğŸ” KEY MEASUREMENTS IN OUR DATA:\n",
      "--------------------------------------------------\n",
      "â€¢ Bio-AL: Axial length (mm)\n",
      "â€¢ Bio-Ks/Kf: Steep and flat keratometry (D)\n",
      "â€¢ CCT: Central corneal thickness (Î¼m) - KEY for edema\n",
      "â€¢ IOL Power: Implanted lens power (D)\n",
      "â€¢ PostOP Spherical Equivalent: Actual outcome (D)\n"
     ]
    }
   ],
   "source": [
    "# IOL CALCULATION FOR PRE-DMEK PATIENTS - SETUP AND DATA LOADING\n",
    "# ================================================================\n",
    "# PURPOSE: Set up the analysis environment and load patient data\n",
    "# This notebook optimizes IOL power calculations for Fuchs' dystrophy patients\n",
    "# undergoing combined phacoemulsification and DMEK surgery\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants for clinical accuracy thresholds (diopters)\n",
    "THRESHOLDS = [0.25, 0.50, 0.75, 1.00]\n",
    "TEST_SIZE = 0.25      # 25% holdout for final testing\n",
    "N_FOLDS = 5           # 5-fold cross-validation\n",
    "\n",
    "# MULTI-SEED CONFIGURATION FOR ROBUST VALIDATION\n",
    "#SEEDS = [42]  # Quick test with single seed\n",
    "#SEEDS = [42, 123]  # Medium test with 2 seeds\n",
    "SEEDS = [42, 123, 456, 789, 2025]  # Multiple seeds for statistical robustness\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”§ MULTI-SEED CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Seeds for validation: {SEEDS}\")\n",
    "print(\"This ensures results are not dependent on random split\")\n",
    "print(\"Each seed creates different train/test splits for robust assessment\")\n",
    "\n",
    "# Storage for multi-seed results\n",
    "multi_seed_results = {\n",
    "\n",
    "    'parameter': {},\n",
    "    'multiplicative': {},\n",
    "    'additive': {},\n",
    "    'combined': {},\n",
    "    'fixed_combined': {}\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"IOL CALCULATION FOR PRE-DMEK PATIENTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nğŸ“Š WHAT WE'RE DOING:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Loading data from Fuchs' dystrophy patients\")\n",
    "print(\"â€¢ These patients had combined cataract + DMEK surgery\")\n",
    "print(\"â€¢ Goal: Improve IOL power calculation accuracy\")\n",
    "print(\"â€¢ Challenge: Edematous corneas distort standard formulas\")\n",
    "print(f\"â€¢ NEW: Using {len(SEEDS)} different seeds for robust validation\")\n",
    "\n",
    "# Load the patient data\n",
    "df = pd.read_excel('FacoDMEK.xlsx')\n",
    "print(f\"\\nâœ… Loaded {len(df)} patients from FacoDMEK.xlsx\")\n",
    "\n",
    "print(\"\\nğŸ” KEY MEASUREMENTS IN OUR DATA:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Bio-AL: Axial length (mm)\")\n",
    "print(\"â€¢ Bio-Ks/Kf: Steep and flat keratometry (D)\")\n",
    "print(\"â€¢ CCT: Central corneal thickness (Î¼m) - KEY for edema\")\n",
    "print(\"â€¢ IOL Power: Implanted lens power (D)\")\n",
    "print(\"â€¢ PostOP Spherical Equivalent: Actual outcome (D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9871e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SRK/T2 FORMULA (Sheard et al. 2010)\n",
      "======================================================================\n",
      "â€¢ SKR/T2 assumes normal corneal properties\n",
      "â€¢ In Fuchs' dystrophy, the cornea is NOT normal:\n",
      "  - Edema changes refractive index (nc)\n",
      "  - Swelling alters keratometric index (k_index)\n",
      "  - Anterior chamber depth is affected\n",
      "\n",
      "Our strategy: Keep the formula structure, optimize the parameters!\n",
      "\n",
      "ğŸ“ THE SRK/T2 FORMULA:\n",
      "\n",
      "         1000Â·nâ‚Â·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) - PÂ·(Lopt - ACDest)Â·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest)\n",
      "REF = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       nâ‚Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) + LoptÂ·r) - 0.001Â·PÂ·(Lopt - ACDest)Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest) + ACDestÂ·r)\n"
     ]
    }
   ],
   "source": [
    "# STANDARD SRK/T2 FORMULA IMPLEMENTATION\n",
    "# ========================================\n",
    "# PURPOSE: Implement the baseline SRK/T2 formula (Sheard et al. 2010)\n",
    "# This is the current gold standard for IOL calculations\n",
    "# We'll use this as our baseline to compare improvements against\n",
    "\n",
    "def calculate_SRKT2(AL, K_avg, IOL_power, A_constant, nc=1.333, k_index=1.3375):\n",
    "    \"\"\"\n",
    "    SRK/T2 Formula (Sheard et al. 2010)\n",
    "    - Assumes NORMAL corneas (nc=1.333, k_index=1.3375)\n",
    "    - These assumptions fail in edematous Fuchs' corneas\n",
    "    \n",
    "    Parameters:\n",
    "    - AL: Axial length (mm)\n",
    "    - K_avg: Average keratometry (D)\n",
    "    - IOL_power: IOL power (D)\n",
    "    - A_constant: Lens-specific constant\n",
    "    - nc: Corneal refractive index (we'll optimize this!)\n",
    "    - k_index: Keratometric index (we'll optimize this too!)\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    na = 1.336  # Aqueous/vitreous refractive index\n",
    "    V = 12      # Vertex distance (mm)\n",
    "    ncm1 = nc - 1\n",
    "    \n",
    "    # Convert keratometry to radius using keratometric index\n",
    "    # This is where edema causes problems - k_index assumes normal cornea!\n",
    "    r = (k_index - 1) * 1000 / K_avg\n",
    "    \n",
    "    # Axial length correction for long eyes\n",
    "    if AL <= 24.2:\n",
    "        LCOR = AL\n",
    "    else:\n",
    "        LCOR = 3.446 + 1.716 * AL - 0.0237 * AL * AL\n",
    "    \n",
    "    # H2 calculation (corneal height) - Sheard's modification\n",
    "    H2 = -10.326 + 0.32630 * LCOR + 0.13533 * K_avg\n",
    "    \n",
    "    # ACD (Anterior Chamber Depth) estimation\n",
    "    # Edema can affect this too!\n",
    "    ACD_const = 0.62467 * A_constant - 68.747\n",
    "    offset = ACD_const - 3.336\n",
    "    ACD_est = H2 + offset\n",
    "    \n",
    "    # Retinal thickness correction\n",
    "    RETHICK = 0.65696 - 0.02029 * AL\n",
    "    LOPT = AL + RETHICK  # Optical axial length\n",
    "    \n",
    "    # SRK/T2 refraction calculation - the complex optics formula\n",
    "    numerator = (1000 * na * (na * r - ncm1 * LOPT) - \n",
    "                 IOL_power * (LOPT - ACD_est) * (na * r - ncm1 * ACD_est))\n",
    "    \n",
    "    denominator = (na * (V * (na * r - ncm1 * LOPT) + LOPT * r) - \n",
    "                   0.001 * IOL_power * (LOPT - ACD_est) * \n",
    "                   (V * (na * r - ncm1 * ACD_est) + ACD_est * r))\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SRK/T2 FORMULA (Sheard et al. 2010)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"â€¢ SKR/T2 assumes normal corneal properties\")\n",
    "print(\"â€¢ In Fuchs' dystrophy, the cornea is NOT normal:\")\n",
    "print(\"  - Edema changes refractive index (nc)\")\n",
    "print(\"  - Swelling alters keratometric index (k_index)\")\n",
    "print(\"  - Anterior chamber depth is affected\")\n",
    "print(\"\\nOur strategy: Keep the formula structure, optimize the parameters!\")\n",
    "\n",
    "print(\"\\nğŸ“ THE SRK/T2 FORMULA:\")\n",
    "print()\n",
    "print(\"         1000Â·nâ‚Â·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) - PÂ·(Lopt - ACDest)Â·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest)\")\n",
    "print(\"REF = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(\"       nâ‚Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) + LoptÂ·r) - 0.001Â·PÂ·(Lopt - ACDest)Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest) + ACDestÂ·r)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db415cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE SRK/T2 PERFORMANCE\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ WHAT WE'RE DOING:\n",
      "--------------------------------------------------\n",
      "1. Calculate average K from steep and flat readings\n",
      "2. Apply standard SRK/T2 to all 96 patients\n",
      "3. Compare predictions to actual outcomes\n",
      "4. Measure error to establish baseline performance\n",
      "\n",
      "ğŸ“Š BASELINE PERFORMANCE METRICS:\n",
      "======================================================================\n",
      "  Mean Absolute Error (MAE):     1.2144 D\n",
      "  Mean Error (ME):                -0.1786 D\n",
      "  Standard Deviation (SD):        1.5836 D\n",
      "  Median Absolute Error:          0.9251 D\n",
      "\n",
      "ğŸ’¡ INTERPRETATION:\n",
      "--------------------------------------------------\n",
      "â€¢ MAE of 1.21 D is POOR (>1.0 D is clinically unacceptable)\n",
      "\n",
      "ğŸ“ˆ CLINICAL ACCURACY:\n",
      "----------------------------------------------------------------------\n",
      "  Within Â±0.25 D:  14.8% of eyes\n",
      "  Within Â±0.50 D:  28.4% of eyes\n",
      "  Within Â±0.75 D:  38.6% of eyes\n",
      "  Within Â±1.00 D:  53.4% of eyes\n",
      "\n",
      "ğŸ¯ CLINICAL TARGETS:\n",
      "--------------------------------------------------\n",
      "â€¢ Modern standard: >70% within Â±0.50 D\n",
      "â€¢ Acceptable: >90% within Â±1.00 D\n",
      "â€¢ Our baseline: 28.4% within Â±0.50 D\n",
      "\n",
      "âš ï¸ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\n",
      "This is why we need optimization!\n"
     ]
    }
   ],
   "source": [
    "# BASELINE PERFORMANCE EVALUATION\n",
    "# =================================\n",
    "# PURPOSE: Calculate how well standard SRK/T2 performs on our Fuchs' patients\n",
    "# This establishes the baseline that we need to beat\n",
    "# Spoiler: It won't be great due to the edematous corneas!\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BASELINE SRK/T2 PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nğŸ“‹ WHAT WE'RE DOING:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. Calculate average K from steep and flat readings\")\n",
    "print(\"2. Apply standard SRK/T2 to all 96 patients\")\n",
    "print(\"3. Compare predictions to actual outcomes\")\n",
    "print(\"4. Measure error to establish baseline performance\")\n",
    "\n",
    "# Calculate average K (needed for SRK/T2)\n",
    "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
    "\n",
    "# Apply standard SRK/T2 formula to all patients\n",
    "df['SRKT2_Prediction'] = df.apply(\n",
    "    lambda row: calculate_SRKT2(\n",
    "        AL=row['Bio-AL'],\n",
    "        K_avg=row['K_avg'],\n",
    "        IOL_power=row['IOL Power'],\n",
    "        A_constant=row['A-Constant']\n",
    "        # Note: Using DEFAULT nc=1.333 and k_index=1.3375\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Calculate prediction errors\n",
    "df['Prediction_Error'] = df['PostOP Spherical Equivalent'] - df['SRKT2_Prediction']\n",
    "df['Absolute_Error'] = abs(df['Prediction_Error'])\n",
    "\n",
    "# Calculate key metrics\n",
    "mae = df['Absolute_Error'].mean()\n",
    "me = df['Prediction_Error'].mean()\n",
    "std = df['Prediction_Error'].std()\n",
    "median_ae = df['Absolute_Error'].median()\n",
    "\n",
    "print(\"\\nğŸ“Š BASELINE PERFORMANCE METRICS:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Mean Absolute Error (MAE):     {mae:.4f} D\")\n",
    "print(f\"  Mean Error (ME):                {me:+.4f} D\")\n",
    "print(f\"  Standard Deviation (SD):        {std:.4f} D\")\n",
    "print(f\"  Median Absolute Error:          {median_ae:.4f} D\")\n",
    "\n",
    "print(\"\\nğŸ’¡ INTERPRETATION:\")\n",
    "print(\"-\" * 50)\n",
    "if mae > 1.0:\n",
    "    print(f\"â€¢ MAE of {mae:.2f} D is POOR (>1.0 D is clinically unacceptable)\")\n",
    "else:\n",
    "    print(f\"â€¢ MAE of {mae:.2f} D is moderate\")\n",
    "    \n",
    "if abs(me) > 0.25:\n",
    "    print(f\"â€¢ Mean error of {me:+.2f} D shows systematic bias\")\n",
    "    if me < 0:\n",
    "        print(\"  â†’ Formula tends to predict too myopic (negative)\")\n",
    "    else:\n",
    "        print(\"  â†’ Formula tends to predict too hyperopic (positive)\")\n",
    "\n",
    "# Calculate clinical accuracy rates\n",
    "within_025 = (df['Absolute_Error'] <= 0.25).sum() / len(df) * 100\n",
    "within_050 = (df['Absolute_Error'] <= 0.50).sum() / len(df) * 100\n",
    "within_075 = (df['Absolute_Error'] <= 0.75).sum() / len(df) * 100\n",
    "within_100 = (df['Absolute_Error'] <= 1.00).sum() / len(df) * 100\n",
    "\n",
    "print(\"\\nğŸ“ˆ CLINICAL ACCURACY:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Within Â±0.25 D:  {within_025:.1f}% of eyes\")\n",
    "print(f\"  Within Â±0.50 D:  {within_050:.1f}% of eyes\")\n",
    "print(f\"  Within Â±0.75 D:  {within_075:.1f}% of eyes\")\n",
    "print(f\"  Within Â±1.00 D:  {within_100:.1f}% of eyes\")\n",
    "\n",
    "print(\"\\nğŸ¯ CLINICAL TARGETS:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Modern standard: >70% within Â±0.50 D\")\n",
    "print(\"â€¢ Acceptable: >90% within Â±1.00 D\")\n",
    "print(f\"â€¢ Our baseline: {within_050:.1f}% within Â±0.50 D\")\n",
    "print(\"\\nâš ï¸ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\")\n",
    "print(\"This is why we need optimization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ridge_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RIDGE REGRESSION FEATURE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ” WHY START WITH RIDGE?\n",
      "--------------------------------------------------\n",
      "â€¢ Ridge regression identifies important features\n",
      "â€¢ Helps us understand what drives prediction errors\n",
      "â€¢ Guides our formula optimization strategy\n",
      "â€¢ If CCT features are important, our hypothesis is correct!\n",
      "\n",
      "ğŸ“Š CREATING FEATURES:\n",
      "--------------------------------------------------\n",
      "Created 12 features including CCT interactions\n",
      "\n",
      "ğŸ† TOP 10 MOST IMPORTANT FEATURES:\n",
      "--------------------------------------------------\n",
      "  CCT_ratio_AL         Coef=+1.4393\n",
      "  CCT_x_AL             Coef=-1.0791\n",
      "  CCT_squared          Coef=-0.6778\n",
      "  IOL Power            Coef=-0.5327\n",
      "  CCT_x_K              Coef=+0.5166\n",
      "  Bio-Ks               Coef=-0.2195\n",
      "  K_avg                Coef=-0.2122\n",
      "  Bio-Kf               Coef=-0.1828\n",
      "  Bio-AL               Coef=+0.1440\n",
      "  CCT_norm             Coef=-0.0331\n",
      "\n",
      "ğŸ’¡ KEY FINDINGS:\n",
      "--------------------------------------------------\n",
      "â€¢ CCT-related features account for 74.7% of total importance\n",
      "â€¢ Top feature: CCT_ratio_AL\n",
      "â€¢ CCT/AL ratio is among top 3 features!\n",
      "â€¢ This validates that CCT relative to eye size matters\n",
      "\n",
      "âœ… HYPOTHESIS CONFIRMED:\n",
      "CCT features dominate prediction - our CCT-dependent approach is justified!\n",
      "\n",
      "ğŸ¯ OPTIMIZATION STRATEGY BASED ON RIDGE:\n",
      "--------------------------------------------------\n",
      "1. Make optical parameters CCT-dependent (nc, k_index)\n",
      "2. Consider CCT/AL ratio in corrections\n",
      "3. Account for CCT interactions with other measurements\n"
     ]
    }
   ],
   "source": [
    "# RIDGE REGRESSION ANALYSIS - IDENTIFYING IMPORTANT FEATURES\n",
    "# ===========================================================\n",
    "# PURPOSE: Use machine learning to identify which features matter most\n",
    "# This will guide our optimization strategy\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RIDGE REGRESSION FEATURE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ” WHY START WITH RIDGE?\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Ridge regression identifies important features\")\n",
    "print(\"â€¢ Helps us understand what drives prediction errors\")\n",
    "print(\"â€¢ Guides our formula optimization strategy\")\n",
    "print(\"â€¢ If CCT features are important, our hypothesis is correct!\")\n",
    "\n",
    "# Create feature matrix with interactions\n",
    "print(\"\\nğŸ“Š CREATING FEATURES:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "features = []\n",
    "feature_names = []\n",
    "\n",
    "# Basic features\n",
    "for col in ['Bio-AL', 'Bio-Ks', 'Bio-Kf', 'IOL Power', 'CCT']:\n",
    "    features.append(df[col].values)\n",
    "    feature_names.append(col)\n",
    "\n",
    "# Add K_avg\n",
    "features.append(df['K_avg'].values)\n",
    "feature_names.append('K_avg')\n",
    "\n",
    "# CCT-derived features\n",
    "df['CCT_squared'] = df['CCT'] ** 2\n",
    "df['CCT_deviation'] = df['CCT'] - 550\n",
    "df['CCT_norm'] = (df['CCT'] - 600) / 100\n",
    "\n",
    "features.extend([\n",
    "    df['CCT_squared'].values,\n",
    "    df['CCT_deviation'].values,\n",
    "    df['CCT_norm'].values\n",
    "])\n",
    "feature_names.extend(['CCT_squared', 'CCT_deviation', 'CCT_norm'])\n",
    "\n",
    "# Interaction terms\n",
    "df['CCT_x_AL'] = df['CCT'] * df['Bio-AL']\n",
    "df['CCT_x_K'] = df['CCT'] * df['K_avg']\n",
    "df['CCT_ratio_AL'] = df['CCT'] / df['Bio-AL']\n",
    "\n",
    "features.extend([\n",
    "    df['CCT_x_AL'].values,\n",
    "    df['CCT_x_K'].values,\n",
    "    df['CCT_ratio_AL'].values\n",
    "])\n",
    "feature_names.extend(['CCT_x_AL', 'CCT_x_K', 'CCT_ratio_AL'])\n",
    "\n",
    "X = np.column_stack(features)\n",
    "y = df['PostOP Spherical Equivalent'].values\n",
    "\n",
    "print(f\"Created {len(feature_names)} features including CCT interactions\")\n",
    "\n",
    "# Standardize and train Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train Ridge to get feature importance\n",
    "ridge_analysis = Ridge(alpha=1.0)\n",
    "ridge_analysis.fit(X_scaled, y)\n",
    "\n",
    "# Get feature importance from coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': ridge_analysis.coef_,\n",
    "    'Abs_Coefficient': np.abs(ridge_analysis.coef_)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ† TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "print(\"-\" * 50)\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"  {row['Feature']:20} Coef={row['Coefficient']:+.4f}\")\n",
    "\n",
    "# Analyze CCT importance\n",
    "cct_features = feature_importance[feature_importance['Feature'].str.contains('CCT')]\n",
    "cct_importance = cct_features['Abs_Coefficient'].sum()\n",
    "total_importance = feature_importance['Abs_Coefficient'].sum()\n",
    "cct_percentage = (cct_importance / total_importance) * 100\n",
    "\n",
    "print(\"\\nğŸ’¡ KEY FINDINGS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ CCT-related features account for {cct_percentage:.1f}% of total importance\")\n",
    "print(f\"â€¢ Top feature: {feature_importance.iloc[0]['Feature']}\")\n",
    "\n",
    "if 'CCT_ratio_AL' in feature_importance.head(3)['Feature'].values:\n",
    "    print(\"â€¢ CCT/AL ratio is among top 3 features!\")\n",
    "    print(\"â€¢ This validates that CCT relative to eye size matters\")\n",
    "\n",
    "if cct_percentage > 50:\n",
    "    print(\"\\nâœ… HYPOTHESIS CONFIRMED:\")\n",
    "    print(\"CCT features dominate prediction - our CCT-dependent approach is justified!\")\n",
    "\n",
    "print(\"\\nğŸ¯ OPTIMIZATION STRATEGY BASED ON RIDGE:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. Make optical parameters CCT-dependent (nc, k_index)\")\n",
    "print(\"2. Consider CCT/AL ratio in corrections\")\n",
    "print(\"3. Account for CCT interactions with other measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rt23gheoiv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ MULTI-SEED NESTED CROSS-VALIDATION:\n",
      "--------------------------------------------------\n",
      "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "â€¢ Each seed: 75% train, 25% test\n",
      "â€¢ Inner: 5-fold CV on training set\n",
      "â€¢ Results averaged across seeds for robustness\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "  CV MAE: 1.1292 Â± 0.3484 D\n",
      "  Train MAE: 1.0876, Test MAE: 1.0855\n",
      "  Test: Baseline=1.1712, Optimized=1.0855\n",
      "  Improvement: 7.3%\n",
      "  âœ… Good generalization: Test only -0.2% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "  CV MAE: 1.2084 Â± 0.1578 D\n",
      "  Train MAE: 1.0749, Test MAE: 1.1508\n",
      "  Test: Baseline=1.0813, Optimized=1.1508\n",
      "  Improvement: -6.4%\n",
      "  âœ… Good generalization: Test only 7.1% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "  CV MAE: 1.0703 Â± 0.1241 D\n",
      "  Train MAE: 0.9451, Test MAE: 1.8925\n",
      "  Test: Baseline=1.5004, Optimized=1.8925\n",
      "  Improvement: -26.1%\n",
      "  âš ï¸ Overfitting detected: Test 100.2% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "  CV MAE: 1.1882 Â± 0.2457 D\n",
      "  Train MAE: 1.0261, Test MAE: 1.2253\n",
      "  Test: Baseline=1.1299, Optimized=1.2253\n",
      "  Improvement: -8.4%\n",
      "  âš ï¸ Mild overfitting: Test 19.4% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "  CV MAE: 1.0602 Â± 0.1224 D\n",
      "  Train MAE: 0.9942, Test MAE: 1.3370\n",
      "  Test: Baseline=1.3515, Optimized=1.3370\n",
      "  Improvement: 1.1%\n",
      "  âš ï¸ Overfitting detected: Test 34.5% worse than train\n",
      "\n",
      "================================================================================\n",
      "PARAMETER OPTIMIZATION - MULTI-SEED SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\n",
      "--------------------------------------------------\n",
      "  Seed  42: MAE=1.0855 D, Improvement=7.3%\n",
      "  Seed 123: MAE=1.1508 D, Improvement=-6.4%\n",
      "  Seed 456: MAE=1.8925 D, Improvement=-26.1%\n",
      "  Seed 789: MAE=1.2253 D, Improvement=-8.4%\n",
      "  Seed 2025: MAE=1.3370 D, Improvement=1.1%\n",
      "\n",
      "ğŸ“ˆ STATISTICAL SUMMARY:\n",
      "--------------------------------------------------\n",
      "  Baseline MAE:      1.2469 Â± 0.1562 D\n",
      "  Train MAE:         1.0256 Â± 0.0524 D\n",
      "  Test MAE:          1.3382 Â± 0.2895 D\n",
      "  Mean Improvement:  -6.5 Â± 11.3%\n",
      "  Best seed:         42 (MAE=1.0855)\n",
      "  Worst seed:        456 (MAE=1.8925)\n",
      "\n",
      "ğŸ” OVERFITTING ANALYSIS:\n",
      "--------------------------------------------------\n",
      "  Mean overfit ratio: 32.2%\n",
      "  (Test MAE is 32.2% worse than Train MAE on average)\n",
      "  âš ï¸ Significant overfitting - consider regularization\n",
      "\n",
      "âœ… CONSENSUS PARAMETERS (averaged across seeds):\n",
      "--------------------------------------------------\n",
      "  nc_base              = +1.4842 Â± 0.0160\n",
      "  nc_cct_coef          = +0.0210 Â± 0.0750\n",
      "  k_index_base         = +1.4668 Â± 0.0155\n",
      "  k_index_cct_coef     = +0.0105 Â± 0.0660\n",
      "  acd_offset_base      = +2.5730 Â± 0.2624\n",
      "  acd_offset_cct_coef  = +1.2976 Â± 1.6383\n",
      "\n",
      "ğŸ’¡ ROBUSTNESS ANALYSIS:\n",
      "--------------------------------------------------\n",
      "âš ï¸ Moderate stability: CV=21.6% (some variation across seeds)\n",
      "\n",
      "ğŸ“Š Range of results: 1.0855 - 1.8925 D\n",
      "   This 0.8070 D range shows the impact of data split\n"
     ]
    }
   ],
   "source": [
    "# PARAMETER OPTIMIZATION WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
    "# =============================================\n",
    "# PURPOSE: Optimize SRK/T2 parameters with nested CV for robust validation\n",
    "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ¯ MULTI-SEED NESTED CROSS-VALIDATION:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"â€¢ Each seed: 75% train, 25% test\")\n",
    "print(\"â€¢ Inner: 5-fold CV on training set\")\n",
    "print(\"â€¢ Results averaged across seeds for robustness\")\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "def calculate_mae_param(params, df_data):\n",
    "    \"\"\"Calculate MAE for parameter optimization\"\"\"\n",
    "    nc_base, nc_cct_coef, k_index_base, k_index_cct_coef, acd_offset_base, acd_offset_cct_coef = params\n",
    "    \n",
    "    predictions = []\n",
    "    for _, row in df_data.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        nc = nc_base + nc_cct_coef * cct_norm\n",
    "        k_index = k_index_base + k_index_cct_coef * cct_norm\n",
    "        acd_offset = acd_offset_base + acd_offset_cct_coef * cct_norm\n",
    "        \n",
    "        pred = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc,\n",
    "            k_index=k_index\n",
    "        )\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    mae = mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "    return mae\n",
    "\n",
    "bounds_param = [\n",
    "    (1.20, 1.50),    # nc_base\n",
    "    (-0.20, 0.20),   # nc_cct_coef  \n",
    "    (1.20, 1.60),    # k_index_base\n",
    "    (-0.30, 0.30),   # k_index_cct_coef\n",
    "    (-3.0, 3.0),     # acd_offset_base\n",
    "    (-3.0, 3.0),     # acd_offset_cct_coef\n",
    "]\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_param = []\n",
    "seed_test_maes_param = []\n",
    "seed_train_maes_param = []  # NEW: Track training MAEs\n",
    "seed_baseline_maes_param = []\n",
    "seed_improvements_param = []\n",
    "seed_overfit_ratios_param = []  # NEW: Track overfitting\n",
    "\n",
    "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT with current seed\n",
    "    X_train_param, X_test_param = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_param['K_avg'] = (X_train_param['Bio-Ks'] + X_train_param['Bio-Kf']) / 2\n",
    "    X_test_param['K_avg'] = (X_test_param['Bio-Ks'] + X_test_param['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"ğŸ“Š Split: {len(X_train_param)} train, {len(X_test_param)} test\")\n",
    "    \n",
    "    # INNER K-FOLD CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    fold_params = []\n",
    "    fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_param), 1):\n",
    "        fold_train = X_train_param.iloc[train_idx]\n",
    "        fold_val = X_train_param.iloc[val_idx]\n",
    "        \n",
    "        # Optimize on fold\n",
    "        result_fold = differential_evolution(\n",
    "            lambda p: calculate_mae_param(p, fold_train),\n",
    "            bounds_param,\n",
    "            maxiter=30,\n",
    "            seed=SEED + fold_num,\n",
    "            workers=1,\n",
    "            updating='deferred',\n",
    "            disp=False\n",
    "        )\n",
    "        \n",
    "        fold_params.append(result_fold.x)\n",
    "        val_mae = calculate_mae_param(result_fold.x, fold_val)\n",
    "        fold_maes.append(val_mae)\n",
    "    \n",
    "    # Average parameters from folds\n",
    "    avg_params = np.mean(fold_params, axis=0)\n",
    "    avg_cv_mae = np.mean(fold_maes)\n",
    "    std_cv_mae = np.std(fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    result_final = differential_evolution(\n",
    "        lambda p: calculate_mae_param(p, X_train_param),\n",
    "        bounds_param,\n",
    "        maxiter=50,\n",
    "        seed=SEED,\n",
    "        workers=1,\n",
    "        updating='deferred',\n",
    "        disp=False\n",
    "    )\n",
    "    \n",
    "    final_params = result_final.x\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    mae_train = calculate_mae_param(final_params, X_train_param)\n",
    "    \n",
    "    # TEST ON HOLDOUT\n",
    "    # Calculate baseline\n",
    "    X_test_param['SRKT2_Baseline'] = X_test_param.apply(\n",
    "        lambda row: calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant']\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    # Apply optimized parameters\n",
    "    predictions_test = []\n",
    "    for _, row in X_test_param.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        nc = final_params[0] + final_params[1] * cct_norm\n",
    "        k_index = final_params[2] + final_params[3] * cct_norm\n",
    "        acd_offset = final_params[4] + final_params[5] * cct_norm\n",
    "        \n",
    "        pred = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc,\n",
    "            k_index=k_index\n",
    "        )\n",
    "        predictions_test.append(pred)\n",
    "    \n",
    "    mae_baseline = np.abs(X_test_param['SRKT2_Baseline'] - X_test_param['PostOP Spherical Equivalent']).mean()\n",
    "    mae_optimized = mean_absolute_error(X_test_param['PostOP Spherical Equivalent'], predictions_test)\n",
    "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
    "    \n",
    "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
    "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
    "    if overfit_ratio > 20:\n",
    "        print(f\"  âš ï¸ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    elif overfit_ratio > 10:\n",
    "        print(f\"  âš ï¸ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    else:\n",
    "        print(f\"  âœ… Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_param.append(final_params)\n",
    "    seed_test_maes_param.append(mae_optimized)\n",
    "    seed_train_maes_param.append(mae_train)\n",
    "    seed_baseline_maes_param.append(mae_baseline)\n",
    "    seed_improvements_param.append(improvement)\n",
    "    seed_overfit_ratios_param.append(overfit_ratio)\n",
    "\n",
    "# MULTI-SEED SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARAMETER OPTIMIZATION - MULTI-SEED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_param[i]:.4f} D, Improvement={seed_improvements_param[i]:.1f}%\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ STATISTICAL SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_param):.4f} Â± {np.std(seed_baseline_maes_param):.4f} D\")\n",
    "print(f\"  Train MAE:         {np.mean(seed_train_maes_param):.4f} Â± {np.std(seed_train_maes_param):.4f} D\")\n",
    "print(f\"  Test MAE:          {np.mean(seed_test_maes_param):.4f} Â± {np.std(seed_test_maes_param):.4f} D\")\n",
    "print(f\"  Mean Improvement:  {np.mean(seed_improvements_param):.1f} Â± {np.std(seed_improvements_param):.1f}%\")\n",
    "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_param)]} (MAE={min(seed_test_maes_param):.4f})\")\n",
    "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_param)]} (MAE={max(seed_test_maes_param):.4f})\")\n",
    "\n",
    "# OVERFITTING ANALYSIS\n",
    "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_param):.1f}%\")\n",
    "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_param):.1f}% worse than Train MAE on average)\")\n",
    "\n",
    "if np.mean(seed_overfit_ratios_param) < 10:\n",
    "    print(\"  âœ… Excellent generalization - minimal overfitting\")\n",
    "elif np.mean(seed_overfit_ratios_param) < 20:\n",
    "    print(\"  âœ… Good generalization - acceptable overfitting\")\n",
    "else:\n",
    "    print(\"  âš ï¸ Significant overfitting - consider regularization\")\n",
    "\n",
    "# Average parameters across seeds\n",
    "avg_params_all_seeds = np.mean(seed_results_param, axis=0)\n",
    "std_params_all_seeds = np.std(seed_results_param, axis=0)\n",
    "\n",
    "print(\"\\nâœ… CONSENSUS PARAMETERS (averaged across seeds):\")\n",
    "print(\"-\" * 50)\n",
    "param_names = ['nc_base', 'nc_cct_coef', 'k_index_base', 'k_index_cct_coef', 'acd_offset_base', 'acd_offset_cct_coef']\n",
    "for i, name in enumerate(param_names):\n",
    "    print(f\"  {name:20} = {avg_params_all_seeds[i]:+.4f} Â± {std_params_all_seeds[i]:.4f}\")\n",
    "\n",
    "# Store in global results dictionary\n",
    "multi_seed_results['parameter'] = {\n",
    "    'test_maes': seed_test_maes_param,\n",
    "    'train_maes': seed_train_maes_param,\n",
    "    'baseline_maes': seed_baseline_maes_param,\n",
    "    'improvements': seed_improvements_param,\n",
    "    'overfit_ratios': seed_overfit_ratios_param,\n",
    "    'mean_mae': np.mean(seed_test_maes_param),\n",
    "    'std_mae': np.std(seed_test_maes_param),\n",
    "    'mean_improvement': np.mean(seed_improvements_param)\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ’¡ ROBUSTNESS ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "mae_cv = np.std(seed_test_maes_param) / np.mean(seed_test_maes_param) * 100\n",
    "if mae_cv < 5:\n",
    "    print(f\"âœ… Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
    "elif mae_cv < 10:\n",
    "    print(f\"âœ… Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Range of results: {min(seed_test_maes_param):.4f} - {max(seed_test_maes_param):.4f} D\")\n",
    "print(f\"   This {max(seed_test_maes_param)-min(seed_test_maes_param):.4f} D range shows the impact of data split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "829090ggs0r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ MULTI-SEED NESTED CV STRATEGY:\n",
      "--------------------------------------------------\n",
      "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "â€¢ Each seed: 75/25 train/test split\n",
      "â€¢ Inner: 5-fold CV on training\n",
      "â€¢ Find stable multiplicative factors across seeds\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "  CV MAE: 0.8196 Â± 0.2064 D\n",
      "  Final params: mâ‚€=-0.0379, mâ‚=-0.0121, mâ‚‚=-0.0379\n",
      "  Train MAE: 0.7998, Test MAE: 1.1124\n",
      "  Test: Baseline=1.1712, Optimized=1.1124\n",
      "  Improvement: 5.0%\n",
      "  âš ï¸ Overfitting detected: Test 39.1% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "  CV MAE: 0.9491 Â± 0.1224 D\n",
      "  Final params: mâ‚€=-0.0382, mâ‚=-0.0058, mâ‚‚=-0.0379\n",
      "  Train MAE: 0.9374, Test MAE: 0.6988\n",
      "  Test: Baseline=1.0813, Optimized=0.6988\n",
      "  Improvement: 35.4%\n",
      "  âœ… Good generalization: Test only -25.5% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "  CV MAE: 0.8517 Â± 0.1288 D\n",
      "  Final params: mâ‚€=-0.0348, mâ‚=-0.0074, mâ‚‚=-0.0358\n",
      "  Train MAE: 0.8244, Test MAE: 1.0451\n",
      "  Test: Baseline=1.5004, Optimized=1.0451\n",
      "  Improvement: 30.3%\n",
      "  âš ï¸ Overfitting detected: Test 26.8% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "  CV MAE: 0.9495 Â± 0.1120 D\n",
      "  Final params: mâ‚€=-0.0642, mâ‚=0.0812, mâ‚‚=-0.0370\n",
      "  Train MAE: 0.8891, Test MAE: 0.8320\n",
      "  Test: Baseline=1.1299, Optimized=0.8320\n",
      "  Improvement: 26.4%\n",
      "  âœ… Good generalization: Test only -6.4% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "  CV MAE: 0.8539 Â± 0.1649 D\n",
      "  Final params: mâ‚€=-0.0387, mâ‚=-0.0091, mâ‚‚=-0.0387\n",
      "  Train MAE: 0.8461, Test MAE: 0.9789\n",
      "  Test: Baseline=1.3515, Optimized=0.9789\n",
      "  Improvement: 27.6%\n",
      "  âš ï¸ Mild overfitting: Test 15.7% worse than train\n",
      "\n",
      "================================================================================\n",
      "MULTIPLICATIVE CORRECTION - MULTI-SEED SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\n",
      "--------------------------------------------------\n",
      "  Seed  42: MAE=1.1124 D, Improvement=5.0%\n",
      "  Seed 123: MAE=0.6988 D, Improvement=35.4%\n",
      "  Seed 456: MAE=1.0451 D, Improvement=30.3%\n",
      "  Seed 789: MAE=0.8320 D, Improvement=26.4%\n",
      "  Seed 2025: MAE=0.9789 D, Improvement=27.6%\n",
      "\n",
      "ğŸ“ˆ STATISTICAL SUMMARY:\n",
      "--------------------------------------------------\n",
      "  Baseline MAE:      1.2469 Â± 0.1562 D\n",
      "  Train MAE:         0.8594 Â± 0.0488 D\n",
      "  Test MAE:          0.9335 Â± 0.1496 D\n",
      "  Mean Improvement:  24.9 Â± 10.4%\n",
      "  Best seed:         123 (MAE=0.6988)\n",
      "  Worst seed:        42 (MAE=1.1124)\n",
      "\n",
      "ğŸ” OVERFITTING ANALYSIS:\n",
      "--------------------------------------------------\n",
      "  Mean overfit ratio: 9.9%\n",
      "  (Test MAE is 9.9% worse than Train MAE on average)\n",
      "  âœ… Excellent generalization - minimal overfitting\n",
      "\n",
      "âœ… CONSENSUS PARAMETERS (averaged across seeds):\n",
      "--------------------------------------------------\n",
      "  mâ‚€ (constant):     -0.0428 Â± 0.0108\n",
      "  mâ‚ (CCT coef):     +0.0094 Â± 0.0360\n",
      "  mâ‚‚ (ratio coef):   -0.0375 Â± 0.0010\n",
      "\n",
      "ğŸ“ CONSENSUS CORRECTION FORMULA:\n",
      "--------------------------------------------------\n",
      "Corrected_REF = Standard_SRK/T2 Ã— Correction_Factor\n",
      "Correction_Factor = 1 -0.0428 +0.0094Ã—CCT_norm -0.0375Ã—(CCT/AL)\n",
      "\n",
      "ğŸ’¡ ROBUSTNESS ANALYSIS:\n",
      "--------------------------------------------------\n",
      "âš ï¸ Moderate stability: CV=16.0% (some variation across seeds)\n",
      "\n",
      "ğŸ“Š Range of results: 0.6988 - 1.1124 D\n",
      "   This 0.4136 D range shows the impact of data split\n",
      "\n",
      "ğŸ“Š Parameter consistency across seeds:\n",
      "  mâ‚€: min=-0.0642, max=-0.0348, range=0.0294\n",
      "  mâ‚: min=-0.0121, max=0.0812, range=0.0933\n",
      "  mâ‚‚: min=-0.0387, max=-0.0358, range=0.0029\n"
     ]
    }
   ],
   "source": [
    "# MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED\n",
    "# ====================================\n",
    "# PURPOSE: Multiplicative correction with nested CV for robust validation\n",
    "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ¯ MULTI-SEED NESTED CV STRATEGY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
    "print(\"â€¢ Inner: 5-fold CV on training\")\n",
    "print(\"â€¢ Find stable multiplicative factors across seeds\")\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "def multiplicative_objective(params, df_data):\n",
    "    \"\"\"Objective function for multiplicative correction\"\"\"\n",
    "    m0, m1, m2 = params\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for _, row in df_data.iterrows():\n",
    "        base_pred = row['SRKT2_Prediction']\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        \n",
    "        correction_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "        corrected_pred = base_pred * correction_factor\n",
    "        \n",
    "        predictions.append(corrected_pred)\n",
    "        actuals.append(row['PostOP Spherical Equivalent'])\n",
    "    \n",
    "    return mean_absolute_error(actuals, predictions)\n",
    "\n",
    "x0_mult = [0, 0, 0]\n",
    "bounds_mult = [(-0.5, 0.5), (-0.5, 0.5), (-0.5, 0.5)]\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_mult = []\n",
    "seed_test_maes_mult = []\n",
    "seed_train_maes_mult = []  # NEW: Track training MAEs\n",
    "seed_baseline_maes_mult = []\n",
    "seed_improvements_mult = []\n",
    "seed_overfit_ratios_mult = []  # NEW: Track overfitting\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT with current seed\n",
    "    X_train_mult, X_test_mult = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_mult['K_avg'] = (X_train_mult['Bio-Ks'] + X_train_mult['Bio-Kf']) / 2\n",
    "    X_test_mult['K_avg'] = (X_test_mult['Bio-Ks'] + X_test_mult['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"ğŸ“Š Split: {len(X_train_mult)} train, {len(X_test_mult)} test\")\n",
    "    \n",
    "    # Calculate baseline SRK/T2 for all data\n",
    "    for dataset in [X_train_mult, X_test_mult]:\n",
    "        dataset['SRKT2_Prediction'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    # INNER K-FOLD CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    fold_params = []\n",
    "    fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_mult), 1):\n",
    "        fold_train = X_train_mult.iloc[train_idx]\n",
    "        fold_val = X_train_mult.iloc[val_idx]\n",
    "        \n",
    "        # Optimize on fold training\n",
    "        result_fold = minimize(\n",
    "            lambda p: multiplicative_objective(p, fold_train),\n",
    "            x0_mult,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds_mult\n",
    "        )\n",
    "        \n",
    "        fold_params.append(result_fold.x)\n",
    "        val_mae = multiplicative_objective(result_fold.x, fold_val)\n",
    "        fold_maes.append(val_mae)\n",
    "    \n",
    "    # Average across folds\n",
    "    avg_params = np.mean(fold_params, axis=0)\n",
    "    avg_cv_mae = np.mean(fold_maes)\n",
    "    std_cv_mae = np.std(fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    result_mult = minimize(\n",
    "        lambda p: multiplicative_objective(p, X_train_mult),\n",
    "        x0_mult,\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds_mult\n",
    "    )\n",
    "    m0_opt, m1_opt, m2_opt = result_mult.x\n",
    "    \n",
    "    print(f\"  Final params: mâ‚€={m0_opt:.4f}, mâ‚={m1_opt:.4f}, mâ‚‚={m2_opt:.4f}\")\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    mae_train = multiplicative_objective([m0_opt, m1_opt, m2_opt], X_train_mult)\n",
    "    \n",
    "    # TEST ON HOLDOUT\n",
    "    predictions_mult_test = []\n",
    "    for _, row in X_test_mult.iterrows():\n",
    "        base_pred = row['SRKT2_Prediction']\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        \n",
    "        correction_factor = 1 + m0_opt + m1_opt * cct_norm + m2_opt * cct_ratio\n",
    "        corrected_pred = base_pred * correction_factor\n",
    "        predictions_mult_test.append(corrected_pred)\n",
    "    \n",
    "    mae_baseline = np.abs(X_test_mult['SRKT2_Prediction'] - X_test_mult['PostOP Spherical Equivalent']).mean()\n",
    "    mae_optimized = mean_absolute_error(X_test_mult['PostOP Spherical Equivalent'], predictions_mult_test)\n",
    "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
    "    \n",
    "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
    "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
    "    if overfit_ratio > 20:\n",
    "        print(f\"  âš ï¸ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    elif overfit_ratio > 10:\n",
    "        print(f\"  âš ï¸ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    else:\n",
    "        print(f\"  âœ… Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_mult.append([m0_opt, m1_opt, m2_opt])\n",
    "    seed_test_maes_mult.append(mae_optimized)\n",
    "    seed_train_maes_mult.append(mae_train)\n",
    "    seed_baseline_maes_mult.append(mae_baseline)\n",
    "    seed_improvements_mult.append(improvement)\n",
    "    seed_overfit_ratios_mult.append(overfit_ratio)\n",
    "\n",
    "# MULTI-SEED SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTIPLICATIVE CORRECTION - MULTI-SEED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_mult[i]:.4f} D, Improvement={seed_improvements_mult[i]:.1f}%\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ STATISTICAL SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_mult):.4f} Â± {np.std(seed_baseline_maes_mult):.4f} D\")\n",
    "print(f\"  Train MAE:         {np.mean(seed_train_maes_mult):.4f} Â± {np.std(seed_train_maes_mult):.4f} D\")\n",
    "print(f\"  Test MAE:          {np.mean(seed_test_maes_mult):.4f} Â± {np.std(seed_test_maes_mult):.4f} D\")\n",
    "print(f\"  Mean Improvement:  {np.mean(seed_improvements_mult):.1f} Â± {np.std(seed_improvements_mult):.1f}%\")\n",
    "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_mult)]} (MAE={min(seed_test_maes_mult):.4f})\")\n",
    "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_mult)]} (MAE={max(seed_test_maes_mult):.4f})\")\n",
    "\n",
    "# OVERFITTING ANALYSIS\n",
    "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_mult):.1f}%\")\n",
    "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_mult):.1f}% worse than Train MAE on average)\")\n",
    "\n",
    "if np.mean(seed_overfit_ratios_mult) < 10:\n",
    "    print(\"  âœ… Excellent generalization - minimal overfitting\")\n",
    "elif np.mean(seed_overfit_ratios_mult) < 20:\n",
    "    print(\"  âœ… Good generalization - acceptable overfitting\")\n",
    "else:\n",
    "    print(\"  âš ï¸ Significant overfitting - consider regularization\")\n",
    "\n",
    "# Average parameters across seeds\n",
    "avg_params_all_seeds = np.mean(seed_results_mult, axis=0)\n",
    "std_params_all_seeds = np.std(seed_results_mult, axis=0)\n",
    "\n",
    "print(\"\\nâœ… CONSENSUS PARAMETERS (averaged across seeds):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  mâ‚€ (constant):     {avg_params_all_seeds[0]:+.4f} Â± {std_params_all_seeds[0]:.4f}\")\n",
    "print(f\"  mâ‚ (CCT coef):     {avg_params_all_seeds[1]:+.4f} Â± {std_params_all_seeds[1]:.4f}\")\n",
    "print(f\"  mâ‚‚ (ratio coef):   {avg_params_all_seeds[2]:+.4f} Â± {std_params_all_seeds[2]:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“ CONSENSUS CORRECTION FORMULA:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Corrected_REF = Standard_SRK/T2 Ã— Correction_Factor\")\n",
    "print(f\"Correction_Factor = 1 {avg_params_all_seeds[0]:+.4f} {avg_params_all_seeds[1]:+.4f}Ã—CCT_norm {avg_params_all_seeds[2]:+.4f}Ã—(CCT/AL)\")\n",
    "\n",
    "# Store in global results dictionary\n",
    "multi_seed_results['multiplicative'] = {\n",
    "    'test_maes': seed_test_maes_mult,\n",
    "    'train_maes': seed_train_maes_mult,\n",
    "    'baseline_maes': seed_baseline_maes_mult,\n",
    "    'improvements': seed_improvements_mult,\n",
    "    'overfit_ratios': seed_overfit_ratios_mult,\n",
    "    'mean_mae': np.mean(seed_test_maes_mult),\n",
    "    'std_mae': np.std(seed_test_maes_mult),\n",
    "    'mean_improvement': np.mean(seed_improvements_mult)\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ’¡ ROBUSTNESS ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "mae_cv = np.std(seed_test_maes_mult) / np.mean(seed_test_maes_mult) * 100\n",
    "if mae_cv < 5:\n",
    "    print(f\"âœ… Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
    "elif mae_cv < 10:\n",
    "    print(f\"âœ… Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Range of results: {min(seed_test_maes_mult):.4f} - {max(seed_test_maes_mult):.4f} D\")\n",
    "print(f\"   This {max(seed_test_maes_mult)-min(seed_test_maes_mult):.4f} D range shows the impact of data split\")\n",
    "\n",
    "# Parameter consistency check\n",
    "print(f\"\\nğŸ“Š Parameter consistency across seeds:\")\n",
    "for i, param_name in enumerate(['mâ‚€', 'mâ‚', 'mâ‚‚']):\n",
    "    param_values = [p[i] for p in seed_results_mult]\n",
    "    print(f\"  {param_name}: min={min(param_values):.4f}, max={max(param_values):.4f}, range={max(param_values)-min(param_values):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9g3yzsp3n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ADDITIVE CORRECTION WITH POLYNOMIAL CCT TERMS - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ TESTING POLYNOMIAL (QUADRATIC & CUBIC) CCT TERMS:\n",
      "--------------------------------------------------\n",
      "â€¢ Linear model: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg\n",
      "â€¢ Quadratic model: + a4*CCT_normÂ²\n",
      "â€¢ Cubic model: + a4*CCT_normÂ² + a5*CCT_normÂ³\n",
      "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "â€¢ Each seed: 75/25 train/test split\n",
      "â€¢ Inner: 5-fold cross-validation\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS WITH POLYNOMIAL TERMS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ Testing LINEAR model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.6012   Fold 2/5: MAE=1.1554   Fold 3/5: MAE=1.6312   Fold 4/5: MAE=1.1934   Fold 5/5: MAE=1.4080 \n",
      "  CV MAE: 1.1979 Â± 0.3435 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (linear):\n",
      "    Train MAE: 1.2013 D\n",
      "    Test MAE:  1.1585 D\n",
      "    Baseline:  1.1712 D\n",
      "    Improvement: 1.1%\n",
      "    Overfit ratio: 0.964\n",
      "\n",
      "ğŸ“ Testing QUADRATIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.5980   Fold 2/5: MAE=1.1750   Fold 3/5: MAE=1.6769   Fold 4/5: MAE=1.2426   Fold 5/5: MAE=1.4406 \n",
      "  CV MAE: 1.2266 Â± 0.3596 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (quadratic):\n",
      "    Train MAE: 1.1489 D\n",
      "    Test MAE:  1.1328 D\n",
      "    Baseline:  1.1712 D\n",
      "    Improvement: 3.3%\n",
      "    Overfit ratio: 0.986\n",
      "\n",
      "ğŸ“ Testing CUBIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.6249   Fold 2/5: MAE=1.1426   Fold 3/5: MAE=1.7150   Fold 4/5: MAE=1.2802   Fold 5/5: MAE=1.7898 \n",
      "  CV MAE: 1.3105 Â± 0.4225 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (cubic):\n",
      "    Train MAE: 1.0867 D\n",
      "    Test MAE:  1.3734 D\n",
      "    Baseline:  1.1712 D\n",
      "    Improvement: -17.3%\n",
      "    Overfit ratio: 1.264\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ Testing LINEAR model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.4338   Fold 2/5: MAE=1.0455   Fold 3/5: MAE=1.1020   Fold 4/5: MAE=1.1877   Fold 5/5: MAE=1.3391 \n",
      "  CV MAE: 1.2216 Â± 0.1451 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (linear):\n",
      "    Train MAE: 1.1760 D\n",
      "    Test MAE:  1.0196 D\n",
      "    Baseline:  1.0813 D\n",
      "    Improvement: 5.7%\n",
      "    Overfit ratio: 0.867\n",
      "\n",
      "ğŸ“ Testing QUADRATIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.4354   Fold 2/5: MAE=1.0467   Fold 3/5: MAE=1.2342   Fold 4/5: MAE=1.1170   Fold 5/5: MAE=1.3185 \n",
      "  CV MAE: 1.2303 Â± 0.1388 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (quadratic):\n",
      "    Train MAE: 1.2005 D\n",
      "    Test MAE:  0.9631 D\n",
      "    Baseline:  1.0813 D\n",
      "    Improvement: 10.9%\n",
      "    Overfit ratio: 0.802\n",
      "\n",
      "ğŸ“ Testing CUBIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.4453   Fold 2/5: MAE=1.0154   Fold 3/5: MAE=1.3413   Fold 4/5: MAE=1.2587   Fold 5/5: MAE=1.3644 \n",
      "  CV MAE: 1.2850 Â± 0.1473 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (cubic):\n",
      "    Train MAE: 1.2034 D\n",
      "    Test MAE:  1.0039 D\n",
      "    Baseline:  1.0813 D\n",
      "    Improvement: 7.2%\n",
      "    Overfit ratio: 0.834\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ Testing LINEAR model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.9302   Fold 2/5: MAE=1.0748   Fold 3/5: MAE=1.0611   Fold 4/5: MAE=0.9925   Fold 5/5: MAE=1.2311 \n",
      "  CV MAE: 1.0579 Â± 0.1009 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (linear):\n",
      "    Train MAE: 1.0164 D\n",
      "    Test MAE:  1.5058 D\n",
      "    Baseline:  1.5004 D\n",
      "    Improvement: -0.4%\n",
      "    Overfit ratio: 1.482\n",
      "\n",
      "ğŸ“ Testing QUADRATIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.9751   Fold 2/5: MAE=1.1835   Fold 3/5: MAE=1.1838   Fold 4/5: MAE=1.1183   Fold 5/5: MAE=1.3195 \n",
      "  CV MAE: 1.1560 Â± 0.1117 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (quadratic):\n",
      "    Train MAE: 1.0163 D\n",
      "    Test MAE:  1.5225 D\n",
      "    Baseline:  1.5004 D\n",
      "    Improvement: -1.5%\n",
      "    Overfit ratio: 1.498\n",
      "\n",
      "ğŸ“ Testing CUBIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.9361   Fold 2/5: MAE=1.1518   Fold 3/5: MAE=1.2708   Fold 4/5: MAE=1.0864   Fold 5/5: MAE=1.3573 \n",
      "  CV MAE: 1.1605 Â± 0.1462 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (cubic):\n",
      "    Train MAE: 0.9716 D\n",
      "    Test MAE:  1.8844 D\n",
      "    Baseline:  1.5004 D\n",
      "    Improvement: -25.6%\n",
      "    Overfit ratio: 1.940\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ Testing LINEAR model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.9870   Fold 2/5: MAE=1.4652   Fold 3/5: MAE=1.6402   Fold 4/5: MAE=1.2905   Fold 5/5: MAE=1.3023 \n",
      "  CV MAE: 1.3371 Â± 0.2164 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (linear):\n",
      "    Train MAE: 1.1681 D\n",
      "    Test MAE:  1.3211 D\n",
      "    Baseline:  1.1299 D\n",
      "    Improvement: -16.9%\n",
      "    Overfit ratio: 1.131\n",
      "\n",
      "ğŸ“ Testing QUADRATIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.8829   Fold 2/5: MAE=1.6014   Fold 3/5: MAE=1.8374   Fold 4/5: MAE=1.3363   Fold 5/5: MAE=1.3519 \n",
      "  CV MAE: 1.4020 Â± 0.3180 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (quadratic):\n",
      "    Train MAE: 1.1223 D\n",
      "    Test MAE:  1.2985 D\n",
      "    Baseline:  1.1299 D\n",
      "    Improvement: -14.9%\n",
      "    Overfit ratio: 1.157\n",
      "\n",
      "ğŸ“ Testing CUBIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.9885   Fold 2/5: MAE=1.5949   Fold 3/5: MAE=1.8310   Fold 4/5: MAE=1.2309   Fold 5/5: MAE=1.2963 \n",
      "  CV MAE: 1.3883 Â± 0.2939 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (cubic):\n",
      "    Train MAE: 1.1638 D\n",
      "    Test MAE:  1.2972 D\n",
      "    Baseline:  1.1299 D\n",
      "    Improvement: -14.8%\n",
      "    Overfit ratio: 1.115\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ Testing LINEAR model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.1310   Fold 2/5: MAE=1.0471   Fold 3/5: MAE=1.1233   Fold 4/5: MAE=1.0757   Fold 5/5: MAE=1.2430 \n",
      "  CV MAE: 1.1240 Â± 0.0670 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (linear):\n",
      "    Train MAE: 1.0701 D\n",
      "    Test MAE:  1.3445 D\n",
      "    Baseline:  1.3515 D\n",
      "    Improvement: 0.5%\n",
      "    Overfit ratio: 1.256\n",
      "\n",
      "ğŸ“ Testing QUADRATIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.1216   Fold 2/5: MAE=1.0973   Fold 3/5: MAE=1.1166   Fold 4/5: MAE=1.0953   Fold 5/5: MAE=1.2936 \n",
      "  CV MAE: 1.1449 Â± 0.0751 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (quadratic):\n",
      "    Train MAE: 1.1292 D\n",
      "    Test MAE:  1.3767 D\n",
      "    Baseline:  1.3515 D\n",
      "    Improvement: -1.9%\n",
      "    Overfit ratio: 1.219\n",
      "\n",
      "ğŸ“ Testing CUBIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.1784   Fold 2/5: MAE=1.0530   Fold 3/5: MAE=1.5539   Fold 4/5: MAE=1.0610   Fold 5/5: MAE=1.3754 \n",
      "  CV MAE: 1.2443 Â± 0.1937 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  ğŸ“ˆ RESULTS (cubic):\n",
      "    Train MAE: 1.0407 D\n",
      "    Test MAE:  1.5098 D\n",
      "    Baseline:  1.3515 D\n",
      "    Improvement: -11.7%\n",
      "    Overfit ratio: 1.451\n",
      "\n",
      "================================================================================\n",
      "POLYNOMIAL COMPARISON SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š PERFORMANCE ACROSS 5 SEEDS:\n",
      "--------------------------------------------------\n",
      "\n",
      "LINEAR MODEL:\n",
      "  Test MAE:     1.2699 Â± 0.1667 D\n",
      "  Train MAE:    1.1264 Â± 0.0708 D\n",
      "  Improvement:  -2.0% Â± 7.8%\n",
      "  Overfit gap:  0.1435 D\n",
      "\n",
      "QUADRATIC MODEL:\n",
      "  Test MAE:     1.2587 Â± 0.1941 D\n",
      "  Train MAE:    1.1234 Â± 0.0602 D\n",
      "  Improvement:  -0.8% Â± 8.4%\n",
      "  Overfit gap:  0.1353 D\n",
      "\n",
      "CUBIC MODEL:\n",
      "  Test MAE:     1.4137 Â± 0.2877 D\n",
      "  Train MAE:    1.0933 Â± 0.0833 D\n",
      "  Improvement:  -12.4% Â± 10.8%\n",
      "  Overfit gap:  0.3205 D\n",
      "\n",
      "ğŸ”¬ PARAMETER ANALYSIS:\n",
      "--------------------------------------------------\n",
      "\n",
      "Quadratic coefficient (a4): 0.0109 Â± 0.1235\n",
      "  Significance: MARGINAL\n",
      "\n",
      "Cubic coefficient (a5): 0.2292 Â± 0.2536\n",
      "  Significance: YES\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATION\n",
      "================================================================================\n",
      "âœ… BEST MODEL: QUADRATIC\n",
      "   Test MAE: 1.2587 D\n",
      "   Improvement over linear: 0.9%\n",
      "\n",
      "   The polynomial terms capture non-linear relationships between\n",
      "   corneal thickness and refractive error in Fuchs' dystrophy patients.\n",
      "\n",
      "ğŸ’¾ Stored quadratic model results for combined approach.\n"
     ]
    }
   ],
   "source": [
    "# ADDITIVE CORRECTION WITH POLYNOMIAL TERMS - MULTI-SEED\n",
    "# ========================================================\n",
    "# PURPOSE: Create an additive correction with polynomial CCT terms\n",
    "# NOW WITH QUADRATIC AND CUBIC CCT TERMS for better non-linear modeling\n",
    "\n",
    "# âš™ï¸ ACTIVATION CONTROL - Set to True to run full polynomial comparison\n",
    "RUN_POLYNOMIAL_COMPARISON = True  # ENABLED - Testing linear, quadratic, and cubic approaches\n",
    "\n",
    "if RUN_POLYNOMIAL_COMPARISON:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ADDITIVE CORRECTION WITH POLYNOMIAL CCT TERMS - MULTI-SEED ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"\\nğŸ¯ TESTING POLYNOMIAL (QUADRATIC & CUBIC) CCT TERMS:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"â€¢ Linear model: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg\")\n",
    "    print(\"â€¢ Quadratic model: + a4*CCT_normÂ²\")  \n",
    "    print(\"â€¢ Cubic model: + a4*CCT_normÂ² + a5*CCT_normÂ³\")\n",
    "    print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "    print(\"â€¢ Each seed: 75/25 train/test split\")\n",
    "    print(\"â€¢ Inner: 5-fold cross-validation\")\n",
    "\n",
    "    from sklearn.model_selection import train_test_split, KFold\n",
    "    from scipy.optimize import minimize\n",
    "    import numpy as np\n",
    "\n",
    "    # Store results for different polynomial degrees\n",
    "    results_by_degree = {\n",
    "        'linear': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []},\n",
    "        'quadratic': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []},\n",
    "        'cubic': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []}\n",
    "    }\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RUNNING MULTI-SEED ANALYSIS WITH POLYNOMIAL TERMS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_add, X_test_add = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "        X_train_add['K_avg'] = (X_train_add['Bio-Ks'] + X_train_add['Bio-Kf']) / 2\n",
    "        X_test_add['K_avg'] = (X_test_add['Bio-Ks'] + X_test_add['Bio-Kf']) / 2\n",
    "        \n",
    "        print(f\"ğŸ“Š Split: {len(X_train_add)} train, {len(X_test_add)} test\")\n",
    "        \n",
    "        # Calculate baseline\n",
    "        for dataset in [X_train_add, X_test_add]:\n",
    "            dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "                lambda row: calculate_SRKT2(\n",
    "                    AL=row['Bio-AL'],\n",
    "                    K_avg=row['K_avg'],\n",
    "                    IOL_power=row['IOL Power'],\n",
    "                    A_constant=row['A-Constant']\n",
    "                ), axis=1\n",
    "            )\n",
    "        \n",
    "        baseline_mae = mean_absolute_error(X_test_add['PostOP Spherical Equivalent'], \n",
    "                                           X_test_add['SRKT2_Baseline'])\n",
    "        \n",
    "        # Test each polynomial degree\n",
    "        for degree_name in ['linear', 'quadratic', 'cubic']:\n",
    "            print(f\"\\nğŸ“ Testing {degree_name.upper()} model:\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Setup K-fold\n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "            fold_results = []\n",
    "            fold_maes = []\n",
    "            \n",
    "            for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_add), 1):\n",
    "                print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
    "                \n",
    "                fold_train = X_train_add.iloc[train_idx]\n",
    "                fold_val = X_train_add.iloc[val_idx]\n",
    "                \n",
    "                # Define objective function based on degree\n",
    "                if degree_name == 'linear':\n",
    "                    def additive_objective(params, df_data):\n",
    "                        a0, a1, a2, a3 = params\n",
    "                        predictions = []\n",
    "                        for _, row in df_data.iterrows():\n",
    "                            base_pred = row['SRKT2_Baseline']\n",
    "                            cct_norm = (row['CCT'] - 600) / 100\n",
    "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                            # Linear only\n",
    "                            correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
    "                            predictions.append(base_pred + correction)\n",
    "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "                    \n",
    "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1)]\n",
    "                    initial = [0, 0, 0, 0]\n",
    "                    \n",
    "                elif degree_name == 'quadratic':\n",
    "                    def additive_objective(params, df_data):\n",
    "                        a0, a1, a2, a3, a4 = params\n",
    "                        predictions = []\n",
    "                        for _, row in df_data.iterrows():\n",
    "                            base_pred = row['SRKT2_Baseline']\n",
    "                            cct_norm = (row['CCT'] - 600) / 100\n",
    "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                            # Linear + quadratic\n",
    "                            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                        a3 * row['K_avg'] + a4 * cct_norm**2)\n",
    "                            predictions.append(base_pred + correction)\n",
    "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "                    \n",
    "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1)]\n",
    "                    initial = [0, 0, 0, 0, 0]\n",
    "                    \n",
    "                else:  # cubic\n",
    "                    def additive_objective(params, df_data):\n",
    "                        a0, a1, a2, a3, a4, a5 = params\n",
    "                        predictions = []\n",
    "                        for _, row in df_data.iterrows():\n",
    "                            base_pred = row['SRKT2_Baseline']\n",
    "                            cct_norm = (row['CCT'] - 600) / 100\n",
    "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                            # Linear + quadratic + cubic\n",
    "                            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                        a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
    "                                        a5 * cct_norm**3)\n",
    "                            predictions.append(base_pred + correction)\n",
    "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "                    \n",
    "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1), (-0.5, 0.5)]\n",
    "                    initial = [0, 0, 0, 0, 0, 0]\n",
    "                \n",
    "                # Optimize\n",
    "                result = minimize(lambda p: additive_objective(p, fold_train), \n",
    "                                initial, method='L-BFGS-B', bounds=bounds)\n",
    "                fold_results.append(result.x)\n",
    "                \n",
    "                # Validate\n",
    "                fold_val_mae = additive_objective(result.x, fold_val)\n",
    "                fold_maes.append(fold_val_mae)\n",
    "                print(f\"MAE={fold_val_mae:.4f} \", end=\"\")\n",
    "            \n",
    "            print()\n",
    "            avg_cv_mae = np.mean(fold_maes)\n",
    "            std_cv_mae = np.std(fold_maes)\n",
    "            print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
    "            \n",
    "            # Final optimization on full training set\n",
    "            print(f\"  Final optimization on full training set...\")\n",
    "            final_result = minimize(lambda p: additive_objective(p, X_train_add), \n",
    "                                  initial, method='L-BFGS-B', bounds=bounds)\n",
    "            \n",
    "            # Evaluate on training set\n",
    "            train_mae = additive_objective(final_result.x, X_train_add)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            test_mae = additive_objective(final_result.x, X_test_add)\n",
    "            \n",
    "            improvement = ((baseline_mae - test_mae) / baseline_mae) * 100\n",
    "            overfit_ratio = test_mae / train_mae if train_mae > 0 else float('inf')\n",
    "            \n",
    "            print(f\"\\n  ğŸ“ˆ RESULTS ({degree_name}):\")\n",
    "            print(f\"    Train MAE: {train_mae:.4f} D\")\n",
    "            print(f\"    Test MAE:  {test_mae:.4f} D\")\n",
    "            print(f\"    Baseline:  {baseline_mae:.4f} D\")\n",
    "            print(f\"    Improvement: {improvement:.1f}%\")\n",
    "            print(f\"    Overfit ratio: {overfit_ratio:.3f}\")\n",
    "            \n",
    "            # Store results\n",
    "            results_by_degree[degree_name]['test_maes'].append(test_mae)\n",
    "            results_by_degree[degree_name]['train_maes'].append(train_mae)\n",
    "            results_by_degree[degree_name]['improvements'].append(improvement)\n",
    "            results_by_degree[degree_name]['params'].append(final_result.x)\n",
    "\n",
    "    # COMPREHENSIVE COMPARISON\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"POLYNOMIAL COMPARISON SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for degree_name in ['linear', 'quadratic', 'cubic']:\n",
    "        results = results_by_degree[degree_name]\n",
    "        print(f\"\\n{degree_name.upper()} MODEL:\")\n",
    "        print(f\"  Test MAE:     {np.mean(results['test_maes']):.4f} Â± {np.std(results['test_maes']):.4f} D\")\n",
    "        print(f\"  Train MAE:    {np.mean(results['train_maes']):.4f} Â± {np.std(results['train_maes']):.4f} D\")\n",
    "        print(f\"  Improvement:  {np.mean(results['improvements']):.1f}% Â± {np.std(results['improvements']):.1f}%\")\n",
    "        print(f\"  Overfit gap:  {np.mean(results['test_maes']) - np.mean(results['train_maes']):.4f} D\")\n",
    "\n",
    "    # Parameter analysis\n",
    "    print(\"\\nğŸ”¬ PARAMETER ANALYSIS:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Analyze quadratic coefficients\n",
    "    quad_params = np.array(results_by_degree['quadratic']['params'])\n",
    "    if quad_params.shape[1] >= 5:\n",
    "        quad_coeffs = quad_params[:, 4]  # a4 (quadratic term)\n",
    "        print(f\"\\nQuadratic coefficient (a4): {np.mean(quad_coeffs):.4f} Â± {np.std(quad_coeffs):.4f}\")\n",
    "        print(f\"  Significance: {'YES' if abs(np.mean(quad_coeffs)) > 0.1 else 'MARGINAL'}\")\n",
    "\n",
    "    # Analyze cubic coefficients\n",
    "    cubic_params = np.array(results_by_degree['cubic']['params'])\n",
    "    if cubic_params.shape[1] >= 6:\n",
    "        cubic_coeffs = cubic_params[:, 5]  # a5 (cubic term)\n",
    "        print(f\"\\nCubic coefficient (a5): {np.mean(cubic_coeffs):.4f} Â± {np.std(cubic_coeffs):.4f}\")\n",
    "        print(f\"  Significance: {'YES' if abs(np.mean(cubic_coeffs)) > 0.05 else 'MARGINAL'}\")\n",
    "\n",
    "    # Winner determination\n",
    "    mean_test_maes = {degree: np.mean(results_by_degree[degree]['test_maes']) \n",
    "                      for degree in ['linear', 'quadratic', 'cubic']}\n",
    "    best_degree = min(mean_test_maes, key=mean_test_maes.get)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RECOMMENDATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"âœ… BEST MODEL: {best_degree.upper()}\")\n",
    "    print(f\"   Test MAE: {mean_test_maes[best_degree]:.4f} D\")\n",
    "\n",
    "    if best_degree != 'linear':\n",
    "        improvement_over_linear = ((mean_test_maes['linear'] - mean_test_maes[best_degree]) / \n",
    "                                   mean_test_maes['linear']) * 100\n",
    "        print(f\"   Improvement over linear: {improvement_over_linear:.1f}%\")\n",
    "        print(f\"\\n   The polynomial terms capture non-linear relationships between\")\n",
    "        print(f\"   corneal thickness and refractive error in Fuchs' dystrophy patients.\")\n",
    "\n",
    "    # Store best results for later use\n",
    "    seed_test_maes_additive = results_by_degree[best_degree]['test_maes']\n",
    "    seed_train_maes_additive = results_by_degree[best_degree]['train_maes']\n",
    "    seed_improvements_additive = results_by_degree[best_degree]['improvements']\n",
    "    seed_additive_params = results_by_degree[best_degree]['params']\n",
    "\n",
    "    print(f\"\\nğŸ’¾ Stored {best_degree} model results for combined approach.\")\n",
    "    \n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"â­ï¸ POLYNOMIAL COMPARISON SKIPPED (RUN_POLYNOMIAL_COMPARISON = False)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Using direct quadratic approach in next cell instead.\")\n",
    "    print(\"To enable full comparison: Set RUN_POLYNOMIAL_COMPARISON = True\")\n",
    "    \n",
    "    # Set best_degree for compatibility\n",
    "    best_degree = 'quadratic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oymvfrf7v1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUADRATIC ADDITIVE CORRECTION - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ QUADRATIC MODEL SPECIFICATION:\n",
      "--------------------------------------------------\n",
      "â€¢ Formula: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg + a4*CCT_normÂ²\n",
      "â€¢ Captures non-linear relationship between CCT and refractive error\n",
      "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "â€¢ Each seed: 75/25 train/test split\n",
      "â€¢ Inner: 5-fold cross-validation\n",
      "\n",
      "================================================================================\n",
      "RUNNING QUADRATIC ADDITIVE CORRECTION\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.5980   Fold 2/5: MAE=1.1750   Fold 3/5: MAE=1.6769   Fold 4/5: MAE=1.2426   Fold 5/5: MAE=1.4406 \n",
      "  CV MAE: 1.2266 Â± 0.3596 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 1.1489 D\n",
      "  Test MAE:  1.1328 D\n",
      "  Baseline:  1.1712 D\n",
      "  Improvement: 3.3%\n",
      "  Overfit ratio: 0.986\n",
      "\n",
      "  Parameters:\n",
      "    a0 (intercept):  -0.2803\n",
      "    a1 (CCT_norm):   -0.8552\n",
      "    a2 (CCT_ratio):   0.1748\n",
      "    a3 (K_avg):      -0.1000\n",
      "    a4 (CCT_normÂ²):   0.1035\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.4354   Fold 2/5: MAE=1.0467   Fold 3/5: MAE=1.2342   Fold 4/5: MAE=1.1170   Fold 5/5: MAE=1.3185 \n",
      "  CV MAE: 1.2303 Â± 0.1388 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 1.2005 D\n",
      "  Test MAE:  0.9631 D\n",
      "  Baseline:  1.0813 D\n",
      "  Improvement: 10.9%\n",
      "  Overfit ratio: 0.802\n",
      "\n",
      "  Parameters:\n",
      "    a0 (intercept):  -0.0015\n",
      "    a1 (CCT_norm):   -0.2701\n",
      "    a2 (CCT_ratio):   0.1750\n",
      "    a3 (K_avg):      -0.1000\n",
      "    a4 (CCT_normÂ²):  -0.2284\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.9751   Fold 2/5: MAE=1.1835   Fold 3/5: MAE=1.1838   Fold 4/5: MAE=1.1183   Fold 5/5: MAE=1.3195 \n",
      "  CV MAE: 1.1560 Â± 0.1117 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 1.0163 D\n",
      "  Test MAE:  1.5225 D\n",
      "  Baseline:  1.5004 D\n",
      "  Improvement: -1.5%\n",
      "  Overfit ratio: 1.498\n",
      "\n",
      "  Parameters:\n",
      "    a0 (intercept):   0.0189\n",
      "    a1 (CCT_norm):   -0.6779\n",
      "    a2 (CCT_ratio):   0.1696\n",
      "    a3 (K_avg):      -0.1000\n",
      "    a4 (CCT_normÂ²):   0.0542\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.8829   Fold 2/5: MAE=1.6014   Fold 3/5: MAE=1.8374   Fold 4/5: MAE=1.3363   Fold 5/5: MAE=1.3519 \n",
      "  CV MAE: 1.4020 Â± 0.3180 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 1.1223 D\n",
      "  Test MAE:  1.2985 D\n",
      "  Baseline:  1.1299 D\n",
      "  Improvement: -14.9%\n",
      "  Overfit ratio: 1.157\n",
      "\n",
      "  Parameters:\n",
      "    a0 (intercept):  -1.4936\n",
      "    a1 (CCT_norm):   -0.5764\n",
      "    a2 (CCT_ratio):   0.2273\n",
      "    a3 (K_avg):      -0.1000\n",
      "    a4 (CCT_normÂ²):   0.1026\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.1216   Fold 2/5: MAE=1.0973   Fold 3/5: MAE=1.1166   Fold 4/5: MAE=1.0953   Fold 5/5: MAE=1.2936 \n",
      "  CV MAE: 1.1449 Â± 0.0751 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 1.1292 D\n",
      "  Test MAE:  1.3767 D\n",
      "  Baseline:  1.3515 D\n",
      "  Improvement: -1.9%\n",
      "  Overfit ratio: 1.219\n",
      "\n",
      "  Parameters:\n",
      "    a0 (intercept):  -0.0085\n",
      "    a1 (CCT_norm):    0.0225\n",
      "    a2 (CCT_ratio):   0.0599\n",
      "    a3 (K_avg):      -0.0374\n",
      "    a4 (CCT_normÂ²):   0.0228\n",
      "\n",
      "================================================================================\n",
      "MULTI-SEED SUMMARY - QUADRATIC ADDITIVE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š PERFORMANCE ACROSS 5 SEEDS:\n",
      "--------------------------------------------------\n",
      "Test MAE:     1.2587 Â± 0.1941 D\n",
      "Train MAE:    1.1234 Â± 0.0602 D\n",
      "Baseline MAE: 1.2469 Â± 0.1562 D\n",
      "Improvement:  -0.8% Â± 8.4%\n",
      "Overfit ratio: 1.133 Â± 0.233\n",
      "\n",
      "ğŸ”¬ PARAMETER CONSISTENCY:\n",
      "--------------------------------------------------\n",
      "\n",
      "Average parameters across seeds:\n",
      "  a0 (intercept) : -0.3530 Â± 0.5808\n",
      "  a1 (CCT_norm)  : -0.4714 Â± 0.3116\n",
      "  a2 (CCT_ratio) :  0.1613 Â± 0.0549\n",
      "  a3 (K_avg)     : -0.0875 Â± 0.0250\n",
      "  a4 (CCT_normÂ²) :  0.0109 Â± 0.1235\n",
      "\n",
      "ğŸ“Š Quadratic term analysis:\n",
      "  Mean coefficient: 0.0109\n",
      "  All seeds negative: False\n",
      "  All seeds positive: False\n",
      "  Significance: WEAK\n",
      "\n",
      "  â¡ï¸ Positive quadratic coefficient indicates:\n",
      "     â€¢ Effect of CCT on error INCREASES at extreme thicknesses\n",
      "     â€¢ Correction curve steepens for very thick corneas\n",
      "\n",
      "ğŸ’¾ Quadratic model results stored for combined approach.\n"
     ]
    }
   ],
   "source": [
    "# QUADRATIC ADDITIVE CORRECTION - STREAMLINED VERSION\n",
    "# ====================================================\n",
    "# PURPOSE: Direct implementation of quadratic additive correction\n",
    "# Skips comparison and goes straight to the optimal quadratic model\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"QUADRATIC ADDITIVE CORRECTION - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ¯ QUADRATIC MODEL SPECIFICATION:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Formula: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg + a4*CCT_normÂ²\")\n",
    "print(\"â€¢ Captures non-linear relationship between CCT and refractive error\")\n",
    "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
    "print(\"â€¢ Inner: 5-fold cross-validation\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# Store results for quadratic model\n",
    "seed_test_maes_additive = []\n",
    "seed_train_maes_additive = []\n",
    "seed_baseline_maes_additive = []\n",
    "seed_improvements_additive = []\n",
    "seed_overfit_ratios_additive = []\n",
    "seed_additive_params = []\n",
    "\n",
    "# Set degree for compatibility with combined approach\n",
    "best_degree = 'quadratic'\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING QUADRATIC ADDITIVE CORRECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_add, X_test_add = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_add['K_avg'] = (X_train_add['Bio-Ks'] + X_train_add['Bio-Kf']) / 2\n",
    "    X_test_add['K_avg'] = (X_test_add['Bio-Ks'] + X_test_add['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"ğŸ“Š Split: {len(X_train_add)} train, {len(X_test_add)} test\")\n",
    "    \n",
    "    # Calculate baseline\n",
    "    for dataset in [X_train_add, X_test_add]:\n",
    "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    baseline_mae = mean_absolute_error(X_test_add['PostOP Spherical Equivalent'], \n",
    "                                       X_test_add['SRKT2_Baseline'])\n",
    "    \n",
    "    print(\"\\nğŸ“ K-FOLD CROSS-VALIDATION:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Setup K-fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    fold_results = []\n",
    "    fold_maes = []\n",
    "    \n",
    "    # Define quadratic objective function\n",
    "    def additive_objective_quad(params, df_data):\n",
    "        a0, a1, a2, a3, a4 = params\n",
    "        predictions = []\n",
    "        for _, row in df_data.iterrows():\n",
    "            base_pred = row['SRKT2_Baseline']\n",
    "            cct_norm = (row['CCT'] - 600) / 100\n",
    "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "            # Quadratic correction\n",
    "            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                        a3 * row['K_avg'] + a4 * cct_norm**2)\n",
    "            predictions.append(base_pred + correction)\n",
    "        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "    \n",
    "    # Bounds and initial values for quadratic model\n",
    "    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1)]\n",
    "    initial = [0, 0, 0, 0, 0]\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_add), 1):\n",
    "        print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
    "        \n",
    "        fold_train = X_train_add.iloc[train_idx]\n",
    "        fold_val = X_train_add.iloc[val_idx]\n",
    "        \n",
    "        # Optimize\n",
    "        result = minimize(lambda p: additive_objective_quad(p, fold_train), \n",
    "                        initial, method='L-BFGS-B', bounds=bounds)\n",
    "        fold_results.append(result.x)\n",
    "        \n",
    "        # Validate\n",
    "        fold_val_mae = additive_objective_quad(result.x, fold_val)\n",
    "        fold_maes.append(fold_val_mae)\n",
    "        print(f\"MAE={fold_val_mae:.4f} \", end=\"\")\n",
    "    \n",
    "    print()\n",
    "    avg_cv_mae = np.mean(fold_maes)\n",
    "    std_cv_mae = np.std(fold_maes)\n",
    "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
    "    \n",
    "    # Final optimization on full training set\n",
    "    print(\"  Final optimization on full training set...\")\n",
    "    final_result = minimize(lambda p: additive_objective_quad(p, X_train_add), \n",
    "                          initial, method='L-BFGS-B', bounds=bounds)\n",
    "    \n",
    "    # Evaluate on training set\n",
    "    train_mae = additive_objective_quad(final_result.x, X_train_add)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_mae = additive_objective_quad(final_result.x, X_test_add)\n",
    "    \n",
    "    improvement = ((baseline_mae - test_mae) / baseline_mae) * 100\n",
    "    overfit_ratio = test_mae / train_mae if train_mae > 0 else float('inf')\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ RESULTS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Train MAE: {train_mae:.4f} D\")\n",
    "    print(f\"  Test MAE:  {test_mae:.4f} D\")\n",
    "    print(f\"  Baseline:  {baseline_mae:.4f} D\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    print(f\"  Overfit ratio: {overfit_ratio:.3f}\")\n",
    "    \n",
    "    # Display parameters\n",
    "    a0, a1, a2, a3, a4 = final_result.x\n",
    "    print(f\"\\n  Parameters:\")\n",
    "    print(f\"    a0 (intercept):  {a0:7.4f}\")\n",
    "    print(f\"    a1 (CCT_norm):   {a1:7.4f}\")\n",
    "    print(f\"    a2 (CCT_ratio):  {a2:7.4f}\")\n",
    "    print(f\"    a3 (K_avg):      {a3:7.4f}\")\n",
    "    print(f\"    a4 (CCT_normÂ²):  {a4:7.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_test_maes_additive.append(test_mae)\n",
    "    seed_train_maes_additive.append(train_mae)\n",
    "    seed_baseline_maes_additive.append(baseline_mae)\n",
    "    seed_improvements_additive.append(improvement)\n",
    "    seed_overfit_ratios_additive.append(overfit_ratio)\n",
    "    seed_additive_params.append(final_result.x)\n",
    "\n",
    "# SUMMARY STATISTICS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTI-SEED SUMMARY - QUADRATIC ADDITIVE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Test MAE:     {np.mean(seed_test_maes_additive):.4f} Â± {np.std(seed_test_maes_additive):.4f} D\")\n",
    "print(f\"Train MAE:    {np.mean(seed_train_maes_additive):.4f} Â± {np.std(seed_train_maes_additive):.4f} D\")\n",
    "print(f\"Baseline MAE: {np.mean(seed_baseline_maes_additive):.4f} Â± {np.std(seed_baseline_maes_additive):.4f} D\")\n",
    "print(f\"Improvement:  {np.mean(seed_improvements_additive):.1f}% Â± {np.std(seed_improvements_additive):.1f}%\")\n",
    "print(f\"Overfit ratio: {np.mean(seed_overfit_ratios_additive):.3f} Â± {np.std(seed_overfit_ratios_additive):.3f}\")\n",
    "\n",
    "# Parameter consistency analysis\n",
    "print(\"\\nğŸ”¬ PARAMETER CONSISTENCY:\")\n",
    "print(\"-\" * 50)\n",
    "param_array = np.array(seed_additive_params)\n",
    "param_names = ['a0 (intercept)', 'a1 (CCT_norm)', 'a2 (CCT_ratio)', 'a3 (K_avg)', 'a4 (CCT_normÂ²)']\n",
    "\n",
    "print(\"\\nAverage parameters across seeds:\")\n",
    "for i, name in enumerate(param_names):\n",
    "    values = param_array[:, i]\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values)\n",
    "    print(f\"  {name:15s}: {mean_val:7.4f} Â± {std_val:.4f}\")\n",
    "\n",
    "# Check quadratic term significance\n",
    "quad_coeffs = param_array[:, 4]\n",
    "print(f\"\\nğŸ“Š Quadratic term analysis:\")\n",
    "print(f\"  Mean coefficient: {np.mean(quad_coeffs):.4f}\")\n",
    "print(f\"  All seeds negative: {np.all(quad_coeffs < 0)}\")\n",
    "print(f\"  All seeds positive: {np.all(quad_coeffs > 0)}\")\n",
    "print(f\"  Significance: {'STRONG' if abs(np.mean(quad_coeffs)) > 0.2 else 'MODERATE' if abs(np.mean(quad_coeffs)) > 0.1 else 'WEAK'}\")\n",
    "\n",
    "if np.mean(quad_coeffs) < 0:\n",
    "    print(\"\\n  â¡ï¸ Negative quadratic coefficient indicates:\")\n",
    "    print(\"     â€¢ Effect of CCT on error DECREASES at extreme thicknesses\")\n",
    "    print(\"     â€¢ Correction curve flattens for very thick corneas\")\n",
    "else:\n",
    "    print(\"\\n  â¡ï¸ Positive quadratic coefficient indicates:\")\n",
    "    print(\"     â€¢ Effect of CCT on error INCREASES at extreme thicknesses\")\n",
    "    print(\"     â€¢ Correction curve steepens for very thick corneas\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Quadratic model results stored for combined approach.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "u4unlmjdt3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMBINED FORMULA WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Using QUADRATIC polynomial degree (determined optimal in additive cell)\n",
      "\n",
      "ğŸ¯ MULTI-SEED NESTED CV FOR COMBINED APPROACH:\n",
      "--------------------------------------------------\n",
      "â€¢ Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "â€¢ Each seed: 75/25 train/test split\n",
      "â€¢ Inner: 5-fold CV for each method\n",
      "â€¢ Additive correction using: quadratic polynomial\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.4629   Fold 2/5: MAE=0.8335   Fold 3/5: MAE=1.1626   Fold 4/5: MAE=0.7179   Fold 5/5: MAE=0.7380 \n",
      "  CV MAE: 0.7830 Â± 0.2260 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.7680 D\n",
      "  Test MAE:  1.0437 D\n",
      "  Baseline:  1.1712 D\n",
      "  Improvement: 10.9%\n",
      "  Overfit ratio: 1.359\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.0370   Fold 2/5: MAE=0.7587   Fold 3/5: MAE=1.0671   Fold 4/5: MAE=0.8469   Fold 5/5: MAE=0.8626 \n",
      "  CV MAE: 0.9145 Â± 0.1182 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.9314 D\n",
      "  Test MAE:  0.6596 D\n",
      "  Baseline:  1.0813 D\n",
      "  Improvement: 39.0%\n",
      "  Overfit ratio: 0.708\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.8469   Fold 2/5: MAE=0.8977   Fold 3/5: MAE=1.3024   Fold 4/5: MAE=0.7976   Fold 5/5: MAE=0.6297 \n",
      "  CV MAE: 0.8949 Â± 0.2228 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.7934 D\n",
      "  Test MAE:  1.0454 D\n",
      "  Baseline:  1.5004 D\n",
      "  Improvement: 30.3%\n",
      "  Overfit ratio: 1.318\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.1314   Fold 2/5: MAE=1.2998   Fold 3/5: MAE=1.2534   Fold 4/5: MAE=0.9516   Fold 5/5: MAE=0.9152 \n",
      "  CV MAE: 1.1103 Â± 0.1550 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.8652 D\n",
      "  Test MAE:  0.9612 D\n",
      "  Baseline:  1.1299 D\n",
      "  Improvement: 14.9%\n",
      "  Overfit ratio: 1.111\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "ğŸ“Š Split: 66 train, 22 test\n",
      "\n",
      "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.6873   Fold 2/5: MAE=0.8008   Fold 3/5: MAE=1.0252   Fold 4/5: MAE=0.9079   Fold 5/5: MAE=0.5272 \n",
      "  CV MAE: 0.7897 Â± 0.1726 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "ğŸ“ˆ RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.8228 D\n",
      "  Test MAE:  1.0516 D\n",
      "  Baseline:  1.3515 D\n",
      "  Improvement: 22.2%\n",
      "  Overfit ratio: 1.278\n",
      "\n",
      "================================================================================\n",
      "MULTI-SEED SUMMARY - COMBINED APPROACH WITH QUADRATIC ADDITIVE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š PERFORMANCE ACROSS 5 SEEDS:\n",
      "--------------------------------------------------\n",
      "Test MAE:     0.9523 Â± 0.1501 D\n",
      "Train MAE:    0.8362 Â± 0.0576 D\n",
      "Baseline MAE: 1.2469 Â± 0.1562 D\n",
      "Improvement:  23.5% Â± 10.2%\n",
      "Overfit ratio: 1.155 Â± 0.239\n",
      "\n",
      "ğŸ”¬ PARAMETER CONSISTENCY:\n",
      "--------------------------------------------------\n",
      "\n",
      "Parameter optimization values:\n",
      "  nc_base   :  1.3956 Â± 0.1009\n",
      "  nc_cct    :  0.0508 Â± 0.0523\n",
      "  k_base    :  1.3795 Â± 0.0961\n",
      "  k_cct     :  0.0404 Â± 0.0549\n",
      "  acd_base  :  2.8131 Â± 0.1324\n",
      "  acd_cct   :  1.2144 Â± 1.3212\n",
      "\n",
      "Multiplicative correction values:\n",
      "  m0        : -0.0428 Â± 0.0108\n",
      "  m1_cct    :  0.0094 Â± 0.0360\n",
      "  m2_ratio  : -0.0375 Â± 0.0010\n",
      "\n",
      "Additive correction values (quadratic):\n",
      "  a0        : -0.3530 Â± 0.5808\n",
      "  a1_cct    : -0.4714 Â± 0.3116\n",
      "  a2_ratio  :  0.1613 Â± 0.0549\n",
      "  a3_K      : -0.0875 Â± 0.0250\n",
      "  a4_cct2   :  0.0109 Â± 0.1235\n",
      "\n",
      "================================================================================\n",
      "CLINICAL INTERPRETATION\n",
      "================================================================================\n",
      "âœ… Combined approach with quadratic additive achieves:\n",
      "   â€¢ Mean absolute error: 0.952 Â± 0.150 D\n",
      "   â€¢ 23% improvement over standard SRK/T2\n",
      "   â€¢ MODERATE: Further optimization may be beneficial\n"
     ]
    }
   ],
   "source": [
    "# COMBINED APPROACH WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
    "# ========================================================\n",
    "# PURPOSE: Combine all three methods with nested K-fold CV and multi-seed validation\n",
    "# NOW USES THE BEST POLYNOMIAL DEGREE FROM ADDITIVE ANALYSIS\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMBINED FORMULA WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Determine which polynomial degree to use from additive cell results\n",
    "if 'best_degree' in locals():\n",
    "    print(f\"\\nğŸ“ Using {best_degree.upper()} polynomial degree (determined optimal in additive cell)\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No polynomial analysis found, defaulting to LINEAR\")\n",
    "    best_degree = 'linear'\n",
    "\n",
    "print(\"\\nğŸ¯ MULTI-SEED NESTED CV FOR COMBINED APPROACH:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
    "print(\"â€¢ Inner: 5-fold CV for each method\")\n",
    "print(f\"â€¢ Additive correction using: {best_degree} polynomial\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "import numpy as np\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_combined = []\n",
    "seed_test_maes_combined = []\n",
    "seed_train_maes_combined = []\n",
    "seed_baseline_maes_combined = []\n",
    "seed_improvements_combined = []\n",
    "seed_overfit_ratios_combined = []\n",
    "\n",
    "# Store individual method results\n",
    "seed_param_results = []\n",
    "seed_mult_results = []\n",
    "seed_add_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT - consistent across all methods\n",
    "    X_train_comb, X_test_comb = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_comb['K_avg'] = (X_train_comb['Bio-Ks'] + X_train_comb['Bio-Kf']) / 2\n",
    "    X_test_comb['K_avg'] = (X_test_comb['Bio-Ks'] + X_test_comb['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"ğŸ“Š Split: {len(X_train_comb)} train, {len(X_test_comb)} test\")\n",
    "    \n",
    "    # Calculate baseline for all\n",
    "    for dataset in [X_train_comb, X_test_comb]:\n",
    "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    print(\"\\nğŸ“ K-FOLD CV FOR EACH METHOD:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Setup K-fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # Store fold results for each method\n",
    "    param_fold_results = []\n",
    "    mult_fold_results = []\n",
    "    add_fold_results = []\n",
    "    combined_fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_comb), 1):\n",
    "        print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
    "        \n",
    "        fold_train = X_train_comb.iloc[train_idx]\n",
    "        fold_val = X_train_comb.iloc[val_idx]\n",
    "        \n",
    "        # 1. PARAMETER METHOD\n",
    "        def param_obj(params, df_data):\n",
    "            nc_base, nc_cct, k_base, k_cct, acd_base, acd_cct = params\n",
    "            predictions = []\n",
    "            for _, row in df_data.iterrows():\n",
    "                cct_norm = (row['CCT'] - 600) / 100\n",
    "                nc = nc_base + nc_cct * cct_norm\n",
    "                k_index = k_base + k_cct * cct_norm\n",
    "                acd_offset = acd_base + acd_cct * cct_norm\n",
    "                pred = calculate_SRKT2(\n",
    "                    AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "                    IOL_power=row['IOL Power'],\n",
    "                    A_constant=row['A-Constant'] + acd_offset,\n",
    "                    nc=nc, k_index=k_index\n",
    "                )\n",
    "                predictions.append(pred)\n",
    "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "        \n",
    "        bounds_p = [(1.20, 1.50), (-0.20, 0.20), (1.20, 1.60), (-0.30, 0.30), (-3.0, 3.0), (-3.0, 3.0)]\n",
    "        result_p = differential_evolution(lambda p: param_obj(p, fold_train), bounds_p, \n",
    "                                         maxiter=20, seed=SEED+fold_num, disp=False)\n",
    "        param_fold_results.append(result_p.x)\n",
    "        \n",
    "        # 2. MULTIPLICATIVE METHOD\n",
    "        def mult_obj(params, df_data):\n",
    "            m0, m1, m2 = params\n",
    "            predictions = []\n",
    "            for _, row in df_data.iterrows():\n",
    "                base_pred = row['SRKT2_Baseline']\n",
    "                cct_norm = (row['CCT'] - 600) / 100\n",
    "                cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                correction = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "                predictions.append(base_pred * correction)\n",
    "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "        \n",
    "        result_m = minimize(lambda p: mult_obj(p, fold_train), [0,0,0], \n",
    "                           method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
    "        mult_fold_results.append(result_m.x)\n",
    "        \n",
    "        # 3. ADDITIVE METHOD - WITH BEST POLYNOMIAL DEGREE\n",
    "        if best_degree == 'linear':\n",
    "            def add_obj(params, df_data):\n",
    "                a0, a1, a2, a3 = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    base_pred = row['SRKT2_Baseline']\n",
    "                    cct_norm = (row['CCT'] - 600) / 100\n",
    "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                    correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
    "                    predictions.append(base_pred + correction)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1)]\n",
    "            add_initial = [0,0,0,0]\n",
    "            \n",
    "        elif best_degree == 'quadratic':\n",
    "            def add_obj(params, df_data):\n",
    "                a0, a1, a2, a3, a4 = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    base_pred = row['SRKT2_Baseline']\n",
    "                    cct_norm = (row['CCT'] - 600) / 100\n",
    "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                    correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2)\n",
    "                    predictions.append(base_pred + correction)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1),(-1,1)]\n",
    "            add_initial = [0,0,0,0,0]\n",
    "            \n",
    "        else:  # cubic\n",
    "            def add_obj(params, df_data):\n",
    "                a0, a1, a2, a3, a4, a5 = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    base_pred = row['SRKT2_Baseline']\n",
    "                    cct_norm = (row['CCT'] - 600) / 100\n",
    "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                    correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
    "                                a5 * cct_norm**3)\n",
    "                    predictions.append(base_pred + correction)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1),(-1,1),(-0.5,0.5)]\n",
    "            add_initial = [0,0,0,0,0,0]\n",
    "        \n",
    "        result_a = minimize(lambda p: add_obj(p, fold_train), add_initial,\n",
    "                           method='L-BFGS-B', bounds=add_bounds)\n",
    "        add_fold_results.append(result_a.x)\n",
    "        \n",
    "        # VALIDATE COMBINED on fold validation set\n",
    "        nc_b, nc_c, k_b, k_c, acd_b, acd_c = result_p.x\n",
    "        m0, m1, m2 = result_m.x\n",
    "        \n",
    "        combined_preds = []\n",
    "        for _, row in fold_val.iterrows():\n",
    "            cct_norm = (row['CCT'] - 600) / 100\n",
    "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "            \n",
    "            # Modified SRK/T2\n",
    "            nc = nc_b + nc_c * cct_norm\n",
    "            k_index = k_b + k_c * cct_norm\n",
    "            acd_offset = acd_b + acd_c * cct_norm\n",
    "            modified = calculate_SRKT2(\n",
    "                AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant'] + acd_offset,\n",
    "                nc=nc, k_index=k_index\n",
    "            )\n",
    "            \n",
    "            # Apply multiplicative\n",
    "            mult_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "            after_mult = modified * mult_factor\n",
    "            \n",
    "            # Apply additive with appropriate polynomial\n",
    "            if best_degree == 'linear':\n",
    "                a0, a1, a2, a3 = result_a.x\n",
    "                add_correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
    "            elif best_degree == 'quadratic':\n",
    "                a0, a1, a2, a3, a4 = result_a.x\n",
    "                add_correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2)\n",
    "            else:  # cubic\n",
    "                a0, a1, a2, a3, a4, a5 = result_a.x\n",
    "                add_correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
    "                                a5 * cct_norm**3)\n",
    "            \n",
    "            final = after_mult + add_correction\n",
    "            combined_preds.append(final)\n",
    "        \n",
    "        fold_mae = mean_absolute_error(fold_val['PostOP Spherical Equivalent'], combined_preds)\n",
    "        combined_fold_maes.append(fold_mae)\n",
    "        print(f\"MAE={fold_mae:.4f} \", end=\"\")\n",
    "    \n",
    "    print()  # New line after folds\n",
    "    \n",
    "    # Average parameters across folds\n",
    "    avg_param = np.mean(param_fold_results, axis=0)\n",
    "    avg_mult = np.mean(mult_fold_results, axis=0)\n",
    "    avg_add = np.mean(add_fold_results, axis=0)\n",
    "    avg_combined_mae = np.mean(combined_fold_maes)\n",
    "    std_combined_mae = np.std(combined_fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_combined_mae:.4f} Â± {std_combined_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    print(\"  Final optimization on full training set...\")\n",
    "    \n",
    "    result_p_final = differential_evolution(lambda p: param_obj(p, X_train_comb), bounds_p, \n",
    "                                           maxiter=50, seed=SEED, disp=False)\n",
    "    nc_base_c, nc_cct_c, k_base_c, k_cct_c, acd_base_c, acd_cct_c = result_p_final.x\n",
    "    \n",
    "    result_m_final = minimize(lambda p: mult_obj(p, X_train_comb), [0,0,0], \n",
    "                             method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
    "    m0_c, m1_c, m2_c = result_m_final.x\n",
    "    \n",
    "    result_a_final = minimize(lambda p: add_obj(p, X_train_comb), add_initial,\n",
    "                             method='L-BFGS-B', bounds=add_bounds)\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    predictions_combined_train = []\n",
    "    for _, row in X_train_comb.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        k_avg = row['K_avg']\n",
    "        \n",
    "        # Modified SRK/T2 with optimized parameters\n",
    "        nc = nc_base_c + nc_cct_c * cct_norm\n",
    "        k_index = k_base_c + k_cct_c * cct_norm\n",
    "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
    "        modified = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'], K_avg=k_avg,\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc, k_index=k_index\n",
    "        )\n",
    "        \n",
    "        # Apply multiplicative correction\n",
    "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
    "        after_mult = modified * mult_factor\n",
    "        \n",
    "        # Apply additive correction with polynomial\n",
    "        if best_degree == 'linear':\n",
    "            a0_c, a1_c, a2_c, a3_c = result_a_final.x\n",
    "            add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
    "        elif best_degree == 'quadratic':\n",
    "            a0_c, a1_c, a2_c, a3_c, a4_c = result_a_final.x\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2)\n",
    "        else:  # cubic\n",
    "            a0_c, a1_c, a2_c, a3_c, a4_c, a5_c = result_a_final.x\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2 + a5_c * cct_norm**3)\n",
    "        \n",
    "        final = after_mult + add_correction\n",
    "        predictions_combined_train.append(final)\n",
    "    \n",
    "    train_mae_combined = mean_absolute_error(X_train_comb['PostOP Spherical Equivalent'], \n",
    "                                            predictions_combined_train)\n",
    "    \n",
    "    # EVALUATE ON TEST SET\n",
    "    predictions_combined_test = []\n",
    "    for _, row in X_test_comb.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        k_avg = row['K_avg']\n",
    "        \n",
    "        # Modified SRK/T2 with optimized parameters\n",
    "        nc = nc_base_c + nc_cct_c * cct_norm\n",
    "        k_index = k_base_c + k_cct_c * cct_norm\n",
    "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
    "        modified = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'], K_avg=k_avg,\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc, k_index=k_index\n",
    "        )\n",
    "        \n",
    "        # Apply multiplicative correction\n",
    "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
    "        after_mult = modified * mult_factor\n",
    "        \n",
    "        # Apply additive correction with polynomial\n",
    "        if best_degree == 'linear':\n",
    "            add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
    "        elif best_degree == 'quadratic':\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2)\n",
    "        else:  # cubic\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2 + a5_c * cct_norm**3)\n",
    "        \n",
    "        final = after_mult + add_correction\n",
    "        predictions_combined_test.append(final)\n",
    "    \n",
    "    test_mae_combined = mean_absolute_error(X_test_comb['PostOP Spherical Equivalent'], \n",
    "                                           predictions_combined_test)\n",
    "    baseline_mae_combined = mean_absolute_error(X_test_comb['PostOP Spherical Equivalent'], \n",
    "                                                X_test_comb['SRKT2_Baseline'])\n",
    "    \n",
    "    improvement_combined = ((baseline_mae_combined - test_mae_combined) / baseline_mae_combined) * 100\n",
    "    overfit_ratio = test_mae_combined / train_mae_combined if train_mae_combined > 0 else float('inf')\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ RESULTS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Train MAE: {train_mae_combined:.4f} D\")\n",
    "    print(f\"  Test MAE:  {test_mae_combined:.4f} D\")\n",
    "    print(f\"  Baseline:  {baseline_mae_combined:.4f} D\")\n",
    "    print(f\"  Improvement: {improvement_combined:.1f}%\")\n",
    "    print(f\"  Overfit ratio: {overfit_ratio:.3f}\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_combined.append({\n",
    "        'seed': SEED,\n",
    "        'param_values': result_p_final.x,\n",
    "        'mult_values': result_m_final.x,\n",
    "        'add_values': result_a_final.x,\n",
    "        'train_mae': train_mae_combined,\n",
    "        'test_mae': test_mae_combined,\n",
    "        'baseline_mae': baseline_mae_combined,\n",
    "        'improvement': improvement_combined,\n",
    "        'overfit_ratio': overfit_ratio\n",
    "    })\n",
    "    \n",
    "    seed_test_maes_combined.append(test_mae_combined)\n",
    "    seed_train_maes_combined.append(train_mae_combined)\n",
    "    seed_baseline_maes_combined.append(baseline_mae_combined)\n",
    "    seed_improvements_combined.append(improvement_combined)\n",
    "    seed_overfit_ratios_combined.append(overfit_ratio)\n",
    "    \n",
    "    seed_param_results.append(result_p_final.x)\n",
    "    seed_mult_results.append(result_m_final.x)\n",
    "    seed_add_results.append(result_a_final.x)\n",
    "\n",
    "# SUMMARY STATISTICS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"MULTI-SEED SUMMARY - COMBINED APPROACH WITH {best_degree.upper()} ADDITIVE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Test MAE:     {np.mean(seed_test_maes_combined):.4f} Â± {np.std(seed_test_maes_combined):.4f} D\")\n",
    "print(f\"Train MAE:    {np.mean(seed_train_maes_combined):.4f} Â± {np.std(seed_train_maes_combined):.4f} D\")\n",
    "print(f\"Baseline MAE: {np.mean(seed_baseline_maes_combined):.4f} Â± {np.std(seed_baseline_maes_combined):.4f} D\")\n",
    "print(f\"Improvement:  {np.mean(seed_improvements_combined):.1f}% Â± {np.std(seed_improvements_combined):.1f}%\")\n",
    "print(f\"Overfit ratio: {np.mean(seed_overfit_ratios_combined):.3f} Â± {np.std(seed_overfit_ratios_combined):.3f}\")\n",
    "\n",
    "# Parameter consistency analysis\n",
    "print(\"\\nğŸ”¬ PARAMETER CONSISTENCY:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "param_names = ['nc_base', 'nc_cct', 'k_base', 'k_cct', 'acd_base', 'acd_cct']\n",
    "param_array = np.array(seed_param_results)\n",
    "print(\"\\nParameter optimization values:\")\n",
    "for i, name in enumerate(param_names):\n",
    "    values = param_array[:, i]\n",
    "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
    "\n",
    "mult_names = ['m0', 'm1_cct', 'm2_ratio']\n",
    "mult_array = np.array(seed_mult_results)\n",
    "print(\"\\nMultiplicative correction values:\")\n",
    "for i, name in enumerate(mult_names):\n",
    "    values = mult_array[:, i]\n",
    "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
    "\n",
    "add_array = np.array(seed_add_results)\n",
    "print(f\"\\nAdditive correction values ({best_degree}):\")\n",
    "if best_degree == 'linear':\n",
    "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K']\n",
    "elif best_degree == 'quadratic':\n",
    "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K', 'a4_cct2']\n",
    "else:  # cubic\n",
    "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K', 'a4_cct2', 'a5_cct3']\n",
    "\n",
    "for i, name in enumerate(add_names):\n",
    "    values = add_array[:, i]\n",
    "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
    "\n",
    "# Clinical significance\n",
    "mae_mean = np.mean(seed_test_maes_combined)\n",
    "mae_std = np.std(seed_test_maes_combined)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLINICAL INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ… Combined approach with {best_degree} additive achieves:\")\n",
    "print(f\"   â€¢ Mean absolute error: {mae_mean:.3f} Â± {mae_std:.3f} D\")\n",
    "print(f\"   â€¢ {np.mean(seed_improvements_combined):.0f}% improvement over standard SRK/T2\")\n",
    "\n",
    "if mae_mean < 0.5:\n",
    "    print(\"   â€¢ EXCELLENT: Within Â±0.50 D target for most patients\")\n",
    "elif mae_mean < 0.75:\n",
    "    print(\"   â€¢ GOOD: Within Â±0.75 D for most patients\")\n",
    "else:\n",
    "    print(\"   â€¢ MODERATE: Further optimization may be beneficial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3yxaies4nqp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MULTI-SEED ANALYSIS - COMPREHENSIVE COMPARISON OF ALL METHODS\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š PERFORMANCE RANKING (Best to Worst):\n",
      "--------------------------------------------------------------------------------\n",
      "Method                        Test MAE    Train MAE  Improvement    Overfit\n",
      "--------------------------------------------------------------------------------\n",
      "Multiplicative            0.9335 Â± 0.1496       0.8594        24.9%      9.937\n",
      "Full Combined (quadratic) 0.9523 Â± 0.1501       0.8362        23.5%      1.155\n",
      "Baseline SRK/T2           1.2469 Â± 0.1562          N/A         0.0%        N/A\n",
      "Additive (quadratic)      1.2587 Â± 0.1941       1.1234        -0.8%      1.133\n",
      "Parameter Opt             1.3382 Â± 0.2895       1.0256        -6.5%     32.199\n",
      "\n",
      "================================================================================\n",
      "ğŸ† WINNER ANALYSIS\n",
      "================================================================================\n",
      "BEST METHOD: Multiplicative\n",
      "  â€¢ Test MAE: 0.9335 Â± 0.1496 D\n",
      "  â€¢ Improvement over baseline: 24.9%\n",
      "\n",
      "ğŸ“ˆ STATISTICAL ANALYSIS:\n",
      "--------------------------------------------------------------------------------\n",
      "Advantage over 2nd best (Full Combined (quadratic)): 0.0188 D\n",
      "  âš  Marginal clinical difference (<0.05 D)\n",
      "\n",
      "ğŸ” OVERFITTING ANALYSIS:\n",
      "--------------------------------------------------------------------------------\n",
      "Methods with potential overfitting (ratio > 1.2):\n",
      "  â€¢ Multiplicative: 9.937\n",
      "  â€¢ Parameter Opt: 32.199\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CLINICAL RECOMMENDATIONS\n",
      "================================================================================\n",
      "âš  MODERATE PERFORMANCE\n",
      "   The Multiplicative method achieves 0.933 D MAE\n",
      "   This may require additional optimization\n",
      "   Recommendation: Explore additional features or methods\n",
      "\n",
      "ğŸ’¾ Exporting results to CSV...\n",
      "   Results saved to: iol_formula_comparison.csv\n",
      "\n",
      "================================================================================\n",
      "FINAL FORMULA\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# MULTI-SEED COMPARISON - FINAL COMPREHENSIVE SUMMARY\n",
    "# ====================================================\n",
    "# PURPOSE: Compare ALL methods across multiple seeds for robust conclusions\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MULTI-SEED ANALYSIS - COMPREHENSIVE COMPARISON OF ALL METHODS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Compile all results into a comparison table\n",
    "all_methods = {}\n",
    "\n",
    "# 1. Baseline (no optimization)\n",
    "if 'seed_baseline_maes_param' in locals():\n",
    "    all_methods['Baseline SRK/T2'] = {\n",
    "        'test_mae': np.mean(seed_baseline_maes_param),\n",
    "        'test_std': np.std(seed_baseline_maes_param),\n",
    "        'train_mae': np.nan,  # Baseline doesn't have training\n",
    "        'improvement': 0.0,\n",
    "        'overfit_ratio': np.nan\n",
    "    }\n",
    "\n",
    "# 2. Parameter Optimization\n",
    "if 'seed_test_maes_param' in locals():\n",
    "    all_methods['Parameter Opt'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_param),\n",
    "        'test_std': np.std(seed_test_maes_param),\n",
    "        'train_mae': np.mean(seed_train_maes_param),\n",
    "        'improvement': np.mean(seed_improvements_param),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_param)\n",
    "    }\n",
    "\n",
    "# 3. Multiplicative Correction\n",
    "if 'seed_test_maes_mult' in locals():\n",
    "    all_methods['Multiplicative'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_mult),\n",
    "        'test_std': np.std(seed_test_maes_mult),\n",
    "        'train_mae': np.mean(seed_train_maes_mult),\n",
    "        'improvement': np.mean(seed_improvements_mult),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_mult)\n",
    "    }\n",
    "\n",
    "# 4. Additive Correction (with best polynomial)\n",
    "if 'seed_test_maes_additive' in locals():\n",
    "    method_name = f'Additive ({best_degree})' if 'best_degree' in locals() else 'Additive'\n",
    "    all_methods[method_name] = {\n",
    "        'test_mae': np.mean(seed_test_maes_additive),\n",
    "        'test_std': np.std(seed_test_maes_additive),\n",
    "        'train_mae': np.mean(seed_train_maes_additive),\n",
    "        'improvement': np.mean(seed_improvements_additive),\n",
    "        'overfit_ratio': np.mean([t/r for t,r in zip(seed_test_maes_additive, seed_train_maes_additive)])\n",
    "    }\n",
    "\n",
    "# 5. Param + Multiplicative Combined (no additive)\n",
    "# 6. Full Combined (all three methods)\n",
    "if 'seed_test_maes_combined' in locals():\n",
    "    poly_label = f' ({best_degree})' if 'best_degree' in locals() else ''\n",
    "    all_methods[f'Full Combined{poly_label}'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_combined),\n",
    "        'test_std': np.std(seed_test_maes_combined),\n",
    "        'train_mae': np.mean(seed_train_maes_combined),\n",
    "        'improvement': np.mean(seed_improvements_combined),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_combined)\n",
    "    }\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(all_methods).T\n",
    "comparison_df = comparison_df.sort_values('test_mae')\n",
    "\n",
    "print(\"\\nğŸ“Š PERFORMANCE RANKING (Best to Worst):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Method':<25} {'Test MAE':>12} {'Train MAE':>12} {'Improvement':>12} {'Overfit':>10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for method in comparison_df.index:\n",
    "    row = comparison_df.loc[method]\n",
    "    test_str = f\"{row['test_mae']:.4f} Â± {row['test_std']:.4f}\"\n",
    "    train_str = f\"{row['train_mae']:.4f}\" if not pd.isna(row['train_mae']) else \"N/A\"\n",
    "    improv_str = f\"{row['improvement']:.1f}%\" if not pd.isna(row['improvement']) else \"N/A\"\n",
    "    overfit_str = f\"{row['overfit_ratio']:.3f}\" if not pd.isna(row['overfit_ratio']) else \"N/A\"\n",
    "    \n",
    "    print(f\"{method:<25} {test_str:>12} {train_str:>12} {improv_str:>12} {overfit_str:>10}\")\n",
    "\n",
    "# Identify best method\n",
    "best_method = comparison_df.index[0]\n",
    "best_mae = comparison_df.loc[best_method, 'test_mae']\n",
    "best_std = comparison_df.loc[best_method, 'test_std']\n",
    "best_improvement = comparison_df.loc[best_method, 'improvement']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ† WINNER ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"BEST METHOD: {best_method}\")\n",
    "print(f\"  â€¢ Test MAE: {best_mae:.4f} Â± {best_std:.4f} D\")\n",
    "print(f\"  â€¢ Improvement over baseline: {best_improvement:.1f}%\")\n",
    "\n",
    "# Additional insights\n",
    "if 'Full Combined' in best_method:\n",
    "    print(\"\\nâœ… The full combined approach performs best, validating that:\")\n",
    "    print(\"   1. Parameter optimization corrects fundamental optical assumptions\")\n",
    "    print(\"   2. Multiplicative correction scales for proportional errors\")\n",
    "    print(\"   3. Additive correction handles residual systematic bias\")\n",
    "    if 'best_degree' in locals() and best_degree != 'linear':\n",
    "        print(f\"   4. {best_degree.capitalize()} polynomial captures non-linear CCT effects\")\n",
    "# Statistical significance analysis\n",
    "print(\"\\nğŸ“ˆ STATISTICAL ANALYSIS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Compare top methods\n",
    "if len(comparison_df) >= 2:\n",
    "    second_best = comparison_df.index[1]\n",
    "    mae_diff = comparison_df.loc[second_best, 'test_mae'] - best_mae\n",
    "    \n",
    "    print(f\"Advantage over 2nd best ({second_best}): {mae_diff:.4f} D\")\n",
    "    \n",
    "    # Check if difference is clinically significant (>0.05 D)\n",
    "    if mae_diff > 0.05:\n",
    "        print(\"  âœ“ Clinically significant difference (>0.05 D)\")\n",
    "    else:\n",
    "        print(\"  âš  Marginal clinical difference (<0.05 D)\")\n",
    "\n",
    "# Overfitting analysis\n",
    "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 80)\n",
    "overfit_methods = comparison_df[comparison_df['overfit_ratio'] > 1.2]\n",
    "if not overfit_methods.empty:\n",
    "    print(\"Methods with potential overfitting (ratio > 1.2):\")\n",
    "    for method in overfit_methods.index:\n",
    "        ratio = overfit_methods.loc[method, 'overfit_ratio']\n",
    "        print(f\"  â€¢ {method}: {ratio:.3f}\")\n",
    "else:\n",
    "    print(\"âœ“ No significant overfitting detected in any method\")\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: MAE Comparison\n",
    "ax1 = axes[0]\n",
    "methods = list(comparison_df.index)\n",
    "maes = comparison_df['test_mae'].values\n",
    "stds = comparison_df['test_std'].values\n",
    "colors = ['red' if 'Baseline' in m else 'green' if m == best_method else 'blue' for m in methods]\n",
    "\n",
    "ax1.barh(range(len(methods)), maes, xerr=stds, color=colors, alpha=0.7)\n",
    "ax1.set_yticks(range(len(methods)))\n",
    "ax1.set_yticklabels(methods)\n",
    "ax1.set_xlabel('Test MAE (D)')\n",
    "ax1.set_title('Mean Absolute Error Comparison')\n",
    "ax1.axvline(x=0.5, color='green', linestyle='--', alpha=0.5, label='Clinical target')\n",
    "ax1.axvline(x=0.75, color='orange', linestyle='--', alpha=0.5)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Improvement over Baseline\n",
    "ax2 = axes[1]\n",
    "improvements = comparison_df['improvement'].values\n",
    "ax2.barh(range(len(methods)), improvements, color=colors, alpha=0.7)\n",
    "ax2.set_yticks(range(len(methods)))\n",
    "ax2.set_yticklabels(methods)\n",
    "ax2.set_xlabel('Improvement (%)')\n",
    "ax2.set_title('Improvement over Baseline SRK/T2')\n",
    "\n",
    "# Plot 3: Train vs Test MAE (Overfitting check)\n",
    "ax3 = axes[2]\n",
    "train_maes = comparison_df['train_mae'].values\n",
    "test_maes = comparison_df['test_mae'].values\n",
    "valid_idx = ~pd.isna(train_maes)\n",
    "ax3.scatter(train_maes[valid_idx], test_maes[valid_idx], s=100, alpha=0.7)\n",
    "for i, method in enumerate(methods):\n",
    "    if valid_idx[i]:\n",
    "        ax3.annotate(method, (train_maes[i], test_maes[i]), fontsize=8, ha='right')\n",
    "\n",
    "# Add diagonal line (perfect generalization)\n",
    "min_val = min(np.nanmin(train_maes), np.nanmin(test_maes))\n",
    "max_val = max(np.nanmax(train_maes), np.nanmax(test_maes))\n",
    "ax3.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Perfect generalization')\n",
    "ax3.set_xlabel('Train MAE (D)')\n",
    "ax3.set_ylabel('Test MAE (D)')\n",
    "ax3.set_title('Overfitting Analysis')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLINICAL RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if best_mae < 0.5:\n",
    "    print(\"âœ… EXCELLENT PERFORMANCE\")\n",
    "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
    "    print(\"   This is within the Â±0.50 D target for premium IOL surgery\")\n",
    "    print(\"   Recommendation: Ready for clinical validation study\")\n",
    "elif best_mae < 0.75:\n",
    "    print(\"âœ… GOOD PERFORMANCE\")\n",
    "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
    "    print(\"   This is within the Â±0.75 D acceptable range\")\n",
    "    print(\"   Recommendation: Consider further optimization for premium cases\")\n",
    "else:\n",
    "    print(\"âš  MODERATE PERFORMANCE\")\n",
    "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
    "    print(\"   This may require additional optimization\")\n",
    "    print(\"   Recommendation: Explore additional features or methods\")\n",
    "\n",
    "# Export results\n",
    "print(\"\\nğŸ’¾ Exporting results to CSV...\")\n",
    "comparison_df.to_csv('iol_formula_comparison.csv')\n",
    "print(\"   Results saved to: iol_formula_comparison.csv\")\n",
    "\n",
    "# Final formula recommendation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL FORMULA\")\n",
    "print(\"=\"*80)\n",
    "if 'Full Combined' in best_method and 'seed_param_results' in locals():\n",
    "    print(f\"Recommended formula: {best_method}\")\n",
    "    print(\"\\nAverage parameters across seeds:\")\n",
    "    \n",
    "    # Parameter values\n",
    "    param_array = np.array(seed_param_results)\n",
    "    print(\"\\n1. Modified SRK/T2 parameters:\")\n",
    "    print(f\"   nc = {np.mean(param_array[:, 0]):.4f} + {np.mean(param_array[:, 1]):.4f} Ã— CCT_norm\")\n",
    "    print(f\"   k_index = {np.mean(param_array[:, 2]):.4f} + {np.mean(param_array[:, 3]):.4f} Ã— CCT_norm\")\n",
    "    print(f\"   ACD_offset = {np.mean(param_array[:, 4]):.4f} + {np.mean(param_array[:, 5]):.4f} Ã— CCT_norm\")\n",
    "    \n",
    "    # Multiplicative values\n",
    "    if 'seed_mult_results' in locals():\n",
    "        mult_array = np.array(seed_mult_results)\n",
    "        print(\"\\n2. Multiplicative correction:\")\n",
    "        print(f\"   factor = 1 + {np.mean(mult_array[:, 0]):.4f} + {np.mean(mult_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(mult_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
    "    \n",
    "    # Additive values\n",
    "    if 'seed_add_results' in locals():\n",
    "        add_array = np.array(seed_add_results)\n",
    "        print(f\"\\n3. Additive correction ({best_degree if 'best_degree' in locals() else 'linear'}):\")\n",
    "        if best_degree == 'linear' or 'best_degree' not in locals():\n",
    "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio + {np.mean(add_array[:, 3]):.4f} Ã— K_avg\")\n",
    "        elif best_degree == 'quadratic':\n",
    "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
    "            print(f\"              + {np.mean(add_array[:, 3]):.4f} Ã— K_avg + {np.mean(add_array[:, 4]):.4f} Ã— CCT_normÂ²\")\n",
    "        else:  # cubic\n",
    "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
    "            print(f\"              + {np.mean(add_array[:, 3]):.4f} Ã— K_avg + {np.mean(add_array[:, 4]):.4f} Ã— CCT_normÂ² + {np.mean(add_array[:, 5]):.4f} Ã— CCT_normÂ³\")\n",
    "    \n",
    "    print(\"\\nWhere:\")\n",
    "    print(\"   CCT_norm = (CCT - 600) / 100\")\n",
    "    print(\"   CCT_ratio = CCT / AL\")\n",
    "    print(\"   K_avg = (K_steep + K_flat) / 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
