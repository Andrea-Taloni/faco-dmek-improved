{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "41782613",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ğŸ”§ MULTI-SEED CONFIGURATION\n",
            "======================================================================\n",
            "Seeds for validation: [42]\n",
            "This ensures results are not dependent on random split\n",
            "Each seed creates different train/test splits for robust assessment\n",
            "======================================================================\n",
            "IOL CALCULATION FOR PRE-DMEK PATIENTS\n",
            "======================================================================\n",
            "\n",
            "ğŸ“Š WHAT WE'RE DOING:\n",
            "--------------------------------------------------\n",
            "â€¢ Loading data from Fuchs' dystrophy patients\n",
            "â€¢ These patients had combined cataract + DMEK surgery\n",
            "â€¢ Goal: Improve IOL power calculation accuracy\n",
            "â€¢ Challenge: Edematous corneas distort standard formulas\n",
            "â€¢ NEW: Using 1 different seeds for robust validation\n",
            "\n",
            "âœ… Loaded 96 patients from FacoDMEK.xlsx\n",
            "\n",
            "ğŸ” KEY MEASUREMENTS IN OUR DATA:\n",
            "--------------------------------------------------\n",
            "â€¢ Bio-AL: Axial length (mm)\n",
            "â€¢ Bio-Ks/Kf: Steep and flat keratometry (D)\n",
            "â€¢ CCT: Central corneal thickness (Î¼m) - KEY for edema\n",
            "â€¢ IOL Power: Implanted lens power (D)\n",
            "â€¢ PostOP Spherical Equivalent: Actual outcome (D)\n"
          ]
        }
      ],
      "source": [
        "# IOL CALCULATION FOR PRE-DMEK PATIENTS - SETUP AND DATA LOADING\n",
        "# ================================================================\n",
        "# PURPOSE: Set up the analysis environment and load patient data\n",
        "# This notebook optimizes IOL power calculations for Fuchs' dystrophy patients\n",
        "# undergoing combined phacoemulsification and DMEK surgery\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Constants for clinical accuracy thresholds (diopters)\n",
        "THRESHOLDS = [0.25, 0.50, 0.75, 1.00]\n",
        "TEST_SIZE = 0.25      # 25% holdout for final testing\n",
        "N_FOLDS = 5           # 5-fold cross-validation\n",
        "\n",
        "# MULTI-SEED CONFIGURATION FOR ROBUST VALIDATION\n",
        "SEEDS = [42]  # Quick test with single seed\n",
        "#SEEDS = [42, 123]  # Medium test with 2 seeds\n",
        "#SEEDS = [42, 123, 456, 789, 2025]  # Multiple seeds for statistical robustness\n",
        "print(\"=\" * 70)\n",
        "print(\"ğŸ”§ MULTI-SEED CONFIGURATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Seeds for validation: {SEEDS}\")\n",
        "print(\"This ensures results are not dependent on random split\")\n",
        "print(\"Each seed creates different train/test splits for robust assessment\")\n",
        "\n",
        "# Storage for multi-seed results\n",
        "multi_seed_results = {\n",
        "\n",
        "    'parameter': {},\n",
        "    'multiplicative': {},\n",
        "    'additive': {},\n",
        "    'combined': {},\n",
        "    'fixed_combined': {}\n",
        "}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"IOL CALCULATION FOR PRE-DMEK PATIENTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nğŸ“Š WHAT WE'RE DOING:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"â€¢ Loading data from Fuchs' dystrophy patients\")\n",
        "print(\"â€¢ These patients had combined cataract + DMEK surgery\")\n",
        "print(\"â€¢ Goal: Improve IOL power calculation accuracy\")\n",
        "print(\"â€¢ Challenge: Edematous corneas distort standard formulas\")\n",
        "print(f\"â€¢ NEW: Using {len(SEEDS)} different seeds for robust validation\")\n",
        "\n",
        "# Load the patient data\n",
        "df = pd.read_excel('FacoDMEK.xlsx')\n",
        "print(f\"\\nâœ… Loaded {len(df)} patients from FacoDMEK.xlsx\")\n",
        "\n",
        "print(\"\\nğŸ” KEY MEASUREMENTS IN OUR DATA:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"â€¢ Bio-AL: Axial length (mm)\")\n",
        "print(\"â€¢ Bio-Ks/Kf: Steep and flat keratometry (D)\")\n",
        "print(\"â€¢ CCT: Central corneal thickness (Î¼m) - KEY for edema\")\n",
        "print(\"â€¢ IOL Power: Implanted lens power (D)\")\n",
        "print(\"â€¢ PostOP Spherical Equivalent: Actual outcome (D)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9871e22d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "SRK/T2 FORMULA (Sheard et al. 2010)\n",
            "======================================================================\n",
            "â€¢ SKR/T2 assumes normal corneal properties\n",
            "â€¢ In Fuchs' dystrophy, the cornea is NOT normal:\n",
            "  - Edema changes refractive index (nc)\n",
            "  - Swelling alters keratometric index (k_index)\n",
            "  - Anterior chamber depth is affected\n",
            "\n",
            "Our strategy: Keep the formula structure, optimize the parameters!\n",
            "\n",
            "ğŸ“ THE SRK/T2 FORMULA:\n",
            "\n",
            "         1000Â·nâ‚Â·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) - PÂ·(Lopt - ACDest)Â·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest)\n",
            "REF = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "       nâ‚Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) + LoptÂ·r) - 0.001Â·PÂ·(Lopt - ACDest)Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest) + ACDestÂ·r)\n"
          ]
        }
      ],
      "source": [
        "# STANDARD SRK/T2 FORMULA IMPLEMENTATION\n",
        "# ========================================\n",
        "# PURPOSE: Implement the baseline SRK/T2 formula (Sheard et al. 2010)\n",
        "# This is the current gold standard for IOL calculations\n",
        "# We'll use this as our baseline to compare improvements against\n",
        "\n",
        "def calculate_SRKT2(AL, K_avg, IOL_power, A_constant, nc=1.333, k_index=1.3375):\n",
        "    \"\"\"\n",
        "    SRK/T2 Formula (Sheard et al. 2010)\n",
        "    - Assumes NORMAL corneas (nc=1.333, k_index=1.3375)\n",
        "    - These assumptions fail in edematous Fuchs' corneas\n",
        "    \n",
        "    Parameters:\n",
        "    - AL: Axial length (mm)\n",
        "    - K_avg: Average keratometry (D)\n",
        "    - IOL_power: IOL power (D)\n",
        "    - A_constant: Lens-specific constant\n",
        "    - nc: Corneal refractive index (we'll optimize this!)\n",
        "    - k_index: Keratometric index (we'll optimize this too!)\n",
        "    \"\"\"\n",
        "    # Constants\n",
        "    na = 1.336  # Aqueous/vitreous refractive index\n",
        "    V = 12      # Vertex distance (mm)\n",
        "    ncm1 = nc - 1\n",
        "    \n",
        "    # Convert keratometry to radius using keratometric index\n",
        "    # This is where edema causes problems - k_index assumes normal cornea!\n",
        "    r = (k_index - 1) * 1000 / K_avg\n",
        "    \n",
        "    # Axial length correction for long eyes\n",
        "    if AL <= 24.2:\n",
        "        LCOR = AL\n",
        "    else:\n",
        "        LCOR = 3.446 + 1.716 * AL - 0.0237 * AL * AL\n",
        "    \n",
        "    # H2 calculation (corneal height) - Sheard's modification\n",
        "    H2 = -10.326 + 0.32630 * LCOR + 0.13533 * K_avg\n",
        "    \n",
        "    # ACD (Anterior Chamber Depth) estimation\n",
        "    # Edema can affect this too!\n",
        "    ACD_const = 0.62467 * A_constant - 68.747\n",
        "    offset = ACD_const - 3.336\n",
        "    ACD_est = H2 + offset\n",
        "    \n",
        "    # Retinal thickness correction\n",
        "    RETHICK = 0.65696 - 0.02029 * AL\n",
        "    LOPT = AL + RETHICK  # Optical axial length\n",
        "    \n",
        "    # SRK/T2 refraction calculation - the complex optics formula\n",
        "    numerator = (1000 * na * (na * r - ncm1 * LOPT) - \n",
        "                 IOL_power * (LOPT - ACD_est) * (na * r - ncm1 * ACD_est))\n",
        "    \n",
        "    denominator = (na * (V * (na * r - ncm1 * LOPT) + LOPT * r) - \n",
        "                   0.001 * IOL_power * (LOPT - ACD_est) * \n",
        "                   (V * (na * r - ncm1 * ACD_est) + ACD_est * r))\n",
        "    \n",
        "    return numerator / denominator\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"SRK/T2 FORMULA (Sheard et al. 2010)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"â€¢ SKR/T2 assumes normal corneal properties\")\n",
        "print(\"â€¢ In Fuchs' dystrophy, the cornea is NOT normal:\")\n",
        "print(\"  - Edema changes refractive index (nc)\")\n",
        "print(\"  - Swelling alters keratometric index (k_index)\")\n",
        "print(\"  - Anterior chamber depth is affected\")\n",
        "print(\"\\nOur strategy: Keep the formula structure, optimize the parameters!\")\n",
        "\n",
        "print(\"\\nğŸ“ THE SRK/T2 FORMULA:\")\n",
        "print()\n",
        "print(\"         1000Â·nâ‚Â·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) - PÂ·(Lopt - ACDest)Â·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest)\")\n",
        "print(\"REF = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "print(\"       nâ‚Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·Lopt) + LoptÂ·r) - 0.001Â·PÂ·(Lopt - ACDest)Â·(VÂ·(nâ‚Â·r - ncâ‚‹â‚Â·ACDest) + ACDestÂ·r)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "db415cc6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "BASELINE SRK/T2 PERFORMANCE\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ WHAT WE'RE DOING:\n",
            "--------------------------------------------------\n",
            "1. Calculate average K from steep and flat readings\n",
            "2. Apply standard SRK/T2 to all 96 patients\n",
            "3. Compare predictions to actual outcomes\n",
            "4. Measure error to establish baseline performance\n",
            "\n",
            "ğŸ“Š BASELINE PERFORMANCE METRICS:\n",
            "======================================================================\n",
            "  Mean Absolute Error (MAE):     1.3591 D\n",
            "  Mean Error (ME):                -0.2915 D\n",
            "  Standard Deviation (SD):        1.7471 D\n",
            "  Median Absolute Error:          1.0311 D\n",
            "\n",
            "ğŸ’¡ INTERPRETATION:\n",
            "--------------------------------------------------\n",
            "â€¢ MAE of 1.36 D is POOR (>1.0 D is clinically unacceptable)\n",
            "â€¢ Mean error of -0.29 D shows systematic bias\n",
            "  â†’ Formula tends to predict too myopic (negative)\n",
            "\n",
            "ğŸ“ˆ CLINICAL ACCURACY:\n",
            "----------------------------------------------------------------------\n",
            "  Within Â±0.25 D:  13.5% of eyes\n",
            "  Within Â±0.50 D:  26.0% of eyes\n",
            "  Within Â±0.75 D:  35.4% of eyes\n",
            "  Within Â±1.00 D:  49.0% of eyes\n",
            "\n",
            "ğŸ¯ CLINICAL TARGETS:\n",
            "--------------------------------------------------\n",
            "â€¢ Modern standard: >70% within Â±0.50 D\n",
            "â€¢ Acceptable: >90% within Â±1.00 D\n",
            "â€¢ Our baseline: 26.0% within Â±0.50 D\n",
            "\n",
            "âš ï¸ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\n",
            "This is why we need optimization!\n"
          ]
        }
      ],
      "source": [
        "# BASELINE PERFORMANCE EVALUATION\n",
        "# =================================\n",
        "# PURPOSE: Calculate how well standard SRK/T2 performs on our Fuchs' patients\n",
        "# This establishes the baseline that we need to beat\n",
        "# Spoiler: It won't be great due to the edematous corneas!\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"BASELINE SRK/T2 PERFORMANCE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nğŸ“‹ WHAT WE'RE DOING:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"1. Calculate average K from steep and flat readings\")\n",
        "print(\"2. Apply standard SRK/T2 to all 96 patients\")\n",
        "print(\"3. Compare predictions to actual outcomes\")\n",
        "print(\"4. Measure error to establish baseline performance\")\n",
        "\n",
        "# Calculate average K (needed for SRK/T2)\n",
        "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
        "\n",
        "# Apply standard SRK/T2 formula to all patients\n",
        "df['SRKT2_Prediction'] = df.apply(\n",
        "    lambda row: calculate_SRKT2(\n",
        "        AL=row['Bio-AL'],\n",
        "        K_avg=row['K_avg'],\n",
        "        IOL_power=row['IOL Power'],\n",
        "        A_constant=row['A-Constant']\n",
        "        # Note: Using DEFAULT nc=1.333 and k_index=1.3375\n",
        "    ), axis=1\n",
        ")\n",
        "\n",
        "# Calculate prediction errors\n",
        "df['Prediction_Error'] = df['PostOP Spherical Equivalent'] - df['SRKT2_Prediction']\n",
        "df['Absolute_Error'] = abs(df['Prediction_Error'])\n",
        "\n",
        "# Calculate key metrics\n",
        "mae = df['Absolute_Error'].mean()\n",
        "me = df['Prediction_Error'].mean()\n",
        "std = df['Prediction_Error'].std()\n",
        "median_ae = df['Absolute_Error'].median()\n",
        "\n",
        "print(\"\\nğŸ“Š BASELINE PERFORMANCE METRICS:\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"  Mean Absolute Error (MAE):     {mae:.4f} D\")\n",
        "print(f\"  Mean Error (ME):                {me:+.4f} D\")\n",
        "print(f\"  Standard Deviation (SD):        {std:.4f} D\")\n",
        "print(f\"  Median Absolute Error:          {median_ae:.4f} D\")\n",
        "\n",
        "print(\"\\nğŸ’¡ INTERPRETATION:\")\n",
        "print(\"-\" * 50)\n",
        "if mae > 1.0:\n",
        "    print(f\"â€¢ MAE of {mae:.2f} D is POOR (>1.0 D is clinically unacceptable)\")\n",
        "else:\n",
        "    print(f\"â€¢ MAE of {mae:.2f} D is moderate\")\n",
        "    \n",
        "if abs(me) > 0.25:\n",
        "    print(f\"â€¢ Mean error of {me:+.2f} D shows systematic bias\")\n",
        "    if me < 0:\n",
        "        print(\"  â†’ Formula tends to predict too myopic (negative)\")\n",
        "    else:\n",
        "        print(\"  â†’ Formula tends to predict too hyperopic (positive)\")\n",
        "\n",
        "# Calculate clinical accuracy rates\n",
        "within_025 = (df['Absolute_Error'] <= 0.25).sum() / len(df) * 100\n",
        "within_050 = (df['Absolute_Error'] <= 0.50).sum() / len(df) * 100\n",
        "within_075 = (df['Absolute_Error'] <= 0.75).sum() / len(df) * 100\n",
        "within_100 = (df['Absolute_Error'] <= 1.00).sum() / len(df) * 100\n",
        "\n",
        "print(\"\\nğŸ“ˆ CLINICAL ACCURACY:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"  Within Â±0.25 D:  {within_025:.1f}% of eyes\")\n",
        "print(f\"  Within Â±0.50 D:  {within_050:.1f}% of eyes\")\n",
        "print(f\"  Within Â±0.75 D:  {within_075:.1f}% of eyes\")\n",
        "print(f\"  Within Â±1.00 D:  {within_100:.1f}% of eyes\")\n",
        "\n",
        "print(\"\\nğŸ¯ CLINICAL TARGETS:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"â€¢ Modern standard: >70% within Â±0.50 D\")\n",
        "print(\"â€¢ Acceptable: >90% within Â±1.00 D\")\n",
        "print(f\"â€¢ Our baseline: {within_050:.1f}% within Â±0.50 D\")\n",
        "print(\"\\nâš ï¸ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\")\n",
        "print(\"This is why we need optimization!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ridge_analysis",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "RIDGE REGRESSION FEATURE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ğŸ” WHY START WITH RIDGE?\n",
            "--------------------------------------------------\n",
            "â€¢ Ridge regression identifies important features\n",
            "â€¢ Helps us understand what drives prediction errors\n",
            "â€¢ Guides our formula optimization strategy\n",
            "â€¢ If CCT features are important, our hypothesis is correct!\n",
            "\n",
            "ğŸ“Š CREATING FEATURES:\n",
            "--------------------------------------------------\n",
            "Created 12 features including CCT interactions\n",
            "\n",
            "ğŸ† TOP 10 MOST IMPORTANT FEATURES:\n",
            "--------------------------------------------------\n",
            "  CCT_ratio_AL         Coef=+1.3677\n",
            "  CCT_x_AL             Coef=-0.8898\n",
            "  CCT_squared          Coef=-0.7666\n",
            "  Bio-AL               Coef=+0.4903\n",
            "  Bio-Ks               Coef=-0.3178\n",
            "  CCT_x_K              Coef=+0.3101\n",
            "  K_avg                Coef=-0.1584\n",
            "  IOL Power            Coef=-0.1189\n",
            "  CCT_norm             Coef=+0.0321\n",
            "  CCT                  Coef=+0.0321\n",
            "\n",
            "ğŸ’¡ KEY FINDINGS:\n",
            "--------------------------------------------------\n",
            "â€¢ CCT-related features account for 75.5% of total importance\n",
            "â€¢ Top feature: CCT_ratio_AL\n",
            "â€¢ CCT/AL ratio is among top 3 features!\n",
            "â€¢ This validates that CCT relative to eye size matters\n",
            "\n",
            "âœ… HYPOTHESIS CONFIRMED:\n",
            "CCT features dominate prediction - our CCT-dependent approach is justified!\n",
            "\n",
            "ğŸ¯ OPTIMIZATION STRATEGY BASED ON RIDGE:\n",
            "--------------------------------------------------\n",
            "1. Make optical parameters CCT-dependent (nc, k_index)\n",
            "2. Consider CCT/AL ratio in corrections\n",
            "3. Account for CCT interactions with other measurements\n"
          ]
        }
      ],
      "source": [
        "# RIDGE REGRESSION ANALYSIS - IDENTIFYING IMPORTANT FEATURES\n",
        "# ===========================================================\n",
        "# PURPOSE: Use machine learning to identify which features matter most\n",
        "# This will guide our optimization strategy\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"RIDGE REGRESSION FEATURE ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nğŸ” WHY START WITH RIDGE?\")\n",
        "print(\"-\" * 50)\n",
        "print(\"â€¢ Ridge regression identifies important features\")\n",
        "print(\"â€¢ Helps us understand what drives prediction errors\")\n",
        "print(\"â€¢ Guides our formula optimization strategy\")\n",
        "print(\"â€¢ If CCT features are important, our hypothesis is correct!\")\n",
        "\n",
        "# Create feature matrix with interactions\n",
        "print(\"\\nğŸ“Š CREATING FEATURES:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "features = []\n",
        "feature_names = []\n",
        "\n",
        "# Basic features\n",
        "for col in ['Bio-AL', 'Bio-Ks', 'Bio-Kf', 'IOL Power', 'CCT']:\n",
        "    features.append(df[col].values)\n",
        "    feature_names.append(col)\n",
        "\n",
        "# Add K_avg\n",
        "features.append(df['K_avg'].values)\n",
        "feature_names.append('K_avg')\n",
        "\n",
        "# CCT-derived features\n",
        "df['CCT_squared'] = df['CCT'] ** 2\n",
        "df['CCT_deviation'] = df['CCT'] - 550\n",
        "df['CCT_norm'] = (df['CCT'] - 600) / 100\n",
        "\n",
        "features.extend([\n",
        "    df['CCT_squared'].values,\n",
        "    df['CCT_deviation'].values,\n",
        "    df['CCT_norm'].values\n",
        "])\n",
        "feature_names.extend(['CCT_squared', 'CCT_deviation', 'CCT_norm'])\n",
        "\n",
        "# Interaction terms\n",
        "df['CCT_x_AL'] = df['CCT'] * df['Bio-AL']\n",
        "df['CCT_x_K'] = df['CCT'] * df['K_avg']\n",
        "df['CCT_ratio_AL'] = df['CCT'] / df['Bio-AL']\n",
        "\n",
        "features.extend([\n",
        "    df['CCT_x_AL'].values,\n",
        "    df['CCT_x_K'].values,\n",
        "    df['CCT_ratio_AL'].values\n",
        "])\n",
        "feature_names.extend(['CCT_x_AL', 'CCT_x_K', 'CCT_ratio_AL'])\n",
        "\n",
        "X = np.column_stack(features)\n",
        "y = df['PostOP Spherical Equivalent'].values\n",
        "\n",
        "print(f\"Created {len(feature_names)} features including CCT interactions\")\n",
        "\n",
        "# Standardize and train Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train Ridge to get feature importance\n",
        "ridge_analysis = Ridge(alpha=1.0)\n",
        "ridge_analysis.fit(X_scaled, y)\n",
        "\n",
        "# Get feature importance from coefficients\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': ridge_analysis.coef_,\n",
        "    'Abs_Coefficient': np.abs(ridge_analysis.coef_)\n",
        "}).sort_values('Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nğŸ† TOP 10 MOST IMPORTANT FEATURES:\")\n",
        "print(\"-\" * 50)\n",
        "for idx, row in feature_importance.head(10).iterrows():\n",
        "    print(f\"  {row['Feature']:20} Coef={row['Coefficient']:+.4f}\")\n",
        "\n",
        "# Analyze CCT importance\n",
        "cct_features = feature_importance[feature_importance['Feature'].str.contains('CCT')]\n",
        "cct_importance = cct_features['Abs_Coefficient'].sum()\n",
        "total_importance = feature_importance['Abs_Coefficient'].sum()\n",
        "cct_percentage = (cct_importance / total_importance) * 100\n",
        "\n",
        "print(\"\\nğŸ’¡ KEY FINDINGS:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"â€¢ CCT-related features account for {cct_percentage:.1f}% of total importance\")\n",
        "print(f\"â€¢ Top feature: {feature_importance.iloc[0]['Feature']}\")\n",
        "\n",
        "if 'CCT_ratio_AL' in feature_importance.head(3)['Feature'].values:\n",
        "    print(\"â€¢ CCT/AL ratio is among top 3 features!\")\n",
        "    print(\"â€¢ This validates that CCT relative to eye size matters\")\n",
        "\n",
        "if cct_percentage > 50:\n",
        "    print(\"\\nâœ… HYPOTHESIS CONFIRMED:\")\n",
        "    print(\"CCT features dominate prediction - our CCT-dependent approach is justified!\")\n",
        "\n",
        "print(\"\\nğŸ¯ OPTIMIZATION STRATEGY BASED ON RIDGE:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"1. Make optical parameters CCT-dependent (nc, k_index)\")\n",
        "print(\"2. Consider CCT/AL ratio in corrections\")\n",
        "print(\"3. Account for CCT interactions with other measurements\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "rt23gheoiv",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ğŸ¯ MULTI-SEED NESTED CROSS-VALIDATION:\n",
            "--------------------------------------------------\n",
            "â€¢ Testing 1 different random seeds: [42]\n",
            "â€¢ Each seed: 75% train, 25% test\n",
            "â€¢ Inner: 5-fold CV on training set\n",
            "â€¢ Results averaged across seeds for robustness\n",
            "\n",
            "================================================================================\n",
            "RUNNING MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "========================================\n",
            "SEED 1/1: 42\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 1.2383 Â± 0.3650 D\n",
            "  Train MAE: 1.1642, Test MAE: 1.4354\n",
            "  Test: Baseline=1.4849, Optimized=1.4354\n",
            "  Improvement: 3.3%\n",
            "  âš ï¸ Overfitting detected: Test 23.3% worse than train\n",
            "\n",
            "================================================================================\n",
            "PARAMETER OPTIMIZATION - MULTI-SEED SUMMARY\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\n",
            "--------------------------------------------------\n",
            "  Seed  42: MAE=1.4354 D, Improvement=3.3%\n",
            "\n",
            "ğŸ“ˆ STATISTICAL SUMMARY:\n",
            "--------------------------------------------------\n",
            "  Baseline MAE:      1.4849 Â± 0.0000 D\n",
            "  Train MAE:         1.1642 Â± 0.0000 D\n",
            "  Test MAE:          1.4354 Â± 0.0000 D\n",
            "  Mean Improvement:  3.3 Â± 0.0%\n",
            "  Best seed:         42 (MAE=1.4354)\n",
            "  Worst seed:        42 (MAE=1.4354)\n",
            "\n",
            "ğŸ” OVERFITTING ANALYSIS:\n",
            "--------------------------------------------------\n",
            "  Mean overfit ratio: 23.3%\n",
            "  (Test MAE is 23.3% worse than Train MAE on average)\n",
            "  âš ï¸ Significant overfitting - consider regularization\n",
            "\n",
            "âœ… CONSENSUS PARAMETERS (averaged across seeds):\n",
            "--------------------------------------------------\n",
            "  nc_base              = +1.3702 Â± 0.0000\n",
            "  nc_cct_coef          = +0.1266 Â± 0.0000\n",
            "  k_index_base         = +1.3538 Â± 0.0000\n",
            "  k_index_cct_coef     = +0.1266 Â± 0.0000\n",
            "  acd_offset_base      = +2.7548 Â± 0.0000\n",
            "  acd_offset_cct_coef  = -0.2684 Â± 0.0000\n",
            "\n",
            "ğŸ’¡ ROBUSTNESS ANALYSIS:\n",
            "--------------------------------------------------\n",
            "âœ… Excellent stability: CV=0.0% (very consistent across seeds)\n",
            "\n",
            "ğŸ“Š Range of results: 1.4354 - 1.4354 D\n",
            "   This 0.0000 D range shows the impact of data split\n"
          ]
        }
      ],
      "source": [
        "# PARAMETER OPTIMIZATION WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
        "# =============================================\n",
        "# PURPOSE: Optimize SRK/T2 parameters with nested CV for robust validation\n",
        "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nğŸ¯ MULTI-SEED NESTED CROSS-VALIDATION:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
        "print(\"â€¢ Each seed: 75% train, 25% test\")\n",
        "print(\"â€¢ Inner: 5-fold CV on training set\")\n",
        "print(\"â€¢ Results averaged across seeds for robustness\")\n",
        "\n",
        "from scipy.optimize import differential_evolution\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import numpy as np\n",
        "\n",
        "def calculate_mae_param(params, df_data):\n",
        "    \"\"\"Calculate MAE for parameter optimization\"\"\"\n",
        "    nc_base, nc_cct_coef, k_index_base, k_index_cct_coef, acd_offset_base, acd_offset_cct_coef = params\n",
        "    \n",
        "    predictions = []\n",
        "    for _, row in df_data.iterrows():\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        nc = nc_base + nc_cct_coef * cct_norm\n",
        "        k_index = k_index_base + k_index_cct_coef * cct_norm\n",
        "        acd_offset = acd_offset_base + acd_offset_cct_coef * cct_norm\n",
        "        \n",
        "        pred = calculate_SRKT2(\n",
        "            AL=row['Bio-AL'],\n",
        "            K_avg=row['K_avg'],\n",
        "            IOL_power=row['IOL Power'],\n",
        "            A_constant=row['A-Constant'] + acd_offset,\n",
        "            nc=nc,\n",
        "            k_index=k_index\n",
        "        )\n",
        "        predictions.append(pred)\n",
        "    \n",
        "    mae = mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "    return mae\n",
        "\n",
        "bounds_param = [\n",
        "    (1.20, 1.50),    # nc_base\n",
        "    (-0.20, 0.20),   # nc_cct_coef  \n",
        "    (1.20, 1.60),    # k_index_base\n",
        "    (-0.30, 0.30),   # k_index_cct_coef\n",
        "    (-3.0, 3.0),     # acd_offset_base\n",
        "    (-3.0, 3.0),     # acd_offset_cct_coef\n",
        "]\n",
        "\n",
        "# Store results for each seed\n",
        "seed_results_param = []\n",
        "seed_test_maes_param = []\n",
        "seed_train_maes_param = []  # NEW: Track training MAEs\n",
        "seed_baseline_maes_param = []\n",
        "seed_improvements_param = []\n",
        "seed_overfit_ratios_param = []  # NEW: Track overfitting\n",
        "\n",
        "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
        "    print(f\"{'='*40}\")\n",
        "    \n",
        "    # OUTER SPLIT with current seed\n",
        "    X_train_param, X_test_param = train_test_split(df, test_size=0.25, random_state=SEED)\n",
        "    X_train_param['K_avg'] = (X_train_param['Bio-Ks'] + X_train_param['Bio-Kf']) / 2\n",
        "    X_test_param['K_avg'] = (X_test_param['Bio-Ks'] + X_test_param['Bio-Kf']) / 2\n",
        "    \n",
        "    print(f\"ğŸ“Š Split: {len(X_train_param)} train, {len(X_test_param)} test\")\n",
        "    \n",
        "    # INNER K-FOLD CV\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    fold_params = []\n",
        "    fold_maes = []\n",
        "    \n",
        "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_param), 1):\n",
        "        fold_train = X_train_param.iloc[train_idx]\n",
        "        fold_val = X_train_param.iloc[val_idx]\n",
        "        \n",
        "        # Optimize on fold\n",
        "        result_fold = differential_evolution(\n",
        "            lambda p: calculate_mae_param(p, fold_train),\n",
        "            bounds_param,\n",
        "            maxiter=30,\n",
        "            seed=SEED + fold_num,\n",
        "            workers=1,\n",
        "            updating='deferred',\n",
        "            disp=False\n",
        "        )\n",
        "        \n",
        "        fold_params.append(result_fold.x)\n",
        "        val_mae = calculate_mae_param(result_fold.x, fold_val)\n",
        "        fold_maes.append(val_mae)\n",
        "    \n",
        "    # Average parameters from folds\n",
        "    avg_params = np.mean(fold_params, axis=0)\n",
        "    avg_cv_mae = np.mean(fold_maes)\n",
        "    std_cv_mae = np.std(fold_maes)\n",
        "    \n",
        "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
        "    \n",
        "    # FINAL RETRAINING on full training set\n",
        "    result_final = differential_evolution(\n",
        "        lambda p: calculate_mae_param(p, X_train_param),\n",
        "        bounds_param,\n",
        "        maxiter=50,\n",
        "        seed=SEED,\n",
        "        workers=1,\n",
        "        updating='deferred',\n",
        "        disp=False\n",
        "    )\n",
        "    \n",
        "    final_params = result_final.x\n",
        "    \n",
        "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
        "    mae_train = calculate_mae_param(final_params, X_train_param)\n",
        "    \n",
        "    # TEST ON HOLDOUT\n",
        "    # Calculate baseline\n",
        "    X_test_param['SRKT2_Baseline'] = X_test_param.apply(\n",
        "        lambda row: calculate_SRKT2(\n",
        "            AL=row['Bio-AL'],\n",
        "            K_avg=row['K_avg'],\n",
        "            IOL_power=row['IOL Power'],\n",
        "            A_constant=row['A-Constant']\n",
        "        ), axis=1\n",
        "    )\n",
        "    \n",
        "    # Apply optimized parameters\n",
        "    predictions_test = []\n",
        "    for _, row in X_test_param.iterrows():\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        nc = final_params[0] + final_params[1] * cct_norm\n",
        "        k_index = final_params[2] + final_params[3] * cct_norm\n",
        "        acd_offset = final_params[4] + final_params[5] * cct_norm\n",
        "        \n",
        "        pred = calculate_SRKT2(\n",
        "            AL=row['Bio-AL'],\n",
        "            K_avg=row['K_avg'],\n",
        "            IOL_power=row['IOL Power'],\n",
        "            A_constant=row['A-Constant'] + acd_offset,\n",
        "            nc=nc,\n",
        "            k_index=k_index\n",
        "        )\n",
        "        predictions_test.append(pred)\n",
        "    \n",
        "    mae_baseline = np.abs(X_test_param['SRKT2_Baseline'] - X_test_param['PostOP Spherical Equivalent']).mean()\n",
        "    mae_optimized = mean_absolute_error(X_test_param['PostOP Spherical Equivalent'], predictions_test)\n",
        "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
        "    \n",
        "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
        "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
        "    print(f\"  Improvement: {improvement:.1f}%\")\n",
        "    \n",
        "    # Check for overfitting\n",
        "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
        "    if overfit_ratio > 20:\n",
        "        print(f\"  âš ï¸ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
        "    elif overfit_ratio > 10:\n",
        "        print(f\"  âš ï¸ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
        "    else:\n",
        "        print(f\"  âœ… Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
        "    \n",
        "    # Store results\n",
        "    seed_results_param.append(final_params)\n",
        "    seed_test_maes_param.append(mae_optimized)\n",
        "    seed_train_maes_param.append(mae_train)\n",
        "    seed_baseline_maes_param.append(mae_baseline)\n",
        "    seed_improvements_param.append(improvement)\n",
        "    seed_overfit_ratios_param.append(overfit_ratio)\n",
        "\n",
        "# MULTI-SEED SUMMARY\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PARAMETER OPTIMIZATION - MULTI-SEED SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\")\n",
        "print(\"-\" * 50)\n",
        "for i, seed in enumerate(SEEDS):\n",
        "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_param[i]:.4f} D, Improvement={seed_improvements_param[i]:.1f}%\")\n",
        "\n",
        "print(\"\\nğŸ“ˆ STATISTICAL SUMMARY:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_param):.4f} Â± {np.std(seed_baseline_maes_param):.4f} D\")\n",
        "print(f\"  Train MAE:         {np.mean(seed_train_maes_param):.4f} Â± {np.std(seed_train_maes_param):.4f} D\")\n",
        "print(f\"  Test MAE:          {np.mean(seed_test_maes_param):.4f} Â± {np.std(seed_test_maes_param):.4f} D\")\n",
        "print(f\"  Mean Improvement:  {np.mean(seed_improvements_param):.1f} Â± {np.std(seed_improvements_param):.1f}%\")\n",
        "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_param)]} (MAE={min(seed_test_maes_param):.4f})\")\n",
        "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_param)]} (MAE={max(seed_test_maes_param):.4f})\")\n",
        "\n",
        "# OVERFITTING ANALYSIS\n",
        "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_param):.1f}%\")\n",
        "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_param):.1f}% worse than Train MAE on average)\")\n",
        "\n",
        "if np.mean(seed_overfit_ratios_param) < 10:\n",
        "    print(\"  âœ… Excellent generalization - minimal overfitting\")\n",
        "elif np.mean(seed_overfit_ratios_param) < 20:\n",
        "    print(\"  âœ… Good generalization - acceptable overfitting\")\n",
        "else:\n",
        "    print(\"  âš ï¸ Significant overfitting - consider regularization\")\n",
        "\n",
        "# Average parameters across seeds\n",
        "avg_params_all_seeds = np.mean(seed_results_param, axis=0)\n",
        "std_params_all_seeds = np.std(seed_results_param, axis=0)\n",
        "\n",
        "print(\"\\nâœ… CONSENSUS PARAMETERS (averaged across seeds):\")\n",
        "print(\"-\" * 50)\n",
        "param_names = ['nc_base', 'nc_cct_coef', 'k_index_base', 'k_index_cct_coef', 'acd_offset_base', 'acd_offset_cct_coef']\n",
        "for i, name in enumerate(param_names):\n",
        "    print(f\"  {name:20} = {avg_params_all_seeds[i]:+.4f} Â± {std_params_all_seeds[i]:.4f}\")\n",
        "\n",
        "# Store in global results dictionary\n",
        "multi_seed_results['parameter'] = {\n",
        "    'test_maes': seed_test_maes_param,\n",
        "    'train_maes': seed_train_maes_param,\n",
        "    'baseline_maes': seed_baseline_maes_param,\n",
        "    'improvements': seed_improvements_param,\n",
        "    'overfit_ratios': seed_overfit_ratios_param,\n",
        "    'mean_mae': np.mean(seed_test_maes_param),\n",
        "    'std_mae': np.std(seed_test_maes_param),\n",
        "    'mean_improvement': np.mean(seed_improvements_param)\n",
        "}\n",
        "\n",
        "print(\"\\nğŸ’¡ ROBUSTNESS ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "mae_cv = np.std(seed_test_maes_param) / np.mean(seed_test_maes_param) * 100\n",
        "if mae_cv < 5:\n",
        "    print(f\"âœ… Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
        "elif mae_cv < 10:\n",
        "    print(f\"âœ… Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
        "else:\n",
        "    print(f\"âš ï¸ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Range of results: {min(seed_test_maes_param):.4f} - {max(seed_test_maes_param):.4f} D\")\n",
        "print(f\"   This {max(seed_test_maes_param)-min(seed_test_maes_param):.4f} D range shows the impact of data split\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "829090ggs0r",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ğŸ¯ MULTI-SEED NESTED CV STRATEGY:\n",
            "--------------------------------------------------\n",
            "â€¢ Testing 1 different random seeds: [42]\n",
            "â€¢ Each seed: 75/25 train/test split\n",
            "â€¢ Inner: 5-fold CV on training\n",
            "â€¢ Find stable multiplicative factors across seeds\n",
            "\n",
            "================================================================================\n",
            "RUNNING MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "========================================\n",
            "SEED 1/1: 42\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "  CV MAE: 0.9016 Â± 0.1279 D\n",
            "  Final params: mâ‚€=-0.0379, mâ‚=-0.0153, mâ‚‚=-0.0378\n",
            "  Train MAE: 0.9068, Test MAE: 1.0063\n",
            "  Test: Baseline=1.4849, Optimized=1.0063\n",
            "  Improvement: 32.2%\n",
            "  âš ï¸ Mild overfitting: Test 11.0% worse than train\n",
            "\n",
            "================================================================================\n",
            "MULTIPLICATIVE CORRECTION - MULTI-SEED SUMMARY\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\n",
            "--------------------------------------------------\n",
            "  Seed  42: MAE=1.0063 D, Improvement=32.2%\n",
            "\n",
            "ğŸ“ˆ STATISTICAL SUMMARY:\n",
            "--------------------------------------------------\n",
            "  Baseline MAE:      1.4849 Â± 0.0000 D\n",
            "  Train MAE:         0.9068 Â± 0.0000 D\n",
            "  Test MAE:          1.0063 Â± 0.0000 D\n",
            "  Mean Improvement:  32.2 Â± 0.0%\n",
            "  Best seed:         42 (MAE=1.0063)\n",
            "  Worst seed:        42 (MAE=1.0063)\n",
            "\n",
            "ğŸ” OVERFITTING ANALYSIS:\n",
            "--------------------------------------------------\n",
            "  Mean overfit ratio: 11.0%\n",
            "  (Test MAE is 11.0% worse than Train MAE on average)\n",
            "  âœ… Good generalization - acceptable overfitting\n",
            "\n",
            "âœ… CONSENSUS PARAMETERS (averaged across seeds):\n",
            "--------------------------------------------------\n",
            "  mâ‚€ (constant):     -0.0379 Â± 0.0000\n",
            "  mâ‚ (CCT coef):     -0.0153 Â± 0.0000\n",
            "  mâ‚‚ (ratio coef):   -0.0378 Â± 0.0000\n",
            "\n",
            "ğŸ“ CONSENSUS CORRECTION FORMULA:\n",
            "--------------------------------------------------\n",
            "Corrected_REF = Standard_SRK/T2 Ã— Correction_Factor\n",
            "Correction_Factor = 1 -0.0379 -0.0153Ã—CCT_norm -0.0378Ã—(CCT/AL)\n",
            "\n",
            "ğŸ’¡ ROBUSTNESS ANALYSIS:\n",
            "--------------------------------------------------\n",
            "âœ… Excellent stability: CV=0.0% (very consistent across seeds)\n",
            "\n",
            "ğŸ“Š Range of results: 1.0063 - 1.0063 D\n",
            "   This 0.0000 D range shows the impact of data split\n",
            "\n",
            "ğŸ“Š Parameter consistency across seeds:\n",
            "  mâ‚€: min=-0.0379, max=-0.0379, range=0.0000\n",
            "  mâ‚: min=-0.0153, max=-0.0153, range=0.0000\n",
            "  mâ‚‚: min=-0.0378, max=-0.0378, range=0.0000\n"
          ]
        }
      ],
      "source": [
        "# MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED\n",
        "# ====================================\n",
        "# PURPOSE: Multiplicative correction with nested CV for robust validation\n",
        "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nğŸ¯ MULTI-SEED NESTED CV STRATEGY:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
        "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
        "print(\"â€¢ Inner: 5-fold CV on training\")\n",
        "print(\"â€¢ Find stable multiplicative factors across seeds\")\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import numpy as np\n",
        "\n",
        "def multiplicative_objective(params, df_data):\n",
        "    \"\"\"Objective function for multiplicative correction\"\"\"\n",
        "    m0, m1, m2 = params\n",
        "    \n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    \n",
        "    for _, row in df_data.iterrows():\n",
        "        base_pred = row['SRKT2_Prediction']\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "        \n",
        "        correction_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
        "        corrected_pred = base_pred * correction_factor\n",
        "        \n",
        "        predictions.append(corrected_pred)\n",
        "        actuals.append(row['PostOP Spherical Equivalent'])\n",
        "    \n",
        "    return mean_absolute_error(actuals, predictions)\n",
        "\n",
        "x0_mult = [0, 0, 0]\n",
        "bounds_mult = [(-0.5, 0.5), (-0.5, 0.5), (-0.5, 0.5)]\n",
        "\n",
        "# Store results for each seed\n",
        "seed_results_mult = []\n",
        "seed_test_maes_mult = []\n",
        "seed_train_maes_mult = []  # NEW: Track training MAEs\n",
        "seed_baseline_maes_mult = []\n",
        "seed_improvements_mult = []\n",
        "seed_overfit_ratios_mult = []  # NEW: Track overfitting\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
        "    print(f\"{'='*40}\")\n",
        "    \n",
        "    # OUTER SPLIT with current seed\n",
        "    X_train_mult, X_test_mult = train_test_split(df, test_size=0.25, random_state=SEED)\n",
        "    X_train_mult['K_avg'] = (X_train_mult['Bio-Ks'] + X_train_mult['Bio-Kf']) / 2\n",
        "    X_test_mult['K_avg'] = (X_test_mult['Bio-Ks'] + X_test_mult['Bio-Kf']) / 2\n",
        "    \n",
        "    print(f\"ğŸ“Š Split: {len(X_train_mult)} train, {len(X_test_mult)} test\")\n",
        "    \n",
        "    # Calculate baseline SRK/T2 for all data\n",
        "    for dataset in [X_train_mult, X_test_mult]:\n",
        "        dataset['SRKT2_Prediction'] = dataset.apply(\n",
        "            lambda row: calculate_SRKT2(\n",
        "                AL=row['Bio-AL'],\n",
        "                K_avg=row['K_avg'],\n",
        "                IOL_power=row['IOL Power'],\n",
        "                A_constant=row['A-Constant']\n",
        "            ), axis=1\n",
        "        )\n",
        "    \n",
        "    # INNER K-FOLD CV\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    fold_params = []\n",
        "    fold_maes = []\n",
        "    \n",
        "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_mult), 1):\n",
        "        fold_train = X_train_mult.iloc[train_idx]\n",
        "        fold_val = X_train_mult.iloc[val_idx]\n",
        "        \n",
        "        # Optimize on fold training\n",
        "        result_fold = minimize(\n",
        "            lambda p: multiplicative_objective(p, fold_train),\n",
        "            x0_mult,\n",
        "            method='L-BFGS-B',\n",
        "            bounds=bounds_mult\n",
        "        )\n",
        "        \n",
        "        fold_params.append(result_fold.x)\n",
        "        val_mae = multiplicative_objective(result_fold.x, fold_val)\n",
        "        fold_maes.append(val_mae)\n",
        "    \n",
        "    # Average across folds\n",
        "    avg_params = np.mean(fold_params, axis=0)\n",
        "    avg_cv_mae = np.mean(fold_maes)\n",
        "    std_cv_mae = np.std(fold_maes)\n",
        "    \n",
        "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
        "    \n",
        "    # FINAL RETRAINING on full training set\n",
        "    result_mult = minimize(\n",
        "        lambda p: multiplicative_objective(p, X_train_mult),\n",
        "        x0_mult,\n",
        "        method='L-BFGS-B',\n",
        "        bounds=bounds_mult\n",
        "    )\n",
        "    m0_opt, m1_opt, m2_opt = result_mult.x\n",
        "    \n",
        "    print(f\"  Final params: mâ‚€={m0_opt:.4f}, mâ‚={m1_opt:.4f}, mâ‚‚={m2_opt:.4f}\")\n",
        "    \n",
        "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
        "    mae_train = multiplicative_objective([m0_opt, m1_opt, m2_opt], X_train_mult)\n",
        "    \n",
        "    # TEST ON HOLDOUT\n",
        "    predictions_mult_test = []\n",
        "    for _, row in X_test_mult.iterrows():\n",
        "        base_pred = row['SRKT2_Prediction']\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "        \n",
        "        correction_factor = 1 + m0_opt + m1_opt * cct_norm + m2_opt * cct_ratio\n",
        "        corrected_pred = base_pred * correction_factor\n",
        "        predictions_mult_test.append(corrected_pred)\n",
        "    \n",
        "    mae_baseline = np.abs(X_test_mult['SRKT2_Prediction'] - X_test_mult['PostOP Spherical Equivalent']).mean()\n",
        "    mae_optimized = mean_absolute_error(X_test_mult['PostOP Spherical Equivalent'], predictions_mult_test)\n",
        "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
        "    \n",
        "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
        "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
        "    print(f\"  Improvement: {improvement:.1f}%\")\n",
        "    \n",
        "    # Check for overfitting\n",
        "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
        "    if overfit_ratio > 20:\n",
        "        print(f\"  âš ï¸ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
        "    elif overfit_ratio > 10:\n",
        "        print(f\"  âš ï¸ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
        "    else:\n",
        "        print(f\"  âœ… Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
        "    \n",
        "    # Store results\n",
        "    seed_results_mult.append([m0_opt, m1_opt, m2_opt])\n",
        "    seed_test_maes_mult.append(mae_optimized)\n",
        "    seed_train_maes_mult.append(mae_train)\n",
        "    seed_baseline_maes_mult.append(mae_baseline)\n",
        "    seed_improvements_mult.append(improvement)\n",
        "    seed_overfit_ratios_mult.append(overfit_ratio)\n",
        "\n",
        "# MULTI-SEED SUMMARY\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MULTIPLICATIVE CORRECTION - MULTI-SEED SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nğŸ“Š TEST PERFORMANCE ACROSS SEEDS:\")\n",
        "print(\"-\" * 50)\n",
        "for i, seed in enumerate(SEEDS):\n",
        "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_mult[i]:.4f} D, Improvement={seed_improvements_mult[i]:.1f}%\")\n",
        "\n",
        "print(\"\\nğŸ“ˆ STATISTICAL SUMMARY:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_mult):.4f} Â± {np.std(seed_baseline_maes_mult):.4f} D\")\n",
        "print(f\"  Train MAE:         {np.mean(seed_train_maes_mult):.4f} Â± {np.std(seed_train_maes_mult):.4f} D\")\n",
        "print(f\"  Test MAE:          {np.mean(seed_test_maes_mult):.4f} Â± {np.std(seed_test_maes_mult):.4f} D\")\n",
        "print(f\"  Mean Improvement:  {np.mean(seed_improvements_mult):.1f} Â± {np.std(seed_improvements_mult):.1f}%\")\n",
        "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_mult)]} (MAE={min(seed_test_maes_mult):.4f})\")\n",
        "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_mult)]} (MAE={max(seed_test_maes_mult):.4f})\")\n",
        "\n",
        "# OVERFITTING ANALYSIS\n",
        "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_mult):.1f}%\")\n",
        "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_mult):.1f}% worse than Train MAE on average)\")\n",
        "\n",
        "if np.mean(seed_overfit_ratios_mult) < 10:\n",
        "    print(\"  âœ… Excellent generalization - minimal overfitting\")\n",
        "elif np.mean(seed_overfit_ratios_mult) < 20:\n",
        "    print(\"  âœ… Good generalization - acceptable overfitting\")\n",
        "else:\n",
        "    print(\"  âš ï¸ Significant overfitting - consider regularization\")\n",
        "\n",
        "# Average parameters across seeds\n",
        "avg_params_all_seeds = np.mean(seed_results_mult, axis=0)\n",
        "std_params_all_seeds = np.std(seed_results_mult, axis=0)\n",
        "\n",
        "print(\"\\nâœ… CONSENSUS PARAMETERS (averaged across seeds):\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"  mâ‚€ (constant):     {avg_params_all_seeds[0]:+.4f} Â± {std_params_all_seeds[0]:.4f}\")\n",
        "print(f\"  mâ‚ (CCT coef):     {avg_params_all_seeds[1]:+.4f} Â± {std_params_all_seeds[1]:.4f}\")\n",
        "print(f\"  mâ‚‚ (ratio coef):   {avg_params_all_seeds[2]:+.4f} Â± {std_params_all_seeds[2]:.4f}\")\n",
        "\n",
        "print(\"\\nğŸ“ CONSENSUS CORRECTION FORMULA:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Corrected_REF = Standard_SRK/T2 Ã— Correction_Factor\")\n",
        "print(f\"Correction_Factor = 1 {avg_params_all_seeds[0]:+.4f} {avg_params_all_seeds[1]:+.4f}Ã—CCT_norm {avg_params_all_seeds[2]:+.4f}Ã—(CCT/AL)\")\n",
        "\n",
        "# Store in global results dictionary\n",
        "multi_seed_results['multiplicative'] = {\n",
        "    'test_maes': seed_test_maes_mult,\n",
        "    'train_maes': seed_train_maes_mult,\n",
        "    'baseline_maes': seed_baseline_maes_mult,\n",
        "    'improvements': seed_improvements_mult,\n",
        "    'overfit_ratios': seed_overfit_ratios_mult,\n",
        "    'mean_mae': np.mean(seed_test_maes_mult),\n",
        "    'std_mae': np.std(seed_test_maes_mult),\n",
        "    'mean_improvement': np.mean(seed_improvements_mult)\n",
        "}\n",
        "\n",
        "print(\"\\nğŸ’¡ ROBUSTNESS ANALYSIS:\")\n",
        "print(\"-\" * 50)\n",
        "mae_cv = np.std(seed_test_maes_mult) / np.mean(seed_test_maes_mult) * 100\n",
        "if mae_cv < 5:\n",
        "    print(f\"âœ… Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
        "elif mae_cv < 10:\n",
        "    print(f\"âœ… Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
        "else:\n",
        "    print(f\"âš ï¸ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Range of results: {min(seed_test_maes_mult):.4f} - {max(seed_test_maes_mult):.4f} D\")\n",
        "print(f\"   This {max(seed_test_maes_mult)-min(seed_test_maes_mult):.4f} D range shows the impact of data split\")\n",
        "\n",
        "# Parameter consistency check\n",
        "print(f\"\\nğŸ“Š Parameter consistency across seeds:\")\n",
        "for i, param_name in enumerate(['mâ‚€', 'mâ‚', 'mâ‚‚']):\n",
        "    param_values = [p[i] for p in seed_results_mult]\n",
        "    print(f\"  {param_name}: min={min(param_values):.4f}, max={max(param_values):.4f}, range={max(param_values)-min(param_values):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a9g3yzsp3n",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "â­ï¸ POLYNOMIAL COMPARISON SKIPPED (RUN_POLYNOMIAL_COMPARISON = False)\n",
            "================================================================================\n",
            "Using direct quadratic approach in next cell instead.\n",
            "To enable full comparison: Set RUN_POLYNOMIAL_COMPARISON = True\n"
          ]
        }
      ],
      "source": [
        "# ADDITIVE CORRECTION WITH POLYNOMIAL TERMS - MULTI-SEED\n",
        "# ========================================================\n",
        "# PURPOSE: Create an additive correction with polynomial CCT terms\n",
        "# NOW WITH QUADRATIC AND CUBIC CCT TERMS for better non-linear modeling\n",
        "\n",
        "# âš™ï¸ ACTIVATION CONTROL - Set to True to run full polynomial comparison\n",
        "RUN_POLYNOMIAL_COMPARISON = False  # ğŸ”´ DISABLED - Using direct quadratic approach instead\n",
        "\n",
        "if RUN_POLYNOMIAL_COMPARISON:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"ADDITIVE CORRECTION WITH POLYNOMIAL CCT TERMS - MULTI-SEED ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(\"\\nğŸ¯ TESTING POLYNOMIAL (QUADRATIC & CUBIC) CCT TERMS:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"â€¢ Linear model: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg\")\n",
        "    print(\"â€¢ Quadratic model: + a4*CCT_normÂ²\")  \n",
        "    print(\"â€¢ Cubic model: + a4*CCT_normÂ² + a5*CCT_normÂ³\")\n",
        "    print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
        "    print(\"â€¢ Each seed: 75/25 train/test split\")\n",
        "    print(\"â€¢ Inner: 5-fold cross-validation\")\n",
        "\n",
        "    from sklearn.model_selection import train_test_split, KFold\n",
        "    from scipy.optimize import minimize\n",
        "    import numpy as np\n",
        "\n",
        "    # Store results for different polynomial degrees\n",
        "    results_by_degree = {\n",
        "        'linear': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []},\n",
        "        'quadratic': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []},\n",
        "        'cubic': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []}\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RUNNING MULTI-SEED ANALYSIS WITH POLYNOMIAL TERMS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "        print(f\"\\n{'='*40}\")\n",
        "        print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
        "        print(f\"{'='*40}\")\n",
        "        \n",
        "        # Split data\n",
        "        X_train_add, X_test_add = train_test_split(df, test_size=0.25, random_state=SEED)\n",
        "        X_train_add['K_avg'] = (X_train_add['Bio-Ks'] + X_train_add['Bio-Kf']) / 2\n",
        "        X_test_add['K_avg'] = (X_test_add['Bio-Ks'] + X_test_add['Bio-Kf']) / 2\n",
        "        \n",
        "        print(f\"ğŸ“Š Split: {len(X_train_add)} train, {len(X_test_add)} test\")\n",
        "        \n",
        "        # Calculate baseline\n",
        "        for dataset in [X_train_add, X_test_add]:\n",
        "            dataset['SRKT2_Baseline'] = dataset.apply(\n",
        "                lambda row: calculate_SRKT2(\n",
        "                    AL=row['Bio-AL'],\n",
        "                    K_avg=row['K_avg'],\n",
        "                    IOL_power=row['IOL Power'],\n",
        "                    A_constant=row['A-Constant']\n",
        "                ), axis=1\n",
        "            )\n",
        "        \n",
        "        baseline_mae = mean_absolute_error(X_test_add['PostOP Spherical Equivalent'], \n",
        "                                           X_test_add['SRKT2_Baseline'])\n",
        "        \n",
        "        # Test each polynomial degree\n",
        "        for degree_name in ['linear', 'quadratic', 'cubic']:\n",
        "            print(f\"\\nğŸ“ Testing {degree_name.upper()} model:\")\n",
        "            print(\"-\" * 40)\n",
        "            \n",
        "            # Setup K-fold\n",
        "            kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "            fold_results = []\n",
        "            fold_maes = []\n",
        "            \n",
        "            for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_add), 1):\n",
        "                print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
        "                \n",
        "                fold_train = X_train_add.iloc[train_idx]\n",
        "                fold_val = X_train_add.iloc[val_idx]\n",
        "                \n",
        "                # Define objective function based on degree\n",
        "                if degree_name == 'linear':\n",
        "                    def additive_objective(params, df_data):\n",
        "                        a0, a1, a2, a3 = params\n",
        "                        predictions = []\n",
        "                        for _, row in df_data.iterrows():\n",
        "                            base_pred = row['SRKT2_Baseline']\n",
        "                            cct_norm = (row['CCT'] - 600) / 100\n",
        "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                            # Linear only\n",
        "                            correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
        "                            predictions.append(base_pred + correction)\n",
        "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "                    \n",
        "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1)]\n",
        "                    initial = [0, 0, 0, 0]\n",
        "                    \n",
        "                elif degree_name == 'quadratic':\n",
        "                    def additive_objective(params, df_data):\n",
        "                        a0, a1, a2, a3, a4 = params\n",
        "                        predictions = []\n",
        "                        for _, row in df_data.iterrows():\n",
        "                            base_pred = row['SRKT2_Baseline']\n",
        "                            cct_norm = (row['CCT'] - 600) / 100\n",
        "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                            # Linear + quadratic\n",
        "                            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                        a3 * row['K_avg'] + a4 * cct_norm**2)\n",
        "                            predictions.append(base_pred + correction)\n",
        "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "                    \n",
        "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1)]\n",
        "                    initial = [0, 0, 0, 0, 0]\n",
        "                    \n",
        "                else:  # cubic\n",
        "                    def additive_objective(params, df_data):\n",
        "                        a0, a1, a2, a3, a4, a5 = params\n",
        "                        predictions = []\n",
        "                        for _, row in df_data.iterrows():\n",
        "                            base_pred = row['SRKT2_Baseline']\n",
        "                            cct_norm = (row['CCT'] - 600) / 100\n",
        "                            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                            # Linear + quadratic + cubic\n",
        "                            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                        a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
        "                                        a5 * cct_norm**3)\n",
        "                            predictions.append(base_pred + correction)\n",
        "                        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "                    \n",
        "                    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1), (-0.5, 0.5)]\n",
        "                    initial = [0, 0, 0, 0, 0, 0]\n",
        "                \n",
        "                # Optimize\n",
        "                result = minimize(lambda p: additive_objective(p, fold_train), \n",
        "                                initial, method='L-BFGS-B', bounds=bounds)\n",
        "                fold_results.append(result.x)\n",
        "                \n",
        "                # Validate\n",
        "                fold_val_mae = additive_objective(result.x, fold_val)\n",
        "                fold_maes.append(fold_val_mae)\n",
        "                print(f\"MAE={fold_val_mae:.4f} \", end=\"\")\n",
        "            \n",
        "            print()\n",
        "            avg_cv_mae = np.mean(fold_maes)\n",
        "            std_cv_mae = np.std(fold_maes)\n",
        "            print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
        "            \n",
        "            # Final optimization on full training set\n",
        "            print(f\"  Final optimization on full training set...\")\n",
        "            final_result = minimize(lambda p: additive_objective(p, X_train_add), \n",
        "                                  initial, method='L-BFGS-B', bounds=bounds)\n",
        "            \n",
        "            # Evaluate on training set\n",
        "            train_mae = additive_objective(final_result.x, X_train_add)\n",
        "            \n",
        "            # Evaluate on test set\n",
        "            test_mae = additive_objective(final_result.x, X_test_add)\n",
        "            \n",
        "            improvement = ((baseline_mae - test_mae) / baseline_mae) * 100\n",
        "            overfit_ratio = test_mae / train_mae if train_mae > 0 else float('inf')\n",
        "            \n",
        "            print(f\"\\n  ğŸ“ˆ RESULTS ({degree_name}):\")\n",
        "            print(f\"    Train MAE: {train_mae:.4f} D\")\n",
        "            print(f\"    Test MAE:  {test_mae:.4f} D\")\n",
        "            print(f\"    Baseline:  {baseline_mae:.4f} D\")\n",
        "            print(f\"    Improvement: {improvement:.1f}%\")\n",
        "            print(f\"    Overfit ratio: {overfit_ratio:.3f}\")\n",
        "            \n",
        "            # Store results\n",
        "            results_by_degree[degree_name]['test_maes'].append(test_mae)\n",
        "            results_by_degree[degree_name]['train_maes'].append(train_mae)\n",
        "            results_by_degree[degree_name]['improvements'].append(improvement)\n",
        "            results_by_degree[degree_name]['params'].append(final_result.x)\n",
        "\n",
        "    # COMPREHENSIVE COMPARISON\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"POLYNOMIAL COMPARISON SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for degree_name in ['linear', 'quadratic', 'cubic']:\n",
        "        results = results_by_degree[degree_name]\n",
        "        print(f\"\\n{degree_name.upper()} MODEL:\")\n",
        "        print(f\"  Test MAE:     {np.mean(results['test_maes']):.4f} Â± {np.std(results['test_maes']):.4f} D\")\n",
        "        print(f\"  Train MAE:    {np.mean(results['train_maes']):.4f} Â± {np.std(results['train_maes']):.4f} D\")\n",
        "        print(f\"  Improvement:  {np.mean(results['improvements']):.1f}% Â± {np.std(results['improvements']):.1f}%\")\n",
        "        print(f\"  Overfit gap:  {np.mean(results['test_maes']) - np.mean(results['train_maes']):.4f} D\")\n",
        "\n",
        "    # Parameter analysis\n",
        "    print(\"\\nğŸ”¬ PARAMETER ANALYSIS:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Analyze quadratic coefficients\n",
        "    quad_params = np.array(results_by_degree['quadratic']['params'])\n",
        "    if quad_params.shape[1] >= 5:\n",
        "        quad_coeffs = quad_params[:, 4]  # a4 (quadratic term)\n",
        "        print(f\"\\nQuadratic coefficient (a4): {np.mean(quad_coeffs):.4f} Â± {np.std(quad_coeffs):.4f}\")\n",
        "        print(f\"  Significance: {'YES' if abs(np.mean(quad_coeffs)) > 0.1 else 'MARGINAL'}\")\n",
        "\n",
        "    # Analyze cubic coefficients\n",
        "    cubic_params = np.array(results_by_degree['cubic']['params'])\n",
        "    if cubic_params.shape[1] >= 6:\n",
        "        cubic_coeffs = cubic_params[:, 5]  # a5 (cubic term)\n",
        "        print(f\"\\nCubic coefficient (a5): {np.mean(cubic_coeffs):.4f} Â± {np.std(cubic_coeffs):.4f}\")\n",
        "        print(f\"  Significance: {'YES' if abs(np.mean(cubic_coeffs)) > 0.05 else 'MARGINAL'}\")\n",
        "\n",
        "    # Winner determination\n",
        "    mean_test_maes = {degree: np.mean(results_by_degree[degree]['test_maes']) \n",
        "                      for degree in ['linear', 'quadratic', 'cubic']}\n",
        "    best_degree = min(mean_test_maes, key=mean_test_maes.get)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RECOMMENDATION\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"âœ… BEST MODEL: {best_degree.upper()}\")\n",
        "    print(f\"   Test MAE: {mean_test_maes[best_degree]:.4f} D\")\n",
        "\n",
        "    if best_degree != 'linear':\n",
        "        improvement_over_linear = ((mean_test_maes['linear'] - mean_test_maes[best_degree]) / \n",
        "                                   mean_test_maes['linear']) * 100\n",
        "        print(f\"   Improvement over linear: {improvement_over_linear:.1f}%\")\n",
        "        print(f\"\\n   The polynomial terms capture non-linear relationships between\")\n",
        "        print(f\"   corneal thickness and refractive error in Fuchs' dystrophy patients.\")\n",
        "\n",
        "    # Store best results for later use\n",
        "    seed_test_maes_additive = results_by_degree[best_degree]['test_maes']\n",
        "    seed_train_maes_additive = results_by_degree[best_degree]['train_maes']\n",
        "    seed_improvements_additive = results_by_degree[best_degree]['improvements']\n",
        "    seed_additive_params = results_by_degree[best_degree]['params']\n",
        "\n",
        "    print(f\"\\nğŸ’¾ Stored {best_degree} model results for combined approach.\")\n",
        "    \n",
        "else:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"â­ï¸ POLYNOMIAL COMPARISON SKIPPED (RUN_POLYNOMIAL_COMPARISON = False)\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Using direct quadratic approach in next cell instead.\")\n",
        "    print(\"To enable full comparison: Set RUN_POLYNOMIAL_COMPARISON = True\")\n",
        "    \n",
        "    # Set best_degree for compatibility\n",
        "    best_degree = 'quadratic'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "oymvfrf7v1a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "QUADRATIC ADDITIVE CORRECTION - MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ğŸ¯ QUADRATIC MODEL SPECIFICATION:\n",
            "--------------------------------------------------\n",
            "â€¢ Formula: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg + a4*CCT_normÂ²\n",
            "â€¢ Captures non-linear relationship between CCT and refractive error\n",
            "â€¢ Testing 1 different random seeds: [42]\n",
            "â€¢ Each seed: 75/25 train/test split\n",
            "â€¢ Inner: 5-fold cross-validation\n",
            "\n",
            "================================================================================\n",
            "RUNNING QUADRATIC ADDITIVE CORRECTION\n",
            "================================================================================\n",
            "\n",
            "========================================\n",
            "SEED 1/1: 42\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CROSS-VALIDATION:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=1.3403   Fold 2/5: MAE=1.9499   Fold 3/5: MAE=1.4080   Fold 4/5: MAE=0.7357   Fold 5/5: MAE=1.1458 \n",
            "  CV MAE: 1.3159 Â± 0.3941 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 1.2721 D\n",
            "  Test MAE:  1.5813 D\n",
            "  Baseline:  1.4849 D\n",
            "  Improvement: -6.5%\n",
            "  Overfit ratio: 1.243\n",
            "\n",
            "  Parameters:\n",
            "    a0 (intercept):  -0.0022\n",
            "    a1 (CCT_norm):    0.0134\n",
            "    a2 (CCT_ratio):   0.0998\n",
            "    a3 (K_avg):      -0.0637\n",
            "    a4 (CCT_normÂ²):   0.0387\n",
            "\n",
            "================================================================================\n",
            "MULTI-SEED SUMMARY - QUADRATIC ADDITIVE\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š PERFORMANCE ACROSS 1 SEEDS:\n",
            "--------------------------------------------------\n",
            "Test MAE:     1.5813 Â± 0.0000 D\n",
            "Train MAE:    1.2721 Â± 0.0000 D\n",
            "Baseline MAE: 1.4849 Â± 0.0000 D\n",
            "Improvement:  -6.5% Â± 0.0%\n",
            "Overfit ratio: 1.243 Â± 0.000\n",
            "\n",
            "ğŸ”¬ PARAMETER CONSISTENCY:\n",
            "--------------------------------------------------\n",
            "\n",
            "Average parameters across seeds:\n",
            "  a0 (intercept) : -0.0022 Â± 0.0000\n",
            "  a1 (CCT_norm)  :  0.0134 Â± 0.0000\n",
            "  a2 (CCT_ratio) :  0.0998 Â± 0.0000\n",
            "  a3 (K_avg)     : -0.0637 Â± 0.0000\n",
            "  a4 (CCT_normÂ²) :  0.0387 Â± 0.0000\n",
            "\n",
            "ğŸ“Š Quadratic term analysis:\n",
            "  Mean coefficient: 0.0387\n",
            "  All seeds negative: False\n",
            "  All seeds positive: True\n",
            "  Significance: WEAK\n",
            "\n",
            "  â¡ï¸ Positive quadratic coefficient indicates:\n",
            "     â€¢ Effect of CCT on error INCREASES at extreme thicknesses\n",
            "     â€¢ Correction curve steepens for very thick corneas\n",
            "\n",
            "ğŸ’¾ Quadratic model results stored for combined approach.\n"
          ]
        }
      ],
      "source": [
        "# QUADRATIC ADDITIVE CORRECTION - STREAMLINED VERSION\n",
        "# ====================================================\n",
        "# PURPOSE: Direct implementation of quadratic additive correction\n",
        "# Skips comparison and goes straight to the optimal quadratic model\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUADRATIC ADDITIVE CORRECTION - MULTI-SEED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nğŸ¯ QUADRATIC MODEL SPECIFICATION:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"â€¢ Formula: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg + a4*CCT_normÂ²\")\n",
        "print(\"â€¢ Captures non-linear relationship between CCT and refractive error\")\n",
        "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
        "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
        "print(\"â€¢ Inner: 5-fold cross-validation\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from scipy.optimize import minimize\n",
        "import numpy as np\n",
        "\n",
        "# Store results for quadratic model\n",
        "seed_test_maes_additive = []\n",
        "seed_train_maes_additive = []\n",
        "seed_baseline_maes_additive = []\n",
        "seed_improvements_additive = []\n",
        "seed_overfit_ratios_additive = []\n",
        "seed_additive_params = []\n",
        "\n",
        "# Set degree for compatibility with combined approach\n",
        "best_degree = 'quadratic'\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RUNNING QUADRATIC ADDITIVE CORRECTION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
        "    print(f\"{'='*40}\")\n",
        "    \n",
        "    # Split data\n",
        "    X_train_add, X_test_add = train_test_split(df, test_size=0.25, random_state=SEED)\n",
        "    X_train_add['K_avg'] = (X_train_add['Bio-Ks'] + X_train_add['Bio-Kf']) / 2\n",
        "    X_test_add['K_avg'] = (X_test_add['Bio-Ks'] + X_test_add['Bio-Kf']) / 2\n",
        "    \n",
        "    print(f\"ğŸ“Š Split: {len(X_train_add)} train, {len(X_test_add)} test\")\n",
        "    \n",
        "    # Calculate baseline\n",
        "    for dataset in [X_train_add, X_test_add]:\n",
        "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
        "            lambda row: calculate_SRKT2(\n",
        "                AL=row['Bio-AL'],\n",
        "                K_avg=row['K_avg'],\n",
        "                IOL_power=row['IOL Power'],\n",
        "                A_constant=row['A-Constant']\n",
        "            ), axis=1\n",
        "        )\n",
        "    \n",
        "    baseline_mae = mean_absolute_error(X_test_add['PostOP Spherical Equivalent'], \n",
        "                                       X_test_add['SRKT2_Baseline'])\n",
        "    \n",
        "    print(\"\\nğŸ“ K-FOLD CROSS-VALIDATION:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Setup K-fold\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    fold_results = []\n",
        "    fold_maes = []\n",
        "    \n",
        "    # Define quadratic objective function\n",
        "    def additive_objective_quad(params, df_data):\n",
        "        a0, a1, a2, a3, a4 = params\n",
        "        predictions = []\n",
        "        for _, row in df_data.iterrows():\n",
        "            base_pred = row['SRKT2_Baseline']\n",
        "            cct_norm = (row['CCT'] - 600) / 100\n",
        "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "            # Quadratic correction\n",
        "            correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                        a3 * row['K_avg'] + a4 * cct_norm**2)\n",
        "            predictions.append(base_pred + correction)\n",
        "        return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "    \n",
        "    # Bounds and initial values for quadratic model\n",
        "    bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1)]\n",
        "    initial = [0, 0, 0, 0, 0]\n",
        "    \n",
        "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_add), 1):\n",
        "        print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
        "        \n",
        "        fold_train = X_train_add.iloc[train_idx]\n",
        "        fold_val = X_train_add.iloc[val_idx]\n",
        "        \n",
        "        # Optimize\n",
        "        result = minimize(lambda p: additive_objective_quad(p, fold_train), \n",
        "                        initial, method='L-BFGS-B', bounds=bounds)\n",
        "        fold_results.append(result.x)\n",
        "        \n",
        "        # Validate\n",
        "        fold_val_mae = additive_objective_quad(result.x, fold_val)\n",
        "        fold_maes.append(fold_val_mae)\n",
        "        print(f\"MAE={fold_val_mae:.4f} \", end=\"\")\n",
        "    \n",
        "    print()\n",
        "    avg_cv_mae = np.mean(fold_maes)\n",
        "    std_cv_mae = np.std(fold_maes)\n",
        "    print(f\"  CV MAE: {avg_cv_mae:.4f} Â± {std_cv_mae:.4f} D\")\n",
        "    \n",
        "    # Final optimization on full training set\n",
        "    print(\"  Final optimization on full training set...\")\n",
        "    final_result = minimize(lambda p: additive_objective_quad(p, X_train_add), \n",
        "                          initial, method='L-BFGS-B', bounds=bounds)\n",
        "    \n",
        "    # Evaluate on training set\n",
        "    train_mae = additive_objective_quad(final_result.x, X_train_add)\n",
        "    \n",
        "    # Evaluate on test set\n",
        "    test_mae = additive_objective_quad(final_result.x, X_test_add)\n",
        "    \n",
        "    improvement = ((baseline_mae - test_mae) / baseline_mae) * 100\n",
        "    overfit_ratio = test_mae / train_mae if train_mae > 0 else float('inf')\n",
        "    \n",
        "    print(\"\\nğŸ“ˆ RESULTS:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"  Train MAE: {train_mae:.4f} D\")\n",
        "    print(f\"  Test MAE:  {test_mae:.4f} D\")\n",
        "    print(f\"  Baseline:  {baseline_mae:.4f} D\")\n",
        "    print(f\"  Improvement: {improvement:.1f}%\")\n",
        "    print(f\"  Overfit ratio: {overfit_ratio:.3f}\")\n",
        "    \n",
        "    # Display parameters\n",
        "    a0, a1, a2, a3, a4 = final_result.x\n",
        "    print(f\"\\n  Parameters:\")\n",
        "    print(f\"    a0 (intercept):  {a0:7.4f}\")\n",
        "    print(f\"    a1 (CCT_norm):   {a1:7.4f}\")\n",
        "    print(f\"    a2 (CCT_ratio):  {a2:7.4f}\")\n",
        "    print(f\"    a3 (K_avg):      {a3:7.4f}\")\n",
        "    print(f\"    a4 (CCT_normÂ²):  {a4:7.4f}\")\n",
        "    \n",
        "    # Store results\n",
        "    seed_test_maes_additive.append(test_mae)\n",
        "    seed_train_maes_additive.append(train_mae)\n",
        "    seed_baseline_maes_additive.append(baseline_mae)\n",
        "    seed_improvements_additive.append(improvement)\n",
        "    seed_overfit_ratios_additive.append(overfit_ratio)\n",
        "    seed_additive_params.append(final_result.x)\n",
        "\n",
        "# SUMMARY STATISTICS\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MULTI-SEED SUMMARY - QUADRATIC ADDITIVE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Test MAE:     {np.mean(seed_test_maes_additive):.4f} Â± {np.std(seed_test_maes_additive):.4f} D\")\n",
        "print(f\"Train MAE:    {np.mean(seed_train_maes_additive):.4f} Â± {np.std(seed_train_maes_additive):.4f} D\")\n",
        "print(f\"Baseline MAE: {np.mean(seed_baseline_maes_additive):.4f} Â± {np.std(seed_baseline_maes_additive):.4f} D\")\n",
        "print(f\"Improvement:  {np.mean(seed_improvements_additive):.1f}% Â± {np.std(seed_improvements_additive):.1f}%\")\n",
        "print(f\"Overfit ratio: {np.mean(seed_overfit_ratios_additive):.3f} Â± {np.std(seed_overfit_ratios_additive):.3f}\")\n",
        "\n",
        "# Parameter consistency analysis\n",
        "print(\"\\nğŸ”¬ PARAMETER CONSISTENCY:\")\n",
        "print(\"-\" * 50)\n",
        "param_array = np.array(seed_additive_params)\n",
        "param_names = ['a0 (intercept)', 'a1 (CCT_norm)', 'a2 (CCT_ratio)', 'a3 (K_avg)', 'a4 (CCT_normÂ²)']\n",
        "\n",
        "print(\"\\nAverage parameters across seeds:\")\n",
        "for i, name in enumerate(param_names):\n",
        "    values = param_array[:, i]\n",
        "    mean_val = np.mean(values)\n",
        "    std_val = np.std(values)\n",
        "    print(f\"  {name:15s}: {mean_val:7.4f} Â± {std_val:.4f}\")\n",
        "\n",
        "# Check quadratic term significance\n",
        "quad_coeffs = param_array[:, 4]\n",
        "print(f\"\\nğŸ“Š Quadratic term analysis:\")\n",
        "print(f\"  Mean coefficient: {np.mean(quad_coeffs):.4f}\")\n",
        "print(f\"  All seeds negative: {np.all(quad_coeffs < 0)}\")\n",
        "print(f\"  All seeds positive: {np.all(quad_coeffs > 0)}\")\n",
        "print(f\"  Significance: {'STRONG' if abs(np.mean(quad_coeffs)) > 0.2 else 'MODERATE' if abs(np.mean(quad_coeffs)) > 0.1 else 'WEAK'}\")\n",
        "\n",
        "if np.mean(quad_coeffs) < 0:\n",
        "    print(\"\\n  â¡ï¸ Negative quadratic coefficient indicates:\")\n",
        "    print(\"     â€¢ Effect of CCT on error DECREASES at extreme thicknesses\")\n",
        "    print(\"     â€¢ Correction curve flattens for very thick corneas\")\n",
        "else:\n",
        "    print(\"\\n  â¡ï¸ Positive quadratic coefficient indicates:\")\n",
        "    print(\"     â€¢ Effect of CCT on error INCREASES at extreme thicknesses\")\n",
        "    print(\"     â€¢ Correction curve steepens for very thick corneas\")\n",
        "\n",
        "print(\"\\nğŸ’¾ Quadratic model results stored for combined approach.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2qmcannd1hs",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "â­ï¸ PARAM+MULT CELL SKIPPED (RUN_PARAM_MULT = False)\n",
            "================================================================================\n",
            "To enable: Set RUN_PARAM_MULT = True at the top of this cell\n",
            "This cell tests parameter + multiplicative without additive correction.\n"
          ]
        }
      ],
      "source": [
        "# COMBINED PARAMETER + MULTIPLICATIVE APPROACH (NO ADDITIVE) - MULTI-SEED\n",
        "# =========================================================================\n",
        "# PURPOSE: Combine parameter optimization with multiplicative correction only\n",
        "# This tests whether the additive component is necessary or if param+mult is sufficient\n",
        "\n",
        "# âš™ï¸ ACTIVATION CONTROL - Set to True to run this cell, False to skip\n",
        "RUN_PARAM_MULT = False  # ğŸ”´ CURRENTLY DISABLED FOR SPEED\n",
        "\n",
        "if RUN_PARAM_MULT:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"COMBINED PARAM + MULTIPLICATIVE FORMULA (NO ADDITIVE) - MULTI-SEED ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(\"\\nğŸ¯ MULTI-SEED NESTED CV FOR PARAM+MULT APPROACH:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
        "    print(\"â€¢ Each seed: 75/25 train/test split\")\n",
        "    print(\"â€¢ Inner: 5-fold CV for parameter and multiplicative methods\")\n",
        "    print(\"â€¢ NO additive correction applied\")\n",
        "\n",
        "    from sklearn.model_selection import train_test_split, KFold\n",
        "    from scipy.optimize import minimize, differential_evolution\n",
        "    import numpy as np\n",
        "\n",
        "    # Store results for each seed\n",
        "    seed_results_param_mult = []\n",
        "    seed_test_maes_param_mult = []\n",
        "    seed_train_maes_param_mult = []\n",
        "    seed_baseline_maes_param_mult = []\n",
        "    seed_improvements_param_mult = []\n",
        "    seed_overfit_ratios_param_mult = []\n",
        "\n",
        "    # Store individual method results\n",
        "    seed_param_results_pm = []\n",
        "    seed_mult_results_pm = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RUNNING MULTI-SEED ANALYSIS (PARAM + MULT ONLY)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "        print(f\"\\n{'='*40}\")\n",
        "        print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
        "        print(f\"{'='*40}\")\n",
        "        \n",
        "        # OUTER SPLIT - consistent across all methods\n",
        "        X_train_pm, X_test_pm = train_test_split(df, test_size=0.25, random_state=SEED)\n",
        "        X_train_pm['K_avg'] = (X_train_pm['Bio-Ks'] + X_train_pm['Bio-Kf']) / 2\n",
        "        X_test_pm['K_avg'] = (X_test_pm['Bio-Ks'] + X_test_pm['Bio-Kf']) / 2\n",
        "        \n",
        "        print(f\"ğŸ“Š Split: {len(X_train_pm)} train, {len(X_test_pm)} test\")\n",
        "        \n",
        "        # Calculate baseline for all\n",
        "        for dataset in [X_train_pm, X_test_pm]:\n",
        "            dataset['SRKT2_Baseline'] = dataset.apply(\n",
        "                lambda row: calculate_SRKT2(\n",
        "                    AL=row['Bio-AL'],\n",
        "                    K_avg=row['K_avg'],\n",
        "                    IOL_power=row['IOL Power'],\n",
        "                    A_constant=row['A-Constant']\n",
        "                ), axis=1\n",
        "            )\n",
        "        \n",
        "        print(\"\\nğŸ“ K-FOLD CV FOR PARAM AND MULT METHODS:\")\n",
        "        print(\"-\" * 40)\n",
        "        \n",
        "        # Setup K-fold\n",
        "        kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "        \n",
        "        # Store fold results for each method\n",
        "        param_fold_results = []\n",
        "        mult_fold_results = []\n",
        "        combined_fold_maes = []\n",
        "        \n",
        "        for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_pm), 1):\n",
        "            print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
        "            \n",
        "            fold_train = X_train_pm.iloc[train_idx]\n",
        "            fold_val = X_train_pm.iloc[val_idx]\n",
        "            \n",
        "            # 1. PARAMETER METHOD\n",
        "            def param_obj(params, df_data):\n",
        "                nc_base, nc_cct, k_base, k_cct, acd_base, acd_cct = params\n",
        "                predictions = []\n",
        "                for _, row in df_data.iterrows():\n",
        "                    cct_norm = (row['CCT'] - 600) / 100\n",
        "                    nc = nc_base + nc_cct * cct_norm\n",
        "                    k_index = k_base + k_cct * cct_norm\n",
        "                    acd_offset = acd_base + acd_cct * cct_norm\n",
        "                    pred = calculate_SRKT2(\n",
        "                        AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
        "                        IOL_power=row['IOL Power'],\n",
        "                        A_constant=row['A-Constant'] + acd_offset,\n",
        "                        nc=nc, k_index=k_index\n",
        "                    )\n",
        "                    predictions.append(pred)\n",
        "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "            \n",
        "            bounds_p = [(1.20, 1.50), (-0.20, 0.20), (1.20, 1.60), (-0.30, 0.30), (-3.0, 3.0), (-3.0, 3.0)]\n",
        "            result_p = differential_evolution(lambda p: param_obj(p, fold_train), bounds_p, \n",
        "                                             maxiter=20, seed=SEED+fold_num, disp=False)\n",
        "            param_fold_results.append(result_p.x)\n",
        "            \n",
        "            # 2. MULTIPLICATIVE METHOD (applied after parameter optimization)\n",
        "            def mult_obj_after_param(params, df_data, param_values):\n",
        "                m0, m1, m2 = params\n",
        "                nc_b, nc_c, k_b, k_c, acd_b, acd_c = param_values\n",
        "                predictions = []\n",
        "                for _, row in df_data.iterrows():\n",
        "                    cct_norm = (row['CCT'] - 600) / 100\n",
        "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                    \n",
        "                    # First apply parameter optimization\n",
        "                    nc = nc_b + nc_c * cct_norm\n",
        "                    k_index = k_b + k_c * cct_norm\n",
        "                    acd_offset = acd_b + acd_c * cct_norm\n",
        "                    modified_pred = calculate_SRKT2(\n",
        "                        AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
        "                        IOL_power=row['IOL Power'],\n",
        "                        A_constant=row['A-Constant'] + acd_offset,\n",
        "                        nc=nc, k_index=k_index\n",
        "                    )\n",
        "                    \n",
        "                    # Then apply multiplicative correction\n",
        "                    correction = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
        "                    predictions.append(modified_pred * correction)\n",
        "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "            \n",
        "            result_m = minimize(lambda p: mult_obj_after_param(p, fold_train, result_p.x), [0,0,0], \n",
        "                               method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
        "            mult_fold_results.append(result_m.x)\n",
        "            \n",
        "            # VALIDATE COMBINED PARAM+MULT on fold validation set\n",
        "            nc_b, nc_c, k_b, k_c, acd_b, acd_c = result_p.x\n",
        "            m0, m1, m2 = result_m.x\n",
        "            \n",
        "            combined_preds = []\n",
        "            for _, row in fold_val.iterrows():\n",
        "                cct_norm = (row['CCT'] - 600) / 100\n",
        "                cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                \n",
        "                # Modified SRK/T2 with optimized parameters\n",
        "                nc = nc_b + nc_c * cct_norm\n",
        "                k_index = k_b + k_c * cct_norm\n",
        "                acd_offset = acd_b + acd_c * cct_norm\n",
        "                modified = calculate_SRKT2(\n",
        "                    AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
        "                    IOL_power=row['IOL Power'],\n",
        "                    A_constant=row['A-Constant'] + acd_offset,\n",
        "                    nc=nc, k_index=k_index\n",
        "                )\n",
        "                \n",
        "                # Apply multiplicative correction\n",
        "                mult_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
        "                final = modified * mult_factor\n",
        "                \n",
        "                combined_preds.append(final)\n",
        "            \n",
        "            fold_mae = mean_absolute_error(fold_val['PostOP Spherical Equivalent'], combined_preds)\n",
        "            combined_fold_maes.append(fold_mae)\n",
        "            print(f\"MAE={fold_mae:.4f} \", end=\"\")\n",
        "        \n",
        "        print()  # New line after folds\n",
        "        \n",
        "        # Average parameters across folds\n",
        "        avg_param = np.mean(param_fold_results, axis=0)\n",
        "        avg_mult = np.mean(mult_fold_results, axis=0)\n",
        "        avg_combined_mae = np.mean(combined_fold_maes)\n",
        "        std_combined_mae = np.std(combined_fold_maes)\n",
        "        \n",
        "        print(f\"  CV MAE: {avg_combined_mae:.4f} Â± {std_combined_mae:.4f} D\")\n",
        "        \n",
        "        # FINAL RETRAINING on full training set\n",
        "        print(\"  Final optimization on full training set...\")\n",
        "        \n",
        "        # Optimize parameters first\n",
        "        result_p_final = differential_evolution(lambda p: param_obj(p, X_train_pm), bounds_p, \n",
        "                                               maxiter=50, seed=SEED, disp=False)\n",
        "        nc_base_pm, nc_cct_pm, k_base_pm, k_cct_pm, acd_base_pm, acd_cct_pm = result_p_final.x\n",
        "        \n",
        "        # Then optimize multiplicative correction\n",
        "        result_m_final = minimize(lambda p: mult_obj_after_param(p, X_train_pm, result_p_final.x), [0,0,0], \n",
        "                                 method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
        "        m0_pm, m1_pm, m2_pm = result_m_final.x\n",
        "        \n",
        "        # EVALUATE ON TRAINING SET (for overfitting check)\n",
        "        predictions_pm_train = []\n",
        "        for _, row in X_train_pm.iterrows():\n",
        "            cct_norm = (row['CCT'] - 600) / 100\n",
        "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "            \n",
        "            # Parameter optimization\n",
        "            nc = nc_base_pm + nc_cct_pm * cct_norm\n",
        "            k_index = k_base_pm + k_cct_pm * cct_norm\n",
        "            acd_offset = acd_base_pm + acd_cct_pm * cct_norm\n",
        "            modified = calculate_SRKT2(\n",
        "                AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
        "                IOL_power=row['IOL Power'],\n",
        "                A_constant=row['A-Constant'] + acd_offset,\n",
        "                nc=nc, k_index=k_index\n",
        "            )\n",
        "            \n",
        "            # Multiplicative correction\n",
        "            mult_factor = 1 + m0_pm + m1_pm * cct_norm + m2_pm * cct_ratio\n",
        "            final = modified * mult_factor\n",
        "            \n",
        "            predictions_pm_train.append(final)\n",
        "        \n",
        "        train_mae_pm = mean_absolute_error(X_train_pm['PostOP Spherical Equivalent'], predictions_pm_train)\n",
        "        \n",
        "        # EVALUATE ON TEST SET\n",
        "        predictions_pm_test = []\n",
        "        for _, row in X_test_pm.iterrows():\n",
        "            cct_norm = (row['CCT'] - 600) / 100\n",
        "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "            \n",
        "            # Parameter optimization\n",
        "            nc = nc_base_pm + nc_cct_pm * cct_norm\n",
        "            k_index = k_base_pm + k_cct_pm * cct_norm\n",
        "            acd_offset = acd_base_pm + acd_cct_pm * cct_norm\n",
        "            modified = calculate_SRKT2(\n",
        "                AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
        "                IOL_power=row['IOL Power'],\n",
        "                A_constant=row['A-Constant'] + acd_offset,\n",
        "                nc=nc, k_index=k_index\n",
        "            )\n",
        "            \n",
        "            # Multiplicative correction\n",
        "            mult_factor = 1 + m0_pm + m1_pm * cct_norm + m2_pm * cct_ratio\n",
        "            final = modified * mult_factor\n",
        "            \n",
        "            predictions_pm_test.append(final)\n",
        "        \n",
        "        test_mae_pm = mean_absolute_error(X_test_pm['PostOP Spherical Equivalent'], predictions_pm_test)\n",
        "        baseline_mae_pm = mean_absolute_error(X_test_pm['PostOP Spherical Equivalent'], \n",
        "                                              X_test_pm['SRKT2_Baseline'])\n",
        "        \n",
        "        improvement_pm = ((baseline_mae_pm - test_mae_pm) / baseline_mae_pm) * 100\n",
        "        overfit_ratio_pm = test_mae_pm / train_mae_pm if train_mae_pm > 0 else float('inf')\n",
        "        \n",
        "        print(\"\\nğŸ“ˆ RESULTS (PARAM + MULT ONLY):\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"  Train MAE: {train_mae_pm:.4f} D\")\n",
        "        print(f\"  Test MAE:  {test_mae_pm:.4f} D\")\n",
        "        print(f\"  Baseline:  {baseline_mae_pm:.4f} D\")\n",
        "        print(f\"  Improvement: {improvement_pm:.1f}%\")\n",
        "        print(f\"  Overfit ratio: {overfit_ratio_pm:.3f}\")\n",
        "        \n",
        "        # Store results\n",
        "        seed_results_param_mult.append({\n",
        "            'seed': SEED,\n",
        "            'param_values': result_p_final.x,\n",
        "            'mult_values': result_m_final.x,\n",
        "            'train_mae': train_mae_pm,\n",
        "            'test_mae': test_mae_pm,\n",
        "            'baseline_mae': baseline_mae_pm,\n",
        "            'improvement': improvement_pm,\n",
        "            'overfit_ratio': overfit_ratio_pm\n",
        "        })\n",
        "        \n",
        "        seed_test_maes_param_mult.append(test_mae_pm)\n",
        "        seed_train_maes_param_mult.append(train_mae_pm)\n",
        "        seed_baseline_maes_param_mult.append(baseline_mae_pm)\n",
        "        seed_improvements_param_mult.append(improvement_pm)\n",
        "        seed_overfit_ratios_param_mult.append(overfit_ratio_pm)\n",
        "        \n",
        "        seed_param_results_pm.append(result_p_final.x)\n",
        "        seed_mult_results_pm.append(result_m_final.x)\n",
        "\n",
        "    # SUMMARY STATISTICS\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MULTI-SEED SUMMARY (PARAM + MULT ONLY)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Test MAE:     {np.mean(seed_test_maes_param_mult):.4f} Â± {np.std(seed_test_maes_param_mult):.4f} D\")\n",
        "    print(f\"Train MAE:    {np.mean(seed_train_maes_param_mult):.4f} Â± {np.std(seed_train_maes_param_mult):.4f} D\")\n",
        "    print(f\"Baseline MAE: {np.mean(seed_baseline_maes_param_mult):.4f} Â± {np.std(seed_baseline_maes_param_mult):.4f} D\")\n",
        "    print(f\"Improvement:  {np.mean(seed_improvements_param_mult):.1f}% Â± {np.std(seed_improvements_param_mult):.1f}%\")\n",
        "    print(f\"Overfit ratio: {np.mean(seed_overfit_ratios_param_mult):.3f} Â± {np.std(seed_overfit_ratios_param_mult):.3f}\")\n",
        "\n",
        "    # Parameter consistency analysis\n",
        "    print(\"\\nğŸ”¬ PARAMETER CONSISTENCY:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    param_names = ['nc_base', 'nc_cct', 'k_base', 'k_cct', 'acd_base', 'acd_cct']\n",
        "    param_array = np.array(seed_param_results_pm)\n",
        "    print(\"\\nParameter optimization values:\")\n",
        "    for i, name in enumerate(param_names):\n",
        "        values = param_array[:, i]\n",
        "        print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
        "\n",
        "    mult_names = ['m0', 'm1_cct', 'm2_ratio']\n",
        "    mult_array = np.array(seed_mult_results_pm)\n",
        "    print(\"\\nMultiplicative correction values:\")\n",
        "    for i, name in enumerate(mult_names):\n",
        "        values = mult_array[:, i]\n",
        "        print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
        "\n",
        "    # Compare with full combined approach if available\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"COMPARISON NOTE\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"This PARAM+MULT approach excludes the additive correction term.\")\n",
        "    print(\"Compare these results with the full combined approach (next cell)\")\n",
        "    print(\"to determine if the additive component provides significant benefit.\")\n",
        "    \n",
        "else:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"â­ï¸ PARAM+MULT CELL SKIPPED (RUN_PARAM_MULT = False)\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"To enable: Set RUN_PARAM_MULT = True at the top of this cell\")\n",
        "    print(\"This cell tests parameter + multiplicative without additive correction.\")\n",
        "    \n",
        "    # Create placeholder variables so final comparison doesn't break\n",
        "    seed_test_maes_param_mult = []\n",
        "    seed_train_maes_param_mult = []\n",
        "    seed_baseline_maes_param_mult = []\n",
        "    seed_improvements_param_mult = []\n",
        "    seed_overfit_ratios_param_mult = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "u4unlmjdt3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "COMBINED FORMULA WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ğŸ“ Using QUADRATIC polynomial degree (determined optimal in additive cell)\n",
            "\n",
            "ğŸ¯ MULTI-SEED NESTED CV FOR COMBINED APPROACH:\n",
            "--------------------------------------------------\n",
            "â€¢ Testing 1 different random seeds: [42]\n",
            "â€¢ Each seed: 75/25 train/test split\n",
            "â€¢ Inner: 5-fold CV for each method\n",
            "â€¢ Additive correction using: quadratic polynomial\n",
            "\n",
            "================================================================================\n",
            "RUNNING MULTI-SEED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "========================================\n",
            "SEED 1/1: 42\n",
            "========================================\n",
            "ğŸ“Š Split: 72 train, 24 test\n",
            "\n",
            "ğŸ“ K-FOLD CV FOR EACH METHOD:\n",
            "----------------------------------------\n",
            "  Fold 1/5: MAE=0.7684   Fold 2/5: MAE=0.9645   Fold 3/5: MAE=0.9380   Fold 4/5: MAE=0.8368   Fold 5/5: MAE=1.0072 \n",
            "  CV MAE: 0.9030 Â± 0.0876 D\n",
            "  Final optimization on full training set...\n",
            "\n",
            "ğŸ“ˆ RESULTS:\n",
            "----------------------------------------\n",
            "  Train MAE: 0.9024 D\n",
            "  Test MAE:  0.8315 D\n",
            "  Baseline:  1.4849 D\n",
            "  Improvement: 44.0%\n",
            "  Overfit ratio: 0.921\n",
            "\n",
            "================================================================================\n",
            "MULTI-SEED SUMMARY - COMBINED APPROACH WITH QUADRATIC ADDITIVE\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š PERFORMANCE ACROSS 1 SEEDS:\n",
            "--------------------------------------------------\n",
            "Test MAE:     0.8315 Â± 0.0000 D\n",
            "Train MAE:    0.9024 Â± 0.0000 D\n",
            "Baseline MAE: 1.4849 Â± 0.0000 D\n",
            "Improvement:  44.0% Â± 0.0%\n",
            "Overfit ratio: 0.921 Â± 0.000\n",
            "\n",
            "ğŸ”¬ PARAMETER CONSISTENCY:\n",
            "--------------------------------------------------\n",
            "\n",
            "Parameter optimization values:\n",
            "  nc_base   :  1.4290 Â± 0.0000\n",
            "  nc_cct    : -0.1113 Â± 0.0000\n",
            "  k_base    :  1.4086 Â± 0.0000\n",
            "  k_cct     : -0.0946 Â± 0.0000\n",
            "  acd_base  :  2.6867 Â± 0.0000\n",
            "  acd_cct   : -1.7350 Â± 0.0000\n",
            "\n",
            "Multiplicative correction values:\n",
            "  m0        : -0.0379 Â± 0.0000\n",
            "  m1_cct    : -0.0153 Â± 0.0000\n",
            "  m2_ratio  : -0.0378 Â± 0.0000\n",
            "\n",
            "Additive correction values (quadratic):\n",
            "  a0        : -0.0022 Â± 0.0000\n",
            "  a1_cct    :  0.0134 Â± 0.0000\n",
            "  a2_ratio  :  0.0998 Â± 0.0000\n",
            "  a3_K      : -0.0637 Â± 0.0000\n",
            "  a4_cct2   :  0.0387 Â± 0.0000\n",
            "\n",
            "================================================================================\n",
            "CLINICAL INTERPRETATION\n",
            "================================================================================\n",
            "âœ… Combined approach with quadratic additive achieves:\n",
            "   â€¢ Mean absolute error: 0.832 Â± 0.000 D\n",
            "   â€¢ 44% improvement over standard SRK/T2\n",
            "   â€¢ MODERATE: Further optimization may be beneficial\n"
          ]
        }
      ],
      "source": [
        "# COMBINED APPROACH WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
        "# ========================================================\n",
        "# PURPOSE: Combine all three methods with nested K-fold CV and multi-seed validation\n",
        "# NOW USES THE BEST POLYNOMIAL DEGREE FROM ADDITIVE ANALYSIS\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"COMBINED FORMULA WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Determine which polynomial degree to use from additive cell results\n",
        "if 'best_degree' in locals():\n",
        "    print(f\"\\nğŸ“ Using {best_degree.upper()} polynomial degree (determined optimal in additive cell)\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ No polynomial analysis found, defaulting to LINEAR\")\n",
        "    best_degree = 'linear'\n",
        "\n",
        "print(\"\\nğŸ¯ MULTI-SEED NESTED CV FOR COMBINED APPROACH:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"â€¢ Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
        "print(\"â€¢ Each seed: 75/25 train/test split\")\n",
        "print(\"â€¢ Inner: 5-fold CV for each method\")\n",
        "print(f\"â€¢ Additive correction using: {best_degree} polynomial\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from scipy.optimize import minimize, differential_evolution\n",
        "import numpy as np\n",
        "\n",
        "# Store results for each seed\n",
        "seed_results_combined = []\n",
        "seed_test_maes_combined = []\n",
        "seed_train_maes_combined = []\n",
        "seed_baseline_maes_combined = []\n",
        "seed_improvements_combined = []\n",
        "seed_overfit_ratios_combined = []\n",
        "\n",
        "# Store individual method results\n",
        "seed_param_results = []\n",
        "seed_mult_results = []\n",
        "seed_add_results = []\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
        "    print(f\"{'='*40}\")\n",
        "    \n",
        "    # OUTER SPLIT - consistent across all methods\n",
        "    X_train_comb, X_test_comb = train_test_split(df, test_size=0.25, random_state=SEED)\n",
        "    X_train_comb['K_avg'] = (X_train_comb['Bio-Ks'] + X_train_comb['Bio-Kf']) / 2\n",
        "    X_test_comb['K_avg'] = (X_test_comb['Bio-Ks'] + X_test_comb['Bio-Kf']) / 2\n",
        "    \n",
        "    print(f\"ğŸ“Š Split: {len(X_train_comb)} train, {len(X_test_comb)} test\")\n",
        "    \n",
        "    # Calculate baseline for all\n",
        "    for dataset in [X_train_comb, X_test_comb]:\n",
        "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
        "            lambda row: calculate_SRKT2(\n",
        "                AL=row['Bio-AL'],\n",
        "                K_avg=row['K_avg'],\n",
        "                IOL_power=row['IOL Power'],\n",
        "                A_constant=row['A-Constant']\n",
        "            ), axis=1\n",
        "        )\n",
        "    \n",
        "    print(\"\\nğŸ“ K-FOLD CV FOR EACH METHOD:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Setup K-fold\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    \n",
        "    # Store fold results for each method\n",
        "    param_fold_results = []\n",
        "    mult_fold_results = []\n",
        "    add_fold_results = []\n",
        "    combined_fold_maes = []\n",
        "    \n",
        "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_comb), 1):\n",
        "        print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
        "        \n",
        "        fold_train = X_train_comb.iloc[train_idx]\n",
        "        fold_val = X_train_comb.iloc[val_idx]\n",
        "        \n",
        "        # 1. PARAMETER METHOD\n",
        "        def param_obj(params, df_data):\n",
        "            nc_base, nc_cct, k_base, k_cct, acd_base, acd_cct = params\n",
        "            predictions = []\n",
        "            for _, row in df_data.iterrows():\n",
        "                cct_norm = (row['CCT'] - 600) / 100\n",
        "                nc = nc_base + nc_cct * cct_norm\n",
        "                k_index = k_base + k_cct * cct_norm\n",
        "                acd_offset = acd_base + acd_cct * cct_norm\n",
        "                pred = calculate_SRKT2(\n",
        "                    AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
        "                    IOL_power=row['IOL Power'],\n",
        "                    A_constant=row['A-Constant'] + acd_offset,\n",
        "                    nc=nc, k_index=k_index\n",
        "                )\n",
        "                predictions.append(pred)\n",
        "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "        \n",
        "        bounds_p = [(1.20, 1.50), (-0.20, 0.20), (1.20, 1.60), (-0.30, 0.30), (-3.0, 3.0), (-3.0, 3.0)]\n",
        "        result_p = differential_evolution(lambda p: param_obj(p, fold_train), bounds_p, \n",
        "                                         maxiter=20, seed=SEED+fold_num, disp=False)\n",
        "        param_fold_results.append(result_p.x)\n",
        "        \n",
        "        # 2. MULTIPLICATIVE METHOD\n",
        "        def mult_obj(params, df_data):\n",
        "            m0, m1, m2 = params\n",
        "            predictions = []\n",
        "            for _, row in df_data.iterrows():\n",
        "                base_pred = row['SRKT2_Baseline']\n",
        "                cct_norm = (row['CCT'] - 600) / 100\n",
        "                cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                correction = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
        "                predictions.append(base_pred * correction)\n",
        "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "        \n",
        "        result_m = minimize(lambda p: mult_obj(p, fold_train), [0,0,0], \n",
        "                           method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
        "        mult_fold_results.append(result_m.x)\n",
        "        \n",
        "        # 3. ADDITIVE METHOD - WITH BEST POLYNOMIAL DEGREE\n",
        "        if best_degree == 'linear':\n",
        "            def add_obj(params, df_data):\n",
        "                a0, a1, a2, a3 = params\n",
        "                predictions = []\n",
        "                for _, row in df_data.iterrows():\n",
        "                    base_pred = row['SRKT2_Baseline']\n",
        "                    cct_norm = (row['CCT'] - 600) / 100\n",
        "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                    correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
        "                    predictions.append(base_pred + correction)\n",
        "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "            \n",
        "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1)]\n",
        "            add_initial = [0,0,0,0]\n",
        "            \n",
        "        elif best_degree == 'quadratic':\n",
        "            def add_obj(params, df_data):\n",
        "                a0, a1, a2, a3, a4 = params\n",
        "                predictions = []\n",
        "                for _, row in df_data.iterrows():\n",
        "                    base_pred = row['SRKT2_Baseline']\n",
        "                    cct_norm = (row['CCT'] - 600) / 100\n",
        "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                    correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                a3 * row['K_avg'] + a4 * cct_norm**2)\n",
        "                    predictions.append(base_pred + correction)\n",
        "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "            \n",
        "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1),(-1,1)]\n",
        "            add_initial = [0,0,0,0,0]\n",
        "            \n",
        "        else:  # cubic\n",
        "            def add_obj(params, df_data):\n",
        "                a0, a1, a2, a3, a4, a5 = params\n",
        "                predictions = []\n",
        "                for _, row in df_data.iterrows():\n",
        "                    base_pred = row['SRKT2_Baseline']\n",
        "                    cct_norm = (row['CCT'] - 600) / 100\n",
        "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "                    correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
        "                                a5 * cct_norm**3)\n",
        "                    predictions.append(base_pred + correction)\n",
        "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
        "            \n",
        "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1),(-1,1),(-0.5,0.5)]\n",
        "            add_initial = [0,0,0,0,0,0]\n",
        "        \n",
        "        result_a = minimize(lambda p: add_obj(p, fold_train), add_initial,\n",
        "                           method='L-BFGS-B', bounds=add_bounds)\n",
        "        add_fold_results.append(result_a.x)\n",
        "        \n",
        "        # VALIDATE COMBINED on fold validation set\n",
        "        nc_b, nc_c, k_b, k_c, acd_b, acd_c = result_p.x\n",
        "        m0, m1, m2 = result_m.x\n",
        "        \n",
        "        combined_preds = []\n",
        "        for _, row in fold_val.iterrows():\n",
        "            cct_norm = (row['CCT'] - 600) / 100\n",
        "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "            \n",
        "            # Modified SRK/T2\n",
        "            nc = nc_b + nc_c * cct_norm\n",
        "            k_index = k_b + k_c * cct_norm\n",
        "            acd_offset = acd_b + acd_c * cct_norm\n",
        "            modified = calculate_SRKT2(\n",
        "                AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
        "                IOL_power=row['IOL Power'],\n",
        "                A_constant=row['A-Constant'] + acd_offset,\n",
        "                nc=nc, k_index=k_index\n",
        "            )\n",
        "            \n",
        "            # Apply multiplicative\n",
        "            mult_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
        "            after_mult = modified * mult_factor\n",
        "            \n",
        "            # Apply additive with appropriate polynomial\n",
        "            if best_degree == 'linear':\n",
        "                a0, a1, a2, a3 = result_a.x\n",
        "                add_correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
        "            elif best_degree == 'quadratic':\n",
        "                a0, a1, a2, a3, a4 = result_a.x\n",
        "                add_correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                a3 * row['K_avg'] + a4 * cct_norm**2)\n",
        "            else:  # cubic\n",
        "                a0, a1, a2, a3, a4, a5 = result_a.x\n",
        "                add_correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
        "                                a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
        "                                a5 * cct_norm**3)\n",
        "            \n",
        "            final = after_mult + add_correction\n",
        "            combined_preds.append(final)\n",
        "        \n",
        "        fold_mae = mean_absolute_error(fold_val['PostOP Spherical Equivalent'], combined_preds)\n",
        "        combined_fold_maes.append(fold_mae)\n",
        "        print(f\"MAE={fold_mae:.4f} \", end=\"\")\n",
        "    \n",
        "    print()  # New line after folds\n",
        "    \n",
        "    # Average parameters across folds\n",
        "    avg_param = np.mean(param_fold_results, axis=0)\n",
        "    avg_mult = np.mean(mult_fold_results, axis=0)\n",
        "    avg_add = np.mean(add_fold_results, axis=0)\n",
        "    avg_combined_mae = np.mean(combined_fold_maes)\n",
        "    std_combined_mae = np.std(combined_fold_maes)\n",
        "    \n",
        "    print(f\"  CV MAE: {avg_combined_mae:.4f} Â± {std_combined_mae:.4f} D\")\n",
        "    \n",
        "    # FINAL RETRAINING on full training set\n",
        "    print(\"  Final optimization on full training set...\")\n",
        "    \n",
        "    result_p_final = differential_evolution(lambda p: param_obj(p, X_train_comb), bounds_p, \n",
        "                                           maxiter=50, seed=SEED, disp=False)\n",
        "    nc_base_c, nc_cct_c, k_base_c, k_cct_c, acd_base_c, acd_cct_c = result_p_final.x\n",
        "    \n",
        "    result_m_final = minimize(lambda p: mult_obj(p, X_train_comb), [0,0,0], \n",
        "                             method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
        "    m0_c, m1_c, m2_c = result_m_final.x\n",
        "    \n",
        "    result_a_final = minimize(lambda p: add_obj(p, X_train_comb), add_initial,\n",
        "                             method='L-BFGS-B', bounds=add_bounds)\n",
        "    \n",
        "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
        "    predictions_combined_train = []\n",
        "    for _, row in X_train_comb.iterrows():\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "        k_avg = row['K_avg']\n",
        "        \n",
        "        # Modified SRK/T2 with optimized parameters\n",
        "        nc = nc_base_c + nc_cct_c * cct_norm\n",
        "        k_index = k_base_c + k_cct_c * cct_norm\n",
        "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
        "        modified = calculate_SRKT2(\n",
        "            AL=row['Bio-AL'], K_avg=k_avg,\n",
        "            IOL_power=row['IOL Power'],\n",
        "            A_constant=row['A-Constant'] + acd_offset,\n",
        "            nc=nc, k_index=k_index\n",
        "        )\n",
        "        \n",
        "        # Apply multiplicative correction\n",
        "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
        "        after_mult = modified * mult_factor\n",
        "        \n",
        "        # Apply additive correction with polynomial\n",
        "        if best_degree == 'linear':\n",
        "            a0_c, a1_c, a2_c, a3_c = result_a_final.x\n",
        "            add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
        "        elif best_degree == 'quadratic':\n",
        "            a0_c, a1_c, a2_c, a3_c, a4_c = result_a_final.x\n",
        "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
        "                            a3_c * k_avg + a4_c * cct_norm**2)\n",
        "        else:  # cubic\n",
        "            a0_c, a1_c, a2_c, a3_c, a4_c, a5_c = result_a_final.x\n",
        "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
        "                            a3_c * k_avg + a4_c * cct_norm**2 + a5_c * cct_norm**3)\n",
        "        \n",
        "        final = after_mult + add_correction\n",
        "        predictions_combined_train.append(final)\n",
        "    \n",
        "    train_mae_combined = mean_absolute_error(X_train_comb['PostOP Spherical Equivalent'], \n",
        "                                            predictions_combined_train)\n",
        "    \n",
        "    # EVALUATE ON TEST SET\n",
        "    predictions_combined_test = []\n",
        "    for _, row in X_test_comb.iterrows():\n",
        "        cct_norm = (row['CCT'] - 600) / 100\n",
        "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
        "        k_avg = row['K_avg']\n",
        "        \n",
        "        # Modified SRK/T2 with optimized parameters\n",
        "        nc = nc_base_c + nc_cct_c * cct_norm\n",
        "        k_index = k_base_c + k_cct_c * cct_norm\n",
        "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
        "        modified = calculate_SRKT2(\n",
        "            AL=row['Bio-AL'], K_avg=k_avg,\n",
        "            IOL_power=row['IOL Power'],\n",
        "            A_constant=row['A-Constant'] + acd_offset,\n",
        "            nc=nc, k_index=k_index\n",
        "        )\n",
        "        \n",
        "        # Apply multiplicative correction\n",
        "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
        "        after_mult = modified * mult_factor\n",
        "        \n",
        "        # Apply additive correction with polynomial\n",
        "        if best_degree == 'linear':\n",
        "            add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
        "        elif best_degree == 'quadratic':\n",
        "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
        "                            a3_c * k_avg + a4_c * cct_norm**2)\n",
        "        else:  # cubic\n",
        "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
        "                            a3_c * k_avg + a4_c * cct_norm**2 + a5_c * cct_norm**3)\n",
        "        \n",
        "        final = after_mult + add_correction\n",
        "        predictions_combined_test.append(final)\n",
        "    \n",
        "    test_mae_combined = mean_absolute_error(X_test_comb['PostOP Spherical Equivalent'], \n",
        "                                           predictions_combined_test)\n",
        "    baseline_mae_combined = mean_absolute_error(X_test_comb['PostOP Spherical Equivalent'], \n",
        "                                                X_test_comb['SRKT2_Baseline'])\n",
        "    \n",
        "    improvement_combined = ((baseline_mae_combined - test_mae_combined) / baseline_mae_combined) * 100\n",
        "    overfit_ratio = test_mae_combined / train_mae_combined if train_mae_combined > 0 else float('inf')\n",
        "    \n",
        "    print(\"\\nğŸ“ˆ RESULTS:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"  Train MAE: {train_mae_combined:.4f} D\")\n",
        "    print(f\"  Test MAE:  {test_mae_combined:.4f} D\")\n",
        "    print(f\"  Baseline:  {baseline_mae_combined:.4f} D\")\n",
        "    print(f\"  Improvement: {improvement_combined:.1f}%\")\n",
        "    print(f\"  Overfit ratio: {overfit_ratio:.3f}\")\n",
        "    \n",
        "    # Store results\n",
        "    seed_results_combined.append({\n",
        "        'seed': SEED,\n",
        "        'param_values': result_p_final.x,\n",
        "        'mult_values': result_m_final.x,\n",
        "        'add_values': result_a_final.x,\n",
        "        'train_mae': train_mae_combined,\n",
        "        'test_mae': test_mae_combined,\n",
        "        'baseline_mae': baseline_mae_combined,\n",
        "        'improvement': improvement_combined,\n",
        "        'overfit_ratio': overfit_ratio\n",
        "    })\n",
        "    \n",
        "    seed_test_maes_combined.append(test_mae_combined)\n",
        "    seed_train_maes_combined.append(train_mae_combined)\n",
        "    seed_baseline_maes_combined.append(baseline_mae_combined)\n",
        "    seed_improvements_combined.append(improvement_combined)\n",
        "    seed_overfit_ratios_combined.append(overfit_ratio)\n",
        "    \n",
        "    seed_param_results.append(result_p_final.x)\n",
        "    seed_mult_results.append(result_m_final.x)\n",
        "    seed_add_results.append(result_a_final.x)\n",
        "\n",
        "# SUMMARY STATISTICS\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"MULTI-SEED SUMMARY - COMBINED APPROACH WITH {best_degree.upper()} ADDITIVE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nğŸ“Š PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Test MAE:     {np.mean(seed_test_maes_combined):.4f} Â± {np.std(seed_test_maes_combined):.4f} D\")\n",
        "print(f\"Train MAE:    {np.mean(seed_train_maes_combined):.4f} Â± {np.std(seed_train_maes_combined):.4f} D\")\n",
        "print(f\"Baseline MAE: {np.mean(seed_baseline_maes_combined):.4f} Â± {np.std(seed_baseline_maes_combined):.4f} D\")\n",
        "print(f\"Improvement:  {np.mean(seed_improvements_combined):.1f}% Â± {np.std(seed_improvements_combined):.1f}%\")\n",
        "print(f\"Overfit ratio: {np.mean(seed_overfit_ratios_combined):.3f} Â± {np.std(seed_overfit_ratios_combined):.3f}\")\n",
        "\n",
        "# Parameter consistency analysis\n",
        "print(\"\\nğŸ”¬ PARAMETER CONSISTENCY:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "param_names = ['nc_base', 'nc_cct', 'k_base', 'k_cct', 'acd_base', 'acd_cct']\n",
        "param_array = np.array(seed_param_results)\n",
        "print(\"\\nParameter optimization values:\")\n",
        "for i, name in enumerate(param_names):\n",
        "    values = param_array[:, i]\n",
        "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
        "\n",
        "mult_names = ['m0', 'm1_cct', 'm2_ratio']\n",
        "mult_array = np.array(seed_mult_results)\n",
        "print(\"\\nMultiplicative correction values:\")\n",
        "for i, name in enumerate(mult_names):\n",
        "    values = mult_array[:, i]\n",
        "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
        "\n",
        "add_array = np.array(seed_add_results)\n",
        "print(f\"\\nAdditive correction values ({best_degree}):\")\n",
        "if best_degree == 'linear':\n",
        "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K']\n",
        "elif best_degree == 'quadratic':\n",
        "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K', 'a4_cct2']\n",
        "else:  # cubic\n",
        "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K', 'a4_cct2', 'a5_cct3']\n",
        "\n",
        "for i, name in enumerate(add_names):\n",
        "    values = add_array[:, i]\n",
        "    print(f\"  {name:10s}: {np.mean(values):7.4f} Â± {np.std(values):.4f}\")\n",
        "\n",
        "# Clinical significance\n",
        "mae_mean = np.mean(seed_test_maes_combined)\n",
        "mae_std = np.std(seed_test_maes_combined)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CLINICAL INTERPRETATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"âœ… Combined approach with {best_degree} additive achieves:\")\n",
        "print(f\"   â€¢ Mean absolute error: {mae_mean:.3f} Â± {mae_std:.3f} D\")\n",
        "print(f\"   â€¢ {np.mean(seed_improvements_combined):.0f}% improvement over standard SRK/T2\")\n",
        "\n",
        "if mae_mean < 0.5:\n",
        "    print(\"   â€¢ EXCELLENT: Within Â±0.50 D target for most patients\")\n",
        "elif mae_mean < 0.75:\n",
        "    print(\"   â€¢ GOOD: Within Â±0.75 D for most patients\")\n",
        "else:\n",
        "    print(\"   â€¢ MODERATE: Further optimization may be beneficial\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3yxaies4nqp",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "MULTI-SEED ANALYSIS - COMPREHENSIVE COMPARISON OF ALL METHODS\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š PERFORMANCE RANKING (Best to Worst):\n",
            "--------------------------------------------------------------------------------\n",
            "Method                        Test MAE    Train MAE  Improvement    Overfit\n",
            "--------------------------------------------------------------------------------\n",
            "Full Combined (quadratic) 0.8315 Â± 0.0000       0.9024        44.0%      0.921\n",
            "Multiplicative            1.0063 Â± 0.0000       0.9068        32.2%     10.982\n",
            "Parameter Opt             1.4354 Â± 0.0000       1.1642         3.3%     23.296\n",
            "Baseline SRK/T2           1.4849 Â± 0.0000          N/A         0.0%        N/A\n",
            "Additive (quadratic)      1.5813 Â± 0.0000       1.2721        -6.5%      1.243\n",
            "Param+Mult                   nan Â± nan          N/A          N/A        N/A\n",
            "\n",
            "================================================================================\n",
            "ğŸ† WINNER ANALYSIS\n",
            "================================================================================\n",
            "BEST METHOD: Full Combined (quadratic)\n",
            "  â€¢ Test MAE: 0.8315 Â± 0.0000 D\n",
            "  â€¢ Improvement over baseline: 44.0%\n",
            "\n",
            "âœ… The full combined approach performs best, validating that:\n",
            "   1. Parameter optimization corrects fundamental optical assumptions\n",
            "   2. Multiplicative correction scales for proportional errors\n",
            "   3. Additive correction handles residual systematic bias\n",
            "   4. Quadratic polynomial captures non-linear CCT effects\n",
            "\n",
            "ğŸ“ˆ STATISTICAL ANALYSIS:\n",
            "--------------------------------------------------------------------------------\n",
            "Advantage over 2nd best (Multiplicative): 0.1748 D\n",
            "  âœ“ Clinically significant difference (>0.05 D)\n",
            "\n",
            "ğŸ” OVERFITTING ANALYSIS:\n",
            "--------------------------------------------------------------------------------\n",
            "Methods with potential overfitting (ratio > 1.2):\n",
            "  â€¢ Multiplicative: 10.982\n",
            "  â€¢ Parameter Opt: 23.296\n",
            "  â€¢ Additive (quadratic): 1.243\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "CLINICAL RECOMMENDATIONS\n",
            "================================================================================\n",
            "âš  MODERATE PERFORMANCE\n",
            "   The Full Combined (quadratic) method achieves 0.832 D MAE\n",
            "   This may require additional optimization\n",
            "   Recommendation: Explore additional features or methods\n",
            "\n",
            "ğŸ’¾ Exporting results to CSV...\n",
            "   Results saved to: iol_formula_comparison.csv\n",
            "\n",
            "================================================================================\n",
            "FINAL FORMULA\n",
            "================================================================================\n",
            "Recommended formula: Full Combined (quadratic)\n",
            "\n",
            "Average parameters across seeds:\n",
            "\n",
            "1. Modified SRK/T2 parameters:\n",
            "   nc = 1.4290 + -0.1113 Ã— CCT_norm\n",
            "   k_index = 1.4086 + -0.0946 Ã— CCT_norm\n",
            "   ACD_offset = 2.6867 + -1.7350 Ã— CCT_norm\n",
            "\n",
            "2. Multiplicative correction:\n",
            "   factor = 1 + -0.0379 + -0.0153 Ã— CCT_norm + -0.0378 Ã— CCT_ratio\n",
            "\n",
            "3. Additive correction (quadratic):\n",
            "   correction = -0.0022 + 0.0134 Ã— CCT_norm + 0.0998 Ã— CCT_ratio\n",
            "              + -0.0637 Ã— K_avg + 0.0387 Ã— CCT_normÂ²\n",
            "\n",
            "Where:\n",
            "   CCT_norm = (CCT - 600) / 100\n",
            "   CCT_ratio = CCT / AL\n",
            "   K_avg = (K_steep + K_flat) / 2\n"
          ]
        }
      ],
      "source": [
        "# MULTI-SEED COMPARISON - FINAL COMPREHENSIVE SUMMARY\n",
        "# ====================================================\n",
        "# PURPOSE: Compare ALL methods across multiple seeds for robust conclusions\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"MULTI-SEED ANALYSIS - COMPREHENSIVE COMPARISON OF ALL METHODS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Compile all results into a comparison table\n",
        "all_methods = {}\n",
        "\n",
        "# 1. Baseline (no optimization)\n",
        "if 'seed_baseline_maes_param' in locals():\n",
        "    all_methods['Baseline SRK/T2'] = {\n",
        "        'test_mae': np.mean(seed_baseline_maes_param),\n",
        "        'test_std': np.std(seed_baseline_maes_param),\n",
        "        'train_mae': np.nan,  # Baseline doesn't have training\n",
        "        'improvement': 0.0,\n",
        "        'overfit_ratio': np.nan\n",
        "    }\n",
        "\n",
        "# 2. Parameter Optimization\n",
        "if 'seed_test_maes_param' in locals():\n",
        "    all_methods['Parameter Opt'] = {\n",
        "        'test_mae': np.mean(seed_test_maes_param),\n",
        "        'test_std': np.std(seed_test_maes_param),\n",
        "        'train_mae': np.mean(seed_train_maes_param),\n",
        "        'improvement': np.mean(seed_improvements_param),\n",
        "        'overfit_ratio': np.mean(seed_overfit_ratios_param)\n",
        "    }\n",
        "\n",
        "# 3. Multiplicative Correction\n",
        "if 'seed_test_maes_mult' in locals():\n",
        "    all_methods['Multiplicative'] = {\n",
        "        'test_mae': np.mean(seed_test_maes_mult),\n",
        "        'test_std': np.std(seed_test_maes_mult),\n",
        "        'train_mae': np.mean(seed_train_maes_mult),\n",
        "        'improvement': np.mean(seed_improvements_mult),\n",
        "        'overfit_ratio': np.mean(seed_overfit_ratios_mult)\n",
        "    }\n",
        "\n",
        "# 4. Additive Correction (with best polynomial)\n",
        "if 'seed_test_maes_additive' in locals():\n",
        "    method_name = f'Additive ({best_degree})' if 'best_degree' in locals() else 'Additive'\n",
        "    all_methods[method_name] = {\n",
        "        'test_mae': np.mean(seed_test_maes_additive),\n",
        "        'test_std': np.std(seed_test_maes_additive),\n",
        "        'train_mae': np.mean(seed_train_maes_additive),\n",
        "        'improvement': np.mean(seed_improvements_additive),\n",
        "        'overfit_ratio': np.mean([t/r for t,r in zip(seed_test_maes_additive, seed_train_maes_additive)])\n",
        "    }\n",
        "\n",
        "# 5. Param + Multiplicative Combined (no additive)\n",
        "if 'seed_test_maes_param_mult' in locals():\n",
        "    all_methods['Param+Mult'] = {\n",
        "        'test_mae': np.mean(seed_test_maes_param_mult),\n",
        "        'test_std': np.std(seed_test_maes_param_mult),\n",
        "        'train_mae': np.mean(seed_train_maes_param_mult),\n",
        "        'improvement': np.mean(seed_improvements_param_mult),\n",
        "        'overfit_ratio': np.mean(seed_overfit_ratios_param_mult)\n",
        "    }\n",
        "\n",
        "# 6. Full Combined (all three methods)\n",
        "if 'seed_test_maes_combined' in locals():\n",
        "    poly_label = f' ({best_degree})' if 'best_degree' in locals() else ''\n",
        "    all_methods[f'Full Combined{poly_label}'] = {\n",
        "        'test_mae': np.mean(seed_test_maes_combined),\n",
        "        'test_std': np.std(seed_test_maes_combined),\n",
        "        'train_mae': np.mean(seed_train_maes_combined),\n",
        "        'improvement': np.mean(seed_improvements_combined),\n",
        "        'overfit_ratio': np.mean(seed_overfit_ratios_combined)\n",
        "    }\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame(all_methods).T\n",
        "comparison_df = comparison_df.sort_values('test_mae')\n",
        "\n",
        "print(\"\\nğŸ“Š PERFORMANCE RANKING (Best to Worst):\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Method':<25} {'Test MAE':>12} {'Train MAE':>12} {'Improvement':>12} {'Overfit':>10}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for method in comparison_df.index:\n",
        "    row = comparison_df.loc[method]\n",
        "    test_str = f\"{row['test_mae']:.4f} Â± {row['test_std']:.4f}\"\n",
        "    train_str = f\"{row['train_mae']:.4f}\" if not pd.isna(row['train_mae']) else \"N/A\"\n",
        "    improv_str = f\"{row['improvement']:.1f}%\" if not pd.isna(row['improvement']) else \"N/A\"\n",
        "    overfit_str = f\"{row['overfit_ratio']:.3f}\" if not pd.isna(row['overfit_ratio']) else \"N/A\"\n",
        "    \n",
        "    print(f\"{method:<25} {test_str:>12} {train_str:>12} {improv_str:>12} {overfit_str:>10}\")\n",
        "\n",
        "# Identify best method\n",
        "best_method = comparison_df.index[0]\n",
        "best_mae = comparison_df.loc[best_method, 'test_mae']\n",
        "best_std = comparison_df.loc[best_method, 'test_std']\n",
        "best_improvement = comparison_df.loc[best_method, 'improvement']\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ† WINNER ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"BEST METHOD: {best_method}\")\n",
        "print(f\"  â€¢ Test MAE: {best_mae:.4f} Â± {best_std:.4f} D\")\n",
        "print(f\"  â€¢ Improvement over baseline: {best_improvement:.1f}%\")\n",
        "\n",
        "# Additional insights\n",
        "if 'Full Combined' in best_method:\n",
        "    print(\"\\nâœ… The full combined approach performs best, validating that:\")\n",
        "    print(\"   1. Parameter optimization corrects fundamental optical assumptions\")\n",
        "    print(\"   2. Multiplicative correction scales for proportional errors\")\n",
        "    print(\"   3. Additive correction handles residual systematic bias\")\n",
        "    if 'best_degree' in locals() and best_degree != 'linear':\n",
        "        print(f\"   4. {best_degree.capitalize()} polynomial captures non-linear CCT effects\")\n",
        "elif 'Param+Mult' in best_method:\n",
        "    print(\"\\nâœ… Param+Mult performs best, suggesting:\")\n",
        "    print(\"   â€¢ Additive correction may not be necessary\")\n",
        "    print(\"   â€¢ The combination of parameter and multiplicative is sufficient\")\n",
        "\n",
        "# Statistical significance analysis\n",
        "print(\"\\nğŸ“ˆ STATISTICAL ANALYSIS:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Compare top methods\n",
        "if len(comparison_df) >= 2:\n",
        "    second_best = comparison_df.index[1]\n",
        "    mae_diff = comparison_df.loc[second_best, 'test_mae'] - best_mae\n",
        "    \n",
        "    print(f\"Advantage over 2nd best ({second_best}): {mae_diff:.4f} D\")\n",
        "    \n",
        "    # Check if difference is clinically significant (>0.05 D)\n",
        "    if mae_diff > 0.05:\n",
        "        print(\"  âœ“ Clinically significant difference (>0.05 D)\")\n",
        "    else:\n",
        "        print(\"  âš  Marginal clinical difference (<0.05 D)\")\n",
        "\n",
        "# Overfitting analysis\n",
        "print(\"\\nğŸ” OVERFITTING ANALYSIS:\")\n",
        "print(\"-\" * 80)\n",
        "overfit_methods = comparison_df[comparison_df['overfit_ratio'] > 1.2]\n",
        "if not overfit_methods.empty:\n",
        "    print(\"Methods with potential overfitting (ratio > 1.2):\")\n",
        "    for method in overfit_methods.index:\n",
        "        ratio = overfit_methods.loc[method, 'overfit_ratio']\n",
        "        print(f\"  â€¢ {method}: {ratio:.3f}\")\n",
        "else:\n",
        "    print(\"âœ“ No significant overfitting detected in any method\")\n",
        "\n",
        "# Create visualization\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: MAE Comparison\n",
        "ax1 = axes[0]\n",
        "methods = list(comparison_df.index)\n",
        "maes = comparison_df['test_mae'].values\n",
        "stds = comparison_df['test_std'].values\n",
        "colors = ['red' if 'Baseline' in m else 'green' if m == best_method else 'blue' for m in methods]\n",
        "\n",
        "ax1.barh(range(len(methods)), maes, xerr=stds, color=colors, alpha=0.7)\n",
        "ax1.set_yticks(range(len(methods)))\n",
        "ax1.set_yticklabels(methods)\n",
        "ax1.set_xlabel('Test MAE (D)')\n",
        "ax1.set_title('Mean Absolute Error Comparison')\n",
        "ax1.axvline(x=0.5, color='green', linestyle='--', alpha=0.5, label='Clinical target')\n",
        "ax1.axvline(x=0.75, color='orange', linestyle='--', alpha=0.5)\n",
        "ax1.legend()\n",
        "\n",
        "# Plot 2: Improvement over Baseline\n",
        "ax2 = axes[1]\n",
        "improvements = comparison_df['improvement'].values\n",
        "ax2.barh(range(len(methods)), improvements, color=colors, alpha=0.7)\n",
        "ax2.set_yticks(range(len(methods)))\n",
        "ax2.set_yticklabels(methods)\n",
        "ax2.set_xlabel('Improvement (%)')\n",
        "ax2.set_title('Improvement over Baseline SRK/T2')\n",
        "\n",
        "# Plot 3: Train vs Test MAE (Overfitting check)\n",
        "ax3 = axes[2]\n",
        "train_maes = comparison_df['train_mae'].values\n",
        "test_maes = comparison_df['test_mae'].values\n",
        "valid_idx = ~pd.isna(train_maes)\n",
        "ax3.scatter(train_maes[valid_idx], test_maes[valid_idx], s=100, alpha=0.7)\n",
        "for i, method in enumerate(methods):\n",
        "    if valid_idx[i]:\n",
        "        ax3.annotate(method, (train_maes[i], test_maes[i]), fontsize=8, ha='right')\n",
        "\n",
        "# Add diagonal line (perfect generalization)\n",
        "min_val = min(np.nanmin(train_maes), np.nanmin(test_maes))\n",
        "max_val = max(np.nanmax(train_maes), np.nanmax(test_maes))\n",
        "ax3.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Perfect generalization')\n",
        "ax3.set_xlabel('Train MAE (D)')\n",
        "ax3.set_ylabel('Test MAE (D)')\n",
        "ax3.set_title('Overfitting Analysis')\n",
        "ax3.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CLINICAL RECOMMENDATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if best_mae < 0.5:\n",
        "    print(\"âœ… EXCELLENT PERFORMANCE\")\n",
        "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
        "    print(\"   This is within the Â±0.50 D target for premium IOL surgery\")\n",
        "    print(\"   Recommendation: Ready for clinical validation study\")\n",
        "elif best_mae < 0.75:\n",
        "    print(\"âœ… GOOD PERFORMANCE\")\n",
        "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
        "    print(\"   This is within the Â±0.75 D acceptable range\")\n",
        "    print(\"   Recommendation: Consider further optimization for premium cases\")\n",
        "else:\n",
        "    print(\"âš  MODERATE PERFORMANCE\")\n",
        "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
        "    print(\"   This may require additional optimization\")\n",
        "    print(\"   Recommendation: Explore additional features or methods\")\n",
        "\n",
        "# Export results\n",
        "print(\"\\nğŸ’¾ Exporting results to CSV...\")\n",
        "comparison_df.to_csv('iol_formula_comparison.csv')\n",
        "print(\"   Results saved to: iol_formula_comparison.csv\")\n",
        "\n",
        "# Final formula recommendation\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL FORMULA\")\n",
        "print(\"=\"*80)\n",
        "if 'Full Combined' in best_method and 'seed_param_results' in locals():\n",
        "    print(f\"Recommended formula: {best_method}\")\n",
        "    print(\"\\nAverage parameters across seeds:\")\n",
        "    \n",
        "    # Parameter values\n",
        "    param_array = np.array(seed_param_results)\n",
        "    print(\"\\n1. Modified SRK/T2 parameters:\")\n",
        "    print(f\"   nc = {np.mean(param_array[:, 0]):.4f} + {np.mean(param_array[:, 1]):.4f} Ã— CCT_norm\")\n",
        "    print(f\"   k_index = {np.mean(param_array[:, 2]):.4f} + {np.mean(param_array[:, 3]):.4f} Ã— CCT_norm\")\n",
        "    print(f\"   ACD_offset = {np.mean(param_array[:, 4]):.4f} + {np.mean(param_array[:, 5]):.4f} Ã— CCT_norm\")\n",
        "    \n",
        "    # Multiplicative values\n",
        "    if 'seed_mult_results' in locals():\n",
        "        mult_array = np.array(seed_mult_results)\n",
        "        print(\"\\n2. Multiplicative correction:\")\n",
        "        print(f\"   factor = 1 + {np.mean(mult_array[:, 0]):.4f} + {np.mean(mult_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(mult_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
        "    \n",
        "    # Additive values\n",
        "    if 'seed_add_results' in locals():\n",
        "        add_array = np.array(seed_add_results)\n",
        "        print(f\"\\n3. Additive correction ({best_degree if 'best_degree' in locals() else 'linear'}):\")\n",
        "        if best_degree == 'linear' or 'best_degree' not in locals():\n",
        "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio + {np.mean(add_array[:, 3]):.4f} Ã— K_avg\")\n",
        "        elif best_degree == 'quadratic':\n",
        "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
        "            print(f\"              + {np.mean(add_array[:, 3]):.4f} Ã— K_avg + {np.mean(add_array[:, 4]):.4f} Ã— CCT_normÂ²\")\n",
        "        else:  # cubic\n",
        "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} Ã— CCT_norm + {np.mean(add_array[:, 2]):.4f} Ã— CCT_ratio\")\n",
        "            print(f\"              + {np.mean(add_array[:, 3]):.4f} Ã— K_avg + {np.mean(add_array[:, 4]):.4f} Ã— CCT_normÂ² + {np.mean(add_array[:, 5]):.4f} Ã— CCT_normÂ³\")\n",
        "    \n",
        "    print(\"\\nWhere:\")\n",
        "    print(\"   CCT_norm = (CCT - 600) / 100\")\n",
        "    print(\"   CCT_ratio = CCT / AL\")\n",
        "    print(\"   K_avg = (K_steep + K_flat) / 2\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
