{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41782613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🔧 MULTI-SEED CONFIGURATION\n",
      "======================================================================\n",
      "Seeds for validation: [42, 123, 456, 789, 2025]\n",
      "This ensures results are not dependent on random split\n",
      "Each seed creates different train/test splits for robust assessment\n",
      "======================================================================\n",
      "IOL CALCULATION FOR PRE-DMEK PATIENTS\n",
      "======================================================================\n",
      "\n",
      "📊 WHAT WE'RE DOING:\n",
      "--------------------------------------------------\n",
      "• Loading data from Fuchs' dystrophy patients\n",
      "• These patients had combined cataract + DMEK surgery\n",
      "• Goal: Improve IOL power calculation accuracy\n",
      "• Challenge: Edematous corneas distort standard formulas\n",
      "• NEW: Using 5 different seeds for robust validation\n",
      "\n",
      "✅ Loaded 96 patients from FacoDMEK.xlsx\n",
      "\n",
      "🔍 KEY MEASUREMENTS IN OUR DATA:\n",
      "--------------------------------------------------\n",
      "• Bio-AL: Axial length (mm)\n",
      "• Bio-Ks/Kf: Steep and flat keratometry (D)\n",
      "• CCT: Central corneal thickness (μm) - KEY for edema\n",
      "• IOL Power: Implanted lens power (D)\n",
      "• PostOP Spherical Equivalent: Actual outcome (D)\n"
     ]
    }
   ],
   "source": [
    "# IOL CALCULATION FOR PRE-DMEK PATIENTS - SETUP AND DATA LOADING\n",
    "# ================================================================\n",
    "# PURPOSE: Set up the analysis environment and load patient data\n",
    "# This notebook optimizes IOL power calculations for Fuchs' dystrophy patients\n",
    "# undergoing combined phacoemulsification and DMEK surgery\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants for clinical accuracy thresholds (diopters)\n",
    "THRESHOLDS = [0.25, 0.50, 0.75, 1.00]\n",
    "TEST_SIZE = 0.25      # 25% holdout for final testing\n",
    "N_FOLDS = 5           # 5-fold cross-validation\n",
    "\n",
    "# MULTI-SEED CONFIGURATION FOR ROBUST VALIDATION\n",
    "SEEDS = [42, 123, 456, 789, 2025]  # Multiple seeds for statistical robustness\n",
    "print(\"=\" * 70)\n",
    "print(\"🔧 MULTI-SEED CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Seeds for validation: {SEEDS}\")\n",
    "print(\"This ensures results are not dependent on random split\")\n",
    "print(\"Each seed creates different train/test splits for robust assessment\")\n",
    "\n",
    "# Storage for multi-seed results\n",
    "multi_seed_results = {\n",
    "\n",
    "    'parameter': {},\n",
    "    'multiplicative': {},\n",
    "    'additive': {},\n",
    "    'combined': {},\n",
    "    'fixed_combined': {}\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"IOL CALCULATION FOR PRE-DMEK PATIENTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n📊 WHAT WE'RE DOING:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• Loading data from Fuchs' dystrophy patients\")\n",
    "print(\"• These patients had combined cataract + DMEK surgery\")\n",
    "print(\"• Goal: Improve IOL power calculation accuracy\")\n",
    "print(\"• Challenge: Edematous corneas distort standard formulas\")\n",
    "print(f\"• NEW: Using {len(SEEDS)} different seeds for robust validation\")\n",
    "\n",
    "# Load the patient data\n",
    "df = pd.read_excel('FacoDMEK.xlsx')\n",
    "print(f\"\\n✅ Loaded {len(df)} patients from FacoDMEK.xlsx\")\n",
    "\n",
    "print(\"\\n🔍 KEY MEASUREMENTS IN OUR DATA:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• Bio-AL: Axial length (mm)\")\n",
    "print(\"• Bio-Ks/Kf: Steep and flat keratometry (D)\")\n",
    "print(\"• CCT: Central corneal thickness (μm) - KEY for edema\")\n",
    "print(\"• IOL Power: Implanted lens power (D)\")\n",
    "print(\"• PostOP Spherical Equivalent: Actual outcome (D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9871e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SRK/T2 FORMULA (Sheard et al. 2010)\n",
      "======================================================================\n",
      "• SKR/T2 assumes normal corneal properties\n",
      "• In Fuchs' dystrophy, the cornea is NOT normal:\n",
      "  - Edema changes refractive index (nc)\n",
      "  - Swelling alters keratometric index (k_index)\n",
      "  - Anterior chamber depth is affected\n",
      "\n",
      "Our strategy: Keep the formula structure, optimize the parameters!\n",
      "\n",
      "📐 THE SRK/T2 FORMULA:\n",
      "\n",
      "         1000·nₐ·(nₐ·r - nc₋₁·Lopt) - P·(Lopt - ACDest)·(nₐ·r - nc₋₁·ACDest)\n",
      "REF = ───────────────────────────────────────────────────────────────────────────\n",
      "       nₐ·(V·(nₐ·r - nc₋₁·Lopt) + Lopt·r) - 0.001·P·(Lopt - ACDest)·(V·(nₐ·r - nc₋₁·ACDest) + ACDest·r)\n"
     ]
    }
   ],
   "source": [
    "# STANDARD SRK/T2 FORMULA IMPLEMENTATION\n",
    "# ========================================\n",
    "# PURPOSE: Implement the baseline SRK/T2 formula (Sheard et al. 2010)\n",
    "# This is the current gold standard for IOL calculations\n",
    "# We'll use this as our baseline to compare improvements against\n",
    "\n",
    "def calculate_SRKT2(AL, K_avg, IOL_power, A_constant, nc=1.333, k_index=1.3375):\n",
    "    \"\"\"\n",
    "    SRK/T2 Formula (Sheard et al. 2010)\n",
    "    - Assumes NORMAL corneas (nc=1.333, k_index=1.3375)\n",
    "    - These assumptions fail in edematous Fuchs' corneas\n",
    "    \n",
    "    Parameters:\n",
    "    - AL: Axial length (mm)\n",
    "    - K_avg: Average keratometry (D)\n",
    "    - IOL_power: IOL power (D)\n",
    "    - A_constant: Lens-specific constant\n",
    "    - nc: Corneal refractive index (we'll optimize this!)\n",
    "    - k_index: Keratometric index (we'll optimize this too!)\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    na = 1.336  # Aqueous/vitreous refractive index\n",
    "    V = 12      # Vertex distance (mm)\n",
    "    ncm1 = nc - 1\n",
    "    \n",
    "    # Convert keratometry to radius using keratometric index\n",
    "    # This is where edema causes problems - k_index assumes normal cornea!\n",
    "    r = (k_index - 1) * 1000 / K_avg\n",
    "    \n",
    "    # Axial length correction for long eyes\n",
    "    if AL <= 24.2:\n",
    "        LCOR = AL\n",
    "    else:\n",
    "        LCOR = 3.446 + 1.716 * AL - 0.0237 * AL * AL\n",
    "    \n",
    "    # H2 calculation (corneal height) - Sheard's modification\n",
    "    H2 = -10.326 + 0.32630 * LCOR + 0.13533 * K_avg\n",
    "    \n",
    "    # ACD (Anterior Chamber Depth) estimation\n",
    "    # Edema can affect this too!\n",
    "    ACD_const = 0.62467 * A_constant - 68.747\n",
    "    offset = ACD_const - 3.336\n",
    "    ACD_est = H2 + offset\n",
    "    \n",
    "    # Retinal thickness correction\n",
    "    RETHICK = 0.65696 - 0.02029 * AL\n",
    "    LOPT = AL + RETHICK  # Optical axial length\n",
    "    \n",
    "    # SRK/T2 refraction calculation - the complex optics formula\n",
    "    numerator = (1000 * na * (na * r - ncm1 * LOPT) - \n",
    "                 IOL_power * (LOPT - ACD_est) * (na * r - ncm1 * ACD_est))\n",
    "    \n",
    "    denominator = (na * (V * (na * r - ncm1 * LOPT) + LOPT * r) - \n",
    "                   0.001 * IOL_power * (LOPT - ACD_est) * \n",
    "                   (V * (na * r - ncm1 * ACD_est) + ACD_est * r))\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SRK/T2 FORMULA (Sheard et al. 2010)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"• SKR/T2 assumes normal corneal properties\")\n",
    "print(\"• In Fuchs' dystrophy, the cornea is NOT normal:\")\n",
    "print(\"  - Edema changes refractive index (nc)\")\n",
    "print(\"  - Swelling alters keratometric index (k_index)\")\n",
    "print(\"  - Anterior chamber depth is affected\")\n",
    "print(\"\\nOur strategy: Keep the formula structure, optimize the parameters!\")\n",
    "\n",
    "print(\"\\n📐 THE SRK/T2 FORMULA:\")\n",
    "print()\n",
    "print(\"         1000·nₐ·(nₐ·r - nc₋₁·Lopt) - P·(Lopt - ACDest)·(nₐ·r - nc₋₁·ACDest)\")\n",
    "print(\"REF = ───────────────────────────────────────────────────────────────────────────\")\n",
    "print(\"       nₐ·(V·(nₐ·r - nc₋₁·Lopt) + Lopt·r) - 0.001·P·(Lopt - ACDest)·(V·(nₐ·r - nc₋₁·ACDest) + ACDest·r)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db415cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE SRK/T2 PERFORMANCE\n",
      "======================================================================\n",
      "\n",
      "📋 WHAT WE'RE DOING:\n",
      "--------------------------------------------------\n",
      "1. Calculate average K from steep and flat readings\n",
      "2. Apply standard SRK/T2 to all 96 patients\n",
      "3. Compare predictions to actual outcomes\n",
      "4. Measure error to establish baseline performance\n",
      "\n",
      "📊 BASELINE PERFORMANCE METRICS:\n",
      "======================================================================\n",
      "  Mean Absolute Error (MAE):     1.3591 D\n",
      "  Mean Error (ME):                -0.2915 D\n",
      "  Standard Deviation (SD):        1.7471 D\n",
      "  Median Absolute Error:          1.0311 D\n",
      "\n",
      "💡 INTERPRETATION:\n",
      "--------------------------------------------------\n",
      "• MAE of 1.36 D is POOR (>1.0 D is clinically unacceptable)\n",
      "• Mean error of -0.29 D shows systematic bias\n",
      "  → Formula tends to predict too myopic (negative)\n",
      "\n",
      "📈 CLINICAL ACCURACY:\n",
      "----------------------------------------------------------------------\n",
      "  Within ±0.25 D:  13.5% of eyes\n",
      "  Within ±0.50 D:  26.0% of eyes\n",
      "  Within ±0.75 D:  35.4% of eyes\n",
      "  Within ±1.00 D:  49.0% of eyes\n",
      "\n",
      "🎯 CLINICAL TARGETS:\n",
      "--------------------------------------------------\n",
      "• Modern standard: >70% within ±0.50 D\n",
      "• Acceptable: >90% within ±1.00 D\n",
      "• Our baseline: 26.0% within ±0.50 D\n",
      "\n",
      "⚠️ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\n",
      "This is why we need optimization!\n"
     ]
    }
   ],
   "source": [
    "# BASELINE PERFORMANCE EVALUATION\n",
    "# =================================\n",
    "# PURPOSE: Calculate how well standard SRK/T2 performs on our Fuchs' patients\n",
    "# This establishes the baseline that we need to beat\n",
    "# Spoiler: It won't be great due to the edematous corneas!\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BASELINE SRK/T2 PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n📋 WHAT WE'RE DOING:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. Calculate average K from steep and flat readings\")\n",
    "print(\"2. Apply standard SRK/T2 to all 96 patients\")\n",
    "print(\"3. Compare predictions to actual outcomes\")\n",
    "print(\"4. Measure error to establish baseline performance\")\n",
    "\n",
    "# Calculate average K (needed for SRK/T2)\n",
    "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
    "\n",
    "# Apply standard SRK/T2 formula to all patients\n",
    "df['SRKT2_Prediction'] = df.apply(\n",
    "    lambda row: calculate_SRKT2(\n",
    "        AL=row['Bio-AL'],\n",
    "        K_avg=row['K_avg'],\n",
    "        IOL_power=row['IOL Power'],\n",
    "        A_constant=row['A-Constant']\n",
    "        # Note: Using DEFAULT nc=1.333 and k_index=1.3375\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Calculate prediction errors\n",
    "df['Prediction_Error'] = df['PostOP Spherical Equivalent'] - df['SRKT2_Prediction']\n",
    "df['Absolute_Error'] = abs(df['Prediction_Error'])\n",
    "\n",
    "# Calculate key metrics\n",
    "mae = df['Absolute_Error'].mean()\n",
    "me = df['Prediction_Error'].mean()\n",
    "std = df['Prediction_Error'].std()\n",
    "median_ae = df['Absolute_Error'].median()\n",
    "\n",
    "print(\"\\n📊 BASELINE PERFORMANCE METRICS:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Mean Absolute Error (MAE):     {mae:.4f} D\")\n",
    "print(f\"  Mean Error (ME):                {me:+.4f} D\")\n",
    "print(f\"  Standard Deviation (SD):        {std:.4f} D\")\n",
    "print(f\"  Median Absolute Error:          {median_ae:.4f} D\")\n",
    "\n",
    "print(\"\\n💡 INTERPRETATION:\")\n",
    "print(\"-\" * 50)\n",
    "if mae > 1.0:\n",
    "    print(f\"• MAE of {mae:.2f} D is POOR (>1.0 D is clinically unacceptable)\")\n",
    "else:\n",
    "    print(f\"• MAE of {mae:.2f} D is moderate\")\n",
    "    \n",
    "if abs(me) > 0.25:\n",
    "    print(f\"• Mean error of {me:+.2f} D shows systematic bias\")\n",
    "    if me < 0:\n",
    "        print(\"  → Formula tends to predict too myopic (negative)\")\n",
    "    else:\n",
    "        print(\"  → Formula tends to predict too hyperopic (positive)\")\n",
    "\n",
    "# Calculate clinical accuracy rates\n",
    "within_025 = (df['Absolute_Error'] <= 0.25).sum() / len(df) * 100\n",
    "within_050 = (df['Absolute_Error'] <= 0.50).sum() / len(df) * 100\n",
    "within_075 = (df['Absolute_Error'] <= 0.75).sum() / len(df) * 100\n",
    "within_100 = (df['Absolute_Error'] <= 1.00).sum() / len(df) * 100\n",
    "\n",
    "print(\"\\n📈 CLINICAL ACCURACY:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Within ±0.25 D:  {within_025:.1f}% of eyes\")\n",
    "print(f\"  Within ±0.50 D:  {within_050:.1f}% of eyes\")\n",
    "print(f\"  Within ±0.75 D:  {within_075:.1f}% of eyes\")\n",
    "print(f\"  Within ±1.00 D:  {within_100:.1f}% of eyes\")\n",
    "\n",
    "print(\"\\n🎯 CLINICAL TARGETS:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• Modern standard: >70% within ±0.50 D\")\n",
    "print(\"• Acceptable: >90% within ±1.00 D\")\n",
    "print(f\"• Our baseline: {within_050:.1f}% within ±0.50 D\")\n",
    "print(\"\\n⚠️ Standard SRK/T2 clearly struggles with Fuchs' dystrophy!\")\n",
    "print(\"This is why we need optimization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ridge_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RIDGE REGRESSION FEATURE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "🔍 WHY START WITH RIDGE?\n",
      "--------------------------------------------------\n",
      "• Ridge regression identifies important features\n",
      "• Helps us understand what drives prediction errors\n",
      "• Guides our formula optimization strategy\n",
      "• If CCT features are important, our hypothesis is correct!\n",
      "\n",
      "📊 CREATING FEATURES:\n",
      "--------------------------------------------------\n",
      "Created 12 features including CCT interactions\n",
      "\n",
      "🏆 TOP 10 MOST IMPORTANT FEATURES:\n",
      "--------------------------------------------------\n",
      "  CCT_ratio_AL         Coef=+1.3677\n",
      "  CCT_x_AL             Coef=-0.8898\n",
      "  CCT_squared          Coef=-0.7666\n",
      "  Bio-AL               Coef=+0.4903\n",
      "  Bio-Ks               Coef=-0.3178\n",
      "  CCT_x_K              Coef=+0.3101\n",
      "  K_avg                Coef=-0.1584\n",
      "  IOL Power            Coef=-0.1189\n",
      "  CCT_norm             Coef=+0.0321\n",
      "  CCT                  Coef=+0.0321\n",
      "\n",
      "💡 KEY FINDINGS:\n",
      "--------------------------------------------------\n",
      "• CCT-related features account for 75.5% of total importance\n",
      "• Top feature: CCT_ratio_AL\n",
      "• CCT/AL ratio is among top 3 features!\n",
      "• This validates that CCT relative to eye size matters\n",
      "\n",
      "✅ HYPOTHESIS CONFIRMED:\n",
      "CCT features dominate prediction - our CCT-dependent approach is justified!\n",
      "\n",
      "🎯 OPTIMIZATION STRATEGY BASED ON RIDGE:\n",
      "--------------------------------------------------\n",
      "1. Make optical parameters CCT-dependent (nc, k_index)\n",
      "2. Consider CCT/AL ratio in corrections\n",
      "3. Account for CCT interactions with other measurements\n"
     ]
    }
   ],
   "source": [
    "# RIDGE REGRESSION ANALYSIS - IDENTIFYING IMPORTANT FEATURES\n",
    "# ===========================================================\n",
    "# PURPOSE: Use machine learning to identify which features matter most\n",
    "# This will guide our optimization strategy\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RIDGE REGRESSION FEATURE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🔍 WHY START WITH RIDGE?\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• Ridge regression identifies important features\")\n",
    "print(\"• Helps us understand what drives prediction errors\")\n",
    "print(\"• Guides our formula optimization strategy\")\n",
    "print(\"• If CCT features are important, our hypothesis is correct!\")\n",
    "\n",
    "# Create feature matrix with interactions\n",
    "print(\"\\n📊 CREATING FEATURES:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "features = []\n",
    "feature_names = []\n",
    "\n",
    "# Basic features\n",
    "for col in ['Bio-AL', 'Bio-Ks', 'Bio-Kf', 'IOL Power', 'CCT']:\n",
    "    features.append(df[col].values)\n",
    "    feature_names.append(col)\n",
    "\n",
    "# Add K_avg\n",
    "features.append(df['K_avg'].values)\n",
    "feature_names.append('K_avg')\n",
    "\n",
    "# CCT-derived features\n",
    "df['CCT_squared'] = df['CCT'] ** 2\n",
    "df['CCT_deviation'] = df['CCT'] - 550\n",
    "df['CCT_norm'] = (df['CCT'] - 600) / 100\n",
    "\n",
    "features.extend([\n",
    "    df['CCT_squared'].values,\n",
    "    df['CCT_deviation'].values,\n",
    "    df['CCT_norm'].values\n",
    "])\n",
    "feature_names.extend(['CCT_squared', 'CCT_deviation', 'CCT_norm'])\n",
    "\n",
    "# Interaction terms\n",
    "df['CCT_x_AL'] = df['CCT'] * df['Bio-AL']\n",
    "df['CCT_x_K'] = df['CCT'] * df['K_avg']\n",
    "df['CCT_ratio_AL'] = df['CCT'] / df['Bio-AL']\n",
    "\n",
    "features.extend([\n",
    "    df['CCT_x_AL'].values,\n",
    "    df['CCT_x_K'].values,\n",
    "    df['CCT_ratio_AL'].values\n",
    "])\n",
    "feature_names.extend(['CCT_x_AL', 'CCT_x_K', 'CCT_ratio_AL'])\n",
    "\n",
    "X = np.column_stack(features)\n",
    "y = df['PostOP Spherical Equivalent'].values\n",
    "\n",
    "print(f\"Created {len(feature_names)} features including CCT interactions\")\n",
    "\n",
    "# Standardize and train Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train Ridge to get feature importance\n",
    "ridge_analysis = Ridge(alpha=1.0)\n",
    "ridge_analysis.fit(X_scaled, y)\n",
    "\n",
    "# Get feature importance from coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': ridge_analysis.coef_,\n",
    "    'Abs_Coefficient': np.abs(ridge_analysis.coef_)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\n🏆 TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "print(\"-\" * 50)\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"  {row['Feature']:20} Coef={row['Coefficient']:+.4f}\")\n",
    "\n",
    "# Analyze CCT importance\n",
    "cct_features = feature_importance[feature_importance['Feature'].str.contains('CCT')]\n",
    "cct_importance = cct_features['Abs_Coefficient'].sum()\n",
    "total_importance = feature_importance['Abs_Coefficient'].sum()\n",
    "cct_percentage = (cct_importance / total_importance) * 100\n",
    "\n",
    "print(\"\\n💡 KEY FINDINGS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• CCT-related features account for {cct_percentage:.1f}% of total importance\")\n",
    "print(f\"• Top feature: {feature_importance.iloc[0]['Feature']}\")\n",
    "\n",
    "if 'CCT_ratio_AL' in feature_importance.head(3)['Feature'].values:\n",
    "    print(\"• CCT/AL ratio is among top 3 features!\")\n",
    "    print(\"• This validates that CCT relative to eye size matters\")\n",
    "\n",
    "if cct_percentage > 50:\n",
    "    print(\"\\n✅ HYPOTHESIS CONFIRMED:\")\n",
    "    print(\"CCT features dominate prediction - our CCT-dependent approach is justified!\")\n",
    "\n",
    "print(\"\\n🎯 OPTIMIZATION STRATEGY BASED ON RIDGE:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. Make optical parameters CCT-dependent (nc, k_index)\")\n",
    "print(\"2. Consider CCT/AL ratio in corrections\")\n",
    "print(\"3. Account for CCT interactions with other measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rt23gheoiv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "🎯 MULTI-SEED NESTED CROSS-VALIDATION:\n",
      "--------------------------------------------------\n",
      "• Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "• Each seed: 75% train, 25% test\n",
      "• Inner: 5-fold CV on training set\n",
      "• Results averaged across seeds for robustness\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 1.2383 ± 0.3650 D\n",
      "  Train MAE: 1.1642, Test MAE: 1.4354\n",
      "  Test: Baseline=1.4849, Optimized=1.4354\n",
      "  Improvement: 3.3%\n",
      "  ⚠️ Overfitting detected: Test 23.3% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 1.3361 ± 0.2740 D\n",
      "  Train MAE: 1.2528, Test MAE: 1.0289\n",
      "  Test: Baseline=1.2755, Optimized=1.0289\n",
      "  Improvement: 19.3%\n",
      "  ✅ Good generalization: Test only -17.9% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 1.1921 ± 0.1903 D\n",
      "  Train MAE: 1.1143, Test MAE: 1.4725\n",
      "  Test: Baseline=1.6714, Optimized=1.4725\n",
      "  Improvement: 11.9%\n",
      "  ⚠️ Overfitting detected: Test 32.1% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 1.1991 ± 0.3443 D\n",
      "  Train MAE: 1.1025, Test MAE: 1.4542\n",
      "  Test: Baseline=1.6185, Optimized=1.4542\n",
      "  Improvement: 10.2%\n",
      "  ⚠️ Overfitting detected: Test 31.9% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 1.3382 ± 0.1226 D\n",
      "  Train MAE: 1.2004, Test MAE: 1.2115\n",
      "  Test: Baseline=1.3566, Optimized=1.2115\n",
      "  Improvement: 10.7%\n",
      "  ✅ Good generalization: Test only 0.9% worse than train\n",
      "\n",
      "================================================================================\n",
      "PARAMETER OPTIMIZATION - MULTI-SEED SUMMARY\n",
      "================================================================================\n",
      "\n",
      "📊 TEST PERFORMANCE ACROSS SEEDS:\n",
      "--------------------------------------------------\n",
      "  Seed  42: MAE=1.4354 D, Improvement=3.3%\n",
      "  Seed 123: MAE=1.0289 D, Improvement=19.3%\n",
      "  Seed 456: MAE=1.4725 D, Improvement=11.9%\n",
      "  Seed 789: MAE=1.4542 D, Improvement=10.2%\n",
      "  Seed 2025: MAE=1.2115 D, Improvement=10.7%\n",
      "\n",
      "📈 STATISTICAL SUMMARY:\n",
      "--------------------------------------------------\n",
      "  Baseline MAE:      1.4814 ± 0.1503 D\n",
      "  Train MAE:         1.1668 ± 0.0555 D\n",
      "  Test MAE:          1.3205 ± 0.1738 D\n",
      "  Mean Improvement:  11.1 ± 5.1%\n",
      "  Best seed:         123 (MAE=1.0289)\n",
      "  Worst seed:        456 (MAE=1.4725)\n",
      "\n",
      "🔍 OVERFITTING ANALYSIS:\n",
      "--------------------------------------------------\n",
      "  Mean overfit ratio: 14.1%\n",
      "  (Test MAE is 14.1% worse than Train MAE on average)\n",
      "  ✅ Good generalization - acceptable overfitting\n",
      "\n",
      "✅ CONSENSUS PARAMETERS (averaged across seeds):\n",
      "--------------------------------------------------\n",
      "  nc_base              = +1.4365 ± 0.0372\n",
      "  nc_cct_coef          = +0.0660 ± 0.0622\n",
      "  k_index_base         = +1.4186 ± 0.0360\n",
      "  k_index_cct_coef     = +0.0602 ± 0.0656\n",
      "  acd_offset_base      = +2.8444 ± 0.1287\n",
      "  acd_offset_cct_coef  = +0.7143 ± 0.9863\n",
      "\n",
      "💡 ROBUSTNESS ANALYSIS:\n",
      "--------------------------------------------------\n",
      "⚠️ Moderate stability: CV=13.2% (some variation across seeds)\n",
      "\n",
      "📊 Range of results: 1.0289 - 1.4725 D\n",
      "   This 0.4436 D range shows the impact of data split\n"
     ]
    }
   ],
   "source": [
    "# PARAMETER OPTIMIZATION WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
    "# =============================================\n",
    "# PURPOSE: Optimize SRK/T2 parameters with nested CV for robust validation\n",
    "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PARAMETER OPTIMIZATION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🎯 MULTI-SEED NESTED CROSS-VALIDATION:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"• Each seed: 75% train, 25% test\")\n",
    "print(\"• Inner: 5-fold CV on training set\")\n",
    "print(\"• Results averaged across seeds for robustness\")\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "def calculate_mae_param(params, df_data):\n",
    "    \"\"\"Calculate MAE for parameter optimization\"\"\"\n",
    "    nc_base, nc_cct_coef, k_index_base, k_index_cct_coef, acd_offset_base, acd_offset_cct_coef = params\n",
    "    \n",
    "    predictions = []\n",
    "    for _, row in df_data.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        nc = nc_base + nc_cct_coef * cct_norm\n",
    "        k_index = k_index_base + k_index_cct_coef * cct_norm\n",
    "        acd_offset = acd_offset_base + acd_offset_cct_coef * cct_norm\n",
    "        \n",
    "        pred = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc,\n",
    "            k_index=k_index\n",
    "        )\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    mae = mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "    return mae\n",
    "\n",
    "bounds_param = [\n",
    "    (1.20, 1.50),    # nc_base\n",
    "    (-0.20, 0.20),   # nc_cct_coef  \n",
    "    (1.20, 1.60),    # k_index_base\n",
    "    (-0.30, 0.30),   # k_index_cct_coef\n",
    "    (-3.0, 3.0),     # acd_offset_base\n",
    "    (-3.0, 3.0),     # acd_offset_cct_coef\n",
    "]\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_param = []\n",
    "seed_test_maes_param = []\n",
    "seed_train_maes_param = []  # NEW: Track training MAEs\n",
    "seed_baseline_maes_param = []\n",
    "seed_improvements_param = []\n",
    "seed_overfit_ratios_param = []  # NEW: Track overfitting\n",
    "\n",
    "df['K_avg'] = (df['Bio-Ks'] + df['Bio-Kf']) / 2\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT with current seed\n",
    "    X_train_param, X_test_param = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_param['K_avg'] = (X_train_param['Bio-Ks'] + X_train_param['Bio-Kf']) / 2\n",
    "    X_test_param['K_avg'] = (X_test_param['Bio-Ks'] + X_test_param['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"📊 Split: {len(X_train_param)} train, {len(X_test_param)} test\")\n",
    "    \n",
    "    # INNER K-FOLD CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    fold_params = []\n",
    "    fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_param), 1):\n",
    "        fold_train = X_train_param.iloc[train_idx]\n",
    "        fold_val = X_train_param.iloc[val_idx]\n",
    "        \n",
    "        # Optimize on fold\n",
    "        result_fold = differential_evolution(\n",
    "            lambda p: calculate_mae_param(p, fold_train),\n",
    "            bounds_param,\n",
    "            maxiter=30,\n",
    "            seed=SEED + fold_num,\n",
    "            workers=1,\n",
    "            updating='deferred',\n",
    "            disp=False\n",
    "        )\n",
    "        \n",
    "        fold_params.append(result_fold.x)\n",
    "        val_mae = calculate_mae_param(result_fold.x, fold_val)\n",
    "        fold_maes.append(val_mae)\n",
    "    \n",
    "    # Average parameters from folds\n",
    "    avg_params = np.mean(fold_params, axis=0)\n",
    "    avg_cv_mae = np.mean(fold_maes)\n",
    "    std_cv_mae = np.std(fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_cv_mae:.4f} ± {std_cv_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    result_final = differential_evolution(\n",
    "        lambda p: calculate_mae_param(p, X_train_param),\n",
    "        bounds_param,\n",
    "        maxiter=50,\n",
    "        seed=SEED,\n",
    "        workers=1,\n",
    "        updating='deferred',\n",
    "        disp=False\n",
    "    )\n",
    "    \n",
    "    final_params = result_final.x\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    mae_train = calculate_mae_param(final_params, X_train_param)\n",
    "    \n",
    "    # TEST ON HOLDOUT\n",
    "    # Calculate baseline\n",
    "    X_test_param['SRKT2_Baseline'] = X_test_param.apply(\n",
    "        lambda row: calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant']\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    # Apply optimized parameters\n",
    "    predictions_test = []\n",
    "    for _, row in X_test_param.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        nc = final_params[0] + final_params[1] * cct_norm\n",
    "        k_index = final_params[2] + final_params[3] * cct_norm\n",
    "        acd_offset = final_params[4] + final_params[5] * cct_norm\n",
    "        \n",
    "        pred = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'],\n",
    "            K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc,\n",
    "            k_index=k_index\n",
    "        )\n",
    "        predictions_test.append(pred)\n",
    "    \n",
    "    mae_baseline = np.abs(X_test_param['SRKT2_Baseline'] - X_test_param['PostOP Spherical Equivalent']).mean()\n",
    "    mae_optimized = mean_absolute_error(X_test_param['PostOP Spherical Equivalent'], predictions_test)\n",
    "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
    "    \n",
    "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
    "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
    "    if overfit_ratio > 20:\n",
    "        print(f\"  ⚠️ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    elif overfit_ratio > 10:\n",
    "        print(f\"  ⚠️ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    else:\n",
    "        print(f\"  ✅ Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_param.append(final_params)\n",
    "    seed_test_maes_param.append(mae_optimized)\n",
    "    seed_train_maes_param.append(mae_train)\n",
    "    seed_baseline_maes_param.append(mae_baseline)\n",
    "    seed_improvements_param.append(improvement)\n",
    "    seed_overfit_ratios_param.append(overfit_ratio)\n",
    "\n",
    "# MULTI-SEED SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARAMETER OPTIMIZATION - MULTI-SEED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 TEST PERFORMANCE ACROSS SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_param[i]:.4f} D, Improvement={seed_improvements_param[i]:.1f}%\")\n",
    "\n",
    "print(\"\\n📈 STATISTICAL SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_param):.4f} ± {np.std(seed_baseline_maes_param):.4f} D\")\n",
    "print(f\"  Train MAE:         {np.mean(seed_train_maes_param):.4f} ± {np.std(seed_train_maes_param):.4f} D\")\n",
    "print(f\"  Test MAE:          {np.mean(seed_test_maes_param):.4f} ± {np.std(seed_test_maes_param):.4f} D\")\n",
    "print(f\"  Mean Improvement:  {np.mean(seed_improvements_param):.1f} ± {np.std(seed_improvements_param):.1f}%\")\n",
    "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_param)]} (MAE={min(seed_test_maes_param):.4f})\")\n",
    "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_param)]} (MAE={max(seed_test_maes_param):.4f})\")\n",
    "\n",
    "# OVERFITTING ANALYSIS\n",
    "print(\"\\n🔍 OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_param):.1f}%\")\n",
    "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_param):.1f}% worse than Train MAE on average)\")\n",
    "\n",
    "if np.mean(seed_overfit_ratios_param) < 10:\n",
    "    print(\"  ✅ Excellent generalization - minimal overfitting\")\n",
    "elif np.mean(seed_overfit_ratios_param) < 20:\n",
    "    print(\"  ✅ Good generalization - acceptable overfitting\")\n",
    "else:\n",
    "    print(\"  ⚠️ Significant overfitting - consider regularization\")\n",
    "\n",
    "# Average parameters across seeds\n",
    "avg_params_all_seeds = np.mean(seed_results_param, axis=0)\n",
    "std_params_all_seeds = np.std(seed_results_param, axis=0)\n",
    "\n",
    "print(\"\\n✅ CONSENSUS PARAMETERS (averaged across seeds):\")\n",
    "print(\"-\" * 50)\n",
    "param_names = ['nc_base', 'nc_cct_coef', 'k_index_base', 'k_index_cct_coef', 'acd_offset_base', 'acd_offset_cct_coef']\n",
    "for i, name in enumerate(param_names):\n",
    "    print(f\"  {name:20} = {avg_params_all_seeds[i]:+.4f} ± {std_params_all_seeds[i]:.4f}\")\n",
    "\n",
    "# Store in global results dictionary\n",
    "multi_seed_results['parameter'] = {\n",
    "    'test_maes': seed_test_maes_param,\n",
    "    'train_maes': seed_train_maes_param,\n",
    "    'baseline_maes': seed_baseline_maes_param,\n",
    "    'improvements': seed_improvements_param,\n",
    "    'overfit_ratios': seed_overfit_ratios_param,\n",
    "    'mean_mae': np.mean(seed_test_maes_param),\n",
    "    'std_mae': np.std(seed_test_maes_param),\n",
    "    'mean_improvement': np.mean(seed_improvements_param)\n",
    "}\n",
    "\n",
    "print(\"\\n💡 ROBUSTNESS ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "mae_cv = np.std(seed_test_maes_param) / np.mean(seed_test_maes_param) * 100\n",
    "if mae_cv < 5:\n",
    "    print(f\"✅ Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
    "elif mae_cv < 10:\n",
    "    print(f\"✅ Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
    "else:\n",
    "    print(f\"⚠️ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
    "\n",
    "print(f\"\\n📊 Range of results: {min(seed_test_maes_param):.4f} - {max(seed_test_maes_param):.4f} D\")\n",
    "print(f\"   This {max(seed_test_maes_param)-min(seed_test_maes_param):.4f} D range shows the impact of data split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "829090ggs0r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "🎯 MULTI-SEED NESTED CV STRATEGY:\n",
      "--------------------------------------------------\n",
      "• Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "• Each seed: 75/25 train/test split\n",
      "• Inner: 5-fold CV on training\n",
      "• Find stable multiplicative factors across seeds\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 0.9016 ± 0.1279 D\n",
      "  Final params: m₀=-0.0379, m₁=-0.0153, m₂=-0.0378\n",
      "  Train MAE: 0.9068, Test MAE: 1.0063\n",
      "  Test: Baseline=1.4849, Optimized=1.0063\n",
      "  Improvement: 32.2%\n",
      "  ⚠️ Mild overfitting: Test 11.0% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 0.9395 ± 0.0938 D\n",
      "  Final params: m₀=-0.0383, m₁=-0.0168, m₂=-0.0383\n",
      "  Train MAE: 0.8772, Test MAE: 1.0940\n",
      "  Test: Baseline=1.2755, Optimized=1.0940\n",
      "  Improvement: 14.2%\n",
      "  ⚠️ Overfitting detected: Test 24.7% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 0.9122 ± 0.2803 D\n",
      "  Final params: m₀=-0.0386, m₁=-0.0133, m₂=-0.0385\n",
      "  Train MAE: 0.8928, Test MAE: 1.0463\n",
      "  Test: Baseline=1.6714, Optimized=1.0463\n",
      "  Improvement: 37.4%\n",
      "  ⚠️ Mild overfitting: Test 17.2% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 0.9511 ± 0.3201 D\n",
      "  Final params: m₀=-0.1211, m₁=0.1059, m₂=-0.0342\n",
      "  Train MAE: 0.8972, Test MAE: 1.0182\n",
      "  Test: Baseline=1.6185, Optimized=1.0182\n",
      "  Improvement: 37.1%\n",
      "  ⚠️ Mild overfitting: Test 13.5% worse than train\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "  CV MAE: 0.9544 ± 0.1953 D\n",
      "  Final params: m₀=-0.0387, m₁=-0.0074, m₂=-0.0386\n",
      "  Train MAE: 0.9448, Test MAE: 0.8892\n",
      "  Test: Baseline=1.3566, Optimized=0.8892\n",
      "  Improvement: 34.5%\n",
      "  ✅ Good generalization: Test only -5.9% worse than train\n",
      "\n",
      "================================================================================\n",
      "MULTIPLICATIVE CORRECTION - MULTI-SEED SUMMARY\n",
      "================================================================================\n",
      "\n",
      "📊 TEST PERFORMANCE ACROSS SEEDS:\n",
      "--------------------------------------------------\n",
      "  Seed  42: MAE=1.0063 D, Improvement=32.2%\n",
      "  Seed 123: MAE=1.0940 D, Improvement=14.2%\n",
      "  Seed 456: MAE=1.0463 D, Improvement=37.4%\n",
      "  Seed 789: MAE=1.0182 D, Improvement=37.1%\n",
      "  Seed 2025: MAE=0.8892 D, Improvement=34.5%\n",
      "\n",
      "📈 STATISTICAL SUMMARY:\n",
      "--------------------------------------------------\n",
      "  Baseline MAE:      1.4814 ± 0.1503 D\n",
      "  Train MAE:         0.9037 ± 0.0226 D\n",
      "  Test MAE:          1.0108 ± 0.0679 D\n",
      "  Mean Improvement:  31.1 ± 8.6%\n",
      "  Best seed:         2025 (MAE=0.8892)\n",
      "  Worst seed:        123 (MAE=1.0940)\n",
      "\n",
      "🔍 OVERFITTING ANALYSIS:\n",
      "--------------------------------------------------\n",
      "  Mean overfit ratio: 12.1%\n",
      "  (Test MAE is 12.1% worse than Train MAE on average)\n",
      "  ✅ Good generalization - acceptable overfitting\n",
      "\n",
      "✅ CONSENSUS PARAMETERS (averaged across seeds):\n",
      "--------------------------------------------------\n",
      "  m₀ (constant):     -0.0549 ± 0.0331\n",
      "  m₁ (CCT coef):     +0.0106 ± 0.0478\n",
      "  m₂ (ratio coef):   -0.0375 ± 0.0017\n",
      "\n",
      "📐 CONSENSUS CORRECTION FORMULA:\n",
      "--------------------------------------------------\n",
      "Corrected_REF = Standard_SRK/T2 × Correction_Factor\n",
      "Correction_Factor = 1 -0.0549 +0.0106×CCT_norm -0.0375×(CCT/AL)\n",
      "\n",
      "💡 ROBUSTNESS ANALYSIS:\n",
      "--------------------------------------------------\n",
      "✅ Good stability: CV=6.7% (consistent across seeds)\n",
      "\n",
      "📊 Range of results: 0.8892 - 1.0940 D\n",
      "   This 0.2048 D range shows the impact of data split\n",
      "\n",
      "📊 Parameter consistency across seeds:\n",
      "  m₀: min=-0.1211, max=-0.0379, range=0.0832\n",
      "  m₁: min=-0.0168, max=0.1059, range=0.1227\n",
      "  m₂: min=-0.0386, max=-0.0342, range=0.0045\n"
     ]
    }
   ],
   "source": [
    "# MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED\n",
    "# ====================================\n",
    "# PURPOSE: Multiplicative correction with nested CV for robust validation\n",
    "# NOW WITH MULTIPLE SEEDS for statistical robustness\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MULTIPLICATIVE CORRECTION WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🎯 MULTI-SEED NESTED CV STRATEGY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"• Each seed: 75/25 train/test split\")\n",
    "print(\"• Inner: 5-fold CV on training\")\n",
    "print(\"• Find stable multiplicative factors across seeds\")\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "def multiplicative_objective(params, df_data):\n",
    "    \"\"\"Objective function for multiplicative correction\"\"\"\n",
    "    m0, m1, m2 = params\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for _, row in df_data.iterrows():\n",
    "        base_pred = row['SRKT2_Prediction']\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        \n",
    "        correction_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "        corrected_pred = base_pred * correction_factor\n",
    "        \n",
    "        predictions.append(corrected_pred)\n",
    "        actuals.append(row['PostOP Spherical Equivalent'])\n",
    "    \n",
    "    return mean_absolute_error(actuals, predictions)\n",
    "\n",
    "x0_mult = [0, 0, 0]\n",
    "bounds_mult = [(-0.5, 0.5), (-0.5, 0.5), (-0.5, 0.5)]\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_mult = []\n",
    "seed_test_maes_mult = []\n",
    "seed_train_maes_mult = []  # NEW: Track training MAEs\n",
    "seed_baseline_maes_mult = []\n",
    "seed_improvements_mult = []\n",
    "seed_overfit_ratios_mult = []  # NEW: Track overfitting\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT with current seed\n",
    "    X_train_mult, X_test_mult = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_mult['K_avg'] = (X_train_mult['Bio-Ks'] + X_train_mult['Bio-Kf']) / 2\n",
    "    X_test_mult['K_avg'] = (X_test_mult['Bio-Ks'] + X_test_mult['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"📊 Split: {len(X_train_mult)} train, {len(X_test_mult)} test\")\n",
    "    \n",
    "    # Calculate baseline SRK/T2 for all data\n",
    "    for dataset in [X_train_mult, X_test_mult]:\n",
    "        dataset['SRKT2_Prediction'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    # INNER K-FOLD CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    fold_params = []\n",
    "    fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_mult), 1):\n",
    "        fold_train = X_train_mult.iloc[train_idx]\n",
    "        fold_val = X_train_mult.iloc[val_idx]\n",
    "        \n",
    "        # Optimize on fold training\n",
    "        result_fold = minimize(\n",
    "            lambda p: multiplicative_objective(p, fold_train),\n",
    "            x0_mult,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds_mult\n",
    "        )\n",
    "        \n",
    "        fold_params.append(result_fold.x)\n",
    "        val_mae = multiplicative_objective(result_fold.x, fold_val)\n",
    "        fold_maes.append(val_mae)\n",
    "    \n",
    "    # Average across folds\n",
    "    avg_params = np.mean(fold_params, axis=0)\n",
    "    avg_cv_mae = np.mean(fold_maes)\n",
    "    std_cv_mae = np.std(fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_cv_mae:.4f} ± {std_cv_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    result_mult = minimize(\n",
    "        lambda p: multiplicative_objective(p, X_train_mult),\n",
    "        x0_mult,\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds_mult\n",
    "    )\n",
    "    m0_opt, m1_opt, m2_opt = result_mult.x\n",
    "    \n",
    "    print(f\"  Final params: m₀={m0_opt:.4f}, m₁={m1_opt:.4f}, m₂={m2_opt:.4f}\")\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    mae_train = multiplicative_objective([m0_opt, m1_opt, m2_opt], X_train_mult)\n",
    "    \n",
    "    # TEST ON HOLDOUT\n",
    "    predictions_mult_test = []\n",
    "    for _, row in X_test_mult.iterrows():\n",
    "        base_pred = row['SRKT2_Prediction']\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        \n",
    "        correction_factor = 1 + m0_opt + m1_opt * cct_norm + m2_opt * cct_ratio\n",
    "        corrected_pred = base_pred * correction_factor\n",
    "        predictions_mult_test.append(corrected_pred)\n",
    "    \n",
    "    mae_baseline = np.abs(X_test_mult['SRKT2_Prediction'] - X_test_mult['PostOP Spherical Equivalent']).mean()\n",
    "    mae_optimized = mean_absolute_error(X_test_mult['PostOP Spherical Equivalent'], predictions_mult_test)\n",
    "    improvement = (mae_baseline - mae_optimized) / mae_baseline * 100\n",
    "    \n",
    "    print(f\"  Train MAE: {mae_train:.4f}, Test MAE: {mae_optimized:.4f}\")\n",
    "    print(f\"  Test: Baseline={mae_baseline:.4f}, Optimized={mae_optimized:.4f}\")\n",
    "    print(f\"  Improvement: {improvement:.1f}%\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfit_ratio = (mae_optimized - mae_train) / mae_train * 100\n",
    "    if overfit_ratio > 20:\n",
    "        print(f\"  ⚠️ Overfitting detected: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    elif overfit_ratio > 10:\n",
    "        print(f\"  ⚠️ Mild overfitting: Test {overfit_ratio:.1f}% worse than train\")\n",
    "    else:\n",
    "        print(f\"  ✅ Good generalization: Test only {overfit_ratio:.1f}% worse than train\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_mult.append([m0_opt, m1_opt, m2_opt])\n",
    "    seed_test_maes_mult.append(mae_optimized)\n",
    "    seed_train_maes_mult.append(mae_train)\n",
    "    seed_baseline_maes_mult.append(mae_baseline)\n",
    "    seed_improvements_mult.append(improvement)\n",
    "    seed_overfit_ratios_mult.append(overfit_ratio)\n",
    "\n",
    "# MULTI-SEED SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTIPLICATIVE CORRECTION - MULTI-SEED SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 TEST PERFORMANCE ACROSS SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"  Seed {seed:3}: MAE={seed_test_maes_mult[i]:.4f} D, Improvement={seed_improvements_mult[i]:.1f}%\")\n",
    "\n",
    "print(\"\\n📈 STATISTICAL SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Baseline MAE:      {np.mean(seed_baseline_maes_mult):.4f} ± {np.std(seed_baseline_maes_mult):.4f} D\")\n",
    "print(f\"  Train MAE:         {np.mean(seed_train_maes_mult):.4f} ± {np.std(seed_train_maes_mult):.4f} D\")\n",
    "print(f\"  Test MAE:          {np.mean(seed_test_maes_mult):.4f} ± {np.std(seed_test_maes_mult):.4f} D\")\n",
    "print(f\"  Mean Improvement:  {np.mean(seed_improvements_mult):.1f} ± {np.std(seed_improvements_mult):.1f}%\")\n",
    "print(f\"  Best seed:         {SEEDS[np.argmin(seed_test_maes_mult)]} (MAE={min(seed_test_maes_mult):.4f})\")\n",
    "print(f\"  Worst seed:        {SEEDS[np.argmax(seed_test_maes_mult)]} (MAE={max(seed_test_maes_mult):.4f})\")\n",
    "\n",
    "# OVERFITTING ANALYSIS\n",
    "print(\"\\n🔍 OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Mean overfit ratio: {np.mean(seed_overfit_ratios_mult):.1f}%\")\n",
    "print(f\"  (Test MAE is {np.mean(seed_overfit_ratios_mult):.1f}% worse than Train MAE on average)\")\n",
    "\n",
    "if np.mean(seed_overfit_ratios_mult) < 10:\n",
    "    print(\"  ✅ Excellent generalization - minimal overfitting\")\n",
    "elif np.mean(seed_overfit_ratios_mult) < 20:\n",
    "    print(\"  ✅ Good generalization - acceptable overfitting\")\n",
    "else:\n",
    "    print(\"  ⚠️ Significant overfitting - consider regularization\")\n",
    "\n",
    "# Average parameters across seeds\n",
    "avg_params_all_seeds = np.mean(seed_results_mult, axis=0)\n",
    "std_params_all_seeds = np.std(seed_results_mult, axis=0)\n",
    "\n",
    "print(\"\\n✅ CONSENSUS PARAMETERS (averaged across seeds):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  m₀ (constant):     {avg_params_all_seeds[0]:+.4f} ± {std_params_all_seeds[0]:.4f}\")\n",
    "print(f\"  m₁ (CCT coef):     {avg_params_all_seeds[1]:+.4f} ± {std_params_all_seeds[1]:.4f}\")\n",
    "print(f\"  m₂ (ratio coef):   {avg_params_all_seeds[2]:+.4f} ± {std_params_all_seeds[2]:.4f}\")\n",
    "\n",
    "print(\"\\n📐 CONSENSUS CORRECTION FORMULA:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Corrected_REF = Standard_SRK/T2 × Correction_Factor\")\n",
    "print(f\"Correction_Factor = 1 {avg_params_all_seeds[0]:+.4f} {avg_params_all_seeds[1]:+.4f}×CCT_norm {avg_params_all_seeds[2]:+.4f}×(CCT/AL)\")\n",
    "\n",
    "# Store in global results dictionary\n",
    "multi_seed_results['multiplicative'] = {\n",
    "    'test_maes': seed_test_maes_mult,\n",
    "    'train_maes': seed_train_maes_mult,\n",
    "    'baseline_maes': seed_baseline_maes_mult,\n",
    "    'improvements': seed_improvements_mult,\n",
    "    'overfit_ratios': seed_overfit_ratios_mult,\n",
    "    'mean_mae': np.mean(seed_test_maes_mult),\n",
    "    'std_mae': np.std(seed_test_maes_mult),\n",
    "    'mean_improvement': np.mean(seed_improvements_mult)\n",
    "}\n",
    "\n",
    "print(\"\\n💡 ROBUSTNESS ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "mae_cv = np.std(seed_test_maes_mult) / np.mean(seed_test_maes_mult) * 100\n",
    "if mae_cv < 5:\n",
    "    print(f\"✅ Excellent stability: CV={mae_cv:.1f}% (very consistent across seeds)\")\n",
    "elif mae_cv < 10:\n",
    "    print(f\"✅ Good stability: CV={mae_cv:.1f}% (consistent across seeds)\")\n",
    "else:\n",
    "    print(f\"⚠️ Moderate stability: CV={mae_cv:.1f}% (some variation across seeds)\")\n",
    "\n",
    "print(f\"\\n📊 Range of results: {min(seed_test_maes_mult):.4f} - {max(seed_test_maes_mult):.4f} D\")\n",
    "print(f\"   This {max(seed_test_maes_mult)-min(seed_test_maes_mult):.4f} D range shows the impact of data split\")\n",
    "\n",
    "# Parameter consistency check\n",
    "print(f\"\\n📊 Parameter consistency across seeds:\")\n",
    "for i, param_name in enumerate(['m₀', 'm₁', 'm₂']):\n",
    "    param_values = [p[i] for p in seed_results_mult]\n",
    "    print(f\"  {param_name}: min={min(param_values):.4f}, max={max(param_values):.4f}, range={max(param_values)-min(param_values):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9g3yzsp3n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ADDITIVE CORRECTION WITH POLYNOMIAL CCT TERMS - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "🎯 TESTING POLYNOMIAL (QUADRATIC & CUBIC) CCT TERMS:\n",
      "--------------------------------------------------\n",
      "• Linear model: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg\n",
      "• Quadratic model: + a4*CCT_norm²\n",
      "• Cubic model: + a4*CCT_norm² + a5*CCT_norm³\n",
      "• Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "• Each seed: 75/25 train/test split\n",
      "• Inner: 5-fold cross-validation\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS WITH POLYNOMIAL TERMS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📐 Testing LINEAR model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.3439   Fold 2/5: MAE=2.0027   Fold 3/5: MAE=1.3757   Fold 4/5: MAE=0.7433   Fold 5/5: MAE=1.1251 \n",
      "  CV MAE: 1.3181 ± 0.4100 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (linear):\n",
      "    Train MAE: 1.2709 D\n",
      "    Test MAE:  1.5624 D\n",
      "    Baseline:  1.4849 D\n",
      "    Improvement: -5.2%\n",
      "    Overfit ratio: 1.229\n",
      "\n",
      "📐 Testing QUADRATIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.3403   Fold 2/5: MAE=1.9499   Fold 3/5: MAE=1.4080   Fold 4/5: MAE=0.7357   Fold 5/5: MAE=1.1458 \n",
      "  CV MAE: 1.3159 ± 0.3941 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (quadratic):\n",
      "    Train MAE: 1.2721 D\n",
      "    Test MAE:  1.5813 D\n",
      "    Baseline:  1.4849 D\n",
      "    Improvement: -6.5%\n",
      "    Overfit ratio: 1.243\n",
      "\n",
      "📐 Testing CUBIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.3354   Fold 2/5: MAE=2.0556   Fold 3/5: MAE=1.4329   Fold 4/5: MAE=0.7437   Fold 5/5: MAE=1.1485 \n",
      "  CV MAE: 1.3432 ± 0.4273 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (cubic):\n",
      "    Train MAE: 1.1850 D\n",
      "    Test MAE:  1.7127 D\n",
      "    Baseline:  1.4849 D\n",
      "    Improvement: -15.3%\n",
      "    Overfit ratio: 1.445\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📐 Testing LINEAR model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.2707   Fold 2/5: MAE=1.2466   Fold 3/5: MAE=1.2027   Fold 4/5: MAE=1.6809   Fold 5/5: MAE=1.3963 \n",
      "  CV MAE: 1.3594 ± 0.1731 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (linear):\n",
      "    Train MAE: 1.3450 D\n",
      "    Test MAE:  1.2941 D\n",
      "    Baseline:  1.2755 D\n",
      "    Improvement: -1.5%\n",
      "    Overfit ratio: 0.962\n",
      "\n",
      "📐 Testing QUADRATIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.4372   Fold 2/5: MAE=1.3204   Fold 3/5: MAE=1.1991   Fold 4/5: MAE=1.6875   Fold 5/5: MAE=1.4111 \n",
      "  CV MAE: 1.4111 ± 0.1614 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (quadratic):\n",
      "    Train MAE: 1.3164 D\n",
      "    Test MAE:  1.2259 D\n",
      "    Baseline:  1.2755 D\n",
      "    Improvement: 3.9%\n",
      "    Overfit ratio: 0.931\n",
      "\n",
      "📐 Testing CUBIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.3992   Fold 2/5: MAE=1.2625   Fold 3/5: MAE=1.2272   Fold 4/5: MAE=1.7399   Fold 5/5: MAE=1.4107 \n",
      "  CV MAE: 1.4079 ± 0.1812 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (cubic):\n",
      "    Train MAE: 1.3408 D\n",
      "    Test MAE:  1.3476 D\n",
      "    Baseline:  1.2755 D\n",
      "    Improvement: -5.6%\n",
      "    Overfit ratio: 1.005\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📐 Testing LINEAR model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.3034   Fold 2/5: MAE=1.5109   Fold 3/5: MAE=1.0920   Fold 4/5: MAE=1.1213   Fold 5/5: MAE=1.1242 \n",
      "  CV MAE: 1.2303 ± 0.1590 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (linear):\n",
      "    Train MAE: 1.2135 D\n",
      "    Test MAE:  1.7353 D\n",
      "    Baseline:  1.6714 D\n",
      "    Improvement: -3.8%\n",
      "    Overfit ratio: 1.430\n",
      "\n",
      "📐 Testing QUADRATIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.4804   Fold 2/5: MAE=1.4519   Fold 3/5: MAE=1.0949   Fold 4/5: MAE=1.2297   Fold 5/5: MAE=1.1429 \n",
      "  CV MAE: 1.2800 ± 0.1583 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (quadratic):\n",
      "    Train MAE: 1.2135 D\n",
      "    Test MAE:  1.7377 D\n",
      "    Baseline:  1.6714 D\n",
      "    Improvement: -4.0%\n",
      "    Overfit ratio: 1.432\n",
      "\n",
      "📐 Testing CUBIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.5981   Fold 2/5: MAE=1.4801   Fold 3/5: MAE=1.2066   Fold 4/5: MAE=1.2267   Fold 5/5: MAE=1.1045 \n",
      "  CV MAE: 1.3232 ± 0.1849 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (cubic):\n",
      "    Train MAE: 1.1883 D\n",
      "    Test MAE:  1.6068 D\n",
      "    Baseline:  1.6714 D\n",
      "    Improvement: 3.9%\n",
      "    Overfit ratio: 1.352\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📐 Testing LINEAR model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.0501   Fold 2/5: MAE=1.2140   Fold 3/5: MAE=1.8880   Fold 4/5: MAE=1.2747   Fold 5/5: MAE=1.1243 \n",
      "  CV MAE: 1.3102 ± 0.2989 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (linear):\n",
      "    Train MAE: 1.2580 D\n",
      "    Test MAE:  1.5592 D\n",
      "    Baseline:  1.6185 D\n",
      "    Improvement: 3.7%\n",
      "    Overfit ratio: 1.239\n",
      "\n",
      "📐 Testing QUADRATIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.0501   Fold 2/5: MAE=1.1883   Fold 3/5: MAE=1.8362   Fold 4/5: MAE=1.2853   Fold 5/5: MAE=1.1106 \n",
      "  CV MAE: 1.2941 ± 0.2823 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (quadratic):\n",
      "    Train MAE: 1.2274 D\n",
      "    Test MAE:  1.5848 D\n",
      "    Baseline:  1.6185 D\n",
      "    Improvement: 2.1%\n",
      "    Overfit ratio: 1.291\n",
      "\n",
      "📐 Testing CUBIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.1099   Fold 2/5: MAE=1.1356   Fold 3/5: MAE=1.8691   Fold 4/5: MAE=1.7573   Fold 5/5: MAE=1.1221 \n",
      "  CV MAE: 1.3988 ± 0.3403 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (cubic):\n",
      "    Train MAE: 1.2315 D\n",
      "    Test MAE:  1.6149 D\n",
      "    Baseline:  1.6185 D\n",
      "    Improvement: 0.2%\n",
      "    Overfit ratio: 1.311\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📐 Testing LINEAR model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.6136   Fold 2/5: MAE=1.2549   Fold 3/5: MAE=1.2852   Fold 4/5: MAE=1.3250   Fold 5/5: MAE=1.1795 \n",
      "  CV MAE: 1.3316 ± 0.1488 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (linear):\n",
      "    Train MAE: 1.3112 D\n",
      "    Test MAE:  1.3891 D\n",
      "    Baseline:  1.3566 D\n",
      "    Improvement: -2.4%\n",
      "    Overfit ratio: 1.059\n",
      "\n",
      "📐 Testing QUADRATIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.5744   Fold 2/5: MAE=1.2680   Fold 3/5: MAE=1.2845   Fold 4/5: MAE=1.3079   Fold 5/5: MAE=1.1874 \n",
      "  CV MAE: 1.3244 ± 0.1314 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (quadratic):\n",
      "    Train MAE: 1.3114 D\n",
      "    Test MAE:  1.3892 D\n",
      "    Baseline:  1.3566 D\n",
      "    Improvement: -2.4%\n",
      "    Overfit ratio: 1.059\n",
      "\n",
      "📐 Testing CUBIC model:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=1.6208   Fold 2/5: MAE=1.6870   Fold 3/5: MAE=1.2646   Fold 4/5: MAE=1.4382   Fold 5/5: MAE=1.1816 \n",
      "  CV MAE: 1.4385 ± 0.1956 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "  📈 RESULTS (cubic):\n",
      "    Train MAE: 1.3114 D\n",
      "    Test MAE:  1.3878 D\n",
      "    Baseline:  1.3566 D\n",
      "    Improvement: -2.3%\n",
      "    Overfit ratio: 1.058\n",
      "\n",
      "================================================================================\n",
      "POLYNOMIAL COMPARISON SUMMARY\n",
      "================================================================================\n",
      "\n",
      "📊 PERFORMANCE ACROSS 5 SEEDS:\n",
      "--------------------------------------------------\n",
      "\n",
      "LINEAR MODEL:\n",
      "  Test MAE:     1.5080 ± 0.1531 D\n",
      "  Train MAE:    1.2797 ± 0.0451 D\n",
      "  Improvement:  -1.8% ± 3.0%\n",
      "  Overfit gap:  0.2283 D\n",
      "\n",
      "QUADRATIC MODEL:\n",
      "  Test MAE:     1.5038 ± 0.1776 D\n",
      "  Train MAE:    1.2682 ± 0.0421 D\n",
      "  Improvement:  -1.4% ± 3.8%\n",
      "  Overfit gap:  0.2356 D\n",
      "\n",
      "CUBIC MODEL:\n",
      "  Test MAE:     1.5340 ± 0.1413 D\n",
      "  Train MAE:    1.2514 ± 0.0639 D\n",
      "  Improvement:  -3.8% ± 6.5%\n",
      "  Overfit gap:  0.2825 D\n",
      "\n",
      "🔬 PARAMETER ANALYSIS:\n",
      "--------------------------------------------------\n",
      "\n",
      "Quadratic coefficient (a4): -0.0054 ± 0.1518\n",
      "  Significance: MARGINAL\n",
      "\n",
      "Cubic coefficient (a5): 0.0754 ± 0.2152\n",
      "  Significance: YES\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATION\n",
      "================================================================================\n",
      "✅ BEST MODEL: QUADRATIC\n",
      "   Test MAE: 1.5038 D\n",
      "   Improvement over linear: 0.3%\n",
      "\n",
      "   The polynomial terms capture non-linear relationships between\n",
      "   corneal thickness and refractive error in Fuchs' dystrophy patients.\n",
      "\n",
      "💾 Stored quadratic model results for combined approach.\n"
     ]
    }
   ],
   "source": [
    "# ADDITIVE CORRECTION WITH POLYNOMIAL TERMS - MULTI-SEED\n",
    "# ========================================================\n",
    "# PURPOSE: Create an additive correction with polynomial CCT terms\n",
    "# NOW WITH QUADRATIC AND CUBIC CCT TERMS for better non-linear modeling\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ADDITIVE CORRECTION WITH POLYNOMIAL CCT TERMS - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🎯 TESTING POLYNOMIAL (QUADRATIC & CUBIC) CCT TERMS:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• Linear model: a0 + a1*CCT_norm + a2*CCT_ratio + a3*K_avg\")\n",
    "print(\"• Quadratic model: + a4*CCT_norm²\")  \n",
    "print(\"• Cubic model: + a4*CCT_norm² + a5*CCT_norm³\")\n",
    "print(f\"• Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"• Each seed: 75/25 train/test split\")\n",
    "print(\"• Inner: 5-fold cross-validation\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# Store results for different polynomial degrees\n",
    "results_by_degree = {\n",
    "    'linear': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []},\n",
    "    'quadratic': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []},\n",
    "    'cubic': {'test_maes': [], 'train_maes': [], 'improvements': [], 'params': []}\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS WITH POLYNOMIAL TERMS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_add, X_test_add = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_add['K_avg'] = (X_train_add['Bio-Ks'] + X_train_add['Bio-Kf']) / 2\n",
    "    X_test_add['K_avg'] = (X_test_add['Bio-Ks'] + X_test_add['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"📊 Split: {len(X_train_add)} train, {len(X_test_add)} test\")\n",
    "    \n",
    "    # Calculate baseline\n",
    "    for dataset in [X_train_add, X_test_add]:\n",
    "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    baseline_mae = mean_absolute_error(X_test_add['PostOP Spherical Equivalent'], \n",
    "                                       X_test_add['SRKT2_Baseline'])\n",
    "    \n",
    "    # Test each polynomial degree\n",
    "    for degree_name in ['linear', 'quadratic', 'cubic']:\n",
    "        print(f\"\\n📐 Testing {degree_name.upper()} model:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Setup K-fold\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "        fold_results = []\n",
    "        fold_maes = []\n",
    "        \n",
    "        for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_add), 1):\n",
    "            print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
    "            \n",
    "            fold_train = X_train_add.iloc[train_idx]\n",
    "            fold_val = X_train_add.iloc[val_idx]\n",
    "            \n",
    "            # Define objective function based on degree\n",
    "            if degree_name == 'linear':\n",
    "                def additive_objective(params, df_data):\n",
    "                    a0, a1, a2, a3 = params\n",
    "                    predictions = []\n",
    "                    for _, row in df_data.iterrows():\n",
    "                        base_pred = row['SRKT2_Baseline']\n",
    "                        cct_norm = (row['CCT'] - 600) / 100\n",
    "                        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                        # Linear only\n",
    "                        correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
    "                        predictions.append(base_pred + correction)\n",
    "                    return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "                \n",
    "                bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1)]\n",
    "                initial = [0, 0, 0, 0]\n",
    "                \n",
    "            elif degree_name == 'quadratic':\n",
    "                def additive_objective(params, df_data):\n",
    "                    a0, a1, a2, a3, a4 = params\n",
    "                    predictions = []\n",
    "                    for _, row in df_data.iterrows():\n",
    "                        base_pred = row['SRKT2_Baseline']\n",
    "                        cct_norm = (row['CCT'] - 600) / 100\n",
    "                        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                        # Linear + quadratic\n",
    "                        correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                    a3 * row['K_avg'] + a4 * cct_norm**2)\n",
    "                        predictions.append(base_pred + correction)\n",
    "                    return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "                \n",
    "                bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1)]\n",
    "                initial = [0, 0, 0, 0, 0]\n",
    "                \n",
    "            else:  # cubic\n",
    "                def additive_objective(params, df_data):\n",
    "                    a0, a1, a2, a3, a4, a5 = params\n",
    "                    predictions = []\n",
    "                    for _, row in df_data.iterrows():\n",
    "                        base_pred = row['SRKT2_Baseline']\n",
    "                        cct_norm = (row['CCT'] - 600) / 100\n",
    "                        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                        # Linear + quadratic + cubic\n",
    "                        correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                    a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
    "                                    a5 * cct_norm**3)\n",
    "                        predictions.append(base_pred + correction)\n",
    "                    return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "                \n",
    "                bounds = [(-2, 2), (-2, 2), (-2, 2), (-0.1, 0.1), (-1, 1), (-0.5, 0.5)]\n",
    "                initial = [0, 0, 0, 0, 0, 0]\n",
    "            \n",
    "            # Optimize\n",
    "            result = minimize(lambda p: additive_objective(p, fold_train), \n",
    "                            initial, method='L-BFGS-B', bounds=bounds)\n",
    "            fold_results.append(result.x)\n",
    "            \n",
    "            # Validate\n",
    "            fold_val_mae = additive_objective(result.x, fold_val)\n",
    "            fold_maes.append(fold_val_mae)\n",
    "            print(f\"MAE={fold_val_mae:.4f} \", end=\"\")\n",
    "        \n",
    "        print()\n",
    "        avg_cv_mae = np.mean(fold_maes)\n",
    "        std_cv_mae = np.std(fold_maes)\n",
    "        print(f\"  CV MAE: {avg_cv_mae:.4f} ± {std_cv_mae:.4f} D\")\n",
    "        \n",
    "        # Final optimization on full training set\n",
    "        print(f\"  Final optimization on full training set...\")\n",
    "        final_result = minimize(lambda p: additive_objective(p, X_train_add), \n",
    "                              initial, method='L-BFGS-B', bounds=bounds)\n",
    "        \n",
    "        # Evaluate on training set\n",
    "        train_mae = additive_objective(final_result.x, X_train_add)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_mae = additive_objective(final_result.x, X_test_add)\n",
    "        \n",
    "        improvement = ((baseline_mae - test_mae) / baseline_mae) * 100\n",
    "        overfit_ratio = test_mae / train_mae if train_mae > 0 else float('inf')\n",
    "        \n",
    "        print(f\"\\n  📈 RESULTS ({degree_name}):\")\n",
    "        print(f\"    Train MAE: {train_mae:.4f} D\")\n",
    "        print(f\"    Test MAE:  {test_mae:.4f} D\")\n",
    "        print(f\"    Baseline:  {baseline_mae:.4f} D\")\n",
    "        print(f\"    Improvement: {improvement:.1f}%\")\n",
    "        print(f\"    Overfit ratio: {overfit_ratio:.3f}\")\n",
    "        \n",
    "        # Store results\n",
    "        results_by_degree[degree_name]['test_maes'].append(test_mae)\n",
    "        results_by_degree[degree_name]['train_maes'].append(train_mae)\n",
    "        results_by_degree[degree_name]['improvements'].append(improvement)\n",
    "        results_by_degree[degree_name]['params'].append(final_result.x)\n",
    "\n",
    "# COMPREHENSIVE COMPARISON\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"POLYNOMIAL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for degree_name in ['linear', 'quadratic', 'cubic']:\n",
    "    results = results_by_degree[degree_name]\n",
    "    print(f\"\\n{degree_name.upper()} MODEL:\")\n",
    "    print(f\"  Test MAE:     {np.mean(results['test_maes']):.4f} ± {np.std(results['test_maes']):.4f} D\")\n",
    "    print(f\"  Train MAE:    {np.mean(results['train_maes']):.4f} ± {np.std(results['train_maes']):.4f} D\")\n",
    "    print(f\"  Improvement:  {np.mean(results['improvements']):.1f}% ± {np.std(results['improvements']):.1f}%\")\n",
    "    print(f\"  Overfit gap:  {np.mean(results['test_maes']) - np.mean(results['train_maes']):.4f} D\")\n",
    "\n",
    "# Parameter analysis\n",
    "print(\"\\n🔬 PARAMETER ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Analyze quadratic coefficients\n",
    "quad_params = np.array(results_by_degree['quadratic']['params'])\n",
    "if quad_params.shape[1] >= 5:\n",
    "    quad_coeffs = quad_params[:, 4]  # a4 (quadratic term)\n",
    "    print(f\"\\nQuadratic coefficient (a4): {np.mean(quad_coeffs):.4f} ± {np.std(quad_coeffs):.4f}\")\n",
    "    print(f\"  Significance: {'YES' if abs(np.mean(quad_coeffs)) > 0.1 else 'MARGINAL'}\")\n",
    "\n",
    "# Analyze cubic coefficients\n",
    "cubic_params = np.array(results_by_degree['cubic']['params'])\n",
    "if cubic_params.shape[1] >= 6:\n",
    "    cubic_coeffs = cubic_params[:, 5]  # a5 (cubic term)\n",
    "    print(f\"\\nCubic coefficient (a5): {np.mean(cubic_coeffs):.4f} ± {np.std(cubic_coeffs):.4f}\")\n",
    "    print(f\"  Significance: {'YES' if abs(np.mean(cubic_coeffs)) > 0.05 else 'MARGINAL'}\")\n",
    "\n",
    "# Winner determination\n",
    "mean_test_maes = {degree: np.mean(results_by_degree[degree]['test_maes']) \n",
    "                  for degree in ['linear', 'quadratic', 'cubic']}\n",
    "best_degree = min(mean_test_maes, key=mean_test_maes.get)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✅ BEST MODEL: {best_degree.upper()}\")\n",
    "print(f\"   Test MAE: {mean_test_maes[best_degree]:.4f} D\")\n",
    "\n",
    "if best_degree != 'linear':\n",
    "    improvement_over_linear = ((mean_test_maes['linear'] - mean_test_maes[best_degree]) / \n",
    "                               mean_test_maes['linear']) * 100\n",
    "    print(f\"   Improvement over linear: {improvement_over_linear:.1f}%\")\n",
    "    print(f\"\\n   The polynomial terms capture non-linear relationships between\")\n",
    "    print(f\"   corneal thickness and refractive error in Fuchs' dystrophy patients.\")\n",
    "\n",
    "# Store best results for later use\n",
    "seed_test_maes_additive = results_by_degree[best_degree]['test_maes']\n",
    "seed_train_maes_additive = results_by_degree[best_degree]['train_maes']\n",
    "seed_improvements_additive = results_by_degree[best_degree]['improvements']\n",
    "seed_additive_params = results_by_degree[best_degree]['params']\n",
    "\n",
    "print(f\"\\n💾 Stored {best_degree} model results for combined approach.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2qmcannd1hs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMBINED PARAM + MULTIPLICATIVE FORMULA (NO ADDITIVE) - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "🎯 MULTI-SEED NESTED CV FOR PARAM+MULT APPROACH:\n",
      "--------------------------------------------------\n",
      "• Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "• Each seed: 75/25 train/test split\n",
      "• Inner: 5-fold CV for parameter and multiplicative methods\n",
      "• NO additive correction applied\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS (PARAM + MULT ONLY)\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📁 K-FOLD CV FOR PARAM AND MULT METHODS:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.7820   Fold 2/5: MAE=1.1065   Fold 3/5: MAE=0.9842   Fold 4/5: MAE=0.7534   Fold 5/5: MAE=0.9934 \n",
      "  CV MAE: 0.9239 ± 0.1349 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "📈 RESULTS (PARAM + MULT ONLY):\n",
      "----------------------------------------\n",
      "  Train MAE: 0.9069 D\n",
      "  Test MAE:  1.0723 D\n",
      "  Baseline:  1.4849 D\n",
      "  Improvement: 27.8%\n",
      "  Overfit ratio: 1.182\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📁 K-FOLD CV FOR PARAM AND MULT METHODS:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.7233   Fold 2/5: MAE=0.8389   Fold 3/5: MAE=0.9630   Fold 4/5: MAE=0.8886   Fold 5/5: MAE=0.9404 \n",
      "  CV MAE: 0.8708 ± 0.0854 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "📈 RESULTS (PARAM + MULT ONLY):\n",
      "----------------------------------------\n",
      "  Train MAE: 0.8884 D\n",
      "  Test MAE:  1.0343 D\n",
      "  Baseline:  1.2755 D\n",
      "  Improvement: 18.9%\n",
      "  Overfit ratio: 1.164\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📁 K-FOLD CV FOR PARAM AND MULT METHODS:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.8363   Fold 2/5: MAE=1.1652   Fold 3/5: MAE=0.7528   Fold 4/5: MAE=1.2720   Fold 5/5: MAE=0.5400 \n",
      "  CV MAE: 0.9132 ± 0.2695 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "📈 RESULTS (PARAM + MULT ONLY):\n",
      "----------------------------------------\n",
      "  Train MAE: 0.8941 D\n",
      "  Test MAE:  1.0576 D\n",
      "  Baseline:  1.6714 D\n",
      "  Improvement: 36.7%\n",
      "  Overfit ratio: 1.183\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📁 K-FOLD CV FOR PARAM AND MULT METHODS:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.7704   Fold 2/5: MAE=0.6914   Fold 3/5: MAE=1.3571   Fold 4/5: MAE=1.3793   Fold 5/5: MAE=0.9360 \n",
      "  CV MAE: 1.0268 ± 0.2898 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "📈 RESULTS (PARAM + MULT ONLY):\n",
      "----------------------------------------\n",
      "  Train MAE: 0.8683 D\n",
      "  Test MAE:  1.0418 D\n",
      "  Baseline:  1.6185 D\n",
      "  Improvement: 35.6%\n",
      "  Overfit ratio: 1.200\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📁 K-FOLD CV FOR PARAM AND MULT METHODS:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.7889   Fold 2/5: MAE=1.0366   Fold 3/5: MAE=1.0095   Fold 4/5: MAE=1.2510   Fold 5/5: MAE=0.7594 \n",
      "  CV MAE: 0.9691 ± 0.1801 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "📈 RESULTS (PARAM + MULT ONLY):\n",
      "----------------------------------------\n",
      "  Train MAE: 0.9101 D\n",
      "  Test MAE:  1.0737 D\n",
      "  Baseline:  1.3566 D\n",
      "  Improvement: 20.8%\n",
      "  Overfit ratio: 1.180\n",
      "\n",
      "================================================================================\n",
      "MULTI-SEED SUMMARY (PARAM + MULT ONLY)\n",
      "================================================================================\n",
      "\n",
      "📊 PERFORMANCE ACROSS 5 SEEDS:\n",
      "--------------------------------------------------\n",
      "Test MAE:     1.0560 ± 0.0158 D\n",
      "Train MAE:    0.8936 ± 0.0149 D\n",
      "Baseline MAE: 1.4814 ± 0.1503 D\n",
      "Improvement:  28.0% ± 7.3%\n",
      "Overfit ratio: 1.182 ± 0.011\n",
      "\n",
      "🔬 PARAMETER CONSISTENCY:\n",
      "--------------------------------------------------\n",
      "\n",
      "Parameter optimization values:\n",
      "  nc_base   :  1.4129 ± 0.0375\n",
      "  nc_cct    : -0.0479 ± 0.1045\n",
      "  k_base    :  1.3956 ± 0.0362\n",
      "  k_cct     : -0.0450 ± 0.0958\n",
      "  acd_base  :  2.7723 ± 0.1113\n",
      "  acd_cct   : -0.1545 ± 1.1884\n",
      "\n",
      "Multiplicative correction values:\n",
      "  m0        : -0.1710 ± 0.1728\n",
      "  m1_cct    :  0.1705 ± 0.1989\n",
      "  m2_ratio  : -0.0284 ± 0.0052\n",
      "\n",
      "================================================================================\n",
      "COMPARISON NOTE\n",
      "================================================================================\n",
      "This PARAM+MULT approach excludes the additive correction term.\n",
      "Compare these results with the full combined approach (next cell)\n",
      "to determine if the additive component provides significant benefit.\n"
     ]
    }
   ],
   "source": [
    "# COMBINED PARAMETER + MULTIPLICATIVE APPROACH (NO ADDITIVE) - MULTI-SEED\n",
    "# =========================================================================\n",
    "# PURPOSE: Combine parameter optimization with multiplicative correction only\n",
    "# This tests whether the additive component is necessary or if param+mult is sufficient\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMBINED PARAM + MULTIPLICATIVE FORMULA (NO ADDITIVE) - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🎯 MULTI-SEED NESTED CV FOR PARAM+MULT APPROACH:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"• Each seed: 75/25 train/test split\")\n",
    "print(\"• Inner: 5-fold CV for parameter and multiplicative methods\")\n",
    "print(\"• NO additive correction applied\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "import numpy as np\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_param_mult = []\n",
    "seed_test_maes_param_mult = []\n",
    "seed_train_maes_param_mult = []\n",
    "seed_baseline_maes_param_mult = []\n",
    "seed_improvements_param_mult = []\n",
    "seed_overfit_ratios_param_mult = []\n",
    "\n",
    "# Store individual method results\n",
    "seed_param_results_pm = []\n",
    "seed_mult_results_pm = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS (PARAM + MULT ONLY)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT - consistent across all methods\n",
    "    X_train_pm, X_test_pm = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_pm['K_avg'] = (X_train_pm['Bio-Ks'] + X_train_pm['Bio-Kf']) / 2\n",
    "    X_test_pm['K_avg'] = (X_test_pm['Bio-Ks'] + X_test_pm['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"📊 Split: {len(X_train_pm)} train, {len(X_test_pm)} test\")\n",
    "    \n",
    "    # Calculate baseline for all\n",
    "    for dataset in [X_train_pm, X_test_pm]:\n",
    "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    print(\"\\n📁 K-FOLD CV FOR PARAM AND MULT METHODS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Setup K-fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # Store fold results for each method\n",
    "    param_fold_results = []\n",
    "    mult_fold_results = []\n",
    "    combined_fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_pm), 1):\n",
    "        print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
    "        \n",
    "        fold_train = X_train_pm.iloc[train_idx]\n",
    "        fold_val = X_train_pm.iloc[val_idx]\n",
    "        \n",
    "        # 1. PARAMETER METHOD\n",
    "        def param_obj(params, df_data):\n",
    "            nc_base, nc_cct, k_base, k_cct, acd_base, acd_cct = params\n",
    "            predictions = []\n",
    "            for _, row in df_data.iterrows():\n",
    "                cct_norm = (row['CCT'] - 600) / 100\n",
    "                nc = nc_base + nc_cct * cct_norm\n",
    "                k_index = k_base + k_cct * cct_norm\n",
    "                acd_offset = acd_base + acd_cct * cct_norm\n",
    "                pred = calculate_SRKT2(\n",
    "                    AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "                    IOL_power=row['IOL Power'],\n",
    "                    A_constant=row['A-Constant'] + acd_offset,\n",
    "                    nc=nc, k_index=k_index\n",
    "                )\n",
    "                predictions.append(pred)\n",
    "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "        \n",
    "        bounds_p = [(1.20, 1.50), (-0.20, 0.20), (1.20, 1.60), (-0.30, 0.30), (-3.0, 3.0), (-3.0, 3.0)]\n",
    "        result_p = differential_evolution(lambda p: param_obj(p, fold_train), bounds_p, \n",
    "                                         maxiter=20, seed=SEED+fold_num, disp=False)\n",
    "        param_fold_results.append(result_p.x)\n",
    "        \n",
    "        # 2. MULTIPLICATIVE METHOD (applied after parameter optimization)\n",
    "        def mult_obj_after_param(params, df_data, param_values):\n",
    "            m0, m1, m2 = params\n",
    "            nc_b, nc_c, k_b, k_c, acd_b, acd_c = param_values\n",
    "            predictions = []\n",
    "            for _, row in df_data.iterrows():\n",
    "                cct_norm = (row['CCT'] - 600) / 100\n",
    "                cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                \n",
    "                # First apply parameter optimization\n",
    "                nc = nc_b + nc_c * cct_norm\n",
    "                k_index = k_b + k_c * cct_norm\n",
    "                acd_offset = acd_b + acd_c * cct_norm\n",
    "                modified_pred = calculate_SRKT2(\n",
    "                    AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "                    IOL_power=row['IOL Power'],\n",
    "                    A_constant=row['A-Constant'] + acd_offset,\n",
    "                    nc=nc, k_index=k_index\n",
    "                )\n",
    "                \n",
    "                # Then apply multiplicative correction\n",
    "                correction = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "                predictions.append(modified_pred * correction)\n",
    "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "        \n",
    "        result_m = minimize(lambda p: mult_obj_after_param(p, fold_train, result_p.x), [0,0,0], \n",
    "                           method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
    "        mult_fold_results.append(result_m.x)\n",
    "        \n",
    "        # VALIDATE COMBINED PARAM+MULT on fold validation set\n",
    "        nc_b, nc_c, k_b, k_c, acd_b, acd_c = result_p.x\n",
    "        m0, m1, m2 = result_m.x\n",
    "        \n",
    "        combined_preds = []\n",
    "        for _, row in fold_val.iterrows():\n",
    "            cct_norm = (row['CCT'] - 600) / 100\n",
    "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "            \n",
    "            # Modified SRK/T2 with optimized parameters\n",
    "            nc = nc_b + nc_c * cct_norm\n",
    "            k_index = k_b + k_c * cct_norm\n",
    "            acd_offset = acd_b + acd_c * cct_norm\n",
    "            modified = calculate_SRKT2(\n",
    "                AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant'] + acd_offset,\n",
    "                nc=nc, k_index=k_index\n",
    "            )\n",
    "            \n",
    "            # Apply multiplicative correction\n",
    "            mult_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "            final = modified * mult_factor\n",
    "            \n",
    "            combined_preds.append(final)\n",
    "        \n",
    "        fold_mae = mean_absolute_error(fold_val['PostOP Spherical Equivalent'], combined_preds)\n",
    "        combined_fold_maes.append(fold_mae)\n",
    "        print(f\"MAE={fold_mae:.4f} \", end=\"\")\n",
    "    \n",
    "    print()  # New line after folds\n",
    "    \n",
    "    # Average parameters across folds\n",
    "    avg_param = np.mean(param_fold_results, axis=0)\n",
    "    avg_mult = np.mean(mult_fold_results, axis=0)\n",
    "    avg_combined_mae = np.mean(combined_fold_maes)\n",
    "    std_combined_mae = np.std(combined_fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_combined_mae:.4f} ± {std_combined_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    print(\"  Final optimization on full training set...\")\n",
    "    \n",
    "    # Optimize parameters first\n",
    "    result_p_final = differential_evolution(lambda p: param_obj(p, X_train_pm), bounds_p, \n",
    "                                           maxiter=50, seed=SEED, disp=False)\n",
    "    nc_base_pm, nc_cct_pm, k_base_pm, k_cct_pm, acd_base_pm, acd_cct_pm = result_p_final.x\n",
    "    \n",
    "    # Then optimize multiplicative correction\n",
    "    result_m_final = minimize(lambda p: mult_obj_after_param(p, X_train_pm, result_p_final.x), [0,0,0], \n",
    "                             method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
    "    m0_pm, m1_pm, m2_pm = result_m_final.x\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    predictions_pm_train = []\n",
    "    for _, row in X_train_pm.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        \n",
    "        # Parameter optimization\n",
    "        nc = nc_base_pm + nc_cct_pm * cct_norm\n",
    "        k_index = k_base_pm + k_cct_pm * cct_norm\n",
    "        acd_offset = acd_base_pm + acd_cct_pm * cct_norm\n",
    "        modified = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc, k_index=k_index\n",
    "        )\n",
    "        \n",
    "        # Multiplicative correction\n",
    "        mult_factor = 1 + m0_pm + m1_pm * cct_norm + m2_pm * cct_ratio\n",
    "        final = modified * mult_factor\n",
    "        \n",
    "        predictions_pm_train.append(final)\n",
    "    \n",
    "    train_mae_pm = mean_absolute_error(X_train_pm['PostOP Spherical Equivalent'], predictions_pm_train)\n",
    "    \n",
    "    # EVALUATE ON TEST SET\n",
    "    predictions_pm_test = []\n",
    "    for _, row in X_test_pm.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        \n",
    "        # Parameter optimization\n",
    "        nc = nc_base_pm + nc_cct_pm * cct_norm\n",
    "        k_index = k_base_pm + k_cct_pm * cct_norm\n",
    "        acd_offset = acd_base_pm + acd_cct_pm * cct_norm\n",
    "        modified = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc, k_index=k_index\n",
    "        )\n",
    "        \n",
    "        # Multiplicative correction\n",
    "        mult_factor = 1 + m0_pm + m1_pm * cct_norm + m2_pm * cct_ratio\n",
    "        final = modified * mult_factor\n",
    "        \n",
    "        predictions_pm_test.append(final)\n",
    "    \n",
    "    test_mae_pm = mean_absolute_error(X_test_pm['PostOP Spherical Equivalent'], predictions_pm_test)\n",
    "    baseline_mae_pm = mean_absolute_error(X_test_pm['PostOP Spherical Equivalent'], \n",
    "                                          X_test_pm['SRKT2_Baseline'])\n",
    "    \n",
    "    improvement_pm = ((baseline_mae_pm - test_mae_pm) / baseline_mae_pm) * 100\n",
    "    overfit_ratio_pm = test_mae_pm / train_mae_pm if train_mae_pm > 0 else float('inf')\n",
    "    \n",
    "    print(\"\\n📈 RESULTS (PARAM + MULT ONLY):\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Train MAE: {train_mae_pm:.4f} D\")\n",
    "    print(f\"  Test MAE:  {test_mae_pm:.4f} D\")\n",
    "    print(f\"  Baseline:  {baseline_mae_pm:.4f} D\")\n",
    "    print(f\"  Improvement: {improvement_pm:.1f}%\")\n",
    "    print(f\"  Overfit ratio: {overfit_ratio_pm:.3f}\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_param_mult.append({\n",
    "        'seed': SEED,\n",
    "        'param_values': result_p_final.x,\n",
    "        'mult_values': result_m_final.x,\n",
    "        'train_mae': train_mae_pm,\n",
    "        'test_mae': test_mae_pm,\n",
    "        'baseline_mae': baseline_mae_pm,\n",
    "        'improvement': improvement_pm,\n",
    "        'overfit_ratio': overfit_ratio_pm\n",
    "    })\n",
    "    \n",
    "    seed_test_maes_param_mult.append(test_mae_pm)\n",
    "    seed_train_maes_param_mult.append(train_mae_pm)\n",
    "    seed_baseline_maes_param_mult.append(baseline_mae_pm)\n",
    "    seed_improvements_param_mult.append(improvement_pm)\n",
    "    seed_overfit_ratios_param_mult.append(overfit_ratio_pm)\n",
    "    \n",
    "    seed_param_results_pm.append(result_p_final.x)\n",
    "    seed_mult_results_pm.append(result_m_final.x)\n",
    "\n",
    "# SUMMARY STATISTICS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTI-SEED SUMMARY (PARAM + MULT ONLY)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Test MAE:     {np.mean(seed_test_maes_param_mult):.4f} ± {np.std(seed_test_maes_param_mult):.4f} D\")\n",
    "print(f\"Train MAE:    {np.mean(seed_train_maes_param_mult):.4f} ± {np.std(seed_train_maes_param_mult):.4f} D\")\n",
    "print(f\"Baseline MAE: {np.mean(seed_baseline_maes_param_mult):.4f} ± {np.std(seed_baseline_maes_param_mult):.4f} D\")\n",
    "print(f\"Improvement:  {np.mean(seed_improvements_param_mult):.1f}% ± {np.std(seed_improvements_param_mult):.1f}%\")\n",
    "print(f\"Overfit ratio: {np.mean(seed_overfit_ratios_param_mult):.3f} ± {np.std(seed_overfit_ratios_param_mult):.3f}\")\n",
    "\n",
    "# Parameter consistency analysis\n",
    "print(\"\\n🔬 PARAMETER CONSISTENCY:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "param_names = ['nc_base', 'nc_cct', 'k_base', 'k_cct', 'acd_base', 'acd_cct']\n",
    "param_array = np.array(seed_param_results_pm)\n",
    "print(\"\\nParameter optimization values:\")\n",
    "for i, name in enumerate(param_names):\n",
    "    values = param_array[:, i]\n",
    "    print(f\"  {name:10s}: {np.mean(values):7.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "mult_names = ['m0', 'm1_cct', 'm2_ratio']\n",
    "mult_array = np.array(seed_mult_results_pm)\n",
    "print(\"\\nMultiplicative correction values:\")\n",
    "for i, name in enumerate(mult_names):\n",
    "    values = mult_array[:, i]\n",
    "    print(f\"  {name:10s}: {np.mean(values):7.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "# Compare with full combined approach if available\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON NOTE\")\n",
    "print(\"=\"*80)\n",
    "print(\"This PARAM+MULT approach excludes the additive correction term.\")\n",
    "print(\"Compare these results with the full combined approach (next cell)\")\n",
    "print(\"to determine if the additive component provides significant benefit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "u4unlmjdt3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMBINED FORMULA WITH K-FOLD CV - MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "📐 Using QUADRATIC polynomial degree (determined optimal in additive cell)\n",
      "\n",
      "🎯 MULTI-SEED NESTED CV FOR COMBINED APPROACH:\n",
      "--------------------------------------------------\n",
      "• Testing 5 different random seeds: [42, 123, 456, 789, 2025]\n",
      "• Each seed: 75/25 train/test split\n",
      "• Inner: 5-fold CV for each method\n",
      "• Additive correction using: quadratic polynomial\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-SEED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "SEED 1/5: 42\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📁 K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.7684   Fold 2/5: MAE=0.9645   Fold 3/5: MAE=0.9380   Fold 4/5: MAE=0.8368   Fold 5/5: MAE=1.0072 \n",
      "  CV MAE: 0.9030 ± 0.0876 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "📈 RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.9024 D\n",
      "  Test MAE:  0.8315 D\n",
      "  Baseline:  1.4849 D\n",
      "  Improvement: 44.0%\n",
      "  Overfit ratio: 0.921\n",
      "\n",
      "========================================\n",
      "SEED 2/5: 123\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📁 K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.9032   Fold 2/5: MAE=1.1230   Fold 3/5: MAE=0.9258   Fold 4/5: MAE=0.9031   Fold 5/5: MAE=0.8809 \n",
      "  CV MAE: 0.9472 ± 0.0890 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "📈 RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.9081 D\n",
      "  Test MAE:  0.8863 D\n",
      "  Baseline:  1.2755 D\n",
      "  Improvement: 30.5%\n",
      "  Overfit ratio: 0.976\n",
      "\n",
      "========================================\n",
      "SEED 3/5: 456\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📁 K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.9324   Fold 2/5: MAE=1.1673   Fold 3/5: MAE=0.6729   Fold 4/5: MAE=1.2506   Fold 5/5: MAE=0.4596 \n",
      "  CV MAE: 0.8966 ± 0.2970 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "📈 RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.8772 D\n",
      "  Test MAE:  1.1337 D\n",
      "  Baseline:  1.6714 D\n",
      "  Improvement: 32.2%\n",
      "  Overfit ratio: 1.292\n",
      "\n",
      "========================================\n",
      "SEED 4/5: 789\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📁 K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.8156   Fold 2/5: MAE=0.6117   Fold 3/5: MAE=1.2834   Fold 4/5: MAE=1.4615   Fold 5/5: MAE=0.6185 \n",
      "  CV MAE: 0.9581 ± 0.3507 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "📈 RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.8753 D\n",
      "  Test MAE:  1.0080 D\n",
      "  Baseline:  1.6185 D\n",
      "  Improvement: 37.7%\n",
      "  Overfit ratio: 1.152\n",
      "\n",
      "========================================\n",
      "SEED 5/5: 2025\n",
      "========================================\n",
      "📊 Split: 72 train, 24 test\n",
      "\n",
      "📁 K-FOLD CV FOR EACH METHOD:\n",
      "----------------------------------------\n",
      "  Fold 1/5: MAE=0.7980   Fold 2/5: MAE=0.8754   Fold 3/5: MAE=0.9112   Fold 4/5: MAE=1.2099   Fold 5/5: MAE=0.8241 \n",
      "  CV MAE: 0.9237 ± 0.1484 D\n",
      "  Final optimization on full training set...\n",
      "\n",
      "📈 RESULTS:\n",
      "----------------------------------------\n",
      "  Train MAE: 0.9421 D\n",
      "  Test MAE:  0.8862 D\n",
      "  Baseline:  1.3566 D\n",
      "  Improvement: 34.7%\n",
      "  Overfit ratio: 0.941\n",
      "\n",
      "================================================================================\n",
      "MULTI-SEED SUMMARY - COMBINED APPROACH WITH QUADRATIC ADDITIVE\n",
      "================================================================================\n",
      "\n",
      "📊 PERFORMANCE ACROSS 5 SEEDS:\n",
      "--------------------------------------------------\n",
      "Test MAE:     0.9491 ± 0.1089 D\n",
      "Train MAE:    0.9010 ± 0.0244 D\n",
      "Baseline MAE: 1.4814 ± 0.1503 D\n",
      "Improvement:  35.8% ± 4.8%\n",
      "Overfit ratio: 1.056 ± 0.143\n",
      "\n",
      "🔬 PARAMETER CONSISTENCY:\n",
      "--------------------------------------------------\n",
      "\n",
      "Parameter optimization values:\n",
      "  nc_base   :  1.4129 ± 0.0375\n",
      "  nc_cct    : -0.0479 ± 0.1045\n",
      "  k_base    :  1.3956 ± 0.0362\n",
      "  k_cct     : -0.0450 ± 0.0958\n",
      "  acd_base  :  2.7723 ± 0.1113\n",
      "  acd_cct   : -0.1545 ± 1.1884\n",
      "\n",
      "Multiplicative correction values:\n",
      "  m0        : -0.0549 ± 0.0331\n",
      "  m1_cct    :  0.0106 ± 0.0478\n",
      "  m2_ratio  : -0.0375 ± 0.0017\n",
      "\n",
      "Additive correction values (quadratic):\n",
      "  a0        : -0.0162 ± 0.0390\n",
      "  a1_cct    : -0.2049 ± 0.3367\n",
      "  a2_ratio  :  0.1137 ± 0.0299\n",
      "  a3_K      : -0.0674 ± 0.0174\n",
      "  a4_cct2   : -0.0054 ± 0.1518\n",
      "\n",
      "================================================================================\n",
      "CLINICAL INTERPRETATION\n",
      "================================================================================\n",
      "✅ Combined approach with quadratic additive achieves:\n",
      "   • Mean absolute error: 0.949 ± 0.109 D\n",
      "   • 36% improvement over standard SRK/T2\n",
      "   • MODERATE: Further optimization may be beneficial\n"
     ]
    }
   ],
   "source": [
    "# COMBINED APPROACH WITH K-FOLD CROSS-VALIDATION - MULTI-SEED\n",
    "# ========================================================\n",
    "# PURPOSE: Combine all three methods with nested K-fold CV and multi-seed validation\n",
    "# NOW USES THE BEST POLYNOMIAL DEGREE FROM ADDITIVE ANALYSIS\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMBINED FORMULA WITH K-FOLD CV - MULTI-SEED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Determine which polynomial degree to use from additive cell results\n",
    "if 'best_degree' in locals():\n",
    "    print(f\"\\n📐 Using {best_degree.upper()} polynomial degree (determined optimal in additive cell)\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No polynomial analysis found, defaulting to LINEAR\")\n",
    "    best_degree = 'linear'\n",
    "\n",
    "print(\"\\n🎯 MULTI-SEED NESTED CV FOR COMBINED APPROACH:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Testing {len(SEEDS)} different random seeds: {SEEDS}\")\n",
    "print(\"• Each seed: 75/25 train/test split\")\n",
    "print(\"• Inner: 5-fold CV for each method\")\n",
    "print(f\"• Additive correction using: {best_degree} polynomial\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "import numpy as np\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results_combined = []\n",
    "seed_test_maes_combined = []\n",
    "seed_train_maes_combined = []\n",
    "seed_baseline_maes_combined = []\n",
    "seed_improvements_combined = []\n",
    "seed_overfit_ratios_combined = []\n",
    "\n",
    "# Store individual method results\n",
    "seed_param_results = []\n",
    "seed_mult_results = []\n",
    "seed_add_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING MULTI-SEED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"SEED {seed_idx}/{len(SEEDS)}: {SEED}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # OUTER SPLIT - consistent across all methods\n",
    "    X_train_comb, X_test_comb = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "    X_train_comb['K_avg'] = (X_train_comb['Bio-Ks'] + X_train_comb['Bio-Kf']) / 2\n",
    "    X_test_comb['K_avg'] = (X_test_comb['Bio-Ks'] + X_test_comb['Bio-Kf']) / 2\n",
    "    \n",
    "    print(f\"📊 Split: {len(X_train_comb)} train, {len(X_test_comb)} test\")\n",
    "    \n",
    "    # Calculate baseline for all\n",
    "    for dataset in [X_train_comb, X_test_comb]:\n",
    "        dataset['SRKT2_Baseline'] = dataset.apply(\n",
    "            lambda row: calculate_SRKT2(\n",
    "                AL=row['Bio-AL'],\n",
    "                K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant']\n",
    "            ), axis=1\n",
    "        )\n",
    "    \n",
    "    print(\"\\n📁 K-FOLD CV FOR EACH METHOD:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Setup K-fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # Store fold results for each method\n",
    "    param_fold_results = []\n",
    "    mult_fold_results = []\n",
    "    add_fold_results = []\n",
    "    combined_fold_maes = []\n",
    "    \n",
    "    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X_train_comb), 1):\n",
    "        print(f\"  Fold {fold_num}/5: \", end=\"\")\n",
    "        \n",
    "        fold_train = X_train_comb.iloc[train_idx]\n",
    "        fold_val = X_train_comb.iloc[val_idx]\n",
    "        \n",
    "        # 1. PARAMETER METHOD\n",
    "        def param_obj(params, df_data):\n",
    "            nc_base, nc_cct, k_base, k_cct, acd_base, acd_cct = params\n",
    "            predictions = []\n",
    "            for _, row in df_data.iterrows():\n",
    "                cct_norm = (row['CCT'] - 600) / 100\n",
    "                nc = nc_base + nc_cct * cct_norm\n",
    "                k_index = k_base + k_cct * cct_norm\n",
    "                acd_offset = acd_base + acd_cct * cct_norm\n",
    "                pred = calculate_SRKT2(\n",
    "                    AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "                    IOL_power=row['IOL Power'],\n",
    "                    A_constant=row['A-Constant'] + acd_offset,\n",
    "                    nc=nc, k_index=k_index\n",
    "                )\n",
    "                predictions.append(pred)\n",
    "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "        \n",
    "        bounds_p = [(1.20, 1.50), (-0.20, 0.20), (1.20, 1.60), (-0.30, 0.30), (-3.0, 3.0), (-3.0, 3.0)]\n",
    "        result_p = differential_evolution(lambda p: param_obj(p, fold_train), bounds_p, \n",
    "                                         maxiter=20, seed=SEED+fold_num, disp=False)\n",
    "        param_fold_results.append(result_p.x)\n",
    "        \n",
    "        # 2. MULTIPLICATIVE METHOD\n",
    "        def mult_obj(params, df_data):\n",
    "            m0, m1, m2 = params\n",
    "            predictions = []\n",
    "            for _, row in df_data.iterrows():\n",
    "                base_pred = row['SRKT2_Baseline']\n",
    "                cct_norm = (row['CCT'] - 600) / 100\n",
    "                cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                correction = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "                predictions.append(base_pred * correction)\n",
    "            return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "        \n",
    "        result_m = minimize(lambda p: mult_obj(p, fold_train), [0,0,0], \n",
    "                           method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
    "        mult_fold_results.append(result_m.x)\n",
    "        \n",
    "        # 3. ADDITIVE METHOD - WITH BEST POLYNOMIAL DEGREE\n",
    "        if best_degree == 'linear':\n",
    "            def add_obj(params, df_data):\n",
    "                a0, a1, a2, a3 = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    base_pred = row['SRKT2_Baseline']\n",
    "                    cct_norm = (row['CCT'] - 600) / 100\n",
    "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                    correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
    "                    predictions.append(base_pred + correction)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1)]\n",
    "            add_initial = [0,0,0,0]\n",
    "            \n",
    "        elif best_degree == 'quadratic':\n",
    "            def add_obj(params, df_data):\n",
    "                a0, a1, a2, a3, a4 = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    base_pred = row['SRKT2_Baseline']\n",
    "                    cct_norm = (row['CCT'] - 600) / 100\n",
    "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                    correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2)\n",
    "                    predictions.append(base_pred + correction)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1),(-1,1)]\n",
    "            add_initial = [0,0,0,0,0]\n",
    "            \n",
    "        else:  # cubic\n",
    "            def add_obj(params, df_data):\n",
    "                a0, a1, a2, a3, a4, a5 = params\n",
    "                predictions = []\n",
    "                for _, row in df_data.iterrows():\n",
    "                    base_pred = row['SRKT2_Baseline']\n",
    "                    cct_norm = (row['CCT'] - 600) / 100\n",
    "                    cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "                    correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
    "                                a5 * cct_norm**3)\n",
    "                    predictions.append(base_pred + correction)\n",
    "                return mean_absolute_error(df_data['PostOP Spherical Equivalent'], predictions)\n",
    "            \n",
    "            add_bounds = [(-2,2),(-2,2),(-2,2),(-0.1,0.1),(-1,1),(-0.5,0.5)]\n",
    "            add_initial = [0,0,0,0,0,0]\n",
    "        \n",
    "        result_a = minimize(lambda p: add_obj(p, fold_train), add_initial,\n",
    "                           method='L-BFGS-B', bounds=add_bounds)\n",
    "        add_fold_results.append(result_a.x)\n",
    "        \n",
    "        # VALIDATE COMBINED on fold validation set\n",
    "        nc_b, nc_c, k_b, k_c, acd_b, acd_c = result_p.x\n",
    "        m0, m1, m2 = result_m.x\n",
    "        \n",
    "        combined_preds = []\n",
    "        for _, row in fold_val.iterrows():\n",
    "            cct_norm = (row['CCT'] - 600) / 100\n",
    "            cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "            \n",
    "            # Modified SRK/T2\n",
    "            nc = nc_b + nc_c * cct_norm\n",
    "            k_index = k_b + k_c * cct_norm\n",
    "            acd_offset = acd_b + acd_c * cct_norm\n",
    "            modified = calculate_SRKT2(\n",
    "                AL=row['Bio-AL'], K_avg=row['K_avg'],\n",
    "                IOL_power=row['IOL Power'],\n",
    "                A_constant=row['A-Constant'] + acd_offset,\n",
    "                nc=nc, k_index=k_index\n",
    "            )\n",
    "            \n",
    "            # Apply multiplicative\n",
    "            mult_factor = 1 + m0 + m1 * cct_norm + m2 * cct_ratio\n",
    "            after_mult = modified * mult_factor\n",
    "            \n",
    "            # Apply additive with appropriate polynomial\n",
    "            if best_degree == 'linear':\n",
    "                a0, a1, a2, a3 = result_a.x\n",
    "                add_correction = a0 + a1 * cct_norm + a2 * cct_ratio + a3 * row['K_avg']\n",
    "            elif best_degree == 'quadratic':\n",
    "                a0, a1, a2, a3, a4 = result_a.x\n",
    "                add_correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2)\n",
    "            else:  # cubic\n",
    "                a0, a1, a2, a3, a4, a5 = result_a.x\n",
    "                add_correction = (a0 + a1 * cct_norm + a2 * cct_ratio + \n",
    "                                a3 * row['K_avg'] + a4 * cct_norm**2 + \n",
    "                                a5 * cct_norm**3)\n",
    "            \n",
    "            final = after_mult + add_correction\n",
    "            combined_preds.append(final)\n",
    "        \n",
    "        fold_mae = mean_absolute_error(fold_val['PostOP Spherical Equivalent'], combined_preds)\n",
    "        combined_fold_maes.append(fold_mae)\n",
    "        print(f\"MAE={fold_mae:.4f} \", end=\"\")\n",
    "    \n",
    "    print()  # New line after folds\n",
    "    \n",
    "    # Average parameters across folds\n",
    "    avg_param = np.mean(param_fold_results, axis=0)\n",
    "    avg_mult = np.mean(mult_fold_results, axis=0)\n",
    "    avg_add = np.mean(add_fold_results, axis=0)\n",
    "    avg_combined_mae = np.mean(combined_fold_maes)\n",
    "    std_combined_mae = np.std(combined_fold_maes)\n",
    "    \n",
    "    print(f\"  CV MAE: {avg_combined_mae:.4f} ± {std_combined_mae:.4f} D\")\n",
    "    \n",
    "    # FINAL RETRAINING on full training set\n",
    "    print(\"  Final optimization on full training set...\")\n",
    "    \n",
    "    result_p_final = differential_evolution(lambda p: param_obj(p, X_train_comb), bounds_p, \n",
    "                                           maxiter=50, seed=SEED, disp=False)\n",
    "    nc_base_c, nc_cct_c, k_base_c, k_cct_c, acd_base_c, acd_cct_c = result_p_final.x\n",
    "    \n",
    "    result_m_final = minimize(lambda p: mult_obj(p, X_train_comb), [0,0,0], \n",
    "                             method='L-BFGS-B', bounds=[(-0.5,0.5)]*3)\n",
    "    m0_c, m1_c, m2_c = result_m_final.x\n",
    "    \n",
    "    result_a_final = minimize(lambda p: add_obj(p, X_train_comb), add_initial,\n",
    "                             method='L-BFGS-B', bounds=add_bounds)\n",
    "    \n",
    "    # EVALUATE ON TRAINING SET (for overfitting check)\n",
    "    predictions_combined_train = []\n",
    "    for _, row in X_train_comb.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        k_avg = row['K_avg']\n",
    "        \n",
    "        # Modified SRK/T2 with optimized parameters\n",
    "        nc = nc_base_c + nc_cct_c * cct_norm\n",
    "        k_index = k_base_c + k_cct_c * cct_norm\n",
    "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
    "        modified = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'], K_avg=k_avg,\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc, k_index=k_index\n",
    "        )\n",
    "        \n",
    "        # Apply multiplicative correction\n",
    "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
    "        after_mult = modified * mult_factor\n",
    "        \n",
    "        # Apply additive correction with polynomial\n",
    "        if best_degree == 'linear':\n",
    "            a0_c, a1_c, a2_c, a3_c = result_a_final.x\n",
    "            add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
    "        elif best_degree == 'quadratic':\n",
    "            a0_c, a1_c, a2_c, a3_c, a4_c = result_a_final.x\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2)\n",
    "        else:  # cubic\n",
    "            a0_c, a1_c, a2_c, a3_c, a4_c, a5_c = result_a_final.x\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2 + a5_c * cct_norm**3)\n",
    "        \n",
    "        final = after_mult + add_correction\n",
    "        predictions_combined_train.append(final)\n",
    "    \n",
    "    train_mae_combined = mean_absolute_error(X_train_comb['PostOP Spherical Equivalent'], \n",
    "                                            predictions_combined_train)\n",
    "    \n",
    "    # EVALUATE ON TEST SET\n",
    "    predictions_combined_test = []\n",
    "    for _, row in X_test_comb.iterrows():\n",
    "        cct_norm = (row['CCT'] - 600) / 100\n",
    "        cct_ratio = row['CCT'] / row['Bio-AL']\n",
    "        k_avg = row['K_avg']\n",
    "        \n",
    "        # Modified SRK/T2 with optimized parameters\n",
    "        nc = nc_base_c + nc_cct_c * cct_norm\n",
    "        k_index = k_base_c + k_cct_c * cct_norm\n",
    "        acd_offset = acd_base_c + acd_cct_c * cct_norm\n",
    "        modified = calculate_SRKT2(\n",
    "            AL=row['Bio-AL'], K_avg=k_avg,\n",
    "            IOL_power=row['IOL Power'],\n",
    "            A_constant=row['A-Constant'] + acd_offset,\n",
    "            nc=nc, k_index=k_index\n",
    "        )\n",
    "        \n",
    "        # Apply multiplicative correction\n",
    "        mult_factor = 1 + m0_c + m1_c * cct_norm + m2_c * cct_ratio\n",
    "        after_mult = modified * mult_factor\n",
    "        \n",
    "        # Apply additive correction with polynomial\n",
    "        if best_degree == 'linear':\n",
    "            add_correction = a0_c + a1_c * cct_norm + a2_c * cct_ratio + a3_c * k_avg\n",
    "        elif best_degree == 'quadratic':\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2)\n",
    "        else:  # cubic\n",
    "            add_correction = (a0_c + a1_c * cct_norm + a2_c * cct_ratio + \n",
    "                            a3_c * k_avg + a4_c * cct_norm**2 + a5_c * cct_norm**3)\n",
    "        \n",
    "        final = after_mult + add_correction\n",
    "        predictions_combined_test.append(final)\n",
    "    \n",
    "    test_mae_combined = mean_absolute_error(X_test_comb['PostOP Spherical Equivalent'], \n",
    "                                           predictions_combined_test)\n",
    "    baseline_mae_combined = mean_absolute_error(X_test_comb['PostOP Spherical Equivalent'], \n",
    "                                                X_test_comb['SRKT2_Baseline'])\n",
    "    \n",
    "    improvement_combined = ((baseline_mae_combined - test_mae_combined) / baseline_mae_combined) * 100\n",
    "    overfit_ratio = test_mae_combined / train_mae_combined if train_mae_combined > 0 else float('inf')\n",
    "    \n",
    "    print(\"\\n📈 RESULTS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Train MAE: {train_mae_combined:.4f} D\")\n",
    "    print(f\"  Test MAE:  {test_mae_combined:.4f} D\")\n",
    "    print(f\"  Baseline:  {baseline_mae_combined:.4f} D\")\n",
    "    print(f\"  Improvement: {improvement_combined:.1f}%\")\n",
    "    print(f\"  Overfit ratio: {overfit_ratio:.3f}\")\n",
    "    \n",
    "    # Store results\n",
    "    seed_results_combined.append({\n",
    "        'seed': SEED,\n",
    "        'param_values': result_p_final.x,\n",
    "        'mult_values': result_m_final.x,\n",
    "        'add_values': result_a_final.x,\n",
    "        'train_mae': train_mae_combined,\n",
    "        'test_mae': test_mae_combined,\n",
    "        'baseline_mae': baseline_mae_combined,\n",
    "        'improvement': improvement_combined,\n",
    "        'overfit_ratio': overfit_ratio\n",
    "    })\n",
    "    \n",
    "    seed_test_maes_combined.append(test_mae_combined)\n",
    "    seed_train_maes_combined.append(train_mae_combined)\n",
    "    seed_baseline_maes_combined.append(baseline_mae_combined)\n",
    "    seed_improvements_combined.append(improvement_combined)\n",
    "    seed_overfit_ratios_combined.append(overfit_ratio)\n",
    "    \n",
    "    seed_param_results.append(result_p_final.x)\n",
    "    seed_mult_results.append(result_m_final.x)\n",
    "    seed_add_results.append(result_a_final.x)\n",
    "\n",
    "# SUMMARY STATISTICS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"MULTI-SEED SUMMARY - COMBINED APPROACH WITH {best_degree.upper()} ADDITIVE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 PERFORMANCE ACROSS {len(SEEDS)} SEEDS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Test MAE:     {np.mean(seed_test_maes_combined):.4f} ± {np.std(seed_test_maes_combined):.4f} D\")\n",
    "print(f\"Train MAE:    {np.mean(seed_train_maes_combined):.4f} ± {np.std(seed_train_maes_combined):.4f} D\")\n",
    "print(f\"Baseline MAE: {np.mean(seed_baseline_maes_combined):.4f} ± {np.std(seed_baseline_maes_combined):.4f} D\")\n",
    "print(f\"Improvement:  {np.mean(seed_improvements_combined):.1f}% ± {np.std(seed_improvements_combined):.1f}%\")\n",
    "print(f\"Overfit ratio: {np.mean(seed_overfit_ratios_combined):.3f} ± {np.std(seed_overfit_ratios_combined):.3f}\")\n",
    "\n",
    "# Parameter consistency analysis\n",
    "print(\"\\n🔬 PARAMETER CONSISTENCY:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "param_names = ['nc_base', 'nc_cct', 'k_base', 'k_cct', 'acd_base', 'acd_cct']\n",
    "param_array = np.array(seed_param_results)\n",
    "print(\"\\nParameter optimization values:\")\n",
    "for i, name in enumerate(param_names):\n",
    "    values = param_array[:, i]\n",
    "    print(f\"  {name:10s}: {np.mean(values):7.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "mult_names = ['m0', 'm1_cct', 'm2_ratio']\n",
    "mult_array = np.array(seed_mult_results)\n",
    "print(\"\\nMultiplicative correction values:\")\n",
    "for i, name in enumerate(mult_names):\n",
    "    values = mult_array[:, i]\n",
    "    print(f\"  {name:10s}: {np.mean(values):7.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "add_array = np.array(seed_add_results)\n",
    "print(f\"\\nAdditive correction values ({best_degree}):\")\n",
    "if best_degree == 'linear':\n",
    "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K']\n",
    "elif best_degree == 'quadratic':\n",
    "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K', 'a4_cct2']\n",
    "else:  # cubic\n",
    "    add_names = ['a0', 'a1_cct', 'a2_ratio', 'a3_K', 'a4_cct2', 'a5_cct3']\n",
    "\n",
    "for i, name in enumerate(add_names):\n",
    "    values = add_array[:, i]\n",
    "    print(f\"  {name:10s}: {np.mean(values):7.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "# Clinical significance\n",
    "mae_mean = np.mean(seed_test_maes_combined)\n",
    "mae_std = np.std(seed_test_maes_combined)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLINICAL INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✅ Combined approach with {best_degree} additive achieves:\")\n",
    "print(f\"   • Mean absolute error: {mae_mean:.3f} ± {mae_std:.3f} D\")\n",
    "print(f\"   • {np.mean(seed_improvements_combined):.0f}% improvement over standard SRK/T2\")\n",
    "\n",
    "if mae_mean < 0.5:\n",
    "    print(\"   • EXCELLENT: Within ±0.50 D target for most patients\")\n",
    "elif mae_mean < 0.75:\n",
    "    print(\"   • GOOD: Within ±0.75 D for most patients\")\n",
    "else:\n",
    "    print(\"   • MODERATE: Further optimization may be beneficial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3yxaies4nqp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MULTI-SEED ANALYSIS - COMPREHENSIVE COMPARISON OF ALL METHODS\n",
      "================================================================================\n",
      "\n",
      "📊 PERFORMANCE RANKING (Best to Worst):\n",
      "--------------------------------------------------------------------------------\n",
      "Method                        Test MAE    Train MAE  Improvement    Overfit\n",
      "--------------------------------------------------------------------------------\n",
      "Full Combined (quadratic) 0.9491 ± 0.1089       0.9010        35.8%      1.056\n",
      "Multiplicative            1.0108 ± 0.0679       0.9037        31.1%     12.099\n",
      "Param+Mult                1.0560 ± 0.0158       0.8936        28.0%      1.182\n",
      "Parameter Opt             1.3205 ± 0.1738       1.1668        11.1%     14.080\n",
      "Baseline SRK/T2           1.4814 ± 0.1503          N/A         0.0%        N/A\n",
      "Additive (quadratic)      1.5038 ± 0.1776       1.2682        -1.4%      1.191\n",
      "\n",
      "================================================================================\n",
      "🏆 WINNER ANALYSIS\n",
      "================================================================================\n",
      "BEST METHOD: Full Combined (quadratic)\n",
      "  • Test MAE: 0.9491 ± 0.1089 D\n",
      "  • Improvement over baseline: 35.8%\n",
      "\n",
      "✅ The full combined approach performs best, validating that:\n",
      "   1. Parameter optimization corrects fundamental optical assumptions\n",
      "   2. Multiplicative correction scales for proportional errors\n",
      "   3. Additive correction handles residual systematic bias\n",
      "   4. Quadratic polynomial captures non-linear CCT effects\n",
      "\n",
      "📈 STATISTICAL ANALYSIS:\n",
      "--------------------------------------------------------------------------------\n",
      "Advantage over 2nd best (Multiplicative): 0.0617 D\n",
      "  ✓ Clinically significant difference (>0.05 D)\n",
      "\n",
      "🔍 OVERFITTING ANALYSIS:\n",
      "--------------------------------------------------------------------------------\n",
      "Methods with potential overfitting (ratio > 1.2):\n",
      "  • Multiplicative: 12.099\n",
      "  • Parameter Opt: 14.080\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CLINICAL RECOMMENDATIONS\n",
      "================================================================================\n",
      "⚠ MODERATE PERFORMANCE\n",
      "   The Full Combined (quadratic) method achieves 0.949 D MAE\n",
      "   This may require additional optimization\n",
      "   Recommendation: Explore additional features or methods\n",
      "\n",
      "💾 Exporting results to CSV...\n",
      "   Results saved to: iol_formula_comparison.csv\n",
      "\n",
      "================================================================================\n",
      "FINAL FORMULA\n",
      "================================================================================\n",
      "Recommended formula: Full Combined (quadratic)\n",
      "\n",
      "Average parameters across seeds:\n",
      "\n",
      "1. Modified SRK/T2 parameters:\n",
      "   nc = 1.4129 + -0.0479 × CCT_norm\n",
      "   k_index = 1.3956 + -0.0450 × CCT_norm\n",
      "   ACD_offset = 2.7723 + -0.1545 × CCT_norm\n",
      "\n",
      "2. Multiplicative correction:\n",
      "   factor = 1 + -0.0549 + 0.0106 × CCT_norm + -0.0375 × CCT_ratio\n",
      "\n",
      "3. Additive correction (quadratic):\n",
      "   correction = -0.0162 + -0.2049 × CCT_norm + 0.1137 × CCT_ratio\n",
      "              + -0.0674 × K_avg + -0.0054 × CCT_norm²\n",
      "\n",
      "Where:\n",
      "   CCT_norm = (CCT - 600) / 100\n",
      "   CCT_ratio = CCT / AL\n",
      "   K_avg = (K_steep + K_flat) / 2\n"
     ]
    }
   ],
   "source": [
    "# MULTI-SEED COMPARISON - FINAL COMPREHENSIVE SUMMARY\n",
    "# ====================================================\n",
    "# PURPOSE: Compare ALL methods across multiple seeds for robust conclusions\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MULTI-SEED ANALYSIS - COMPREHENSIVE COMPARISON OF ALL METHODS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Compile all results into a comparison table\n",
    "all_methods = {}\n",
    "\n",
    "# 1. Baseline (no optimization)\n",
    "if 'seed_baseline_maes_param' in locals():\n",
    "    all_methods['Baseline SRK/T2'] = {\n",
    "        'test_mae': np.mean(seed_baseline_maes_param),\n",
    "        'test_std': np.std(seed_baseline_maes_param),\n",
    "        'train_mae': np.nan,  # Baseline doesn't have training\n",
    "        'improvement': 0.0,\n",
    "        'overfit_ratio': np.nan\n",
    "    }\n",
    "\n",
    "# 2. Parameter Optimization\n",
    "if 'seed_test_maes_param' in locals():\n",
    "    all_methods['Parameter Opt'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_param),\n",
    "        'test_std': np.std(seed_test_maes_param),\n",
    "        'train_mae': np.mean(seed_train_maes_param),\n",
    "        'improvement': np.mean(seed_improvements_param),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_param)\n",
    "    }\n",
    "\n",
    "# 3. Multiplicative Correction\n",
    "if 'seed_test_maes_mult' in locals():\n",
    "    all_methods['Multiplicative'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_mult),\n",
    "        'test_std': np.std(seed_test_maes_mult),\n",
    "        'train_mae': np.mean(seed_train_maes_mult),\n",
    "        'improvement': np.mean(seed_improvements_mult),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_mult)\n",
    "    }\n",
    "\n",
    "# 4. Additive Correction (with best polynomial)\n",
    "if 'seed_test_maes_additive' in locals():\n",
    "    method_name = f'Additive ({best_degree})' if 'best_degree' in locals() else 'Additive'\n",
    "    all_methods[method_name] = {\n",
    "        'test_mae': np.mean(seed_test_maes_additive),\n",
    "        'test_std': np.std(seed_test_maes_additive),\n",
    "        'train_mae': np.mean(seed_train_maes_additive),\n",
    "        'improvement': np.mean(seed_improvements_additive),\n",
    "        'overfit_ratio': np.mean([t/r for t,r in zip(seed_test_maes_additive, seed_train_maes_additive)])\n",
    "    }\n",
    "\n",
    "# 5. Param + Multiplicative Combined (no additive)\n",
    "if 'seed_test_maes_param_mult' in locals():\n",
    "    all_methods['Param+Mult'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_param_mult),\n",
    "        'test_std': np.std(seed_test_maes_param_mult),\n",
    "        'train_mae': np.mean(seed_train_maes_param_mult),\n",
    "        'improvement': np.mean(seed_improvements_param_mult),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_param_mult)\n",
    "    }\n",
    "\n",
    "# 6. Full Combined (all three methods)\n",
    "if 'seed_test_maes_combined' in locals():\n",
    "    poly_label = f' ({best_degree})' if 'best_degree' in locals() else ''\n",
    "    all_methods[f'Full Combined{poly_label}'] = {\n",
    "        'test_mae': np.mean(seed_test_maes_combined),\n",
    "        'test_std': np.std(seed_test_maes_combined),\n",
    "        'train_mae': np.mean(seed_train_maes_combined),\n",
    "        'improvement': np.mean(seed_improvements_combined),\n",
    "        'overfit_ratio': np.mean(seed_overfit_ratios_combined)\n",
    "    }\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(all_methods).T\n",
    "comparison_df = comparison_df.sort_values('test_mae')\n",
    "\n",
    "print(\"\\n📊 PERFORMANCE RANKING (Best to Worst):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Method':<25} {'Test MAE':>12} {'Train MAE':>12} {'Improvement':>12} {'Overfit':>10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for method in comparison_df.index:\n",
    "    row = comparison_df.loc[method]\n",
    "    test_str = f\"{row['test_mae']:.4f} ± {row['test_std']:.4f}\"\n",
    "    train_str = f\"{row['train_mae']:.4f}\" if not pd.isna(row['train_mae']) else \"N/A\"\n",
    "    improv_str = f\"{row['improvement']:.1f}%\" if not pd.isna(row['improvement']) else \"N/A\"\n",
    "    overfit_str = f\"{row['overfit_ratio']:.3f}\" if not pd.isna(row['overfit_ratio']) else \"N/A\"\n",
    "    \n",
    "    print(f\"{method:<25} {test_str:>12} {train_str:>12} {improv_str:>12} {overfit_str:>10}\")\n",
    "\n",
    "# Identify best method\n",
    "best_method = comparison_df.index[0]\n",
    "best_mae = comparison_df.loc[best_method, 'test_mae']\n",
    "best_std = comparison_df.loc[best_method, 'test_std']\n",
    "best_improvement = comparison_df.loc[best_method, 'improvement']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🏆 WINNER ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"BEST METHOD: {best_method}\")\n",
    "print(f\"  • Test MAE: {best_mae:.4f} ± {best_std:.4f} D\")\n",
    "print(f\"  • Improvement over baseline: {best_improvement:.1f}%\")\n",
    "\n",
    "# Additional insights\n",
    "if 'Full Combined' in best_method:\n",
    "    print(\"\\n✅ The full combined approach performs best, validating that:\")\n",
    "    print(\"   1. Parameter optimization corrects fundamental optical assumptions\")\n",
    "    print(\"   2. Multiplicative correction scales for proportional errors\")\n",
    "    print(\"   3. Additive correction handles residual systematic bias\")\n",
    "    if 'best_degree' in locals() and best_degree != 'linear':\n",
    "        print(f\"   4. {best_degree.capitalize()} polynomial captures non-linear CCT effects\")\n",
    "elif 'Param+Mult' in best_method:\n",
    "    print(\"\\n✅ Param+Mult performs best, suggesting:\")\n",
    "    print(\"   • Additive correction may not be necessary\")\n",
    "    print(\"   • The combination of parameter and multiplicative is sufficient\")\n",
    "\n",
    "# Statistical significance analysis\n",
    "print(\"\\n📈 STATISTICAL ANALYSIS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Compare top methods\n",
    "if len(comparison_df) >= 2:\n",
    "    second_best = comparison_df.index[1]\n",
    "    mae_diff = comparison_df.loc[second_best, 'test_mae'] - best_mae\n",
    "    \n",
    "    print(f\"Advantage over 2nd best ({second_best}): {mae_diff:.4f} D\")\n",
    "    \n",
    "    # Check if difference is clinically significant (>0.05 D)\n",
    "    if mae_diff > 0.05:\n",
    "        print(\"  ✓ Clinically significant difference (>0.05 D)\")\n",
    "    else:\n",
    "        print(\"  ⚠ Marginal clinical difference (<0.05 D)\")\n",
    "\n",
    "# Overfitting analysis\n",
    "print(\"\\n🔍 OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 80)\n",
    "overfit_methods = comparison_df[comparison_df['overfit_ratio'] > 1.2]\n",
    "if not overfit_methods.empty:\n",
    "    print(\"Methods with potential overfitting (ratio > 1.2):\")\n",
    "    for method in overfit_methods.index:\n",
    "        ratio = overfit_methods.loc[method, 'overfit_ratio']\n",
    "        print(f\"  • {method}: {ratio:.3f}\")\n",
    "else:\n",
    "    print(\"✓ No significant overfitting detected in any method\")\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: MAE Comparison\n",
    "ax1 = axes[0]\n",
    "methods = list(comparison_df.index)\n",
    "maes = comparison_df['test_mae'].values\n",
    "stds = comparison_df['test_std'].values\n",
    "colors = ['red' if 'Baseline' in m else 'green' if m == best_method else 'blue' for m in methods]\n",
    "\n",
    "ax1.barh(range(len(methods)), maes, xerr=stds, color=colors, alpha=0.7)\n",
    "ax1.set_yticks(range(len(methods)))\n",
    "ax1.set_yticklabels(methods)\n",
    "ax1.set_xlabel('Test MAE (D)')\n",
    "ax1.set_title('Mean Absolute Error Comparison')\n",
    "ax1.axvline(x=0.5, color='green', linestyle='--', alpha=0.5, label='Clinical target')\n",
    "ax1.axvline(x=0.75, color='orange', linestyle='--', alpha=0.5)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Improvement over Baseline\n",
    "ax2 = axes[1]\n",
    "improvements = comparison_df['improvement'].values\n",
    "ax2.barh(range(len(methods)), improvements, color=colors, alpha=0.7)\n",
    "ax2.set_yticks(range(len(methods)))\n",
    "ax2.set_yticklabels(methods)\n",
    "ax2.set_xlabel('Improvement (%)')\n",
    "ax2.set_title('Improvement over Baseline SRK/T2')\n",
    "\n",
    "# Plot 3: Train vs Test MAE (Overfitting check)\n",
    "ax3 = axes[2]\n",
    "train_maes = comparison_df['train_mae'].values\n",
    "test_maes = comparison_df['test_mae'].values\n",
    "valid_idx = ~pd.isna(train_maes)\n",
    "ax3.scatter(train_maes[valid_idx], test_maes[valid_idx], s=100, alpha=0.7)\n",
    "for i, method in enumerate(methods):\n",
    "    if valid_idx[i]:\n",
    "        ax3.annotate(method, (train_maes[i], test_maes[i]), fontsize=8, ha='right')\n",
    "\n",
    "# Add diagonal line (perfect generalization)\n",
    "min_val = min(np.nanmin(train_maes), np.nanmin(test_maes))\n",
    "max_val = max(np.nanmax(train_maes), np.nanmax(test_maes))\n",
    "ax3.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Perfect generalization')\n",
    "ax3.set_xlabel('Train MAE (D)')\n",
    "ax3.set_ylabel('Test MAE (D)')\n",
    "ax3.set_title('Overfitting Analysis')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLINICAL RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if best_mae < 0.5:\n",
    "    print(\"✅ EXCELLENT PERFORMANCE\")\n",
    "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
    "    print(\"   This is within the ±0.50 D target for premium IOL surgery\")\n",
    "    print(\"   Recommendation: Ready for clinical validation study\")\n",
    "elif best_mae < 0.75:\n",
    "    print(\"✅ GOOD PERFORMANCE\")\n",
    "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
    "    print(\"   This is within the ±0.75 D acceptable range\")\n",
    "    print(\"   Recommendation: Consider further optimization for premium cases\")\n",
    "else:\n",
    "    print(\"⚠ MODERATE PERFORMANCE\")\n",
    "    print(f\"   The {best_method} method achieves {best_mae:.3f} D MAE\")\n",
    "    print(\"   This may require additional optimization\")\n",
    "    print(\"   Recommendation: Explore additional features or methods\")\n",
    "\n",
    "# Export results\n",
    "print(\"\\n💾 Exporting results to CSV...\")\n",
    "comparison_df.to_csv('iol_formula_comparison.csv')\n",
    "print(\"   Results saved to: iol_formula_comparison.csv\")\n",
    "\n",
    "# Final formula recommendation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL FORMULA\")\n",
    "print(\"=\"*80)\n",
    "if 'Full Combined' in best_method and 'seed_param_results' in locals():\n",
    "    print(f\"Recommended formula: {best_method}\")\n",
    "    print(\"\\nAverage parameters across seeds:\")\n",
    "    \n",
    "    # Parameter values\n",
    "    param_array = np.array(seed_param_results)\n",
    "    print(\"\\n1. Modified SRK/T2 parameters:\")\n",
    "    print(f\"   nc = {np.mean(param_array[:, 0]):.4f} + {np.mean(param_array[:, 1]):.4f} × CCT_norm\")\n",
    "    print(f\"   k_index = {np.mean(param_array[:, 2]):.4f} + {np.mean(param_array[:, 3]):.4f} × CCT_norm\")\n",
    "    print(f\"   ACD_offset = {np.mean(param_array[:, 4]):.4f} + {np.mean(param_array[:, 5]):.4f} × CCT_norm\")\n",
    "    \n",
    "    # Multiplicative values\n",
    "    if 'seed_mult_results' in locals():\n",
    "        mult_array = np.array(seed_mult_results)\n",
    "        print(\"\\n2. Multiplicative correction:\")\n",
    "        print(f\"   factor = 1 + {np.mean(mult_array[:, 0]):.4f} + {np.mean(mult_array[:, 1]):.4f} × CCT_norm + {np.mean(mult_array[:, 2]):.4f} × CCT_ratio\")\n",
    "    \n",
    "    # Additive values\n",
    "    if 'seed_add_results' in locals():\n",
    "        add_array = np.array(seed_add_results)\n",
    "        print(f\"\\n3. Additive correction ({best_degree if 'best_degree' in locals() else 'linear'}):\")\n",
    "        if best_degree == 'linear' or 'best_degree' not in locals():\n",
    "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} × CCT_norm + {np.mean(add_array[:, 2]):.4f} × CCT_ratio + {np.mean(add_array[:, 3]):.4f} × K_avg\")\n",
    "        elif best_degree == 'quadratic':\n",
    "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} × CCT_norm + {np.mean(add_array[:, 2]):.4f} × CCT_ratio\")\n",
    "            print(f\"              + {np.mean(add_array[:, 3]):.4f} × K_avg + {np.mean(add_array[:, 4]):.4f} × CCT_norm²\")\n",
    "        else:  # cubic\n",
    "            print(f\"   correction = {np.mean(add_array[:, 0]):.4f} + {np.mean(add_array[:, 1]):.4f} × CCT_norm + {np.mean(add_array[:, 2]):.4f} × CCT_ratio\")\n",
    "            print(f\"              + {np.mean(add_array[:, 3]):.4f} × K_avg + {np.mean(add_array[:, 4]):.4f} × CCT_norm² + {np.mean(add_array[:, 5]):.4f} × CCT_norm³\")\n",
    "    \n",
    "    print(\"\\nWhere:\")\n",
    "    print(\"   CCT_norm = (CCT - 600) / 100\")\n",
    "    print(\"   CCT_ratio = CCT / AL\")\n",
    "    print(\"   K_avg = (K_steep + K_flat) / 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
